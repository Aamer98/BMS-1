Fri Sep 24 06:30:26 2021       
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 470.57.02    Driver Version: 470.57.02    CUDA Version: 11.4     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|                               |                      |               MIG M. |
|===============================+======================+======================|
|   0  Tesla V100-SXM2...  Off  | 00000000:1A:00.0 Off |                    0 |
| N/A   34C    P0    38W / 300W |      0MiB / 16160MiB |      0%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
|   1  Tesla V100-SXM2...  Off  | 00000000:1C:00.0 Off |                    0 |
| N/A   31C    P0    39W / 300W |      0MiB / 16160MiB |      0%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
|   2  Tesla V100-SXM2...  Off  | 00000000:1D:00.0 Off |                    0 |
| N/A   31C    P0    40W / 300W |      0MiB / 16160MiB |      0%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
|   3  Tesla V100-SXM2...  Off  | 00000000:1E:00.0 Off |                    0 |
| N/A   35C    P0    38W / 300W |      0MiB / 16160MiB |      0%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                                  |
|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |
|        ID   ID                                                   Usage      |
|=============================================================================|
|  No running processes found                                                 |
+-----------------------------------------------------------------------------+
------------------------------------< Data preparation>----------------------------------
Copying the source code
06:30:26
Copying the datasets
06:34:01
creating data directories
06:35:43
----------------------------------< End of data preparation>--------------------------------
06:36:00
--------------------------------------------------------------------------------------------
---------------------------------------<Run the program>------------------------------------
06:36:00
Size of base validation set 1920
Training Epoch: [0/1] Step: [10 / 285] Batch Time: 0.1451 (0.2584) Data Time: 0.0126 (0.1172) Average Loss: 4.5552 (5.4276) Average CE Loss (Source):  4.5552 ( 5.4276) Learning Rate: 0.1000 (0.1000) Top1_base: 1.5625 (2.8906) Top1_base_per_class: 1.5152 (2.7388) 
Training Epoch: [0/1] Step: [20 / 285] Batch Time: 0.1455 (0.2151) Data Time: 0.0140 (0.0786) Average Loss: 4.3538 (4.8704) Average CE Loss (Source):  4.3538 ( 4.8704) Learning Rate: 0.1000 (0.1000) Top1_base: 4.6875 (3.5938) Top1_base_per_class: 3.1447 (3.3602) 
Training Epoch: [0/1] Step: [30 / 285] Batch Time: 0.1410 (0.2024) Data Time: 0.0089 (0.0674) Average Loss: 4.2154 (4.6642) Average CE Loss (Source):  4.2154 ( 4.6642) Learning Rate: 0.1000 (0.1000) Top1_base: 5.4688 (3.8021) Top1_base_per_class: 7.9532 (3.6184) 
Training Epoch: [0/1] Step: [40 / 285] Batch Time: 0.1472 (0.1889) Data Time: 0.0154 (0.0546) Average Loss: 4.1756 (4.5219) Average CE Loss (Source):  4.1756 ( 4.5219) Learning Rate: 0.1000 (0.1000) Top1_base: 4.6875 (4.2969) Top1_base_per_class: 4.9383 (4.2839) 
Training Epoch: [0/1] Step: [50 / 285] Batch Time: 0.1455 (0.1828) Data Time: 0.0139 (0.0490) Average Loss: 3.7815 (4.4056) Average CE Loss (Source):  3.7815 ( 4.4056) Learning Rate: 0.1000 (0.1000) Top1_base: 7.8125 (4.8125) Top1_base_per_class: 10.0000 (4.8836) 
Training Epoch: [0/1] Step: [60 / 285] Batch Time: 0.1457 (0.1774) Data Time: 0.0134 (0.0439) Average Loss: 3.8223 (4.3181) Average CE Loss (Source):  3.8223 ( 4.3181) Learning Rate: 0.1000 (0.1000) Top1_base: 9.3750 (5.3776) Top1_base_per_class: 9.1228 (5.3830) 
Training Epoch: [0/1] Step: [70 / 285] Batch Time: 0.1456 (0.1745) Data Time: 0.0123 (0.0410) Average Loss: 3.9381 (4.2514) Average CE Loss (Source):  3.9381 ( 4.2514) Learning Rate: 0.1000 (0.1000) Top1_base: 6.2500 (5.7366) Top1_base_per_class: 6.3333 (5.7770) 
Training Epoch: [0/1] Step: [80 / 285] Batch Time: 0.1465 (0.1728) Data Time: 0.0136 (0.0395) Average Loss: 3.8164 (4.1977) Average CE Loss (Source):  3.8164 ( 4.1977) Learning Rate: 0.1000 (0.1000) Top1_base: 7.8125 (5.9082) Top1_base_per_class: 7.4113 (5.9505) 
Training Epoch: [0/1] Step: [90 / 285] Batch Time: 0.2277 (0.1723) Data Time: 0.0952 (0.0390) Average Loss: 3.8843 (4.1523) Average CE Loss (Source):  3.8843 ( 4.1523) Learning Rate: 0.1000 (0.1000) Top1_base: 6.2500 (6.3021) Top1_base_per_class: 8.0357 (6.3168) 
Training Epoch: [0/1] Step: [100 / 285] Batch Time: 0.1562 (0.1703) Data Time: 0.0240 (0.0372) Average Loss: 3.7254 (4.1114) Average CE Loss (Source):  3.7254 ( 4.1114) Learning Rate: 0.1000 (0.1000) Top1_base: 9.3750 (6.7266) Top1_base_per_class: 9.5988 (6.7497) 
Training Epoch: [0/1] Step: [110 / 285] Batch Time: 0.1793 (0.1707) Data Time: 0.0465 (0.0376) Average Loss: 3.7870 (4.0798) Average CE Loss (Source):  3.7870 ( 4.0798) Learning Rate: 0.1000 (0.1000) Top1_base: 8.5938 (6.9460) Top1_base_per_class: 7.5455 (6.9103) 
Training Epoch: [0/1] Step: [120 / 285] Batch Time: 0.1447 (0.1705) Data Time: 0.0140 (0.0376) Average Loss: 3.5628 (4.0439) Average CE Loss (Source):  3.5628 ( 4.0439) Learning Rate: 0.1000 (0.1000) Top1_base: 13.2812 (7.2461) Top1_base_per_class: 11.6369 (7.2613) 
Training Epoch: [0/1] Step: [130 / 285] Batch Time: 0.2503 (0.1698) Data Time: 0.1176 (0.0369) Average Loss: 3.6590 (4.0130) Average CE Loss (Source):  3.6590 ( 4.0130) Learning Rate: 0.1000 (0.1000) Top1_base: 7.8125 (7.5000) Top1_base_per_class: 7.6149 (7.4932) 
Training Epoch: [0/1] Step: [140 / 285] Batch Time: 0.1458 (0.1685) Data Time: 0.0124 (0.0357) Average Loss: 3.6184 (3.9908) Average CE Loss (Source):  3.6184 ( 3.9908) Learning Rate: 0.1000 (0.1000) Top1_base: 13.2812 (7.6172) Top1_base_per_class: 14.0476 (7.5865) 
Training Epoch: [0/1] Step: [150 / 285] Batch Time: 0.2225 (0.1680) Data Time: 0.0891 (0.0352) Average Loss: 3.6447 (3.9679) Average CE Loss (Source):  3.6447 ( 3.9679) Learning Rate: 0.1000 (0.1000) Top1_base: 12.5000 (7.7969) Top1_base_per_class: 11.0714 (7.7869) 
Training Epoch: [0/1] Step: [160 / 285] Batch Time: 0.1449 (0.1676) Data Time: 0.0121 (0.0349) Average Loss: 3.7087 (3.9513) Average CE Loss (Source):  3.7087 ( 3.9513) Learning Rate: 0.1000 (0.1000) Top1_base: 11.7188 (8.0225) Top1_base_per_class: 12.3810 (8.0133) 
Training Epoch: [0/1] Step: [170 / 285] Batch Time: 0.1983 (0.1679) Data Time: 0.0670 (0.0351) Average Loss: 3.5574 (3.9312) Average CE Loss (Source):  3.5574 ( 3.9312) Learning Rate: 0.1000 (0.1000) Top1_base: 10.1562 (8.2399) Top1_base_per_class: 11.8182 (8.2332) 
Training Epoch: [0/1] Step: [180 / 285] Batch Time: 0.1439 (0.1674) Data Time: 0.0125 (0.0347) Average Loss: 3.6283 (3.9135) Average CE Loss (Source):  3.6283 ( 3.9135) Learning Rate: 0.1000 (0.1000) Top1_base: 7.8125 (8.3854) Top1_base_per_class: 6.4151 (8.4070) 
Training Epoch: [0/1] Step: [190 / 285] Batch Time: 0.2831 (0.1683) Data Time: 0.1508 (0.0355) Average Loss: 3.5664 (3.8980) Average CE Loss (Source):  3.5664 ( 3.8980) Learning Rate: 0.1000 (0.1000) Top1_base: 13.2812 (8.6184) Top1_base_per_class: 15.3274 (8.6240) 
Training Epoch: [0/1] Step: [200 / 285] Batch Time: 0.1440 (0.1676) Data Time: 0.0112 (0.0349) Average Loss: 3.5945 (3.8819) Average CE Loss (Source):  3.5945 ( 3.8819) Learning Rate: 0.1000 (0.1000) Top1_base: 10.1562 (8.7852) Top1_base_per_class: 8.3333 (8.8332) 
Training Epoch: [0/1] Step: [210 / 285] Batch Time: 0.2097 (0.1676) Data Time: 0.0769 (0.0349) Average Loss: 3.5891 (3.8663) Average CE Loss (Source):  3.5891 ( 3.8663) Learning Rate: 0.1000 (0.1000) Top1_base: 9.3750 (8.9658) Top1_base_per_class: 12.7119 (9.0406) 
Training Epoch: [0/1] Step: [220 / 285] Batch Time: 0.1472 (0.1675) Data Time: 0.0140 (0.0348) Average Loss: 3.5189 (3.8500) Average CE Loss (Source):  3.5189 ( 3.8500) Learning Rate: 0.1000 (0.1000) Top1_base: 11.7188 (9.1193) Top1_base_per_class: 9.4540 (9.1582) 
Training Epoch: [0/1] Step: [230 / 285] Batch Time: 0.3890 (0.1681) Data Time: 0.2570 (0.0353) Average Loss: 3.6718 (3.8359) Average CE Loss (Source):  3.6718 ( 3.8359) Learning Rate: 0.1000 (0.1000) Top1_base: 10.9375 (9.2527) Top1_base_per_class: 14.3860 (9.3133) 
Training Epoch: [0/1] Step: [240 / 285] Batch Time: 0.1476 (0.1676) Data Time: 0.0148 (0.0348) Average Loss: 3.6075 (3.8242) Average CE Loss (Source):  3.6075 ( 3.8242) Learning Rate: 0.1000 (0.1000) Top1_base: 10.9375 (9.4043) Top1_base_per_class: 12.0468 (9.4896) 
Training Epoch: [0/1] Step: [250 / 285] Batch Time: 0.2227 (0.1673) Data Time: 0.0902 (0.0345) Average Loss: 3.6079 (3.8168) Average CE Loss (Source):  3.6079 ( 3.8168) Learning Rate: 0.1000 (0.1000) Top1_base: 14.8438 (9.5031) Top1_base_per_class: 15.6410 (9.6122) 
Training Epoch: [0/1] Step: [260 / 285] Batch Time: 0.1474 (0.1672) Data Time: 0.0145 (0.0344) Average Loss: 3.5403 (3.8043) Average CE Loss (Source):  3.5403 ( 3.8043) Learning Rate: 0.1000 (0.1000) Top1_base: 10.1562 (9.6484) Top1_base_per_class: 11.5741 (9.7543) 
Training Epoch: [0/1] Step: [270 / 285] Batch Time: 0.1826 (0.1669) Data Time: 0.0512 (0.0341) Average Loss: 3.4827 (3.7910) Average CE Loss (Source):  3.4827 ( 3.7910) Learning Rate: 0.1000 (0.1000) Top1_base: 9.3750 (9.7656) Top1_base_per_class: 10.1818 (9.8764) 
Training Epoch: [0/1] Step: [280 / 285] Batch Time: 0.1439 (0.1663) Data Time: 0.0127 (0.0335) Average Loss: 3.6139 (3.7797) Average CE Loss (Source):  3.6139 ( 3.7797) Learning Rate: 0.1000 (0.1000) Top1_base: 10.9375 (9.8689) Top1_base_per_class: 9.2857 (10.0061) 
Training Epoch: [1/1] Step: [0] Batch Time: 0.1399 (0.1659) Data Time: 0.0096 (0.0331) Average Loss: 3.4618 (3.7741) Average CE Loss (Source):  3.4618 ( 3.7741) Learning Rate: 0.1000 (0.1000) Top1_base: 13.2812 (9.9616) Top1_base_per_class: 10.4386 (10.0834) 
  0%|          | 0/1000 [00:00<?, ?it/s]Training Epoch: [0/1000] Step: [10 / 285] Batch Time: 0.1440 (0.2308) Data Time: 0.0127 (0.0995) Average Loss: 4.3201 (5.3778) Average CE Loss (Source):  4.3201 ( 5.3778) Learning Rate: 0.1000 (0.1000) Top1_base: 1.5625 (2.1094) Top1_base_per_class: 1.0606 (2.2911) 
Training Epoch: [0/1000] Step: [20 / 285] Batch Time: 0.1437 (0.1973) Data Time: 0.0118 (0.0654) Average Loss: 4.1418 (4.8050) Average CE Loss (Source):  4.1418 ( 4.8050) Learning Rate: 0.1000 (0.1000) Top1_base: 3.9062 (3.4375) Top1_base_per_class: 2.3392 (3.4429) 
Training Epoch: [0/1000] Step: [30 / 285] Batch Time: 0.1632 (0.1830) Data Time: 0.0313 (0.0508) Average Loss: 4.2135 (4.6242) Average CE Loss (Source):  4.2135 ( 4.6242) Learning Rate: 0.1000 (0.1000) Top1_base: 3.1250 (4.1406) Top1_base_per_class: 3.8580 (4.1644) 
Training Epoch: [0/1000] Step: [40 / 285] Batch Time: 0.1470 (0.1753) Data Time: 0.0133 (0.0431) Average Loss: 3.9049 (4.4806) Average CE Loss (Source):  3.9049 ( 4.4806) Learning Rate: 0.1000 (0.1000) Top1_base: 7.0312 (4.6289) Top1_base_per_class: 8.0357 (4.5961) 
Training Epoch: [0/1000] Step: [50 / 285] Batch Time: 0.1721 (0.1728) Data Time: 0.0401 (0.0406) Average Loss: 3.7446 (4.3646) Average CE Loss (Source):  3.7446 ( 4.3646) Learning Rate: 0.1000 (0.1000) Top1_base: 11.7188 (5.0625) Top1_base_per_class: 10.1543 (4.9196) 
Training Epoch: [0/1000] Step: [60 / 285] Batch Time: 0.2107 (0.1696) Data Time: 0.0794 (0.0374) Average Loss: 3.7524 (4.2774) Average CE Loss (Source):  3.7524 ( 4.2774) Learning Rate: 0.1000 (0.1000) Top1_base: 7.8125 (5.4427) Top1_base_per_class: 8.7719 (5.2722) 
Training Epoch: [0/1000] Step: [70 / 285] Batch Time: 0.1440 (0.1708) Data Time: 0.0128 (0.0385) Average Loss: 3.6895 (4.2170) Average CE Loss (Source):  3.6895 ( 4.2170) Learning Rate: 0.1000 (0.1000) Top1_base: 7.8125 (5.8929) Top1_base_per_class: 8.7719 (5.7471) 
Training Epoch: [0/1000] Step: [80 / 285] Batch Time: 0.3085 (0.1724) Data Time: 0.1762 (0.0401) Average Loss: 3.7210 (4.1621) Average CE Loss (Source):  3.7210 ( 4.1621) Learning Rate: 0.1000 (0.1000) Top1_base: 10.1562 (6.2598) Top1_base_per_class: 8.2390 (6.1189) 
Training Epoch: [0/1000] Step: [90 / 285] Batch Time: 0.1457 (0.1716) Data Time: 0.0115 (0.0393) Average Loss: 3.5549 (4.1158) Average CE Loss (Source):  3.5549 ( 4.1158) Learning Rate: 0.1000 (0.1000) Top1_base: 14.8438 (6.5972) Top1_base_per_class: 10.3720 (6.3896) 
Training Epoch: [0/1000] Step: [100 / 285] Batch Time: 0.2560 (0.1716) Data Time: 0.1240 (0.0392) Average Loss: 3.6867 (4.0777) Average CE Loss (Source):  3.6867 ( 4.0777) Learning Rate: 0.1000 (0.1000) Top1_base: 13.2812 (6.8672) Top1_base_per_class: 16.9697 (6.7707) 
Training Epoch: [0/1000] Step: [110 / 285] Batch Time: 0.1443 (0.1709) Data Time: 0.0112 (0.0385) Average Loss: 3.7842 (4.0422) Average CE Loss (Source):  3.7842 ( 4.0422) Learning Rate: 0.1000 (0.1000) Top1_base: 9.3750 (7.2301) Top1_base_per_class: 8.6310 (7.2147) 
Training Epoch: [0/1000] Step: [120 / 285] Batch Time: 0.1479 (0.1695) Data Time: 0.0165 (0.0371) Average Loss: 3.7761 (4.0136) Average CE Loss (Source):  3.7761 ( 4.0136) Learning Rate: 0.1000 (0.1000) Top1_base: 13.2812 (7.5521) Top1_base_per_class: 12.1345 (7.5957) 
Training Epoch: [0/1000] Step: [130 / 285] Batch Time: 0.1466 (0.1683) Data Time: 0.0124 (0.0358) Average Loss: 3.6358 (3.9887) Average CE Loss (Source):  3.6358 ( 3.9887) Learning Rate: 0.1000 (0.1000) Top1_base: 12.5000 (7.7103) Top1_base_per_class: 11.5517 (7.8201) 
Training Epoch: [0/1000] Step: [140 / 285] Batch Time: 0.2098 (0.1679) Data Time: 0.0754 (0.0353) Average Loss: 3.6918 (3.9648) Average CE Loss (Source):  3.6918 ( 3.9648) Learning Rate: 0.1000 (0.1000) Top1_base: 11.7188 (8.0525) Top1_base_per_class: 11.7529 (8.1515) 
Training Epoch: [0/1000] Step: [150 / 285] Batch Time: 0.1442 (0.1679) Data Time: 0.0113 (0.0353) Average Loss: 3.5552 (3.9417) Average CE Loss (Source):  3.5552 ( 3.9417) Learning Rate: 0.1000 (0.1000) Top1_base: 10.1562 (8.2865) Top1_base_per_class: 11.7475 (8.4164) 
Training Epoch: [0/1000] Step: [160 / 285] Batch Time: 0.1975 (0.1673) Data Time: 0.0653 (0.0347) Average Loss: 3.7011 (3.9249) Average CE Loss (Source):  3.7011 ( 3.9249) Learning Rate: 0.1000 (0.1000) Top1_base: 11.7188 (8.4668) Top1_base_per_class: 13.2390 (8.6054) 
Training Epoch: [0/1000] Step: [170 / 285] Batch Time: 0.1454 (0.1667) Data Time: 0.0135 (0.0342) Average Loss: 4.0277 (3.9105) Average CE Loss (Source):  4.0277 ( 3.9105) Learning Rate: 0.1000 (0.1000) Top1_base: 10.9375 (8.6259) Top1_base_per_class: 12.2531 (8.7180) 
Training Epoch: [0/1000] Step: [180 / 285] Batch Time: 0.1717 (0.1661) Data Time: 0.0386 (0.0336) Average Loss: 3.6839 (3.8941) Average CE Loss (Source):  3.6839 ( 3.8941) Learning Rate: 0.1000 (0.1000) Top1_base: 11.7188 (8.8108) Top1_base_per_class: 10.6111 (8.8261) 
Training Epoch: [0/1000] Step: [190 / 285] Batch Time: 0.1424 (0.1653) Data Time: 0.0095 (0.0328) Average Loss: 3.6108 (3.8783) Average CE Loss (Source):  3.6108 ( 3.8783) Learning Rate: 0.1000 (0.1000) Top1_base: 15.6250 (9.0543) Top1_base_per_class: 13.8136 (9.0609) 
Training Epoch: [0/1000] Step: [200 / 285] Batch Time: 0.2420 (0.1656) Data Time: 0.1102 (0.0331) Average Loss: 3.6284 (3.8619) Average CE Loss (Source):  3.6284 ( 3.8619) Learning Rate: 0.1000 (0.1000) Top1_base: 10.9375 (9.1992) Top1_base_per_class: 11.6667 (9.2207) 
Training Epoch: [0/1000] Step: [210 / 285] Batch Time: 0.1438 (0.1648) Data Time: 0.0115 (0.0323) Average Loss: 3.4630 (3.8451) Average CE Loss (Source):  3.4630 ( 3.8451) Learning Rate: 0.1000 (0.1000) Top1_base: 20.3125 (9.4680) Top1_base_per_class: 18.3939 (9.4926) 
Training Epoch: [0/1000] Step: [220 / 285] Batch Time: 0.1653 (0.1640) Data Time: 0.0328 (0.0315) Average Loss: 3.3923 (3.8320) Average CE Loss (Source):  3.3923 ( 3.8320) Learning Rate: 0.1000 (0.1000) Top1_base: 15.6250 (9.5952) Top1_base_per_class: 14.3155 (9.6270) 
Training Epoch: [0/1000] Step: [230 / 285] Batch Time: 0.1445 (0.1634) Data Time: 0.0115 (0.0309) Average Loss: 3.4845 (3.8198) Average CE Loss (Source):  3.4845 ( 3.8198) Learning Rate: 0.1000 (0.1000) Top1_base: 14.0625 (9.7147) Top1_base_per_class: 11.4943 (9.7480) 
Training Epoch: [0/1000] Step: [240 / 285] Batch Time: 0.2036 (0.1632) Data Time: 0.0716 (0.0307) Average Loss: 3.5136 (3.8089) Average CE Loss (Source):  3.5136 ( 3.8089) Learning Rate: 0.1000 (0.1000) Top1_base: 16.4062 (9.8503) Top1_base_per_class: 16.5801 (9.9071) 
Training Epoch: [0/1000] Step: [250 / 285] Batch Time: 0.1456 (0.1627) Data Time: 0.0131 (0.0301) Average Loss: 3.5905 (3.7956) Average CE Loss (Source):  3.5905 ( 3.7956) Learning Rate: 0.1000 (0.1000) Top1_base: 15.6250 (10.0375) Top1_base_per_class: 13.4545 (10.0996) 
Training Epoch: [0/1000] Step: [260 / 285] Batch Time: 0.2039 (0.1629) Data Time: 0.0716 (0.0304) Average Loss: 3.6147 (3.7859) Average CE Loss (Source):  3.6147 ( 3.7859) Learning Rate: 0.1000 (0.1000) Top1_base: 14.0625 (10.1562) Top1_base_per_class: 15.4545 (10.2499) 
Training Epoch: [0/1000] Step: [270 / 285] Batch Time: 0.1440 (0.1630) Data Time: 0.0125 (0.0304) Average Loss: 3.5727 (3.7746) Average CE Loss (Source):  3.5727 ( 3.7746) Learning Rate: 0.1000 (0.1000) Top1_base: 16.4062 (10.3212) Top1_base_per_class: 17.3765 (10.4084) 
Training Epoch: [0/1000] Step: [280 / 285] Batch Time: 0.1442 (0.1632) Data Time: 0.0121 (0.0306) Average Loss: 3.5486 (3.7631) Average CE Loss (Source):  3.5486 ( 3.7631) Learning Rate: 0.1000 (0.1000) Top1_base: 10.9375 (10.4715) Top1_base_per_class: 13.1173 (10.5557) 
Training Epoch: [1/1000] Step: [0] Batch Time: 0.1411 (0.1631) Data Time: 0.0116 (0.0305) Average Loss: 3.4769 (3.7565) Average CE Loss (Source):  3.4769 ( 3.7565) Learning Rate: 0.1000 (0.1000) Top1_base: 15.6250 (10.5674) Top1_base_per_class: 19.4004 (10.6739) 
  0%|          | 1/1000 [00:49<13:42:32, 49.40s/it]Training Epoch: [1/1000] Step: [10 / 285] Batch Time: 0.1439 (0.2271) Data Time: 0.0128 (0.0957) Average Loss: 3.5383 (3.4708) Average CE Loss (Source):  3.5383 ( 3.4708) Learning Rate: 0.1000 (0.1000) Top1_base: 13.2812 (15.0000) Top1_base_per_class: 14.8148 (15.3311) 
Training Epoch: [1/1000] Step: [20 / 285] Batch Time: 0.1445 (0.1920) Data Time: 0.0115 (0.0602) Average Loss: 3.4077 (3.4379) Average CE Loss (Source):  3.4077 ( 3.4379) Learning Rate: 0.1000 (0.1000) Top1_base: 13.2812 (15.8203) Top1_base_per_class: 12.9167 (15.3715) 
Training Epoch: [1/1000] Step: [30 / 285] Batch Time: 0.1472 (0.1820) Data Time: 0.0152 (0.0500) Average Loss: 3.4852 (3.4167) Average CE Loss (Source):  3.4852 ( 3.4167) Learning Rate: 0.1000 (0.1000) Top1_base: 12.5000 (15.9115) Top1_base_per_class: 12.4691 (15.9611) 
Training Epoch: [1/1000] Step: [40 / 285] Batch Time: 0.1439 (0.1780) Data Time: 0.0105 (0.0459) Average Loss: 3.5301 (3.4093) Average CE Loss (Source):  3.5301 ( 3.4093) Learning Rate: 0.1000 (0.1000) Top1_base: 14.8438 (15.9961) Top1_base_per_class: 17.9598 (16.2310) 
Training Epoch: [1/1000] Step: [50 / 285] Batch Time: 0.2519 (0.1747) Data Time: 0.1199 (0.0426) Average Loss: 3.0422 (3.3891) Average CE Loss (Source):  3.0422 ( 3.3891) Learning Rate: 0.1000 (0.1000) Top1_base: 20.3125 (16.6250) Top1_base_per_class: 23.0303 (16.7596) 
Training Epoch: [1/1000] Step: [60 / 285] Batch Time: 0.1439 (0.1730) Data Time: 0.0113 (0.0406) Average Loss: 3.4364 (3.3733) Average CE Loss (Source):  3.4364 ( 3.3733) Learning Rate: 0.1000 (0.1000) Top1_base: 7.8125 (16.4453) Top1_base_per_class: 9.1808 (16.4955) 
Training Epoch: [1/1000] Step: [70 / 285] Batch Time: 0.2507 (0.1726) Data Time: 0.1195 (0.0401) Average Loss: 3.4162 (3.3695) Average CE Loss (Source):  3.4162 ( 3.3695) Learning Rate: 0.1000 (0.1000) Top1_base: 14.8438 (16.4844) Top1_base_per_class: 15.0606 (16.5444) 
Training Epoch: [1/1000] Step: [80 / 285] Batch Time: 0.1440 (0.1719) Data Time: 0.0127 (0.0393) Average Loss: 3.3544 (3.3673) Average CE Loss (Source):  3.3544 ( 3.3673) Learning Rate: 0.1000 (0.1000) Top1_base: 14.0625 (16.3672) Top1_base_per_class: 17.1855 (16.5475) 
Training Epoch: [1/1000] Step: [90 / 285] Batch Time: 0.2991 (0.1720) Data Time: 0.1677 (0.0394) Average Loss: 3.2892 (3.3682) Average CE Loss (Source):  3.2892 ( 3.3682) Learning Rate: 0.1000 (0.1000) Top1_base: 25.0000 (16.3715) Top1_base_per_class: 24.1375 (16.5497) 
Training Epoch: [1/1000] Step: [100 / 285] Batch Time: 0.1447 (0.1706) Data Time: 0.0126 (0.0379) Average Loss: 3.2127 (3.3614) Average CE Loss (Source):  3.2127 ( 3.3614) Learning Rate: 0.1000 (0.1000) Top1_base: 19.5312 (16.6172) Top1_base_per_class: 23.0247 (16.8085) 
Training Epoch: [1/1000] Step: [110 / 285] Batch Time: 0.3116 (0.1714) Data Time: 0.1795 (0.0387) Average Loss: 3.3196 (3.3499) Average CE Loss (Source):  3.3196 ( 3.3499) Learning Rate: 0.1000 (0.1000) Top1_base: 14.8438 (16.8040) Top1_base_per_class: 15.2632 (17.0308) 
Training Epoch: [1/1000] Step: [120 / 285] Batch Time: 0.1490 (0.1714) Data Time: 0.0143 (0.0386) Average Loss: 3.4224 (3.3412) Average CE Loss (Source):  3.4224 ( 3.3412) Learning Rate: 0.1000 (0.1000) Top1_base: 18.7500 (17.0573) Top1_base_per_class: 18.3025 (17.2506) 
Training Epoch: [1/1000] Step: [130 / 285] Batch Time: 0.2531 (0.1735) Data Time: 0.1202 (0.0407) Average Loss: 3.4131 (3.3286) Average CE Loss (Source):  3.4131 ( 3.3286) Learning Rate: 0.1000 (0.1000) Top1_base: 16.4062 (17.2897) Top1_base_per_class: 17.0988 (17.4968) 
Training Epoch: [1/1000] Step: [140 / 285] Batch Time: 0.1429 (0.1725) Data Time: 0.0103 (0.0397) Average Loss: 3.4436 (3.3286) Average CE Loss (Source):  3.4436 ( 3.3286) Learning Rate: 0.1000 (0.1000) Top1_base: 17.1875 (17.2489) Top1_base_per_class: 21.7836 (17.5196) 
Training Epoch: [1/1000] Step: [150 / 285] Batch Time: 0.3138 (0.1730) Data Time: 0.1806 (0.0402) Average Loss: 3.2926 (3.3240) Average CE Loss (Source):  3.2926 ( 3.3240) Learning Rate: 0.1000 (0.1000) Top1_base: 13.2812 (17.4010) Top1_base_per_class: 13.6550 (17.6073) 
Training Epoch: [1/1000] Step: [160 / 285] Batch Time: 0.1431 (0.1720) Data Time: 0.0115 (0.0393) Average Loss: 3.3207 (3.3166) Average CE Loss (Source):  3.3207 ( 3.3166) Learning Rate: 0.1000 (0.1000) Top1_base: 17.1875 (17.5684) Top1_base_per_class: 16.8667 (17.8127) 
Training Epoch: [1/1000] Step: [170 / 285] Batch Time: 0.1691 (0.1709) Data Time: 0.0365 (0.0382) Average Loss: 3.6159 (3.3145) Average CE Loss (Source):  3.6159 ( 3.3145) Learning Rate: 0.1000 (0.1000) Top1_base: 11.7188 (17.6057) Top1_base_per_class: 14.3452 (17.8315) 
Training Epoch: [1/1000] Step: [180 / 285] Batch Time: 0.1480 (0.1706) Data Time: 0.0140 (0.0379) Average Loss: 3.2730 (3.3081) Average CE Loss (Source):  3.2730 ( 3.3081) Learning Rate: 0.1000 (0.1000) Top1_base: 19.5312 (17.7778) Top1_base_per_class: 15.8152 (17.9729) 
Training Epoch: [1/1000] Step: [190 / 285] Batch Time: 0.1592 (0.1702) Data Time: 0.0275 (0.0375) Average Loss: 3.1921 (3.3013) Average CE Loss (Source):  3.1921 ( 3.3013) Learning Rate: 0.1000 (0.1000) Top1_base: 20.3125 (17.9564) Top1_base_per_class: 21.6981 (18.1179) 
Training Epoch: [1/1000] Step: [200 / 285] Batch Time: 0.1455 (0.1693) Data Time: 0.0128 (0.0366) Average Loss: 3.1497 (3.2954) Average CE Loss (Source):  3.1497 ( 3.2954) Learning Rate: 0.1000 (0.1000) Top1_base: 21.8750 (18.0586) Top1_base_per_class: 20.7440 (18.1944) 
Training Epoch: [1/1000] Step: [210 / 285] Batch Time: 0.2374 (0.1705) Data Time: 0.1052 (0.0378) Average Loss: 3.1276 (3.2886) Average CE Loss (Source):  3.1276 ( 3.2886) Learning Rate: 0.1000 (0.1000) Top1_base: 19.5312 (18.1510) Top1_base_per_class: 21.0303 (18.2697) 
Training Epoch: [1/1000] Step: [220 / 285] Batch Time: 0.1434 (0.1694) Data Time: 0.0112 (0.0368) Average Loss: 3.2603 (3.2824) Average CE Loss (Source):  3.2603 ( 3.2824) Learning Rate: 0.1000 (0.1000) Top1_base: 22.6562 (18.2706) Top1_base_per_class: 23.5417 (18.3430) 
Training Epoch: [1/1000] Step: [230 / 285] Batch Time: 0.2111 (0.1690) Data Time: 0.0800 (0.0364) Average Loss: 3.0234 (3.2744) Average CE Loss (Source):  3.0234 ( 3.2744) Learning Rate: 0.1000 (0.1000) Top1_base: 23.4375 (18.4069) Top1_base_per_class: 20.4403 (18.4919) 
Training Epoch: [1/1000] Step: [240 / 285] Batch Time: 0.1441 (0.1687) Data Time: 0.0115 (0.0361) Average Loss: 3.1623 (3.2702) Average CE Loss (Source):  3.1623 ( 3.2702) Learning Rate: 0.1000 (0.1000) Top1_base: 21.8750 (18.5124) Top1_base_per_class: 23.8596 (18.6060) 
Training Epoch: [1/1000] Step: [250 / 285] Batch Time: 0.2041 (0.1685) Data Time: 0.0708 (0.0359) Average Loss: 3.2733 (3.2652) Average CE Loss (Source):  3.2733 ( 3.2652) Learning Rate: 0.1000 (0.1000) Top1_base: 20.3125 (18.6313) Top1_base_per_class: 20.7650 (18.7663) 
Training Epoch: [1/1000] Step: [260 / 285] Batch Time: 0.1482 (0.1683) Data Time: 0.0150 (0.0356) Average Loss: 3.0129 (3.2603) Average CE Loss (Source):  3.0129 ( 3.2603) Learning Rate: 0.1000 (0.1000) Top1_base: 23.4375 (18.7049) Top1_base_per_class: 26.0458 (18.8603) 
Training Epoch: [1/1000] Step: [270 / 285] Batch Time: 0.1864 (0.1680) Data Time: 0.0545 (0.0353) Average Loss: 3.1887 (3.2568) Average CE Loss (Source):  3.1887 ( 3.2568) Learning Rate: 0.1000 (0.1000) Top1_base: 22.6562 (18.8397) Top1_base_per_class: 24.5536 (18.9953) 
Training Epoch: [1/1000] Step: [280 / 285] Batch Time: 0.1433 (0.1674) Data Time: 0.0106 (0.0348) Average Loss: 3.3112 (3.2538) Average CE Loss (Source):  3.3112 ( 3.2538) Learning Rate: 0.1000 (0.1000) Top1_base: 17.1875 (18.8588) Top1_base_per_class: 19.7740 (19.0294) 
Training Epoch: [2/1000] Step: [0] Batch Time: 0.1376 (0.1671) Data Time: 0.0094 (0.0345) Average Loss: 3.0318 (3.2506) Average CE Loss (Source):  3.0318 ( 3.2506) Learning Rate: 0.1000 (0.1000) Top1_base: 24.2188 (18.9556) Top1_base_per_class: 24.8428 (19.1101) 
  0%|          | 2/1000 [01:39<13:52:52, 50.07s/it]  0%|          | 3/1000 [02:26<13:28:00, 48.63s/it]Training Epoch: [2/1000] Step: [10 / 285] Batch Time: 0.1429 (0.2291) Data Time: 0.0107 (0.0977) Average Loss: 3.0650 (3.0365) Average CE Loss (Source):  3.0650 ( 3.0365) Learning Rate: 0.1000 (0.1000) Top1_base: 21.8750 (22.4219) Top1_base_per_class: 23.5632 (22.4136) 
Training Epoch: [2/1000] Step: [20 / 285] Batch Time: 0.1420 (0.2019) Data Time: 0.0096 (0.0698) Average Loss: 3.1751 (3.0453) Average CE Loss (Source):  3.1751 ( 3.0453) Learning Rate: 0.1000 (0.1000) Top1_base: 21.0938 (22.2656) Top1_base_per_class: 22.4702 (22.4501) 
Training Epoch: [2/1000] Step: [30 / 285] Batch Time: 0.1413 (0.1934) Data Time: 0.0103 (0.0613) Average Loss: 3.0160 (3.0382) Average CE Loss (Source):  3.0160 ( 3.0382) Learning Rate: 0.1000 (0.1000) Top1_base: 28.9062 (22.2396) Top1_base_per_class: 27.9938 (22.3266) 
Training Epoch: [2/1000] Step: [40 / 285] Batch Time: 0.1453 (0.1842) Data Time: 0.0125 (0.0520) Average Loss: 3.2111 (3.0570) Average CE Loss (Source):  3.2111 ( 3.0570) Learning Rate: 0.1000 (0.1000) Top1_base: 23.4375 (22.0117) Top1_base_per_class: 23.9198 (22.2336) 
Training Epoch: [2/1000] Step: [50 / 285] Batch Time: 0.1449 (0.1787) Data Time: 0.0124 (0.0464) Average Loss: 3.0706 (3.0574) Average CE Loss (Source):  3.0706 ( 3.0574) Learning Rate: 0.1000 (0.1000) Top1_base: 19.5312 (21.8750) Top1_base_per_class: 19.8788 (22.0688) 
Training Epoch: [2/1000] Step: [60 / 285] Batch Time: 0.1461 (0.1738) Data Time: 0.0129 (0.0414) Average Loss: 2.8591 (3.0508) Average CE Loss (Source):  2.8591 ( 3.0508) Learning Rate: 0.1000 (0.1000) Top1_base: 31.2500 (22.2135) Top1_base_per_class: 31.9167 (22.3810) 
Training Epoch: [2/1000] Step: [70 / 285] Batch Time: 0.1434 (0.1713) Data Time: 0.0117 (0.0389) Average Loss: 2.7774 (3.0407) Average CE Loss (Source):  2.7774 ( 3.0407) Learning Rate: 0.1000 (0.1000) Top1_base: 34.3750 (22.5893) Top1_base_per_class: 37.6190 (22.8647) 
Training Epoch: [2/1000] Step: [80 / 285] Batch Time: 0.1438 (0.1685) Data Time: 0.0113 (0.0361) Average Loss: 2.9506 (3.0387) Average CE Loss (Source):  2.9506 ( 3.0387) Learning Rate: 0.1000 (0.1000) Top1_base: 20.3125 (22.4707) Top1_base_per_class: 21.0185 (22.8274) 
Training Epoch: [2/1000] Step: [90 / 285] Batch Time: 0.1513 (0.1671) Data Time: 0.0173 (0.0345) Average Loss: 3.0862 (3.0457) Average CE Loss (Source):  3.0862 ( 3.0457) Learning Rate: 0.1000 (0.1000) Top1_base: 21.0938 (22.4306) Top1_base_per_class: 23.0864 (22.7199) 
Training Epoch: [2/1000] Step: [100 / 285] Batch Time: 0.1465 (0.1653) Data Time: 0.0118 (0.0326) Average Loss: 2.9542 (3.0437) Average CE Loss (Source):  2.9542 ( 3.0437) Learning Rate: 0.1000 (0.1000) Top1_base: 28.9062 (22.5391) Top1_base_per_class: 32.6543 (22.7709) 
Training Epoch: [2/1000] Step: [110 / 285] Batch Time: 0.1872 (0.1654) Data Time: 0.0551 (0.0327) Average Loss: 2.9732 (3.0425) Average CE Loss (Source):  2.9732 ( 3.0425) Learning Rate: 0.1000 (0.1000) Top1_base: 23.4375 (22.5142) Top1_base_per_class: 25.3448 (22.8192) 
Training Epoch: [2/1000] Step: [120 / 285] Batch Time: 0.1432 (0.1649) Data Time: 0.0104 (0.0322) Average Loss: 3.1385 (3.0417) Average CE Loss (Source):  3.1385 ( 3.0417) Learning Rate: 0.1000 (0.1000) Top1_base: 21.8750 (22.4935) Top1_base_per_class: 27.8869 (22.7437) 
Training Epoch: [2/1000] Step: [130 / 285] Batch Time: 0.1844 (0.1653) Data Time: 0.0523 (0.0326) Average Loss: 2.8951 (3.0407) Average CE Loss (Source):  2.8951 ( 3.0407) Learning Rate: 0.1000 (0.1000) Top1_base: 29.6875 (22.5481) Top1_base_per_class: 26.5238 (22.7198) 
Training Epoch: [2/1000] Step: [140 / 285] Batch Time: 0.1480 (0.1656) Data Time: 0.0133 (0.0328) Average Loss: 2.8704 (3.0372) Average CE Loss (Source):  2.8704 ( 3.0372) Learning Rate: 0.1000 (0.1000) Top1_base: 25.0000 (22.6507) Top1_base_per_class: 22.3563 (22.7740) 
Training Epoch: [2/1000] Step: [150 / 285] Batch Time: 0.1752 (0.1654) Data Time: 0.0409 (0.0327) Average Loss: 2.9034 (3.0348) Average CE Loss (Source):  2.9034 ( 3.0348) Learning Rate: 0.1000 (0.1000) Top1_base: 23.4375 (22.8073) Top1_base_per_class: 22.0760 (22.8761) 
Training Epoch: [2/1000] Step: [160 / 285] Batch Time: 0.1452 (0.1646) Data Time: 0.0138 (0.0319) Average Loss: 2.9471 (3.0345) Average CE Loss (Source):  2.9471 ( 3.0345) Learning Rate: 0.1000 (0.1000) Top1_base: 24.2188 (22.7295) Top1_base_per_class: 25.8908 (22.8398) 
Training Epoch: [2/1000] Step: [170 / 285] Batch Time: 0.2035 (0.1649) Data Time: 0.0706 (0.0321) Average Loss: 3.0389 (3.0346) Average CE Loss (Source):  3.0389 ( 3.0346) Learning Rate: 0.1000 (0.1000) Top1_base: 22.6562 (22.7160) Top1_base_per_class: 25.1887 (22.8743) 
Training Epoch: [2/1000] Step: [180 / 285] Batch Time: 0.1452 (0.1652) Data Time: 0.0120 (0.0324) Average Loss: 2.8705 (3.0249) Average CE Loss (Source):  2.8705 ( 3.0249) Learning Rate: 0.1000 (0.1000) Top1_base: 21.8750 (22.8646) Top1_base_per_class: 16.6667 (22.9804) 
Training Epoch: [2/1000] Step: [190 / 285] Batch Time: 0.1912 (0.1652) Data Time: 0.0587 (0.0324) Average Loss: 2.8449 (3.0210) Average CE Loss (Source):  2.8449 ( 3.0210) Learning Rate: 0.1000 (0.1000) Top1_base: 21.0938 (22.9770) Top1_base_per_class: 21.2644 (23.0995) 
Training Epoch: [2/1000] Step: [200 / 285] Batch Time: 0.1457 (0.1654) Data Time: 0.0130 (0.0327) Average Loss: 3.2016 (3.0219) Average CE Loss (Source):  3.2016 ( 3.0219) Learning Rate: 0.1000 (0.1000) Top1_base: 17.1875 (23.0156) Top1_base_per_class: 18.0117 (23.1723) 
Training Epoch: [2/1000] Step: [210 / 285] Batch Time: 0.2163 (0.1657) Data Time: 0.0837 (0.0329) Average Loss: 2.8456 (3.0183) Average CE Loss (Source):  2.8456 ( 3.0183) Learning Rate: 0.1000 (0.1000) Top1_base: 32.8125 (23.1362) Top1_base_per_class: 31.7857 (23.3279) 
Training Epoch: [2/1000] Step: [220 / 285] Batch Time: 0.1474 (0.1652) Data Time: 0.0136 (0.0324) Average Loss: 3.0183 (3.0159) Average CE Loss (Source):  3.0183 ( 3.0159) Learning Rate: 0.1000 (0.1000) Top1_base: 22.6562 (23.2138) Top1_base_per_class: 24.0909 (23.4717) 
Training Epoch: [2/1000] Step: [230 / 285] Batch Time: 0.1709 (0.1652) Data Time: 0.0393 (0.0323) Average Loss: 3.0463 (3.0105) Average CE Loss (Source):  3.0463 ( 3.0105) Learning Rate: 0.1000 (0.1000) Top1_base: 24.2188 (23.4851) Top1_base_per_class: 27.3684 (23.7069) 
Training Epoch: [2/1000] Step: [240 / 285] Batch Time: 0.1449 (0.1650) Data Time: 0.0125 (0.0321) Average Loss: 3.0054 (3.0077) Average CE Loss (Source):  3.0054 ( 3.0077) Learning Rate: 0.1000 (0.1000) Top1_base: 21.8750 (23.5352) Top1_base_per_class: 22.4425 (23.7724) 
Training Epoch: [2/1000] Step: [250 / 285] Batch Time: 0.2604 (0.1651) Data Time: 0.1282 (0.0323) Average Loss: 2.8823 (3.0041) Average CE Loss (Source):  2.8823 ( 3.0041) Learning Rate: 0.1000 (0.1000) Top1_base: 27.3438 (23.5688) Top1_base_per_class: 26.0303 (23.8269) 
Training Epoch: [2/1000] Step: [260 / 285] Batch Time: 0.1462 (0.1650) Data Time: 0.0134 (0.0321) Average Loss: 2.8919 (3.0015) Average CE Loss (Source):  2.8919 ( 3.0015) Learning Rate: 0.1000 (0.1000) Top1_base: 20.3125 (23.6208) Top1_base_per_class: 20.5060 (23.9015) 
Training Epoch: [2/1000] Step: [270 / 285] Batch Time: 0.2247 (0.1650) Data Time: 0.0918 (0.0322) Average Loss: 2.8261 (2.9961) Average CE Loss (Source):  2.8261 ( 2.9961) Learning Rate: 0.1000 (0.1000) Top1_base: 29.6875 (23.7384) Top1_base_per_class: 32.6970 (24.0264) 
Training Epoch: [2/1000] Step: [280 / 285] Batch Time: 0.1417 (0.1646) Data Time: 0.0106 (0.0318) Average Loss: 2.7931 (2.9895) Average CE Loss (Source):  2.7931 ( 2.9895) Learning Rate: 0.1000 (0.1000) Top1_base: 28.9062 (23.8839) Top1_base_per_class: 27.7469 (24.2047) 
Training Epoch: [3/1000] Step: [0] Batch Time: 0.1411 (0.1644) Data Time: 0.0092 (0.0315) Average Loss: 2.8894 (2.9865) Average CE Loss (Source):  2.8894 ( 2.9865) Learning Rate: 0.1000 (0.1000) Top1_base: 24.2188 (23.9720) Top1_base_per_class: 28.2749 (24.2838) 
Training Epoch: [3/1000] Step: [10 / 285] Batch Time: 0.1397 (0.2494) Data Time: 0.0095 (0.1183) Average Loss: 2.9268 (2.7965) Average CE Loss (Source):  2.9268 ( 2.7965) Learning Rate: 0.1000 (0.1000) Top1_base: 17.9688 (27.3438) Top1_base_per_class: 22.2222 (27.0633) 
Training Epoch: [3/1000] Step: [20 / 285] Batch Time: 0.1417 (0.2045) Data Time: 0.0105 (0.0738) Average Loss: 2.8642 (2.7974) Average CE Loss (Source):  2.8642 ( 2.7974) Learning Rate: 0.1000 (0.1000) Top1_base: 28.1250 (27.3438) Top1_base_per_class: 31.9345 (27.0824) 
Training Epoch: [3/1000] Step: [30 / 285] Batch Time: 0.1431 (0.1968) Data Time: 0.0112 (0.0657) Average Loss: 2.8240 (2.8162) Average CE Loss (Source):  2.8240 ( 2.8162) Learning Rate: 0.1000 (0.1000) Top1_base: 27.3438 (27.6562) Top1_base_per_class: 27.1944 (27.3075) 
Training Epoch: [3/1000] Step: [40 / 285] Batch Time: 0.1445 (0.1895) Data Time: 0.0105 (0.0580) Average Loss: 2.8038 (2.8245) Average CE Loss (Source):  2.8038 ( 2.8245) Learning Rate: 0.1000 (0.1000) Top1_base: 30.4688 (27.7734) Top1_base_per_class: 33.1790 (27.6342) 
Training Epoch: [3/1000] Step: [50 / 285] Batch Time: 0.1447 (0.1869) Data Time: 0.0125 (0.0552) Average Loss: 2.7180 (2.8251) Average CE Loss (Source):  2.7180 ( 2.8251) Learning Rate: 0.1000 (0.1000) Top1_base: 26.5625 (27.6094) Top1_base_per_class: 26.0256 (27.7620) 
Training Epoch: [3/1000] Step: [60 / 285] Batch Time: 0.1461 (0.1821) Data Time: 0.0135 (0.0502) Average Loss: 2.7237 (2.8272) Average CE Loss (Source):  2.7237 ( 2.8272) Learning Rate: 0.1000 (0.1000) Top1_base: 28.9062 (27.5391) Top1_base_per_class: 31.0920 (27.4838) 
Training Epoch: [3/1000] Step: [70 / 285] Batch Time: 0.1443 (0.1790) Data Time: 0.0115 (0.0470) Average Loss: 3.1317 (2.8250) Average CE Loss (Source):  3.1317 ( 2.8250) Learning Rate: 0.1000 (0.1000) Top1_base: 17.1875 (27.6451) Top1_base_per_class: 18.2716 (27.6434) 
Training Epoch: [3/1000] Step: [80 / 285] Batch Time: 0.1411 (0.1771) Data Time: 0.0101 (0.0451) Average Loss: 3.0422 (2.8324) Average CE Loss (Source):  3.0422 ( 2.8324) Learning Rate: 0.1000 (0.1000) Top1_base: 28.1250 (27.4316) Top1_base_per_class: 30.9394 (27.5502) 
Training Epoch: [3/1000] Step: [90 / 285] Batch Time: 0.1458 (0.1745) Data Time: 0.0116 (0.0425) Average Loss: 2.9540 (2.8371) Average CE Loss (Source):  2.9540 ( 2.8371) Learning Rate: 0.1000 (0.1000) Top1_base: 23.4375 (27.2743) Top1_base_per_class: 30.5655 (27.5050) 
Training Epoch: [3/1000] Step: [100 / 285] Batch Time: 0.1431 (0.1722) Data Time: 0.0105 (0.0401) Average Loss: 2.8883 (2.8407) Average CE Loss (Source):  2.8883 ( 2.8407) Learning Rate: 0.1000 (0.1000) Top1_base: 21.8750 (27.2109) Top1_base_per_class: 24.1515 (27.4340) 
Training Epoch: [3/1000] Step: [110 / 285] Batch Time: 0.1406 (0.1725) Data Time: 0.0098 (0.0405) Average Loss: 2.9285 (2.8376) Average CE Loss (Source):  2.9285 ( 2.8376) Learning Rate: 0.1000 (0.1000) Top1_base: 25.0000 (27.2443) Top1_base_per_class: 25.6090 (27.4965) 
Training Epoch: [3/1000] Step: [120 / 285] Batch Time: 0.1443 (0.1714) Data Time: 0.0115 (0.0394) Average Loss: 2.8886 (2.8369) Average CE Loss (Source):  2.8886 ( 2.8369) Learning Rate: 0.1000 (0.1000) Top1_base: 26.5625 (27.2917) Top1_base_per_class: 28.3333 (27.6428) 
Training Epoch: [3/1000] Step: [130 / 285] Batch Time: 0.1480 (0.1717) Data Time: 0.0106 (0.0396) Average Loss: 2.4983 (2.8279) Average CE Loss (Source):  2.4983 ( 2.8279) Learning Rate: 0.1000 (0.1000) Top1_base: 33.5938 (27.4159) Top1_base_per_class: 33.6842 (27.6043) 
Training Epoch: [3/1000] Step: [140 / 285] Batch Time: 0.1429 (0.1706) Data Time: 0.0095 (0.0383) Average Loss: 2.8532 (2.8218) Average CE Loss (Source):  2.8532 ( 2.8218) Learning Rate: 0.1000 (0.1000) Top1_base: 23.4375 (27.4554) Top1_base_per_class: 26.1494 (27.6942) 
Training Epoch: [3/1000] Step: [150 / 285] Batch Time: 0.1450 (0.1692) Data Time: 0.0115 (0.0368) Average Loss: 2.5789 (2.8167) Average CE Loss (Source):  2.5789 ( 2.8167) Learning Rate: 0.1000 (0.1000) Top1_base: 34.3750 (27.5781) Top1_base_per_class: 39.4545 (27.8674) 
Training Epoch: [3/1000] Step: [160 / 285] Batch Time: 0.1420 (0.1686) Data Time: 0.0093 (0.0363) Average Loss: 2.5136 (2.8122) Average CE Loss (Source):  2.5136 ( 2.8122) Learning Rate: 0.1000 (0.1000) Top1_base: 29.6875 (27.7148) Top1_base_per_class: 35.4520 (28.0987) 
Training Epoch: [3/1000] Step: [170 / 285] Batch Time: 0.1436 (0.1688) Data Time: 0.0114 (0.0365) Average Loss: 2.7254 (2.8105) Average CE Loss (Source):  2.7254 ( 2.8105) Learning Rate: 0.1000 (0.1000) Top1_base: 37.5000 (27.8539) Top1_base_per_class: 35.9184 (28.2053) 
Training Epoch: [3/1000] Step: [180 / 285] Batch Time: 0.1435 (0.1678) Data Time: 0.0116 (0.0356) Average Loss: 2.9377 (2.8106) Average CE Loss (Source):  2.9377 ( 2.8106) Learning Rate: 0.1000 (0.1000) Top1_base: 19.5312 (27.8559) Top1_base_per_class: 18.4242 (28.2147) 
Training Epoch: [3/1000] Step: [190 / 285] Batch Time: 0.1431 (0.1675) Data Time: 0.0110 (0.0352) Average Loss: 2.8552 (2.8090) Average CE Loss (Source):  2.8552 ( 2.8090) Learning Rate: 0.1000 (0.1000) Top1_base: 21.0938 (27.8618) Top1_base_per_class: 20.2727 (28.1871) 
Training Epoch: [3/1000] Step: [200 / 285] Batch Time: 0.1459 (0.1672) Data Time: 0.0120 (0.0349) Average Loss: 2.9954 (2.8034) Average CE Loss (Source):  2.9954 ( 2.8034) Learning Rate: 0.1000 (0.1000) Top1_base: 21.0938 (27.9922) Top1_base_per_class: 24.4719 (28.4102) 
Training Epoch: [3/1000] Step: [210 / 285] Batch Time: 0.1462 (0.1686) Data Time: 0.0132 (0.0363) Average Loss: 2.5927 (2.7994) Average CE Loss (Source):  2.5927 ( 2.7994) Learning Rate: 0.1000 (0.1000) Top1_base: 28.9062 (28.1027) Top1_base_per_class: 25.4722 (28.4523) 
Training Epoch: [3/1000] Step: [220 / 285] Batch Time: 0.1464 (0.1679) Data Time: 0.0117 (0.0356) Average Loss: 2.8592 (2.7987) Average CE Loss (Source):  2.8592 ( 2.7987) Learning Rate: 0.1000 (0.1000) Top1_base: 29.6875 (28.0504) Top1_base_per_class: 23.9134 (28.4087) 
Training Epoch: [3/1000] Step: [230 / 285] Batch Time: 0.1442 (0.1678) Data Time: 0.0116 (0.0354) Average Loss: 2.6961 (2.7974) Average CE Loss (Source):  2.6961 ( 2.7974) Learning Rate: 0.1000 (0.1000) Top1_base: 30.4688 (28.1590) Top1_base_per_class: 29.2857 (28.5128) 
Training Epoch: [3/1000] Step: [240 / 285] Batch Time: 0.1415 (0.1670) Data Time: 0.0106 (0.0347) Average Loss: 2.7048 (2.7955) Average CE Loss (Source):  2.7048 ( 2.7955) Learning Rate: 0.1000 (0.1000) Top1_base: 28.9062 (28.2096) Top1_base_per_class: 29.0774 (28.6459) 
Training Epoch: [3/1000] Step: [250 / 285] Batch Time: 0.1433 (0.1667) Data Time: 0.0100 (0.0343) Average Loss: 2.9405 (2.7906) Average CE Loss (Source):  2.9405 ( 2.7906) Learning Rate: 0.1000 (0.1000) Top1_base: 28.1250 (28.3062) Top1_base_per_class: 30.8480 (28.7075) 
Training Epoch: [3/1000] Step: [260 / 285] Batch Time: 0.1455 (0.1662) Data Time: 0.0116 (0.0338) Average Loss: 2.6720 (2.7869) Average CE Loss (Source):  2.6720 ( 2.7869) Learning Rate: 0.1000 (0.1000) Top1_base: 31.2500 (28.3624) Top1_base_per_class: 34.5455 (28.7440) 
Training Epoch: [3/1000] Step: [270 / 285] Batch Time: 0.1441 (0.1659) Data Time: 0.0105 (0.0335) Average Loss: 2.7442 (2.7845) Average CE Loss (Source):  2.7442 ( 2.7845) Learning Rate: 0.1000 (0.1000) Top1_base: 31.2500 (28.3970) Top1_base_per_class: 30.0823 (28.7987) 
Training Epoch: [3/1000] Step: [280 / 285] Batch Time: 0.1467 (0.1655) Data Time: 0.0135 (0.0331) Average Loss: 2.7006 (2.7821) Average CE Loss (Source):  2.7006 ( 2.7821) Learning Rate: 0.1000 (0.1000) Top1_base: 29.6875 (28.4375) Top1_base_per_class: 27.6970 (28.8213) 
Training Epoch: [4/1000] Step: [0] Batch Time: 0.1899 (0.1654) Data Time: 0.0535 (0.0330) Average Loss: 2.7007 (2.7811) Average CE Loss (Source):  2.7007 ( 2.7811) Learning Rate: 0.1000 (0.1000) Top1_base: 26.5625 (28.4677) Top1_base_per_class: 26.4583 (28.8481) 
  0%|          | 4/1000 [03:16<13:36:23, 49.18s/it]  0%|          | 5/1000 [04:02<13:16:45, 48.05s/it]Training Epoch: [4/1000] Step: [10 / 285] Batch Time: 0.1648 (0.2339) Data Time: 0.0355 (0.1021) Average Loss: 2.7961 (2.6915) Average CE Loss (Source):  2.7961 ( 2.6915) Learning Rate: 0.1000 (0.1000) Top1_base: 32.0312 (30.1562) Top1_base_per_class: 33.9081 (30.6392) 
Training Epoch: [4/1000] Step: [20 / 285] Batch Time: 0.1434 (0.1969) Data Time: 0.0123 (0.0652) Average Loss: 2.5799 (2.6935) Average CE Loss (Source):  2.5799 ( 2.6935) Learning Rate: 0.1000 (0.1000) Top1_base: 33.5938 (30.3906) Top1_base_per_class: 33.4226 (31.3325) 
Training Epoch: [4/1000] Step: [30 / 285] Batch Time: 0.1656 (0.1903) Data Time: 0.0353 (0.0589) Average Loss: 2.6660 (2.6700) Average CE Loss (Source):  2.6660 ( 2.6700) Learning Rate: 0.1000 (0.1000) Top1_base: 28.1250 (30.5729) Top1_base_per_class: 22.9825 (30.9797) 
Training Epoch: [4/1000] Step: [40 / 285] Batch Time: 0.1437 (0.1810) Data Time: 0.0109 (0.0498) Average Loss: 2.8796 (2.6648) Average CE Loss (Source):  2.8796 ( 2.6648) Learning Rate: 0.1000 (0.1000) Top1_base: 23.4375 (31.0547) Top1_base_per_class: 24.0566 (31.2270) 
Training Epoch: [4/1000] Step: [50 / 285] Batch Time: 0.2071 (0.1774) Data Time: 0.0757 (0.0460) Average Loss: 2.6826 (2.6694) Average CE Loss (Source):  2.6826 ( 2.6694) Learning Rate: 0.1000 (0.1000) Top1_base: 27.3438 (30.7188) Top1_base_per_class: 29.6784 (31.1090) 
Training Epoch: [4/1000] Step: [60 / 285] Batch Time: 0.1445 (0.1734) Data Time: 0.0125 (0.0419) Average Loss: 2.8453 (2.6695) Average CE Loss (Source):  2.8453 ( 2.6695) Learning Rate: 0.1000 (0.1000) Top1_base: 31.2500 (30.7812) Top1_base_per_class: 34.7756 (31.2753) 
Training Epoch: [4/1000] Step: [70 / 285] Batch Time: 0.1450 (0.1714) Data Time: 0.0126 (0.0398) Average Loss: 2.7049 (2.6698) Average CE Loss (Source):  2.7049 ( 2.6698) Learning Rate: 0.1000 (0.1000) Top1_base: 33.5938 (30.8705) Top1_base_per_class: 32.6235 (31.3709) 
Training Epoch: [4/1000] Step: [80 / 285] Batch Time: 0.1418 (0.1702) Data Time: 0.0102 (0.0384) Average Loss: 2.6749 (2.6678) Average CE Loss (Source):  2.6749 ( 2.6678) Learning Rate: 0.1000 (0.1000) Top1_base: 29.6875 (30.9766) Top1_base_per_class: 32.3148 (31.3676) 
Training Epoch: [4/1000] Step: [90 / 285] Batch Time: 0.1417 (0.1699) Data Time: 0.0098 (0.0381) Average Loss: 2.5110 (2.6620) Average CE Loss (Source):  2.5110 ( 2.6620) Learning Rate: 0.1000 (0.1000) Top1_base: 32.8125 (31.1285) Top1_base_per_class: 36.5230 (31.5139) 
Training Epoch: [4/1000] Step: [100 / 285] Batch Time: 0.1446 (0.1687) Data Time: 0.0118 (0.0369) Average Loss: 2.7612 (2.6622) Average CE Loss (Source):  2.7612 ( 2.6622) Learning Rate: 0.1000 (0.1000) Top1_base: 28.1250 (31.1484) Top1_base_per_class: 28.4848 (31.7465) 
Training Epoch: [4/1000] Step: [110 / 285] Batch Time: 0.1429 (0.1678) Data Time: 0.0101 (0.0360) Average Loss: 2.7205 (2.6586) Average CE Loss (Source):  2.7205 ( 2.6586) Learning Rate: 0.1000 (0.1000) Top1_base: 30.4688 (31.1790) Top1_base_per_class: 33.5849 (31.8182) 
Training Epoch: [4/1000] Step: [120 / 285] Batch Time: 0.1461 (0.1665) Data Time: 0.0133 (0.0346) Average Loss: 2.7400 (2.6616) Average CE Loss (Source):  2.7400 ( 2.6616) Learning Rate: 0.1000 (0.1000) Top1_base: 32.8125 (31.2500) Top1_base_per_class: 37.1667 (31.9405) 
Training Epoch: [4/1000] Step: [130 / 285] Batch Time: 0.1427 (0.1664) Data Time: 0.0105 (0.0345) Average Loss: 2.5399 (2.6495) Average CE Loss (Source):  2.5399 ( 2.6495) Learning Rate: 0.1000 (0.1000) Top1_base: 35.9375 (31.6106) Top1_base_per_class: 35.4402 (32.2289) 
Training Epoch: [4/1000] Step: [140 / 285] Batch Time: 0.1466 (0.1656) Data Time: 0.0158 (0.0337) Average Loss: 2.7137 (2.6525) Average CE Loss (Source):  2.7137 ( 2.6525) Learning Rate: 0.1000 (0.1000) Top1_base: 29.6875 (31.5234) Top1_base_per_class: 31.2180 (32.0712) 
Training Epoch: [4/1000] Step: [150 / 285] Batch Time: 0.1441 (0.1651) Data Time: 0.0112 (0.0331) Average Loss: 2.5837 (2.6534) Average CE Loss (Source):  2.5837 ( 2.6534) Learning Rate: 0.1000 (0.1000) Top1_base: 34.3750 (31.5625) Top1_base_per_class: 36.0757 (32.0531) 
Training Epoch: [4/1000] Step: [160 / 285] Batch Time: 0.1474 (0.1644) Data Time: 0.0138 (0.0324) Average Loss: 2.6889 (2.6554) Average CE Loss (Source):  2.6889 ( 2.6554) Learning Rate: 0.1000 (0.1000) Top1_base: 28.1250 (31.4844) Top1_base_per_class: 30.2632 (32.0021) 
Training Epoch: [4/1000] Step: [170 / 285] Batch Time: 0.1466 (0.1640) Data Time: 0.0117 (0.0319) Average Loss: 2.5603 (2.6562) Average CE Loss (Source):  2.5603 ( 2.6562) Learning Rate: 0.1000 (0.1000) Top1_base: 32.0312 (31.4844) Top1_base_per_class: 29.4494 (31.9386) 
Training Epoch: [4/1000] Step: [180 / 285] Batch Time: 0.1462 (0.1632) Data Time: 0.0142 (0.0311) Average Loss: 2.6373 (2.6539) Average CE Loss (Source):  2.6373 ( 2.6539) Learning Rate: 0.1000 (0.1000) Top1_base: 32.8125 (31.4974) Top1_base_per_class: 32.1930 (31.9618) 
Training Epoch: [4/1000] Step: [190 / 285] Batch Time: 0.1454 (0.1632) Data Time: 0.0129 (0.0311) Average Loss: 2.8294 (2.6561) Average CE Loss (Source):  2.8294 ( 2.6561) Learning Rate: 0.1000 (0.1000) Top1_base: 28.1250 (31.4391) Top1_base_per_class: 29.4643 (31.8928) 
Training Epoch: [4/1000] Step: [200 / 285] Batch Time: 0.1480 (0.1629) Data Time: 0.0143 (0.0308) Average Loss: 2.7738 (2.6544) Average CE Loss (Source):  2.7738 ( 2.6544) Learning Rate: 0.1000 (0.1000) Top1_base: 30.4688 (31.4258) Top1_base_per_class: 29.9394 (31.8759) 
Training Epoch: [4/1000] Step: [210 / 285] Batch Time: 0.1412 (0.1627) Data Time: 0.0109 (0.0305) Average Loss: 2.6525 (2.6489) Average CE Loss (Source):  2.6525 ( 2.6489) Learning Rate: 0.1000 (0.1000) Top1_base: 33.5938 (31.6295) Top1_base_per_class: 35.1027 (32.1375) 
Training Epoch: [4/1000] Step: [220 / 285] Batch Time: 0.1474 (0.1623) Data Time: 0.0128 (0.0301) Average Loss: 2.5764 (2.6479) Average CE Loss (Source):  2.5764 ( 2.6479) Learning Rate: 0.1000 (0.1000) Top1_base: 32.0312 (31.6016) Top1_base_per_class: 35.2083 (32.0627) 
Training Epoch: [4/1000] Step: [230 / 285] Batch Time: 0.1450 (0.1618) Data Time: 0.0122 (0.0295) Average Loss: 2.5215 (2.6469) Average CE Loss (Source):  2.5215 ( 2.6469) Learning Rate: 0.1000 (0.1000) Top1_base: 35.1562 (31.5999) Top1_base_per_class: 36.3218 (32.0967) 
Training Epoch: [4/1000] Step: [240 / 285] Batch Time: 0.1489 (0.1620) Data Time: 0.0135 (0.0297) Average Loss: 2.5354 (2.6413) Average CE Loss (Source):  2.5354 ( 2.6413) Learning Rate: 0.1000 (0.1000) Top1_base: 33.5938 (31.6862) Top1_base_per_class: 32.3099 (32.1249) 
Training Epoch: [4/1000] Step: [250 / 285] Batch Time: 0.1445 (0.1617) Data Time: 0.0118 (0.0294) Average Loss: 2.6522 (2.6407) Average CE Loss (Source):  2.6522 ( 2.6407) Learning Rate: 0.1000 (0.1000) Top1_base: 30.4688 (31.6719) Top1_base_per_class: 32.4713 (32.1069) 
Training Epoch: [4/1000] Step: [260 / 285] Batch Time: 0.1457 (0.1618) Data Time: 0.0122 (0.0295) Average Loss: 2.4062 (2.6375) Average CE Loss (Source):  2.4062 ( 2.6375) Learning Rate: 0.1000 (0.1000) Top1_base: 32.8125 (31.6887) Top1_base_per_class: 33.6576 (32.1752) 
Training Epoch: [4/1000] Step: [270 / 285] Batch Time: 0.1461 (0.1614) Data Time: 0.0132 (0.0290) Average Loss: 2.4626 (2.6344) Average CE Loss (Source):  2.4626 ( 2.6344) Learning Rate: 0.1000 (0.1000) Top1_base: 37.5000 (31.7477) Top1_base_per_class: 36.5230 (32.2216) 
Training Epoch: [4/1000] Step: [280 / 285] Batch Time: 0.1474 (0.1613) Data Time: 0.0138 (0.0289) Average Loss: 2.5244 (2.6291) Average CE Loss (Source):  2.5244 ( 2.6291) Learning Rate: 0.1000 (0.1000) Top1_base: 30.4688 (31.8638) Top1_base_per_class: 31.6667 (32.3433) 
Training Epoch: [5/1000] Step: [0] Batch Time: 0.1997 (0.1613) Data Time: 0.0718 (0.0290) Average Loss: 2.3607 (2.6288) Average CE Loss (Source):  2.3607 ( 2.6288) Learning Rate: 0.1000 (0.1000) Top1_base: 39.8438 (31.8668) Top1_base_per_class: 33.3951 (32.3016) 
Training Epoch: [5/1000] Step: [10 / 285] Batch Time: 0.1449 (0.2413) Data Time: 0.0110 (0.1095) Average Loss: 2.6229 (2.5836) Average CE Loss (Source):  2.6229 ( 2.5836) Learning Rate: 0.1000 (0.1000) Top1_base: 34.3750 (33.2812) Top1_base_per_class: 37.2013 (32.4643) 
Training Epoch: [5/1000] Step: [20 / 285] Batch Time: 0.1415 (0.2032) Data Time: 0.0108 (0.0717) Average Loss: 2.4272 (2.5165) Average CE Loss (Source):  2.4272 ( 2.5165) Learning Rate: 0.1000 (0.1000) Top1_base: 36.7188 (35.1953) Top1_base_per_class: 40.5172 (34.8211) 
Training Epoch: [5/1000] Step: [30 / 285] Batch Time: 0.1430 (0.1880) Data Time: 0.0101 (0.0566) Average Loss: 2.3866 (2.5224) Average CE Loss (Source):  2.3866 ( 2.5224) Learning Rate: 0.1000 (0.1000) Top1_base: 38.2812 (34.6615) Top1_base_per_class: 40.3274 (34.6912) 
Training Epoch: [5/1000] Step: [40 / 285] Batch Time: 0.1407 (0.1813) Data Time: 0.0102 (0.0499) Average Loss: 2.7545 (2.5069) Average CE Loss (Source):  2.7545 ( 2.5069) Learning Rate: 0.1000 (0.1000) Top1_base: 28.1250 (35.1758) Top1_base_per_class: 29.4699 (35.6331) 
Training Epoch: [5/1000] Step: [50 / 285] Batch Time: 0.1420 (0.1771) Data Time: 0.0101 (0.0456) Average Loss: 2.6080 (2.5153) Average CE Loss (Source):  2.6080 ( 2.5153) Learning Rate: 0.1000 (0.1000) Top1_base: 36.7188 (34.7500) Top1_base_per_class: 37.6852 (35.2212) 
Training Epoch: [5/1000] Step: [60 / 285] Batch Time: 0.1412 (0.1740) Data Time: 0.0105 (0.0426) Average Loss: 2.3531 (2.5158) Average CE Loss (Source):  2.3531 ( 2.5158) Learning Rate: 0.1000 (0.1000) Top1_base: 41.4062 (34.6354) Top1_base_per_class: 40.3205 (34.8925) 
Training Epoch: [5/1000] Step: [70 / 285] Batch Time: 0.1420 (0.1718) Data Time: 0.0102 (0.0404) Average Loss: 2.6477 (2.5188) Average CE Loss (Source):  2.6477 ( 2.5188) Learning Rate: 0.1000 (0.1000) Top1_base: 32.8125 (34.6429) Top1_base_per_class: 36.1728 (34.9657) 
Training Epoch: [5/1000] Step: [80 / 285] Batch Time: 0.1436 (0.1703) Data Time: 0.0121 (0.0389) Average Loss: 2.6299 (2.5172) Average CE Loss (Source):  2.6299 ( 2.5172) Learning Rate: 0.1000 (0.1000) Top1_base: 31.2500 (34.5703) Top1_base_per_class: 28.3333 (34.7980) 
Training Epoch: [5/1000] Step: [90 / 285] Batch Time: 0.1416 (0.1685) Data Time: 0.0103 (0.0370) Average Loss: 2.3796 (2.5156) Average CE Loss (Source):  2.3796 ( 2.5156) Learning Rate: 0.1000 (0.1000) Top1_base: 35.9375 (34.5920) Top1_base_per_class: 36.8452 (34.8926) 
Training Epoch: [5/1000] Step: [100 / 285] Batch Time: 0.1416 (0.1683) Data Time: 0.0101 (0.0368) Average Loss: 2.3239 (2.5170) Average CE Loss (Source):  2.3239 ( 2.5170) Learning Rate: 0.1000 (0.1000) Top1_base: 38.2812 (34.6250) Top1_base_per_class: 38.0449 (34.7332) 
Training Epoch: [5/1000] Step: [110 / 285] Batch Time: 0.1443 (0.1676) Data Time: 0.0123 (0.0361) Average Loss: 2.4207 (2.5109) Average CE Loss (Source):  2.4207 ( 2.5109) Learning Rate: 0.1000 (0.1000) Top1_base: 39.8438 (34.6804) Top1_base_per_class: 39.5621 (34.7560) 
Training Epoch: [5/1000] Step: [120 / 285] Batch Time: 0.1428 (0.1685) Data Time: 0.0101 (0.0371) Average Loss: 2.4378 (2.5079) Average CE Loss (Source):  2.4378 ( 2.5079) Learning Rate: 0.1000 (0.1000) Top1_base: 30.4688 (34.7852) Top1_base_per_class: 30.1977 (34.9033) 
Training Epoch: [5/1000] Step: [130 / 285] Batch Time: 0.1448 (0.1676) Data Time: 0.0130 (0.0361) Average Loss: 2.5473 (2.5104) Average CE Loss (Source):  2.5473 ( 2.5104) Learning Rate: 0.1000 (0.1000) Top1_base: 36.7188 (34.7356) Top1_base_per_class: 38.5165 (34.8611) 
Training Epoch: [5/1000] Step: [140 / 285] Batch Time: 0.1421 (0.1677) Data Time: 0.0103 (0.0362) Average Loss: 2.3719 (2.5112) Average CE Loss (Source):  2.3719 ( 2.5112) Learning Rate: 0.1000 (0.1000) Top1_base: 38.2812 (34.6596) Top1_base_per_class: 41.7262 (34.8470) 
Training Epoch: [5/1000] Step: [150 / 285] Batch Time: 0.1437 (0.1666) Data Time: 0.0120 (0.0350) Average Loss: 2.5059 (2.5049) Average CE Loss (Source):  2.5059 ( 2.5049) Learning Rate: 0.1000 (0.1000) Top1_base: 32.0312 (34.8021) Top1_base_per_class: 31.6379 (35.0335) 
Training Epoch: [5/1000] Step: [160 / 285] Batch Time: 0.1495 (0.1663) Data Time: 0.0157 (0.0347) Average Loss: 2.7202 (2.5090) Average CE Loss (Source):  2.7202 ( 2.5090) Learning Rate: 0.1000 (0.1000) Top1_base: 32.0312 (34.6973) Top1_base_per_class: 34.6970 (34.9364) 
Training Epoch: [5/1000] Step: [170 / 285] Batch Time: 0.1424 (0.1658) Data Time: 0.0111 (0.0341) Average Loss: 2.2567 (2.5089) Average CE Loss (Source):  2.2567 ( 2.5089) Learning Rate: 0.1000 (0.1000) Top1_base: 40.6250 (34.6875) Top1_base_per_class: 41.1607 (34.9595) 
Training Epoch: [5/1000] Step: [180 / 285] Batch Time: 0.1444 (0.1664) Data Time: 0.0132 (0.0348) Average Loss: 2.5400 (2.5087) Average CE Loss (Source):  2.5400 ( 2.5087) Learning Rate: 0.1000 (0.1000) Top1_base: 27.3438 (34.6441) Top1_base_per_class: 30.4612 (34.9767) 
Training Epoch: [5/1000] Step: [190 / 285] Batch Time: 0.1426 (0.1662) Data Time: 0.0104 (0.0345) Average Loss: 2.3583 (2.5019) Average CE Loss (Source):  2.3583 ( 2.5019) Learning Rate: 0.1000 (0.1000) Top1_base: 32.8125 (34.7780) Top1_base_per_class: 36.6970 (35.1943) 
Training Epoch: [5/1000] Step: [200 / 285] Batch Time: 0.2710 (0.1668) Data Time: 0.1394 (0.0352) Average Loss: 2.3544 (2.5036) Average CE Loss (Source):  2.3544 ( 2.5036) Learning Rate: 0.1000 (0.1000) Top1_base: 32.8125 (34.7031) Top1_base_per_class: 32.3148 (35.0555) 
Training Epoch: [5/1000] Step: [210 / 285] Batch Time: 0.1443 (0.1665) Data Time: 0.0120 (0.0348) Average Loss: 2.4798 (2.5064) Average CE Loss (Source):  2.4798 ( 2.5064) Learning Rate: 0.1000 (0.1000) Top1_base: 32.0312 (34.5424) Top1_base_per_class: 35.5758 (34.9218) 
Training Epoch: [5/1000] Step: [220 / 285] Batch Time: 0.2305 (0.1666) Data Time: 0.0984 (0.0350) Average Loss: 2.5537 (2.5027) Average CE Loss (Source):  2.5537 ( 2.5027) Learning Rate: 0.1000 (0.1000) Top1_base: 30.4688 (34.6555) Top1_base_per_class: 31.3393 (34.9580) 
Training Epoch: [5/1000] Step: [230 / 285] Batch Time: 0.1442 (0.1669) Data Time: 0.0124 (0.0352) Average Loss: 2.6490 (2.5012) Average CE Loss (Source):  2.6490 ( 2.5012) Learning Rate: 0.1000 (0.1000) Top1_base: 23.4375 (34.6977) Top1_base_per_class: 23.6905 (34.9426) 
Training Epoch: [5/1000] Step: [240 / 285] Batch Time: 0.2375 (0.1672) Data Time: 0.1044 (0.0355) Average Loss: 2.4100 (2.4974) Average CE Loss (Source):  2.4100 ( 2.4974) Learning Rate: 0.1000 (0.1000) Top1_base: 32.8125 (34.8145) Top1_base_per_class: 33.0952 (35.1081) 
Training Epoch: [5/1000] Step: [250 / 285] Batch Time: 0.1426 (0.1670) Data Time: 0.0114 (0.0353) Average Loss: 2.4696 (2.4950) Average CE Loss (Source):  2.4696 ( 2.4950) Learning Rate: 0.1000 (0.1000) Top1_base: 38.2812 (34.9656) Top1_base_per_class: 40.6482 (35.3026) 
Training Epoch: [5/1000] Step: [260 / 285] Batch Time: 0.2206 (0.1671) Data Time: 0.0890 (0.0354) Average Loss: 2.3591 (2.4939) Average CE Loss (Source):  2.3591 ( 2.4939) Learning Rate: 0.1000 (0.1000) Top1_base: 38.2812 (34.9429) Top1_base_per_class: 38.3738 (35.2968) 
Training Epoch: [5/1000] Step: [270 / 285] Batch Time: 0.1421 (0.1669) Data Time: 0.0109 (0.0351) Average Loss: 2.4021 (2.4907) Average CE Loss (Source):  2.4021 ( 2.4907) Learning Rate: 0.1000 (0.1000) Top1_base: 39.0625 (35.0203) Top1_base_per_class: 42.1018 (35.4403) 
Training Epoch: [5/1000] Step: [280 / 285] Batch Time: 0.2393 (0.1669) Data Time: 0.1081 (0.0351) Average Loss: 2.3759 (2.4858) Average CE Loss (Source):  2.3759 ( 2.4858) Learning Rate: 0.1000 (0.1000) Top1_base: 37.5000 (35.1395) Top1_base_per_class: 37.4691 (35.5251) 
Training Epoch: [6/1000] Step: [0] Batch Time: 0.1378 (0.1665) Data Time: 0.0090 (0.0348) Average Loss: 2.7675 (2.4856) Average CE Loss (Source):  2.7675 ( 2.4856) Learning Rate: 0.1000 (0.1000) Top1_base: 27.3438 (35.1919) Top1_base_per_class: 31.3710 (35.5709) 
  1%|          | 6/1000 [04:53<13:29:22, 48.86s/it]  1%|          | 7/1000 [05:39<13:15:18, 48.06s/it]Training Epoch: [6/1000] Step: [10 / 285] Batch Time: 0.1415 (0.2354) Data Time: 0.0099 (0.1037) Average Loss: 2.4226 (2.3637) Average CE Loss (Source):  2.4226 ( 2.3637) Learning Rate: 0.1000 (0.1000) Top1_base: 34.3750 (39.2188) Top1_base_per_class: 35.0292 (39.2917) 
Training Epoch: [6/1000] Step: [20 / 285] Batch Time: 0.1420 (0.1955) Data Time: 0.0111 (0.0640) Average Loss: 2.3243 (2.3428) Average CE Loss (Source):  2.3243 ( 2.3428) Learning Rate: 0.1000 (0.1000) Top1_base: 38.2812 (39.4141) Top1_base_per_class: 35.5975 (39.3543) 
Training Epoch: [6/1000] Step: [30 / 285] Batch Time: 0.1479 (0.1822) Data Time: 0.0131 (0.0503) Average Loss: 2.5243 (2.3691) Average CE Loss (Source):  2.5243 ( 2.3691) Learning Rate: 0.1000 (0.1000) Top1_base: 32.0312 (38.7240) Top1_base_per_class: 33.6420 (39.3608) 
Training Epoch: [6/1000] Step: [40 / 285] Batch Time: 0.1468 (0.1749) Data Time: 0.0127 (0.0424) Average Loss: 2.3836 (2.3656) Average CE Loss (Source):  2.3836 ( 2.3656) Learning Rate: 0.1000 (0.1000) Top1_base: 34.3750 (38.6914) Top1_base_per_class: 34.8485 (39.3778) 
Training Epoch: [6/1000] Step: [50 / 285] Batch Time: 0.1445 (0.1748) Data Time: 0.0119 (0.0420) Average Loss: 2.4948 (2.3696) Average CE Loss (Source):  2.4948 ( 2.3696) Learning Rate: 0.1000 (0.1000) Top1_base: 34.3750 (38.6250) Top1_base_per_class: 34.6855 (39.2211) 
Training Epoch: [6/1000] Step: [60 / 285] Batch Time: 0.1958 (0.1726) Data Time: 0.0623 (0.0397) Average Loss: 2.3288 (2.3730) Average CE Loss (Source):  2.3288 ( 2.3730) Learning Rate: 0.1000 (0.1000) Top1_base: 34.3750 (38.3594) Top1_base_per_class: 34.8333 (38.6010) 
Training Epoch: [6/1000] Step: [70 / 285] Batch Time: 0.1442 (0.1699) Data Time: 0.0122 (0.0369) Average Loss: 2.5132 (2.3610) Average CE Loss (Source):  2.5132 ( 2.3610) Learning Rate: 0.1000 (0.1000) Top1_base: 31.2500 (38.6830) Top1_base_per_class: 35.0314 (38.9545) 
Training Epoch: [6/1000] Step: [80 / 285] Batch Time: 0.2194 (0.1693) Data Time: 0.0884 (0.0365) Average Loss: 2.3225 (2.3643) Average CE Loss (Source):  2.3225 ( 2.3643) Learning Rate: 0.1000 (0.1000) Top1_base: 42.1875 (38.6133) Top1_base_per_class: 43.9286 (38.9626) 
Training Epoch: [6/1000] Step: [90 / 285] Batch Time: 0.1431 (0.1688) Data Time: 0.0120 (0.0360) Average Loss: 2.5012 (2.3656) Average CE Loss (Source):  2.5012 ( 2.3656) Learning Rate: 0.1000 (0.1000) Top1_base: 35.9375 (38.4462) Top1_base_per_class: 33.1558 (38.7051) 
Training Epoch: [6/1000] Step: [100 / 285] Batch Time: 0.1802 (0.1677) Data Time: 0.0481 (0.0350) Average Loss: 2.4137 (2.3563) Average CE Loss (Source):  2.4137 ( 2.3563) Learning Rate: 0.1000 (0.1000) Top1_base: 35.9375 (38.6484) Top1_base_per_class: 37.6437 (38.8072) 
Training Epoch: [6/1000] Step: [110 / 285] Batch Time: 0.1454 (0.1671) Data Time: 0.0135 (0.0344) Average Loss: 2.2969 (2.3585) Average CE Loss (Source):  2.2969 ( 2.3585) Learning Rate: 0.1000 (0.1000) Top1_base: 45.3125 (38.5156) Top1_base_per_class: 46.1696 (38.8201) 
Training Epoch: [6/1000] Step: [120 / 285] Batch Time: 0.2568 (0.1672) Data Time: 0.1252 (0.0346) Average Loss: 2.6516 (2.3599) Average CE Loss (Source):  2.6516 ( 2.3599) Learning Rate: 0.1000 (0.1000) Top1_base: 31.2500 (38.3659) Top1_base_per_class: 29.9425 (38.6058) 
Training Epoch: [6/1000] Step: [130 / 285] Batch Time: 0.1426 (0.1666) Data Time: 0.0109 (0.0339) Average Loss: 2.2809 (2.3615) Average CE Loss (Source):  2.2809 ( 2.3615) Learning Rate: 0.1000 (0.1000) Top1_base: 35.9375 (38.2272) Top1_base_per_class: 37.7337 (38.5190) 
Training Epoch: [6/1000] Step: [140 / 285] Batch Time: 0.2158 (0.1664) Data Time: 0.0844 (0.0338) Average Loss: 2.3522 (2.3626) Average CE Loss (Source):  2.3522 ( 2.3626) Learning Rate: 0.1000 (0.1000) Top1_base: 38.2812 (38.1975) Top1_base_per_class: 39.6296 (38.4015) 
Training Epoch: [6/1000] Step: [150 / 285] Batch Time: 0.1412 (0.1657) Data Time: 0.0108 (0.0332) Average Loss: 2.5200 (2.3700) Average CE Loss (Source):  2.5200 ( 2.3700) Learning Rate: 0.1000 (0.1000) Top1_base: 36.7188 (38.0000) Top1_base_per_class: 38.5256 (38.2990) 
Training Epoch: [6/1000] Step: [160 / 285] Batch Time: 0.1817 (0.1650) Data Time: 0.0500 (0.0324) Average Loss: 2.5925 (2.3689) Average CE Loss (Source):  2.5925 ( 2.3689) Learning Rate: 0.1000 (0.1000) Top1_base: 34.3750 (37.9688) Top1_base_per_class: 39.0230 (38.3695) 
Training Epoch: [6/1000] Step: [170 / 285] Batch Time: 0.1466 (0.1648) Data Time: 0.0133 (0.0322) Average Loss: 2.2955 (2.3636) Average CE Loss (Source):  2.2955 ( 2.3636) Learning Rate: 0.1000 (0.1000) Top1_base: 39.8438 (38.1158) Top1_base_per_class: 44.6939 (38.5342) 
Training Epoch: [6/1000] Step: [180 / 285] Batch Time: 0.2096 (0.1648) Data Time: 0.0770 (0.0322) Average Loss: 2.2564 (2.3596) Average CE Loss (Source):  2.2564 ( 2.3596) Learning Rate: 0.1000 (0.1000) Top1_base: 34.3750 (38.1901) Top1_base_per_class: 35.3736 (38.6284) 
Training Epoch: [6/1000] Step: [190 / 285] Batch Time: 0.1445 (0.1640) Data Time: 0.0119 (0.0314) Average Loss: 2.2382 (2.3589) Average CE Loss (Source):  2.2382 ( 2.3589) Learning Rate: 0.1000 (0.1000) Top1_base: 42.9688 (38.2072) Top1_base_per_class: 43.3287 (38.6740) 
Training Epoch: [6/1000] Step: [200 / 285] Batch Time: 0.1954 (0.1637) Data Time: 0.0627 (0.0311) Average Loss: 2.2692 (2.3576) Average CE Loss (Source):  2.2692 ( 2.3576) Learning Rate: 0.1000 (0.1000) Top1_base: 35.1562 (38.1875) Top1_base_per_class: 38.0909 (38.7612) 
Training Epoch: [6/1000] Step: [210 / 285] Batch Time: 0.1459 (0.1636) Data Time: 0.0127 (0.0309) Average Loss: 2.4123 (2.3558) Average CE Loss (Source):  2.4123 ( 2.3558) Learning Rate: 0.1000 (0.1000) Top1_base: 38.2812 (38.1882) Top1_base_per_class: 39.0936 (38.7195) 
Training Epoch: [6/1000] Step: [220 / 285] Batch Time: 0.1934 (0.1633) Data Time: 0.0599 (0.0306) Average Loss: 2.3400 (2.3554) Average CE Loss (Source):  2.3400 ( 2.3554) Learning Rate: 0.1000 (0.1000) Top1_base: 43.7500 (38.1712) Top1_base_per_class: 45.7104 (38.7056) 
Training Epoch: [6/1000] Step: [230 / 285] Batch Time: 0.1452 (0.1632) Data Time: 0.0135 (0.0305) Average Loss: 2.6127 (2.3534) Average CE Loss (Source):  2.6127 ( 2.3534) Learning Rate: 0.1000 (0.1000) Top1_base: 27.3438 (38.1929) Top1_base_per_class: 32.5146 (38.7126) 
Training Epoch: [6/1000] Step: [240 / 285] Batch Time: 0.1719 (0.1634) Data Time: 0.0385 (0.0307) Average Loss: 2.2008 (2.3499) Average CE Loss (Source):  2.2008 ( 2.3499) Learning Rate: 0.1000 (0.1000) Top1_base: 39.0625 (38.2878) Top1_base_per_class: 37.4660 (38.8036) 
Training Epoch: [6/1000] Step: [250 / 285] Batch Time: 0.1455 (0.1630) Data Time: 0.0109 (0.0302) Average Loss: 2.0926 (2.3468) Average CE Loss (Source):  2.0926 ( 2.3468) Learning Rate: 0.1000 (0.1000) Top1_base: 49.2188 (38.3563) Top1_base_per_class: 46.5476 (38.8583) 
Training Epoch: [6/1000] Step: [260 / 285] Batch Time: 0.1519 (0.1627) Data Time: 0.0200 (0.0300) Average Loss: 2.3202 (2.3450) Average CE Loss (Source):  2.3202 ( 2.3450) Learning Rate: 0.1000 (0.1000) Top1_base: 36.7188 (38.3594) Top1_base_per_class: 39.2816 (38.9043) 
Training Epoch: [6/1000] Step: [270 / 285] Batch Time: 0.1437 (0.1630) Data Time: 0.0121 (0.0302) Average Loss: 2.2533 (2.3441) Average CE Loss (Source):  2.2533 ( 2.3441) Learning Rate: 0.1000 (0.1000) Top1_base: 43.7500 (38.4288) Top1_base_per_class: 45.2679 (38.9170) 
Training Epoch: [6/1000] Step: [280 / 285] Batch Time: 0.2149 (0.1628) Data Time: 0.0845 (0.0300) Average Loss: 2.2811 (2.3427) Average CE Loss (Source):  2.2811 ( 2.3427) Learning Rate: 0.1000 (0.1000) Top1_base: 41.4062 (38.4905) Top1_base_per_class: 44.5192 (38.9968) 
Training Epoch: [7/1000] Step: [0] Batch Time: 0.1403 (0.1626) Data Time: 0.0097 (0.0299) Average Loss: 2.5087 (2.3410) Average CE Loss (Source):  2.5087 ( 2.3410) Learning Rate: 0.1000 (0.1000) Top1_base: 35.9375 (38.5581) Top1_base_per_class: 36.3272 (39.0470) 
Training Epoch: [7/1000] Step: [10 / 285] Batch Time: 0.1451 (0.2429) Data Time: 0.0142 (0.1113) Average Loss: 2.3131 (2.3635) Average CE Loss (Source):  2.3131 ( 2.3635) Learning Rate: 0.1000 (0.1000) Top1_base: 43.7500 (37.0312) Top1_base_per_class: 45.6970 (38.0190) 
Training Epoch: [7/1000] Step: [20 / 285] Batch Time: 0.1419 (0.2060) Data Time: 0.0107 (0.0745) Average Loss: 2.0788 (2.2781) Average CE Loss (Source):  2.0788 ( 2.2781) Learning Rate: 0.1000 (0.1000) Top1_base: 41.4062 (40.1953) Top1_base_per_class: 43.3374 (40.5173) 
Training Epoch: [7/1000] Step: [30 / 285] Batch Time: 0.2544 (0.1943) Data Time: 0.1225 (0.0625) Average Loss: 2.0069 (2.2506) Average CE Loss (Source):  2.0069 ( 2.2506) Learning Rate: 0.1000 (0.1000) Top1_base: 46.8750 (41.0938) Top1_base_per_class: 46.8954 (41.2676) 
Training Epoch: [7/1000] Step: [40 / 285] Batch Time: 0.1404 (0.1858) Data Time: 0.0097 (0.0539) Average Loss: 2.2808 (2.2499) Average CE Loss (Source):  2.2808 ( 2.2499) Learning Rate: 0.1000 (0.1000) Top1_base: 41.4062 (40.9766) Top1_base_per_class: 40.3571 (41.0936) 
Training Epoch: [7/1000] Step: [50 / 285] Batch Time: 0.3155 (0.1839) Data Time: 0.1834 (0.0521) Average Loss: 2.0590 (2.2504) Average CE Loss (Source):  2.0590 ( 2.2504) Learning Rate: 0.1000 (0.1000) Top1_base: 46.0938 (40.6719) Top1_base_per_class: 48.5311 (41.0355) 
Training Epoch: [7/1000] Step: [60 / 285] Batch Time: 0.1438 (0.1802) Data Time: 0.0108 (0.0483) Average Loss: 2.1030 (2.2394) Average CE Loss (Source):  2.1030 ( 2.2394) Learning Rate: 0.1000 (0.1000) Top1_base: 46.8750 (40.8333) Top1_base_per_class: 48.5994 (41.1954) 
Training Epoch: [7/1000] Step: [70 / 285] Batch Time: 0.2485 (0.1784) Data Time: 0.1156 (0.0463) Average Loss: 2.1539 (2.2344) Average CE Loss (Source):  2.1539 ( 2.2344) Learning Rate: 0.1000 (0.1000) Top1_base: 43.7500 (41.0603) Top1_base_per_class: 42.3851 (41.5343) 
Training Epoch: [7/1000] Step: [80 / 285] Batch Time: 0.1439 (0.1752) Data Time: 0.0112 (0.0430) Average Loss: 2.2790 (2.2328) Average CE Loss (Source):  2.2790 ( 2.2328) Learning Rate: 0.1000 (0.1000) Top1_base: 39.0625 (41.0254) Top1_base_per_class: 38.7356 (41.5306) 
Training Epoch: [7/1000] Step: [90 / 285] Batch Time: 0.2797 (0.1753) Data Time: 0.1462 (0.0429) Average Loss: 2.1546 (2.2369) Average CE Loss (Source):  2.1546 ( 2.2369) Learning Rate: 0.1000 (0.1000) Top1_base: 42.1875 (40.8854) Top1_base_per_class: 45.5932 (41.3982) 
Training Epoch: [7/1000] Step: [100 / 285] Batch Time: 0.1451 (0.1733) Data Time: 0.0128 (0.0409) Average Loss: 2.1985 (2.2379) Average CE Loss (Source):  2.1985 ( 2.2379) Learning Rate: 0.1000 (0.1000) Top1_base: 45.3125 (41.0156) Top1_base_per_class: 49.9713 (41.4989) 
Training Epoch: [7/1000] Step: [110 / 285] Batch Time: 0.1508 (0.1727) Data Time: 0.0202 (0.0404) Average Loss: 2.3696 (2.2377) Average CE Loss (Source):  2.3696 ( 2.2377) Learning Rate: 0.1000 (0.1000) Top1_base: 39.0625 (40.9020) Top1_base_per_class: 43.7963 (41.3252) 
Training Epoch: [7/1000] Step: [120 / 285] Batch Time: 0.1430 (0.1709) Data Time: 0.0108 (0.0386) Average Loss: 2.4287 (2.2435) Average CE Loss (Source):  2.4287 ( 2.2435) Learning Rate: 0.1000 (0.1000) Top1_base: 36.7188 (40.8398) Top1_base_per_class: 38.6607 (41.2098) 
Training Epoch: [7/1000] Step: [130 / 285] Batch Time: 0.1767 (0.1703) Data Time: 0.0452 (0.0380) Average Loss: 2.0000 (2.2453) Average CE Loss (Source):  2.0000 ( 2.2453) Learning Rate: 0.1000 (0.1000) Top1_base: 43.7500 (40.8654) Top1_base_per_class: 45.5556 (41.2872) 
Training Epoch: [7/1000] Step: [140 / 285] Batch Time: 0.1432 (0.1686) Data Time: 0.0111 (0.0363) Average Loss: 1.9864 (2.2493) Average CE Loss (Source):  1.9864 ( 2.2493) Learning Rate: 0.1000 (0.1000) Top1_base: 53.1250 (40.8036) Top1_base_per_class: 55.8985 (41.1543) 
Training Epoch: [7/1000] Step: [150 / 285] Batch Time: 0.1820 (0.1685) Data Time: 0.0509 (0.0362) Average Loss: 2.0805 (2.2484) Average CE Loss (Source):  2.0805 ( 2.2484) Learning Rate: 0.1000 (0.1000) Top1_base: 42.9688 (40.8073) Top1_base_per_class: 44.0566 (41.1698) 
Training Epoch: [7/1000] Step: [160 / 285] Batch Time: 0.1452 (0.1680) Data Time: 0.0129 (0.0357) Average Loss: 2.2288 (2.2461) Average CE Loss (Source):  2.2288 ( 2.2461) Learning Rate: 0.1000 (0.1000) Top1_base: 38.2812 (40.8301) Top1_base_per_class: 40.3145 (41.1641) 
Training Epoch: [7/1000] Step: [170 / 285] Batch Time: 0.2008 (0.1679) Data Time: 0.0649 (0.0354) Average Loss: 2.1136 (2.2478) Average CE Loss (Source):  2.1136 ( 2.2478) Learning Rate: 0.1000 (0.1000) Top1_base: 44.5312 (40.8869) Top1_base_per_class: 46.7284 (41.2134) 
Training Epoch: [7/1000] Step: [180 / 285] Batch Time: 0.1414 (0.1677) Data Time: 0.0103 (0.0353) Average Loss: 2.3418 (2.2472) Average CE Loss (Source):  2.3418 ( 2.2472) Learning Rate: 0.1000 (0.1000) Top1_base: 39.8438 (40.9635) Top1_base_per_class: 40.9434 (41.2890) 
Training Epoch: [7/1000] Step: [190 / 285] Batch Time: 0.2057 (0.1676) Data Time: 0.0737 (0.0352) Average Loss: 2.0534 (2.2450) Average CE Loss (Source):  2.0534 ( 2.2450) Learning Rate: 0.1000 (0.1000) Top1_base: 48.4375 (41.0321) Top1_base_per_class: 48.7571 (41.3628) 
Training Epoch: [7/1000] Step: [200 / 285] Batch Time: 0.1430 (0.1671) Data Time: 0.0110 (0.0348) Average Loss: 2.1124 (2.2423) Average CE Loss (Source):  2.1124 ( 2.2423) Learning Rate: 0.1000 (0.1000) Top1_base: 43.7500 (41.0234) Top1_base_per_class: 46.0452 (41.3840) 
Training Epoch: [7/1000] Step: [210 / 285] Batch Time: 0.2357 (0.1672) Data Time: 0.1024 (0.0348) Average Loss: 2.0333 (2.2367) Average CE Loss (Source):  2.0333 ( 2.2367) Learning Rate: 0.1000 (0.1000) Top1_base: 45.3125 (41.2277) Top1_base_per_class: 45.7895 (41.6063) 
Training Epoch: [7/1000] Step: [220 / 285] Batch Time: 0.1480 (0.1665) Data Time: 0.0142 (0.0341) Average Loss: 1.9862 (2.2389) Average CE Loss (Source):  1.9862 ( 2.2389) Learning Rate: 0.1000 (0.1000) Top1_base: 46.8750 (41.1293) Top1_base_per_class: 48.8304 (41.5654) 
Training Epoch: [7/1000] Step: [230 / 285] Batch Time: 0.1634 (0.1663) Data Time: 0.0314 (0.0339) Average Loss: 2.2296 (2.2410) Average CE Loss (Source):  2.2296 ( 2.2410) Learning Rate: 0.1000 (0.1000) Top1_base: 44.5312 (41.1889) Top1_base_per_class: 47.5298 (41.6273) 
Training Epoch: [7/1000] Step: [240 / 285] Batch Time: 0.1442 (0.1661) Data Time: 0.0132 (0.0337) Average Loss: 2.1044 (2.2380) Average CE Loss (Source):  2.1044 ( 2.2380) Learning Rate: 0.1000 (0.1000) Top1_base: 48.4375 (41.3053) Top1_base_per_class: 46.6071 (41.7849) 
Training Epoch: [7/1000] Step: [250 / 285] Batch Time: 0.1785 (0.1659) Data Time: 0.0469 (0.0336) Average Loss: 2.2376 (2.2360) Average CE Loss (Source):  2.2376 ( 2.2360) Learning Rate: 0.1000 (0.1000) Top1_base: 45.3125 (41.4094) Top1_base_per_class: 46.9591 (41.9014) 
Training Epoch: [7/1000] Step: [260 / 285] Batch Time: 0.1434 (0.1657) Data Time: 0.0115 (0.0334) Average Loss: 2.0359 (2.2315) Average CE Loss (Source):  2.0359 ( 2.2315) Learning Rate: 0.1000 (0.1000) Top1_base: 46.0938 (41.5475) Top1_base_per_class: 46.8391 (42.0292) 
Training Epoch: [7/1000] Step: [270 / 285] Batch Time: 0.1510 (0.1652) Data Time: 0.0161 (0.0328) Average Loss: 2.1378 (2.2287) Average CE Loss (Source):  2.1378 ( 2.2287) Learning Rate: 0.1000 (0.1000) Top1_base: 42.9688 (41.5828) Top1_base_per_class: 42.0056 (42.0798) 
Training Epoch: [7/1000] Step: [280 / 285] Batch Time: 0.1479 (0.1648) Data Time: 0.0133 (0.0324) Average Loss: 2.2964 (2.2303) Average CE Loss (Source):  2.2964 ( 2.2303) Learning Rate: 0.1000 (0.1000) Top1_base: 38.2812 (41.5290) Top1_base_per_class: 38.1250 (42.0549) 
Training Epoch: [8/1000] Step: [0] Batch Time: 0.1420 (0.1647) Data Time: 0.0117 (0.0323) Average Loss: 2.2749 (2.2294) Average CE Loss (Source):  2.2749 ( 2.2294) Learning Rate: 0.1000 (0.1000) Top1_base: 39.0625 (41.5570) Top1_base_per_class: 45.3216 (42.1175) 
  1%|          | 8/1000 [06:29<13:23:32, 48.60s/it]  1%|          | 9/1000 [07:14<13:03:31, 47.44s/it]Training Epoch: [8/1000] Step: [10 / 285] Batch Time: 0.1442 (0.2354) Data Time: 0.0096 (0.1022) Average Loss: 2.2628 (2.0646) Average CE Loss (Source):  2.2628 ( 2.0646) Learning Rate: 0.1000 (0.1000) Top1_base: 41.4062 (44.1406) Top1_base_per_class: 44.0252 (44.8772) 
Training Epoch: [8/1000] Step: [20 / 285] Batch Time: 0.1442 (0.1932) Data Time: 0.0107 (0.0598) Average Loss: 2.0561 (2.1304) Average CE Loss (Source):  2.0561 ( 2.1304) Learning Rate: 0.1000 (0.1000) Top1_base: 44.5312 (43.3203) Top1_base_per_class: 50.2288 (43.7662) 
Training Epoch: [8/1000] Step: [30 / 285] Batch Time: 0.1456 (0.1856) Data Time: 0.0102 (0.0525) Average Loss: 2.4575 (2.1570) Average CE Loss (Source):  2.4575 ( 2.1570) Learning Rate: 0.1000 (0.1000) Top1_base: 40.6250 (42.4479) Top1_base_per_class: 37.0760 (42.9151) 
Training Epoch: [8/1000] Step: [40 / 285] Batch Time: 0.1420 (0.1795) Data Time: 0.0099 (0.0466) Average Loss: 2.0485 (2.1551) Average CE Loss (Source):  2.0485 ( 2.1551) Learning Rate: 0.1000 (0.1000) Top1_base: 46.8750 (42.9688) Top1_base_per_class: 47.1751 (43.7433) 
Training Epoch: [8/1000] Step: [50 / 285] Batch Time: 0.1470 (0.1761) Data Time: 0.0111 (0.0431) Average Loss: 2.1140 (2.1532) Average CE Loss (Source):  2.1140 ( 2.1532) Learning Rate: 0.1000 (0.1000) Top1_base: 43.7500 (42.9688) Top1_base_per_class: 44.8611 (43.6536) 
Training Epoch: [8/1000] Step: [60 / 285] Batch Time: 0.1463 (0.1716) Data Time: 0.0102 (0.0384) Average Loss: 2.1025 (2.1405) Average CE Loss (Source):  2.1025 ( 2.1405) Learning Rate: 0.1000 (0.1000) Top1_base: 45.3125 (43.2031) Top1_base_per_class: 45.6364 (43.7868) 
Training Epoch: [8/1000] Step: [70 / 285] Batch Time: 0.1435 (0.1694) Data Time: 0.0100 (0.0361) Average Loss: 2.0259 (2.1350) Average CE Loss (Source):  2.0259 ( 2.1350) Learning Rate: 0.1000 (0.1000) Top1_base: 45.3125 (43.3705) Top1_base_per_class: 46.3836 (43.7312) 
Training Epoch: [8/1000] Step: [80 / 285] Batch Time: 0.1418 (0.1676) Data Time: 0.0108 (0.0345) Average Loss: 2.0506 (2.1425) Average CE Loss (Source):  2.0506 ( 2.1425) Learning Rate: 0.1000 (0.1000) Top1_base: 46.8750 (43.3496) Top1_base_per_class: 46.6333 (43.6673) 
Training Epoch: [8/1000] Step: [90 / 285] Batch Time: 0.1415 (0.1654) Data Time: 0.0107 (0.0325) Average Loss: 2.1720 (2.1422) Average CE Loss (Source):  2.1720 ( 2.1422) Learning Rate: 0.1000 (0.1000) Top1_base: 40.6250 (43.3854) Top1_base_per_class: 40.5848 (43.6711) 
Training Epoch: [8/1000] Step: [100 / 285] Batch Time: 0.1460 (0.1647) Data Time: 0.0111 (0.0318) Average Loss: 2.0485 (2.1509) Average CE Loss (Source):  2.0485 ( 2.1509) Learning Rate: 0.1000 (0.1000) Top1_base: 42.9688 (43.0703) Top1_base_per_class: 38.4503 (43.2827) 
Training Epoch: [8/1000] Step: [110 / 285] Batch Time: 0.1423 (0.1638) Data Time: 0.0103 (0.0308) Average Loss: 2.4002 (2.1461) Average CE Loss (Source):  2.4002 ( 2.1461) Learning Rate: 0.1000 (0.1000) Top1_base: 39.8438 (43.2244) Top1_base_per_class: 42.5000 (43.4781) 
Training Epoch: [8/1000] Step: [120 / 285] Batch Time: 0.1417 (0.1627) Data Time: 0.0102 (0.0298) Average Loss: 2.2376 (2.1408) Average CE Loss (Source):  2.2376 ( 2.1408) Learning Rate: 0.1000 (0.1000) Top1_base: 40.6250 (43.2161) Top1_base_per_class: 38.0952 (43.4606) 
Training Epoch: [8/1000] Step: [130 / 285] Batch Time: 0.1408 (0.1625) Data Time: 0.0103 (0.0297) Average Loss: 2.1929 (2.1380) Average CE Loss (Source):  2.1929 ( 2.1380) Learning Rate: 0.1000 (0.1000) Top1_base: 42.9688 (43.3714) Top1_base_per_class: 42.5325 (43.5546) 
Training Epoch: [8/1000] Step: [140 / 285] Batch Time: 0.1413 (0.1618) Data Time: 0.0096 (0.0291) Average Loss: 2.0924 (2.1340) Average CE Loss (Source):  2.0924 ( 2.1340) Learning Rate: 0.1000 (0.1000) Top1_base: 45.3125 (43.5770) Top1_base_per_class: 41.8827 (43.8052) 
Training Epoch: [8/1000] Step: [150 / 285] Batch Time: 0.1417 (0.1608) Data Time: 0.0106 (0.0281) Average Loss: 2.1571 (2.1298) Average CE Loss (Source):  2.1571 ( 2.1298) Learning Rate: 0.1000 (0.1000) Top1_base: 42.9688 (43.6354) Top1_base_per_class: 42.4214 (43.8974) 
Training Epoch: [8/1000] Step: [160 / 285] Batch Time: 0.1426 (0.1606) Data Time: 0.0104 (0.0280) Average Loss: 1.9933 (2.1248) Average CE Loss (Source):  1.9933 ( 2.1248) Learning Rate: 0.1000 (0.1000) Top1_base: 47.6562 (43.7891) Top1_base_per_class: 49.8457 (44.1079) 
Training Epoch: [8/1000] Step: [170 / 285] Batch Time: 0.1418 (0.1607) Data Time: 0.0109 (0.0281) Average Loss: 2.1556 (2.1171) Average CE Loss (Source):  2.1556 ( 2.1171) Learning Rate: 0.1000 (0.1000) Top1_base: 45.3125 (43.9246) Top1_base_per_class: 43.1410 (44.2805) 
Training Epoch: [8/1000] Step: [180 / 285] Batch Time: 0.1436 (0.1605) Data Time: 0.0097 (0.0279) Average Loss: 2.1375 (2.1206) Average CE Loss (Source):  2.1375 ( 2.1206) Learning Rate: 0.1000 (0.1000) Top1_base: 47.6562 (43.8325) Top1_base_per_class: 53.5628 (44.1555) 
Training Epoch: [8/1000] Step: [190 / 285] Batch Time: 0.1447 (0.1599) Data Time: 0.0101 (0.0272) Average Loss: 2.3758 (2.1214) Average CE Loss (Source):  2.3758 ( 2.1214) Learning Rate: 0.1000 (0.1000) Top1_base: 45.3125 (43.9268) Top1_base_per_class: 46.3435 (44.2513) 
Training Epoch: [8/1000] Step: [200 / 285] Batch Time: 0.1464 (0.1593) Data Time: 0.0117 (0.0266) Average Loss: 1.8666 (2.1192) Average CE Loss (Source):  1.8666 ( 2.1192) Learning Rate: 0.1000 (0.1000) Top1_base: 47.6562 (44.0273) Top1_base_per_class: 49.9138 (44.2706) 
Training Epoch: [8/1000] Step: [210 / 285] Batch Time: 0.1414 (0.1594) Data Time: 0.0103 (0.0266) Average Loss: 2.0107 (2.1175) Average CE Loss (Source):  2.0107 ( 2.1175) Learning Rate: 0.1000 (0.1000) Top1_base: 50.7812 (44.0885) Top1_base_per_class: 51.4536 (44.3545) 
Training Epoch: [8/1000] Step: [220 / 285] Batch Time: 0.1421 (0.1590) Data Time: 0.0105 (0.0263) Average Loss: 2.2499 (2.1174) Average CE Loss (Source):  2.2499 ( 2.1174) Learning Rate: 0.1000 (0.1000) Top1_base: 39.0625 (44.0376) Top1_base_per_class: 44.3452 (44.3237) 
Training Epoch: [8/1000] Step: [230 / 285] Batch Time: 0.1423 (0.1589) Data Time: 0.0107 (0.0263) Average Loss: 2.2247 (2.1171) Average CE Loss (Source):  2.2247 ( 2.1171) Learning Rate: 0.1000 (0.1000) Top1_base: 46.0938 (44.0625) Top1_base_per_class: 50.8485 (44.4768) 
Training Epoch: [8/1000] Step: [240 / 285] Batch Time: 0.1434 (0.1584) Data Time: 0.0107 (0.0258) Average Loss: 2.0160 (2.1170) Average CE Loss (Source):  2.0160 ( 2.1170) Learning Rate: 0.1000 (0.1000) Top1_base: 51.5625 (44.1276) Top1_base_per_class: 51.4689 (44.4879) 
Training Epoch: [8/1000] Step: [250 / 285] Batch Time: 0.1454 (0.1579) Data Time: 0.0128 (0.0253) Average Loss: 2.2584 (2.1176) Average CE Loss (Source):  2.2584 ( 2.1176) Learning Rate: 0.1000 (0.1000) Top1_base: 43.7500 (44.0688) Top1_base_per_class: 46.1310 (44.4416) 
Training Epoch: [8/1000] Step: [260 / 285] Batch Time: 0.1433 (0.1576) Data Time: 0.0102 (0.0251) Average Loss: 2.1486 (2.1167) Average CE Loss (Source):  2.1486 ( 2.1167) Learning Rate: 0.1000 (0.1000) Top1_base: 49.2188 (44.1076) Top1_base_per_class: 51.2668 (44.5168) 
Training Epoch: [8/1000] Step: [270 / 285] Batch Time: 0.1440 (0.1572) Data Time: 0.0125 (0.0247) Average Loss: 2.2344 (2.1179) Average CE Loss (Source):  2.2344 ( 2.1179) Learning Rate: 0.1000 (0.1000) Top1_base: 43.7500 (44.0596) Top1_base_per_class: 49.2942 (44.5177) 
Training Epoch: [8/1000] Step: [280 / 285] Batch Time: 0.1410 (0.1574) Data Time: 0.0097 (0.0249) Average Loss: 2.0326 (2.1162) Average CE Loss (Source):  2.0326 ( 2.1162) Learning Rate: 0.1000 (0.1000) Top1_base: 42.1875 (44.0653) Top1_base_per_class: 44.0156 (44.5418) 
Training Epoch: [9/1000] Step: [0] Batch Time: 0.1410 (0.1573) Data Time: 0.0097 (0.0248) Average Loss: 2.4028 (2.1171) Average CE Loss (Source):  2.4028 ( 2.1171) Learning Rate: 0.1000 (0.1000) Top1_base: 35.1562 (44.0022) Top1_base_per_class: 36.8391 (44.5064) 
Training Epoch: [9/1000] Step: [10 / 285] Batch Time: 0.1428 (0.2288) Data Time: 0.0117 (0.0961) Average Loss: 2.1275 (2.0891) Average CE Loss (Source):  2.1275 ( 2.0891) Learning Rate: 0.1000 (0.1000) Top1_base: 44.5312 (43.8281) Top1_base_per_class: 43.8388 (44.3538) 
Training Epoch: [9/1000] Step: [20 / 285] Batch Time: 0.1435 (0.1925) Data Time: 0.0118 (0.0602) Average Loss: 2.2527 (2.1021) Average CE Loss (Source):  2.2527 ( 2.1021) Learning Rate: 0.1000 (0.1000) Top1_base: 45.3125 (44.7266) Top1_base_per_class: 47.6603 (45.4300) 
Training Epoch: [9/1000] Step: [30 / 285] Batch Time: 0.1393 (0.1849) Data Time: 0.0102 (0.0530) Average Loss: 2.2141 (2.0781) Average CE Loss (Source):  2.2141 ( 2.0781) Learning Rate: 0.1000 (0.1000) Top1_base: 44.5312 (45.0781) Top1_base_per_class: 45.8667 (45.4394) 
Training Epoch: [9/1000] Step: [40 / 285] Batch Time: 0.1441 (0.1797) Data Time: 0.0109 (0.0476) Average Loss: 2.0544 (2.0893) Average CE Loss (Source):  2.0544 ( 2.0893) Learning Rate: 0.1000 (0.1000) Top1_base: 44.5312 (45.0000) Top1_base_per_class: 50.4971 (45.7230) 
Training Epoch: [9/1000] Step: [50 / 285] Batch Time: 0.2551 (0.1767) Data Time: 0.1232 (0.0445) Average Loss: 2.0712 (2.0788) Average CE Loss (Source):  2.0712 ( 2.0788) Learning Rate: 0.1000 (0.1000) Top1_base: 42.9688 (45.1250) Top1_base_per_class: 43.9766 (45.7560) 
Training Epoch: [9/1000] Step: [60 / 285] Batch Time: 0.1448 (0.1727) Data Time: 0.0114 (0.0403) Average Loss: 2.3249 (2.0742) Average CE Loss (Source):  2.3249 ( 2.0742) Learning Rate: 0.1000 (0.1000) Top1_base: 34.3750 (45.0391) Top1_base_per_class: 34.3391 (45.4114) 
Training Epoch: [9/1000] Step: [70 / 285] Batch Time: 0.1487 (0.1713) Data Time: 0.0170 (0.0389) Average Loss: 2.0614 (2.0765) Average CE Loss (Source):  2.0614 ( 2.0765) Learning Rate: 0.1000 (0.1000) Top1_base: 44.5312 (44.8772) Top1_base_per_class: 48.3025 (45.3445) 
Training Epoch: [9/1000] Step: [80 / 285] Batch Time: 0.1462 (0.1700) Data Time: 0.0131 (0.0375) Average Loss: 2.0654 (2.0668) Average CE Loss (Source):  2.0654 ( 2.0668) Learning Rate: 0.1000 (0.1000) Top1_base: 46.8750 (45.0391) Top1_base_per_class: 42.2778 (45.6158) 
Training Epoch: [9/1000] Step: [90 / 285] Batch Time: 0.1459 (0.1686) Data Time: 0.0114 (0.0359) Average Loss: 1.8664 (2.0672) Average CE Loss (Source):  1.8664 ( 2.0672) Learning Rate: 0.1000 (0.1000) Top1_base: 49.2188 (45.0174) Top1_base_per_class: 49.6505 (45.5868) 
Training Epoch: [9/1000] Step: [100 / 285] Batch Time: 0.1418 (0.1673) Data Time: 0.0117 (0.0347) Average Loss: 1.9015 (2.0647) Average CE Loss (Source):  1.9015 ( 2.0647) Learning Rate: 0.1000 (0.1000) Top1_base: 45.3125 (45.1875) Top1_base_per_class: 48.6792 (45.8554) 
Training Epoch: [9/1000] Step: [110 / 285] Batch Time: 0.1430 (0.1657) Data Time: 0.0113 (0.0330) Average Loss: 2.0726 (2.0623) Average CE Loss (Source):  2.0726 ( 2.0623) Learning Rate: 0.1000 (0.1000) Top1_base: 45.3125 (45.2770) Top1_base_per_class: 45.5655 (45.8688) 
Training Epoch: [9/1000] Step: [120 / 285] Batch Time: 0.2023 (0.1648) Data Time: 0.0699 (0.0322) Average Loss: 2.1637 (2.0582) Average CE Loss (Source):  2.1637 ( 2.0582) Learning Rate: 0.1000 (0.1000) Top1_base: 42.9688 (45.4102) Top1_base_per_class: 44.1243 (45.9538) 
Training Epoch: [9/1000] Step: [130 / 285] Batch Time: 0.1419 (0.1639) Data Time: 0.0108 (0.0313) Average Loss: 2.1682 (2.0541) Average CE Loss (Source):  2.1682 ( 2.0541) Learning Rate: 0.1000 (0.1000) Top1_base: 42.9688 (45.4748) Top1_base_per_class: 43.9286 (46.0319) 
Training Epoch: [9/1000] Step: [140 / 285] Batch Time: 0.2547 (0.1650) Data Time: 0.1232 (0.0325) Average Loss: 2.2845 (2.0545) Average CE Loss (Source):  2.2845 ( 2.0545) Learning Rate: 0.1000 (0.1000) Top1_base: 42.1875 (45.4185) Top1_base_per_class: 42.4859 (46.0062) 
Training Epoch: [9/1000] Step: [150 / 285] Batch Time: 0.1439 (0.1648) Data Time: 0.0105 (0.0322) Average Loss: 1.8777 (2.0471) Average CE Loss (Source):  1.8777 ( 2.0471) Learning Rate: 0.1000 (0.1000) Top1_base: 46.8750 (45.6094) Top1_base_per_class: 45.3846 (46.1767) 
Training Epoch: [9/1000] Step: [160 / 285] Batch Time: 0.3425 (0.1659) Data Time: 0.2116 (0.0333) Average Loss: 1.9884 (2.0453) Average CE Loss (Source):  1.9884 ( 2.0453) Learning Rate: 0.1000 (0.1000) Top1_base: 46.0938 (45.6250) Top1_base_per_class: 44.7321 (46.1378) 
Training Epoch: [9/1000] Step: [170 / 285] Batch Time: 0.1455 (0.1655) Data Time: 0.0134 (0.0330) Average Loss: 2.0385 (2.0421) Average CE Loss (Source):  2.0385 ( 2.0421) Learning Rate: 0.1000 (0.1000) Top1_base: 46.8750 (45.7675) Top1_base_per_class: 48.9943 (46.2764) 
Training Epoch: [9/1000] Step: [180 / 285] Batch Time: 0.2083 (0.1656) Data Time: 0.0758 (0.0330) Average Loss: 1.9307 (2.0401) Average CE Loss (Source):  1.9307 ( 2.0401) Learning Rate: 0.1000 (0.1000) Top1_base: 50.7812 (45.7943) Top1_base_per_class: 53.6728 (46.2178) 
Training Epoch: [9/1000] Step: [190 / 285] Batch Time: 0.1441 (0.1653) Data Time: 0.0114 (0.0327) Average Loss: 2.1111 (2.0426) Average CE Loss (Source):  2.1111 ( 2.0426) Learning Rate: 0.1000 (0.1000) Top1_base: 42.9688 (45.6661) Top1_base_per_class: 43.0670 (46.0333) 
Training Epoch: [9/1000] Step: [200 / 285] Batch Time: 0.2242 (0.1652) Data Time: 0.0917 (0.0325) Average Loss: 1.8840 (2.0422) Average CE Loss (Source):  1.8840 ( 2.0422) Learning Rate: 0.1000 (0.1000) Top1_base: 51.5625 (45.7617) Top1_base_per_class: 53.8788 (46.1579) 
Training Epoch: [9/1000] Step: [210 / 285] Batch Time: 0.1469 (0.1648) Data Time: 0.0134 (0.0321) Average Loss: 1.8329 (2.0425) Average CE Loss (Source):  1.8329 ( 2.0425) Learning Rate: 0.1000 (0.1000) Top1_base: 54.6875 (45.8147) Top1_base_per_class: 54.7012 (46.1572) 
Training Epoch: [9/1000] Step: [220 / 285] Batch Time: 0.2152 (0.1649) Data Time: 0.0835 (0.0321) Average Loss: 2.0415 (2.0418) Average CE Loss (Source):  2.0415 ( 2.0418) Learning Rate: 0.1000 (0.1000) Top1_base: 52.3438 (45.8523) Top1_base_per_class: 51.0377 (46.1914) 
Training Epoch: [9/1000] Step: [230 / 285] Batch Time: 0.1435 (0.1648) Data Time: 0.0120 (0.0320) Average Loss: 1.9383 (2.0401) Average CE Loss (Source):  1.9383 ( 2.0401) Learning Rate: 0.1000 (0.1000) Top1_base: 48.4375 (45.8865) Top1_base_per_class: 47.0760 (46.1766) 
Training Epoch: [9/1000] Step: [240 / 285] Batch Time: 0.2284 (0.1647) Data Time: 0.0979 (0.0320) Average Loss: 2.2571 (2.0394) Average CE Loss (Source):  2.2571 ( 2.0394) Learning Rate: 0.1000 (0.1000) Top1_base: 39.8438 (45.9310) Top1_base_per_class: 46.0303 (46.2570) 
Training Epoch: [9/1000] Step: [250 / 285] Batch Time: 0.1442 (0.1649) Data Time: 0.0125 (0.0322) Average Loss: 1.7970 (2.0369) Average CE Loss (Source):  1.7970 ( 2.0369) Learning Rate: 0.1000 (0.1000) Top1_base: 53.1250 (46.0250) Top1_base_per_class: 55.0926 (46.3635) 
Training Epoch: [9/1000] Step: [260 / 285] Batch Time: 0.2069 (0.1652) Data Time: 0.0716 (0.0325) Average Loss: 2.1834 (2.0361) Average CE Loss (Source):  2.1834 ( 2.0361) Learning Rate: 0.1000 (0.1000) Top1_base: 44.5312 (46.0096) Top1_base_per_class: 41.7251 (46.3045) 
Training Epoch: [9/1000] Step: [270 / 285] Batch Time: 0.1436 (0.1647) Data Time: 0.0109 (0.0320) Average Loss: 2.1278 (2.0338) Average CE Loss (Source):  2.1278 ( 2.0338) Learning Rate: 0.1000 (0.1000) Top1_base: 45.3125 (46.0764) Top1_base_per_class: 46.2424 (46.4131) 
Training Epoch: [9/1000] Step: [280 / 285] Batch Time: 0.1492 (0.1644) Data Time: 0.0179 (0.0316) Average Loss: 1.8189 (2.0338) Average CE Loss (Source):  1.8189 ( 2.0338) Learning Rate: 0.1000 (0.1000) Top1_base: 47.6562 (46.0379) Top1_base_per_class: 44.5193 (46.3657) 
Training Epoch: [10/1000] Step: [0] Batch Time: 0.1409 (0.1641) Data Time: 0.0096 (0.0314) Average Loss: 2.1535 (2.0337) Average CE Loss (Source):  2.1535 ( 2.0337) Learning Rate: 0.1000 (0.1000) Top1_base: 44.5312 (46.0280) Top1_base_per_class: 46.4151 (46.3525) 
  1%|          | 10/1000 [08:04<13:14:02, 48.12s/it]  1%|          | 11/1000 [08:50<13:06:39, 47.72s/it]Training Epoch: [10/1000] Step: [10 / 285] Batch Time: 0.1420 (0.2370) Data Time: 0.0123 (0.1059) Average Loss: 2.0336 (1.9114) Average CE Loss (Source):  2.0336 ( 1.9114) Learning Rate: 0.1000 (0.1000) Top1_base: 46.0938 (47.6562) Top1_base_per_class: 51.3333 (48.1412) 
Training Epoch: [10/1000] Step: [20 / 285] Batch Time: 0.1413 (0.1965) Data Time: 0.0105 (0.0656) Average Loss: 2.1522 (1.9408) Average CE Loss (Source):  2.1522 ( 1.9408) Learning Rate: 0.1000 (0.1000) Top1_base: 44.5312 (48.9453) Top1_base_per_class: 45.9524 (49.6181) 
Training Epoch: [10/1000] Step: [30 / 285] Batch Time: 0.1472 (0.1883) Data Time: 0.0137 (0.0569) Average Loss: 1.9768 (1.9590) Average CE Loss (Source):  1.9768 ( 1.9590) Learning Rate: 0.1000 (0.1000) Top1_base: 51.5625 (48.6979) Top1_base_per_class: 50.4422 (49.4296) 
Training Epoch: [10/1000] Step: [40 / 285] Batch Time: 0.1455 (0.1817) Data Time: 0.0131 (0.0498) Average Loss: 2.0335 (1.9520) Average CE Loss (Source):  2.0335 ( 1.9520) Learning Rate: 0.1000 (0.1000) Top1_base: 43.7500 (48.5938) Top1_base_per_class: 48.9583 (49.3683) 
Training Epoch: [10/1000] Step: [50 / 285] Batch Time: 0.1448 (0.1804) Data Time: 0.0125 (0.0484) Average Loss: 1.8627 (1.9501) Average CE Loss (Source):  1.8627 ( 1.9501) Learning Rate: 0.1000 (0.1000) Top1_base: 51.5625 (48.7031) Top1_base_per_class: 50.1462 (49.3643) 
Training Epoch: [10/1000] Step: [60 / 285] Batch Time: 0.1451 (0.1774) Data Time: 0.0130 (0.0453) Average Loss: 1.9852 (1.9448) Average CE Loss (Source):  1.9852 ( 1.9448) Learning Rate: 0.1000 (0.1000) Top1_base: 45.3125 (48.7630) Top1_base_per_class: 45.2424 (49.4857) 
Training Epoch: [10/1000] Step: [70 / 285] Batch Time: 0.1458 (0.1791) Data Time: 0.0114 (0.0468) Average Loss: 1.8831 (1.9434) Average CE Loss (Source):  1.8831 ( 1.9434) Learning Rate: 0.1000 (0.1000) Top1_base: 50.7812 (48.4598) Top1_base_per_class: 49.7874 (49.0972) 
Training Epoch: [10/1000] Step: [80 / 285] Batch Time: 0.1418 (0.1761) Data Time: 0.0111 (0.0437) Average Loss: 1.8742 (1.9456) Average CE Loss (Source):  1.8742 ( 1.9456) Learning Rate: 0.1000 (0.1000) Top1_base: 50.0000 (48.4180) Top1_base_per_class: 53.0861 (49.0957) 
Training Epoch: [10/1000] Step: [90 / 285] Batch Time: 0.1434 (0.1758) Data Time: 0.0108 (0.0434) Average Loss: 2.1885 (1.9459) Average CE Loss (Source):  2.1885 ( 1.9459) Learning Rate: 0.1000 (0.1000) Top1_base: 45.3125 (48.4375) Top1_base_per_class: 46.0057 (49.0271) 
Training Epoch: [10/1000] Step: [100 / 285] Batch Time: 0.1453 (0.1743) Data Time: 0.0125 (0.0419) Average Loss: 1.8563 (1.9415) Average CE Loss (Source):  1.8563 ( 1.9415) Learning Rate: 0.1000 (0.1000) Top1_base: 52.3438 (48.5391) Top1_base_per_class: 53.3333 (49.1478) 
Training Epoch: [10/1000] Step: [110 / 285] Batch Time: 0.1429 (0.1718) Data Time: 0.0106 (0.0394) Average Loss: 1.9735 (1.9444) Average CE Loss (Source):  1.9735 ( 1.9444) Learning Rate: 0.1000 (0.1000) Top1_base: 46.8750 (48.3594) Top1_base_per_class: 50.8475 (48.9539) 
Training Epoch: [10/1000] Step: [120 / 285] Batch Time: 0.1421 (0.1702) Data Time: 0.0106 (0.0378) Average Loss: 1.8830 (1.9528) Average CE Loss (Source):  1.8830 ( 1.9528) Learning Rate: 0.1000 (0.1000) Top1_base: 49.2188 (48.0404) Top1_base_per_class: 50.1786 (48.7322) 
Training Epoch: [10/1000] Step: [130 / 285] Batch Time: 0.1425 (0.1696) Data Time: 0.0097 (0.0372) Average Loss: 2.1728 (1.9508) Average CE Loss (Source):  2.1728 ( 1.9508) Learning Rate: 0.1000 (0.1000) Top1_base: 41.4062 (48.0889) Top1_base_per_class: 39.4345 (48.6747) 
Training Epoch: [10/1000] Step: [140 / 285] Batch Time: 0.1453 (0.1688) Data Time: 0.0101 (0.0363) Average Loss: 1.8304 (1.9496) Average CE Loss (Source):  1.8304 ( 1.9496) Learning Rate: 0.1000 (0.1000) Top1_base: 53.1250 (48.1417) Top1_base_per_class: 52.1212 (48.6596) 
Training Epoch: [10/1000] Step: [150 / 285] Batch Time: 0.1437 (0.1690) Data Time: 0.0103 (0.0365) Average Loss: 2.0434 (1.9538) Average CE Loss (Source):  2.0434 ( 1.9538) Learning Rate: 0.1000 (0.1000) Top1_base: 45.3125 (47.9062) Top1_base_per_class: 46.5705 (48.3759) 
Training Epoch: [10/1000] Step: [160 / 285] Batch Time: 0.1455 (0.1684) Data Time: 0.0104 (0.0358) Average Loss: 2.1366 (1.9522) Average CE Loss (Source):  2.1366 ( 1.9522) Learning Rate: 0.1000 (0.1000) Top1_base: 41.4062 (48.0078) Top1_base_per_class: 44.7917 (48.5509) 
Training Epoch: [10/1000] Step: [170 / 285] Batch Time: 0.1476 (0.1676) Data Time: 0.0122 (0.0349) Average Loss: 2.0771 (1.9540) Average CE Loss (Source):  2.0771 ( 1.9540) Learning Rate: 0.1000 (0.1000) Top1_base: 47.6562 (47.9733) Top1_base_per_class: 46.9006 (48.4240) 
Training Epoch: [10/1000] Step: [180 / 285] Batch Time: 0.1478 (0.1667) Data Time: 0.0135 (0.0339) Average Loss: 1.8369 (1.9530) Average CE Loss (Source):  1.8369 ( 1.9530) Learning Rate: 0.1000 (0.1000) Top1_base: 48.4375 (47.9601) Top1_base_per_class: 50.9295 (48.4082) 
Training Epoch: [10/1000] Step: [190 / 285] Batch Time: 0.1437 (0.1660) Data Time: 0.0118 (0.0331) Average Loss: 2.0116 (1.9507) Average CE Loss (Source):  2.0116 ( 1.9507) Learning Rate: 0.1000 (0.1000) Top1_base: 46.0938 (47.9441) Top1_base_per_class: 49.8485 (48.3636) 
Training Epoch: [10/1000] Step: [200 / 285] Batch Time: 0.1485 (0.1656) Data Time: 0.0154 (0.0328) Average Loss: 1.8936 (1.9496) Average CE Loss (Source):  1.8936 ( 1.9496) Learning Rate: 0.1000 (0.1000) Top1_base: 48.4375 (47.9258) Top1_base_per_class: 51.8421 (48.2841) 
Training Epoch: [10/1000] Step: [210 / 285] Batch Time: 0.1452 (0.1654) Data Time: 0.0104 (0.0324) Average Loss: 1.9936 (1.9473) Average CE Loss (Source):  1.9936 ( 1.9473) Learning Rate: 0.1000 (0.1000) Top1_base: 45.3125 (48.0022) Top1_base_per_class: 43.7037 (48.3580) 
Training Epoch: [10/1000] Step: [220 / 285] Batch Time: 0.1490 (0.1647) Data Time: 0.0171 (0.0317) Average Loss: 1.9321 (1.9461) Average CE Loss (Source):  1.9321 ( 1.9461) Learning Rate: 0.1000 (0.1000) Top1_base: 46.0938 (48.1143) Top1_base_per_class: 45.4321 (48.5167) 
Training Epoch: [10/1000] Step: [230 / 285] Batch Time: 0.1441 (0.1650) Data Time: 0.0123 (0.0320) Average Loss: 1.9342 (1.9483) Average CE Loss (Source):  1.9342 ( 1.9483) Learning Rate: 0.1000 (0.1000) Top1_base: 51.5625 (48.0842) Top1_base_per_class: 47.7469 (48.4554) 
Training Epoch: [10/1000] Step: [240 / 285] Batch Time: 0.1449 (0.1645) Data Time: 0.0132 (0.0316) Average Loss: 1.8318 (1.9464) Average CE Loss (Source):  1.8318 ( 1.9464) Learning Rate: 0.1000 (0.1000) Top1_base: 47.6562 (48.1087) Top1_base_per_class: 47.2577 (48.4954) 
Training Epoch: [10/1000] Step: [250 / 285] Batch Time: 0.1458 (0.1649) Data Time: 0.0130 (0.0319) Average Loss: 1.9318 (1.9443) Average CE Loss (Source):  1.9318 ( 1.9443) Learning Rate: 0.1000 (0.1000) Top1_base: 46.0938 (48.1063) Top1_base_per_class: 47.8042 (48.5276) 
Training Epoch: [10/1000] Step: [260 / 285] Batch Time: 0.1484 (0.1642) Data Time: 0.0126 (0.0312) Average Loss: 1.6283 (1.9403) Average CE Loss (Source):  1.6283 ( 1.9403) Learning Rate: 0.1000 (0.1000) Top1_base: 55.4688 (48.1971) Top1_base_per_class: 53.9766 (48.6352) 
Training Epoch: [10/1000] Step: [270 / 285] Batch Time: 0.1466 (0.1638) Data Time: 0.0140 (0.0308) Average Loss: 1.8808 (1.9406) Average CE Loss (Source):  1.8808 ( 1.9406) Learning Rate: 0.1000 (0.1000) Top1_base: 43.7500 (48.2292) Top1_base_per_class: 47.3512 (48.6641) 
Training Epoch: [10/1000] Step: [280 / 285] Batch Time: 0.3681 (0.1642) Data Time: 0.2379 (0.0312) Average Loss: 1.8207 (1.9390) Average CE Loss (Source):  1.8207 ( 1.9390) Learning Rate: 0.1000 (0.1000) Top1_base: 55.4688 (48.2729) Top1_base_per_class: 52.6276 (48.6721) 
Training Epoch: [11/1000] Step: [0] Batch Time: 0.1415 (0.1640) Data Time: 0.0109 (0.0310) Average Loss: 2.1420 (1.9386) Average CE Loss (Source):  2.1420 ( 1.9386) Learning Rate: 0.1000 (0.1000) Top1_base: 46.0938 (48.2977) Top1_base_per_class: 47.1955 (48.7594) 
Training Epoch: [11/1000] Step: [10 / 285] Batch Time: 0.1439 (0.2317) Data Time: 0.0133 (0.1000) Average Loss: 1.8408 (1.9382) Average CE Loss (Source):  1.8408 ( 1.9382) Learning Rate: 0.1000 (0.1000) Top1_base: 50.0000 (49.1406) Top1_base_per_class: 50.9615 (49.3755) 
Training Epoch: [11/1000] Step: [20 / 285] Batch Time: 0.1484 (0.1947) Data Time: 0.0155 (0.0630) Average Loss: 1.9499 (1.8723) Average CE Loss (Source):  1.9499 ( 1.8723) Learning Rate: 0.1000 (0.1000) Top1_base: 47.6562 (50.0781) Top1_base_per_class: 47.4259 (50.3033) 
Training Epoch: [11/1000] Step: [30 / 285] Batch Time: 0.2058 (0.1862) Data Time: 0.0750 (0.0545) Average Loss: 1.8321 (1.8467) Average CE Loss (Source):  1.8321 ( 1.8467) Learning Rate: 0.1000 (0.1000) Top1_base: 57.0312 (51.0938) Top1_base_per_class: 58.7772 (51.3225) 
Training Epoch: [11/1000] Step: [40 / 285] Batch Time: 0.2485 (0.1820) Data Time: 0.1179 (0.0504) Average Loss: 1.8141 (1.8397) Average CE Loss (Source):  1.8141 ( 1.8397) Learning Rate: 0.1000 (0.1000) Top1_base: 50.7812 (50.7812) Top1_base_per_class: 53.2121 (51.1948) 
Training Epoch: [11/1000] Step: [50 / 285] Batch Time: 0.1435 (0.1799) Data Time: 0.0126 (0.0483) Average Loss: 1.8335 (1.8497) Average CE Loss (Source):  1.8335 ( 1.8497) Learning Rate: 0.1000 (0.1000) Top1_base: 47.6562 (50.3125) Top1_base_per_class: 42.1839 (50.5346) 
Training Epoch: [11/1000] Step: [60 / 285] Batch Time: 0.3035 (0.1784) Data Time: 0.1726 (0.0469) Average Loss: 1.9851 (1.8405) Average CE Loss (Source):  1.9851 ( 1.8405) Learning Rate: 0.1000 (0.1000) Top1_base: 47.6562 (50.5078) Top1_base_per_class: 43.8701 (50.5734) 
Training Epoch: [11/1000] Step: [70 / 285] Batch Time: 0.1422 (0.1756) Data Time: 0.0112 (0.0441) Average Loss: 1.9016 (1.8519) Average CE Loss (Source):  1.9016 ( 1.8519) Learning Rate: 0.1000 (0.1000) Top1_base: 48.4375 (50.2567) Top1_base_per_class: 50.3819 (50.3723) 
Training Epoch: [11/1000] Step: [80 / 285] Batch Time: 0.2543 (0.1756) Data Time: 0.1237 (0.0441) Average Loss: 1.8225 (1.8483) Average CE Loss (Source):  1.8225 ( 1.8483) Learning Rate: 0.1000 (0.1000) Top1_base: 44.5312 (50.3027) Top1_base_per_class: 46.3158 (50.6454) 
Training Epoch: [11/1000] Step: [90 / 285] Batch Time: 0.1416 (0.1740) Data Time: 0.0113 (0.0426) Average Loss: 1.7329 (1.8495) Average CE Loss (Source):  1.7329 ( 1.8495) Learning Rate: 0.1000 (0.1000) Top1_base: 55.4688 (50.2083) Top1_base_per_class: 57.4405 (50.5098) 
Training Epoch: [11/1000] Step: [100 / 285] Batch Time: 0.2052 (0.1732) Data Time: 0.0756 (0.0418) Average Loss: 2.0042 (1.8511) Average CE Loss (Source):  2.0042 ( 1.8511) Learning Rate: 0.1000 (0.1000) Top1_base: 46.8750 (50.1562) Top1_base_per_class: 49.3518 (50.5280) 
Training Epoch: [11/1000] Step: [110 / 285] Batch Time: 0.1417 (0.1717) Data Time: 0.0107 (0.0404) Average Loss: 1.7281 (1.8505) Average CE Loss (Source):  1.7281 ( 1.8505) Learning Rate: 0.1000 (0.1000) Top1_base: 54.6875 (50.2344) Top1_base_per_class: 59.5238 (50.5067) 
Training Epoch: [11/1000] Step: [120 / 285] Batch Time: 0.2124 (0.1715) Data Time: 0.0816 (0.0401) Average Loss: 1.7409 (1.8510) Average CE Loss (Source):  1.7409 ( 1.8510) Learning Rate: 0.1000 (0.1000) Top1_base: 53.1250 (50.2865) Top1_base_per_class: 58.9181 (50.6264) 
Training Epoch: [11/1000] Step: [130 / 285] Batch Time: 0.1410 (0.1699) Data Time: 0.0106 (0.0387) Average Loss: 1.9028 (1.8477) Average CE Loss (Source):  1.9028 ( 1.8477) Learning Rate: 0.1000 (0.1000) Top1_base: 48.4375 (50.3906) Top1_base_per_class: 53.1593 (50.6853) 
Training Epoch: [11/1000] Step: [140 / 285] Batch Time: 0.1725 (0.1690) Data Time: 0.0422 (0.0377) Average Loss: 1.9862 (1.8466) Average CE Loss (Source):  1.9862 ( 1.8466) Learning Rate: 0.1000 (0.1000) Top1_base: 45.3125 (50.4185) Top1_base_per_class: 49.6364 (50.7699) 
Training Epoch: [11/1000] Step: [150 / 285] Batch Time: 0.1424 (0.1684) Data Time: 0.0112 (0.0372) Average Loss: 1.8554 (1.8468) Average CE Loss (Source):  1.8554 ( 1.8468) Learning Rate: 0.1000 (0.1000) Top1_base: 50.0000 (50.4323) Top1_base_per_class: 50.5541 (50.7636) 
Training Epoch: [11/1000] Step: [160 / 285] Batch Time: 0.2132 (0.1678) Data Time: 0.0829 (0.0365) Average Loss: 2.2258 (1.8516) Average CE Loss (Source):  2.2258 ( 1.8516) Learning Rate: 0.1000 (0.1000) Top1_base: 47.6562 (50.4395) Top1_base_per_class: 44.9221 (50.6712) 
Training Epoch: [11/1000] Step: [170 / 285] Batch Time: 0.1426 (0.1667) Data Time: 0.0116 (0.0355) Average Loss: 1.8401 (1.8525) Average CE Loss (Source):  1.8401 ( 1.8525) Learning Rate: 0.1000 (0.1000) Top1_base: 55.4688 (50.5055) Top1_base_per_class: 52.1053 (50.7227) 
Training Epoch: [11/1000] Step: [180 / 285] Batch Time: 0.2374 (0.1663) Data Time: 0.1049 (0.0350) Average Loss: 2.0160 (1.8523) Average CE Loss (Source):  2.0160 ( 1.8523) Learning Rate: 0.1000 (0.1000) Top1_base: 39.0625 (50.3646) Top1_base_per_class: 43.0172 (50.5930) 
Training Epoch: [11/1000] Step: [190 / 285] Batch Time: 0.1441 (0.1655) Data Time: 0.0126 (0.0342) Average Loss: 1.8517 (1.8554) Average CE Loss (Source):  1.8517 ( 1.8554) Learning Rate: 0.1000 (0.1000) Top1_base: 49.2188 (50.2714) Top1_base_per_class: 46.8651 (50.5109) 
Training Epoch: [11/1000] Step: [200 / 285] Batch Time: 0.1449 (0.1651) Data Time: 0.0131 (0.0338) Average Loss: 1.7694 (1.8550) Average CE Loss (Source):  1.7694 ( 1.8550) Learning Rate: 0.1000 (0.1000) Top1_base: 55.4688 (50.3711) Top1_base_per_class: 56.9006 (50.5712) 
Training Epoch: [11/1000] Step: [210 / 285] Batch Time: 0.1426 (0.1644) Data Time: 0.0120 (0.0331) Average Loss: 1.7441 (1.8519) Average CE Loss (Source):  1.7441 ( 1.8519) Learning Rate: 0.1000 (0.1000) Top1_base: 52.3438 (50.4948) Top1_base_per_class: 52.1212 (50.6360) 
Training Epoch: [11/1000] Step: [220 / 285] Batch Time: 0.1819 (0.1639) Data Time: 0.0507 (0.0326) Average Loss: 1.6862 (1.8483) Average CE Loss (Source):  1.6862 ( 1.8483) Learning Rate: 0.1000 (0.1000) Top1_base: 57.8125 (50.5149) Top1_base_per_class: 55.4237 (50.6816) 
Training Epoch: [11/1000] Step: [230 / 285] Batch Time: 0.1424 (0.1637) Data Time: 0.0113 (0.0324) Average Loss: 1.7530 (1.8480) Average CE Loss (Source):  1.7530 ( 1.8480) Learning Rate: 0.1000 (0.1000) Top1_base: 56.2500 (50.5299) Top1_base_per_class: 57.7778 (50.7881) 
Training Epoch: [11/1000] Step: [240 / 285] Batch Time: 0.1859 (0.1631) Data Time: 0.0547 (0.0318) Average Loss: 1.6164 (1.8458) Average CE Loss (Source):  1.6164 ( 1.8458) Learning Rate: 0.1000 (0.1000) Top1_base: 56.2500 (50.5208) Top1_base_per_class: 56.9253 (50.8514) 
Training Epoch: [11/1000] Step: [250 / 285] Batch Time: 0.1440 (0.1626) Data Time: 0.0122 (0.0313) Average Loss: 1.8195 (1.8471) Average CE Loss (Source):  1.8195 ( 1.8471) Learning Rate: 0.1000 (0.1000) Top1_base: 51.5625 (50.4594) Top1_base_per_class: 51.9136 (50.7339) 
Training Epoch: [11/1000] Step: [260 / 285] Batch Time: 0.2227 (0.1624) Data Time: 0.0918 (0.0311) Average Loss: 1.7519 (1.8479) Average CE Loss (Source):  1.7519 ( 1.8479) Learning Rate: 0.1000 (0.1000) Top1_base: 49.2188 (50.4207) Top1_base_per_class: 48.8983 (50.7093) 
Training Epoch: [11/1000] Step: [270 / 285] Batch Time: 0.1433 (0.1620) Data Time: 0.0110 (0.0307) Average Loss: 1.9277 (1.8479) Average CE Loss (Source):  1.9277 ( 1.8479) Learning Rate: 0.1000 (0.1000) Top1_base: 49.2188 (50.4630) Top1_base_per_class: 45.1754 (50.8013) 
Training Epoch: [11/1000] Step: [280 / 285] Batch Time: 0.1811 (0.1619) Data Time: 0.0507 (0.0306) Average Loss: 1.6820 (1.8477) Average CE Loss (Source):  1.6820 ( 1.8477) Learning Rate: 0.1000 (0.1000) Top1_base: 60.1562 (50.5385) Top1_base_per_class: 61.4151 (50.8590) 
Training Epoch: [12/1000] Step: [0] Batch Time: 0.1376 (0.1617) Data Time: 0.0091 (0.0304) Average Loss: 1.8396 (1.8484) Average CE Loss (Source):  1.8396 ( 1.8484) Learning Rate: 0.1000 (0.1000) Top1_base: 45.3125 (50.4962) Top1_base_per_class: 47.2121 (50.8336) 
  1%|          | 12/1000 [09:39<13:11:46, 48.08s/it]  1%|▏         | 13/1000 [10:26<13:04:23, 47.68s/it]Training Epoch: [12/1000] Step: [10 / 285] Batch Time: 0.1421 (0.2312) Data Time: 0.0121 (0.0997) Average Loss: 1.9810 (1.7805) Average CE Loss (Source):  1.9810 ( 1.7805) Learning Rate: 0.1000 (0.1000) Top1_base: 46.0938 (52.5781) Top1_base_per_class: 50.0303 (53.4773) 
Training Epoch: [12/1000] Step: [20 / 285] Batch Time: 0.1471 (0.1947) Data Time: 0.0139 (0.0631) Average Loss: 1.7327 (1.7789) Average CE Loss (Source):  1.7327 ( 1.7789) Learning Rate: 0.1000 (0.1000) Top1_base: 54.6875 (52.4609) Top1_base_per_class: 53.1967 (53.1297) 
Training Epoch: [12/1000] Step: [30 / 285] Batch Time: 0.1454 (0.1876) Data Time: 0.0138 (0.0555) Average Loss: 1.9679 (1.7742) Average CE Loss (Source):  1.9679 ( 1.7742) Learning Rate: 0.1000 (0.1000) Top1_base: 45.3125 (52.5000) Top1_base_per_class: 51.5646 (53.6263) 
Training Epoch: [12/1000] Step: [40 / 285] Batch Time: 0.1434 (0.1792) Data Time: 0.0115 (0.0472) Average Loss: 1.5754 (1.7891) Average CE Loss (Source):  1.5754 ( 1.7891) Learning Rate: 0.1000 (0.1000) Top1_base: 52.3438 (51.9727) Top1_base_per_class: 52.4713 (52.5105) 
Training Epoch: [12/1000] Step: [50 / 285] Batch Time: 0.1646 (0.1755) Data Time: 0.0331 (0.0435) Average Loss: 1.6199 (1.8029) Average CE Loss (Source):  1.6199 ( 1.8029) Learning Rate: 0.1000 (0.1000) Top1_base: 53.1250 (51.3906) Top1_base_per_class: 50.7862 (51.6903) 
Training Epoch: [12/1000] Step: [60 / 285] Batch Time: 0.1459 (0.1727) Data Time: 0.0137 (0.0405) Average Loss: 1.9020 (1.7973) Average CE Loss (Source):  1.9020 ( 1.7973) Learning Rate: 0.1000 (0.1000) Top1_base: 48.4375 (51.6406) Top1_base_per_class: 50.9591 (51.9501) 
Training Epoch: [12/1000] Step: [70 / 285] Batch Time: 0.1894 (0.1713) Data Time: 0.0581 (0.0390) Average Loss: 2.0511 (1.8008) Average CE Loss (Source):  2.0511 ( 1.8008) Learning Rate: 0.1000 (0.1000) Top1_base: 50.7812 (51.5848) Top1_base_per_class: 56.0550 (51.9613) 
Training Epoch: [12/1000] Step: [80 / 285] Batch Time: 0.1449 (0.1688) Data Time: 0.0124 (0.0365) Average Loss: 1.7105 (1.7921) Average CE Loss (Source):  1.7105 ( 1.7921) Learning Rate: 0.1000 (0.1000) Top1_base: 55.4688 (51.7188) Top1_base_per_class: 57.1000 (52.0818) 
Training Epoch: [12/1000] Step: [90 / 285] Batch Time: 0.2175 (0.1691) Data Time: 0.0842 (0.0367) Average Loss: 1.6959 (1.7929) Average CE Loss (Source):  1.6959 ( 1.7929) Learning Rate: 0.1000 (0.1000) Top1_base: 55.4688 (51.8056) Top1_base_per_class: 52.6608 (52.1448) 
Training Epoch: [12/1000] Step: [100 / 285] Batch Time: 0.1454 (0.1684) Data Time: 0.0120 (0.0360) Average Loss: 2.0331 (1.7956) Average CE Loss (Source):  2.0331 ( 1.7956) Learning Rate: 0.1000 (0.1000) Top1_base: 50.7812 (51.8906) Top1_base_per_class: 49.5614 (52.2633) 
Training Epoch: [12/1000] Step: [110 / 285] Batch Time: 0.1939 (0.1678) Data Time: 0.0613 (0.0355) Average Loss: 1.6822 (1.7925) Average CE Loss (Source):  1.6822 ( 1.7925) Learning Rate: 0.1000 (0.1000) Top1_base: 53.9062 (51.9176) Top1_base_per_class: 53.6207 (52.2653) 
Training Epoch: [12/1000] Step: [120 / 285] Batch Time: 0.1441 (0.1668) Data Time: 0.0121 (0.0344) Average Loss: 1.9627 (1.7912) Average CE Loss (Source):  1.9627 ( 1.7912) Learning Rate: 0.1000 (0.1000) Top1_base: 46.8750 (51.9336) Top1_base_per_class: 45.7100 (52.2106) 
Training Epoch: [12/1000] Step: [130 / 285] Batch Time: 0.1487 (0.1665) Data Time: 0.0163 (0.0341) Average Loss: 1.6472 (1.7834) Average CE Loss (Source):  1.6472 ( 1.7834) Learning Rate: 0.1000 (0.1000) Top1_base: 53.9062 (52.0312) Top1_base_per_class: 58.8889 (52.3093) 
Training Epoch: [12/1000] Step: [140 / 285] Batch Time: 0.1474 (0.1651) Data Time: 0.0137 (0.0327) Average Loss: 1.8301 (1.7841) Average CE Loss (Source):  1.8301 ( 1.7841) Learning Rate: 0.1000 (0.1000) Top1_base: 50.7812 (52.0145) Top1_base_per_class: 48.1638 (52.2424) 
Training Epoch: [12/1000] Step: [150 / 285] Batch Time: 0.1465 (0.1640) Data Time: 0.0129 (0.0315) Average Loss: 1.6476 (1.7821) Average CE Loss (Source):  1.6476 ( 1.7821) Learning Rate: 0.1000 (0.1000) Top1_base: 55.4688 (51.9948) Top1_base_per_class: 54.6970 (52.2508) 
Training Epoch: [12/1000] Step: [160 / 285] Batch Time: 0.1504 (0.1643) Data Time: 0.0165 (0.0317) Average Loss: 1.5777 (1.7785) Average CE Loss (Source):  1.5777 ( 1.7785) Learning Rate: 0.1000 (0.1000) Top1_base: 60.1562 (52.1680) Top1_base_per_class: 55.4938 (52.4734) 
Training Epoch: [12/1000] Step: [170 / 285] Batch Time: 0.2106 (0.1640) Data Time: 0.0765 (0.0313) Average Loss: 1.6745 (1.7776) Average CE Loss (Source):  1.6745 ( 1.7776) Learning Rate: 0.1000 (0.1000) Top1_base: 52.3438 (52.2426) Top1_base_per_class: 55.6061 (52.5685) 
Training Epoch: [12/1000] Step: [180 / 285] Batch Time: 0.1484 (0.1637) Data Time: 0.0143 (0.0310) Average Loss: 1.6824 (1.7786) Average CE Loss (Source):  1.6824 ( 1.7786) Learning Rate: 0.1000 (0.1000) Top1_base: 55.4688 (52.2309) Top1_base_per_class: 51.4943 (52.5632) 
Training Epoch: [12/1000] Step: [190 / 285] Batch Time: 0.2038 (0.1641) Data Time: 0.0691 (0.0312) Average Loss: 1.9767 (1.7764) Average CE Loss (Source):  1.9767 ( 1.7764) Learning Rate: 0.1000 (0.1000) Top1_base: 49.2188 (52.3026) Top1_base_per_class: 49.6667 (52.6636) 
Training Epoch: [12/1000] Step: [200 / 285] Batch Time: 0.1430 (0.1638) Data Time: 0.0110 (0.0309) Average Loss: 1.9010 (1.7786) Average CE Loss (Source):  1.9010 ( 1.7786) Learning Rate: 0.1000 (0.1000) Top1_base: 46.8750 (52.2539) Top1_base_per_class: 48.1132 (52.5628) 
Training Epoch: [12/1000] Step: [210 / 285] Batch Time: 0.1547 (0.1638) Data Time: 0.0226 (0.0310) Average Loss: 1.6701 (1.7777) Average CE Loss (Source):  1.6701 ( 1.7777) Learning Rate: 0.1000 (0.1000) Top1_base: 52.3438 (52.2768) Top1_base_per_class: 52.3333 (52.6009) 
Training Epoch: [12/1000] Step: [220 / 285] Batch Time: 0.1459 (0.1633) Data Time: 0.0123 (0.0305) Average Loss: 1.7753 (1.7794) Average CE Loss (Source):  1.7753 ( 1.7794) Learning Rate: 0.1000 (0.1000) Top1_base: 56.2500 (52.3118) Top1_base_per_class: 53.8690 (52.6588) 
Training Epoch: [12/1000] Step: [230 / 285] Batch Time: 0.1498 (0.1626) Data Time: 0.0166 (0.0298) Average Loss: 1.4724 (1.7767) Average CE Loss (Source):  1.4724 ( 1.7767) Learning Rate: 0.1000 (0.1000) Top1_base: 58.5938 (52.3505) Top1_base_per_class: 55.0893 (52.6713) 
Training Epoch: [12/1000] Step: [240 / 285] Batch Time: 0.1469 (0.1625) Data Time: 0.0115 (0.0296) Average Loss: 1.9520 (1.7778) Average CE Loss (Source):  1.9520 ( 1.7778) Learning Rate: 0.1000 (0.1000) Top1_base: 44.5312 (52.2754) Top1_base_per_class: 41.9591 (52.6220) 
Training Epoch: [12/1000] Step: [250 / 285] Batch Time: 0.3346 (0.1634) Data Time: 0.2023 (0.0305) Average Loss: 1.8211 (1.7833) Average CE Loss (Source):  1.8211 ( 1.7833) Learning Rate: 0.1000 (0.1000) Top1_base: 52.3438 (52.1469) Top1_base_per_class: 56.3837 (52.5482) 
Training Epoch: [12/1000] Step: [260 / 285] Batch Time: 0.1476 (0.1635) Data Time: 0.0144 (0.0305) Average Loss: 1.9112 (1.7825) Average CE Loss (Source):  1.9112 ( 1.7825) Learning Rate: 0.1000 (0.1000) Top1_base: 53.9062 (52.1815) Top1_base_per_class: 58.2716 (52.5917) 
Training Epoch: [12/1000] Step: [270 / 285] Batch Time: 0.2174 (0.1638) Data Time: 0.0844 (0.0309) Average Loss: 1.8587 (1.7832) Average CE Loss (Source):  1.8587 ( 1.7832) Learning Rate: 0.1000 (0.1000) Top1_base: 52.3438 (52.1788) Top1_base_per_class: 48.4591 (52.5795) 
Training Epoch: [12/1000] Step: [280 / 285] Batch Time: 0.1434 (0.1642) Data Time: 0.0104 (0.0312) Average Loss: 1.9042 (1.7815) Average CE Loss (Source):  1.9042 ( 1.7815) Learning Rate: 0.1000 (0.1000) Top1_base: 46.0938 (52.1987) Top1_base_per_class: 47.5706 (52.5729) 
Training Epoch: [13/1000] Step: [0] Batch Time: 0.1458 (0.1638) Data Time: 0.0109 (0.0309) Average Loss: 1.9253 (1.7814) Average CE Loss (Source):  1.9253 ( 1.7814) Learning Rate: 0.1000 (0.1000) Top1_base: 46.8750 (52.1848) Top1_base_per_class: 40.2083 (52.5592) 
Training Epoch: [13/1000] Step: [10 / 285] Batch Time: 0.1464 (0.2279) Data Time: 0.0136 (0.0963) Average Loss: 1.6806 (1.6671) Average CE Loss (Source):  1.6806 ( 1.6671) Learning Rate: 0.1000 (0.1000) Top1_base: 50.0000 (55.2344) Top1_base_per_class: 52.5893 (56.4508) 
Training Epoch: [13/1000] Step: [20 / 285] Batch Time: 0.1437 (0.1975) Data Time: 0.0117 (0.0657) Average Loss: 1.9958 (1.7333) Average CE Loss (Source):  1.9958 ( 1.7333) Learning Rate: 0.1000 (0.1000) Top1_base: 46.0938 (53.1641) Top1_base_per_class: 43.6111 (54.3133) 
Training Epoch: [13/1000] Step: [30 / 285] Batch Time: 0.1451 (0.1856) Data Time: 0.0122 (0.0536) Average Loss: 1.9543 (1.7477) Average CE Loss (Source):  1.9543 ( 1.7477) Learning Rate: 0.1000 (0.1000) Top1_base: 42.9688 (52.7865) Top1_base_per_class: 41.2573 (53.1005) 
Training Epoch: [13/1000] Step: [40 / 285] Batch Time: 0.1439 (0.1806) Data Time: 0.0124 (0.0484) Average Loss: 1.8814 (1.7533) Average CE Loss (Source):  1.8814 ( 1.7533) Learning Rate: 0.1000 (0.1000) Top1_base: 46.8750 (52.4805) Top1_base_per_class: 47.3810 (53.0541) 
Training Epoch: [13/1000] Step: [50 / 285] Batch Time: 0.1437 (0.1787) Data Time: 0.0112 (0.0464) Average Loss: 1.7439 (1.7646) Average CE Loss (Source):  1.7439 ( 1.7646) Learning Rate: 0.1000 (0.1000) Top1_base: 54.6875 (52.5156) Top1_base_per_class: 54.0252 (52.8720) 
Training Epoch: [13/1000] Step: [60 / 285] Batch Time: 0.1474 (0.1751) Data Time: 0.0142 (0.0428) Average Loss: 1.6095 (1.7638) Average CE Loss (Source):  1.6095 ( 1.7638) Learning Rate: 0.1000 (0.1000) Top1_base: 51.5625 (52.3958) Top1_base_per_class: 53.8889 (52.7512) 
Training Epoch: [13/1000] Step: [70 / 285] Batch Time: 0.1452 (0.1744) Data Time: 0.0119 (0.0421) Average Loss: 1.7269 (1.7574) Average CE Loss (Source):  1.7269 ( 1.7574) Learning Rate: 0.1000 (0.1000) Top1_base: 57.0312 (52.4777) Top1_base_per_class: 62.1518 (52.8779) 
Training Epoch: [13/1000] Step: [80 / 285] Batch Time: 0.1444 (0.1730) Data Time: 0.0129 (0.0407) Average Loss: 1.5959 (1.7386) Average CE Loss (Source):  1.5959 ( 1.7386) Learning Rate: 0.1000 (0.1000) Top1_base: 56.2500 (52.9590) Top1_base_per_class: 53.7197 (53.3680) 
Training Epoch: [13/1000] Step: [90 / 285] Batch Time: 0.1444 (0.1722) Data Time: 0.0134 (0.0398) Average Loss: 1.7400 (1.7395) Average CE Loss (Source):  1.7400 ( 1.7395) Learning Rate: 0.1000 (0.1000) Top1_base: 50.7812 (52.9514) Top1_base_per_class: 51.4052 (53.4173) 
Training Epoch: [13/1000] Step: [100 / 285] Batch Time: 0.1463 (0.1702) Data Time: 0.0137 (0.0378) Average Loss: 1.6653 (1.7392) Average CE Loss (Source):  1.6653 ( 1.7392) Learning Rate: 0.1000 (0.1000) Top1_base: 56.2500 (53.0312) Top1_base_per_class: 55.2011 (53.3697) 
Training Epoch: [13/1000] Step: [110 / 285] Batch Time: 0.1495 (0.1705) Data Time: 0.0132 (0.0379) Average Loss: 1.6439 (1.7406) Average CE Loss (Source):  1.6439 ( 1.7406) Learning Rate: 0.1000 (0.1000) Top1_base: 53.9062 (52.9403) Top1_base_per_class: 58.3333 (53.3823) 
Training Epoch: [13/1000] Step: [120 / 285] Batch Time: 0.1968 (0.1704) Data Time: 0.0646 (0.0377) Average Loss: 1.7357 (1.7440) Average CE Loss (Source):  1.7357 ( 1.7440) Learning Rate: 0.1000 (0.1000) Top1_base: 53.1250 (52.9167) Top1_base_per_class: 56.6346 (53.2978) 
Training Epoch: [13/1000] Step: [130 / 285] Batch Time: 0.1485 (0.1695) Data Time: 0.0138 (0.0368) Average Loss: 1.6350 (1.7377) Average CE Loss (Source):  1.6350 ( 1.7377) Learning Rate: 0.1000 (0.1000) Top1_base: 55.4688 (53.0769) Top1_base_per_class: 58.2738 (53.5996) 
Training Epoch: [13/1000] Step: [140 / 285] Batch Time: 0.1505 (0.1695) Data Time: 0.0164 (0.0367) Average Loss: 1.8267 (1.7345) Average CE Loss (Source):  1.8267 ( 1.7345) Learning Rate: 0.1000 (0.1000) Top1_base: 48.4375 (53.1473) Top1_base_per_class: 46.1420 (53.6611) 
Training Epoch: [13/1000] Step: [150 / 285] Batch Time: 0.1446 (0.1693) Data Time: 0.0125 (0.0365) Average Loss: 2.0062 (1.7376) Average CE Loss (Source):  2.0062 ( 1.7376) Learning Rate: 0.1000 (0.1000) Top1_base: 44.5312 (53.1094) Top1_base_per_class: 46.5151 (53.6151) 
Training Epoch: [13/1000] Step: [160 / 285] Batch Time: 0.2490 (0.1695) Data Time: 0.1178 (0.0366) Average Loss: 1.6445 (1.7406) Average CE Loss (Source):  1.6445 ( 1.7406) Learning Rate: 0.1000 (0.1000) Top1_base: 51.5625 (52.9346) Top1_base_per_class: 49.7531 (53.5876) 
Training Epoch: [13/1000] Step: [170 / 285] Batch Time: 0.1440 (0.1685) Data Time: 0.0115 (0.0356) Average Loss: 1.6816 (1.7448) Average CE Loss (Source):  1.6816 ( 1.7448) Learning Rate: 0.1000 (0.1000) Top1_base: 53.9062 (52.7987) Top1_base_per_class: 51.6384 (53.4155) 
Training Epoch: [13/1000] Step: [180 / 285] Batch Time: 0.1729 (0.1680) Data Time: 0.0413 (0.0352) Average Loss: 1.5315 (1.7417) Average CE Loss (Source):  1.5315 ( 1.7417) Learning Rate: 0.1000 (0.1000) Top1_base: 58.5938 (52.9427) Top1_base_per_class: 57.4425 (53.5097) 
Training Epoch: [13/1000] Step: [190 / 285] Batch Time: 0.1464 (0.1686) Data Time: 0.0133 (0.0358) Average Loss: 1.7447 (1.7353) Average CE Loss (Source):  1.7447 ( 1.7353) Learning Rate: 0.1000 (0.1000) Top1_base: 56.2500 (53.1538) Top1_base_per_class: 61.1212 (53.7115) 
Training Epoch: [13/1000] Step: [200 / 285] Batch Time: 0.1439 (0.1682) Data Time: 0.0110 (0.0354) Average Loss: 1.4902 (1.7346) Average CE Loss (Source):  1.4902 ( 1.7346) Learning Rate: 0.1000 (0.1000) Top1_base: 54.6875 (53.2148) Top1_base_per_class: 56.4881 (53.7489) 
Training Epoch: [13/1000] Step: [210 / 285] Batch Time: 0.1441 (0.1681) Data Time: 0.0115 (0.0354) Average Loss: 1.4643 (1.7295) Average CE Loss (Source):  1.4643 ( 1.7295) Learning Rate: 0.1000 (0.1000) Top1_base: 56.2500 (53.3557) Top1_base_per_class: 55.5085 (53.8341) 
Training Epoch: [13/1000] Step: [220 / 285] Batch Time: 0.1473 (0.1677) Data Time: 0.0163 (0.0350) Average Loss: 1.7097 (1.7243) Average CE Loss (Source):  1.7097 ( 1.7243) Learning Rate: 0.1000 (0.1000) Top1_base: 55.4688 (53.5050) Top1_base_per_class: 57.8918 (54.0124) 
Training Epoch: [13/1000] Step: [230 / 285] Batch Time: 0.1448 (0.1673) Data Time: 0.0119 (0.0346) Average Loss: 1.7127 (1.7238) Average CE Loss (Source):  1.7127 ( 1.7238) Learning Rate: 0.1000 (0.1000) Top1_base: 56.2500 (53.6073) Top1_base_per_class: 57.3899 (54.1035) 
Training Epoch: [13/1000] Step: [240 / 285] Batch Time: 0.1473 (0.1669) Data Time: 0.0144 (0.0342) Average Loss: 1.6168 (1.7238) Average CE Loss (Source):  1.6168 ( 1.7238) Learning Rate: 0.1000 (0.1000) Top1_base: 54.6875 (53.6719) Top1_base_per_class: 57.0635 (54.1663) 
Training Epoch: [13/1000] Step: [250 / 285] Batch Time: 0.1465 (0.1671) Data Time: 0.0135 (0.0344) Average Loss: 1.7632 (1.7235) Average CE Loss (Source):  1.7632 ( 1.7235) Learning Rate: 0.1000 (0.1000) Top1_base: 50.0000 (53.6938) Top1_base_per_class: 52.2327 (54.2021) 
Training Epoch: [13/1000] Step: [260 / 285] Batch Time: 0.1482 (0.1668) Data Time: 0.0157 (0.0340) Average Loss: 1.7057 (1.7236) Average CE Loss (Source):  1.7057 ( 1.7236) Learning Rate: 0.1000 (0.1000) Top1_base: 50.0000 (53.7620) Top1_base_per_class: 54.4946 (54.3360) 
Training Epoch: [13/1000] Step: [270 / 285] Batch Time: 0.1441 (0.1671) Data Time: 0.0129 (0.0344) Average Loss: 1.6542 (1.7239) Average CE Loss (Source):  1.6542 ( 1.7239) Learning Rate: 0.1000 (0.1000) Top1_base: 50.0000 (53.7818) Top1_base_per_class: 45.6790 (54.3368) 
Training Epoch: [13/1000] Step: [280 / 285] Batch Time: 0.1434 (0.1665) Data Time: 0.0121 (0.0338) Average Loss: 1.7931 (1.7258) Average CE Loss (Source):  1.7931 ( 1.7258) Learning Rate: 0.1000 (0.1000) Top1_base: 50.0000 (53.7667) Top1_base_per_class: 52.2956 (54.3664) 
Training Epoch: [14/1000] Step: [0] Batch Time: 0.1803 (0.1663) Data Time: 0.0504 (0.0336) Average Loss: 1.5890 (1.7243) Average CE Loss (Source):  1.5890 ( 1.7243) Learning Rate: 0.1000 (0.1000) Top1_base: 57.0312 (53.7966) Top1_base_per_class: 59.8148 (54.4179) 
  1%|▏         | 14/1000 [11:16<13:16:35, 48.47s/it]  2%|▏         | 15/1000 [12:03<13:09:09, 48.07s/it]Training Epoch: [14/1000] Step: [10 / 285] Batch Time: 0.1414 (0.2403) Data Time: 0.0087 (0.1089) Average Loss: 1.7467 (1.6605) Average CE Loss (Source):  1.7467 ( 1.6605) Learning Rate: 0.1000 (0.1000) Top1_base: 57.8125 (54.5312) Top1_base_per_class: 57.6560 (54.8287) 
Training Epoch: [14/1000] Step: [20 / 285] Batch Time: 0.1470 (0.1979) Data Time: 0.0136 (0.0658) Average Loss: 1.6106 (1.6734) Average CE Loss (Source):  1.6106 ( 1.6734) Learning Rate: 0.1000 (0.1000) Top1_base: 57.0312 (54.8047) Top1_base_per_class: 59.3391 (55.2382) 
Training Epoch: [14/1000] Step: [30 / 285] Batch Time: 0.1429 (0.1870) Data Time: 0.0108 (0.0549) Average Loss: 1.8342 (1.6980) Average CE Loss (Source):  1.8342 ( 1.6980) Learning Rate: 0.1000 (0.1000) Top1_base: 50.0000 (54.2448) Top1_base_per_class: 51.3333 (54.8988) 
Training Epoch: [14/1000] Step: [40 / 285] Batch Time: 0.1456 (0.1807) Data Time: 0.0119 (0.0485) Average Loss: 1.5555 (1.6920) Average CE Loss (Source):  1.5555 ( 1.6920) Learning Rate: 0.1000 (0.1000) Top1_base: 59.3750 (54.4922) Top1_base_per_class: 59.6045 (54.7246) 
Training Epoch: [14/1000] Step: [50 / 285] Batch Time: 0.1444 (0.1771) Data Time: 0.0112 (0.0448) Average Loss: 1.6739 (1.6941) Average CE Loss (Source):  1.6739 ( 1.6941) Learning Rate: 0.1000 (0.1000) Top1_base: 57.0312 (54.3906) Top1_base_per_class: 55.7672 (54.5566) 
Training Epoch: [14/1000] Step: [60 / 285] Batch Time: 0.1447 (0.1725) Data Time: 0.0120 (0.0402) Average Loss: 1.4532 (1.6928) Average CE Loss (Source):  1.4532 ( 1.6928) Learning Rate: 0.1000 (0.1000) Top1_base: 59.3750 (54.6615) Top1_base_per_class: 59.3518 (54.8025) 
Training Epoch: [14/1000] Step: [70 / 285] Batch Time: 0.1434 (0.1703) Data Time: 0.0107 (0.0381) Average Loss: 1.8645 (1.6981) Average CE Loss (Source):  1.8645 ( 1.6981) Learning Rate: 0.1000 (0.1000) Top1_base: 52.3438 (54.6317) Top1_base_per_class: 53.9109 (54.9767) 
Training Epoch: [14/1000] Step: [80 / 285] Batch Time: 0.1485 (0.1690) Data Time: 0.0142 (0.0367) Average Loss: 1.4412 (1.6938) Average CE Loss (Source):  1.4412 ( 1.6938) Learning Rate: 0.1000 (0.1000) Top1_base: 60.9375 (54.5703) Top1_base_per_class: 62.8655 (54.8486) 
Training Epoch: [14/1000] Step: [90 / 285] Batch Time: 0.1451 (0.1693) Data Time: 0.0118 (0.0369) Average Loss: 1.8182 (1.6938) Average CE Loss (Source):  1.8182 ( 1.6938) Learning Rate: 0.1000 (0.1000) Top1_base: 50.0000 (54.5226) Top1_base_per_class: 48.7736 (54.7444) 
Training Epoch: [14/1000] Step: [100 / 285] Batch Time: 0.1453 (0.1680) Data Time: 0.0116 (0.0355) Average Loss: 1.7584 (1.6905) Average CE Loss (Source):  1.7584 ( 1.6905) Learning Rate: 0.1000 (0.1000) Top1_base: 57.8125 (54.6250) Top1_base_per_class: 59.0000 (54.9599) 
Training Epoch: [14/1000] Step: [110 / 285] Batch Time: 0.1455 (0.1680) Data Time: 0.0110 (0.0354) Average Loss: 1.5609 (1.6894) Average CE Loss (Source):  1.5609 ( 1.6894) Learning Rate: 0.1000 (0.1000) Top1_base: 54.6875 (54.6307) Top1_base_per_class: 57.4848 (54.9394) 
Training Epoch: [14/1000] Step: [120 / 285] Batch Time: 0.1470 (0.1673) Data Time: 0.0139 (0.0347) Average Loss: 1.7350 (1.6868) Average CE Loss (Source):  1.7350 ( 1.6868) Learning Rate: 0.1000 (0.1000) Top1_base: 58.5938 (54.7266) Top1_base_per_class: 59.4654 (55.0245) 
Training Epoch: [14/1000] Step: [130 / 285] Batch Time: 0.1407 (0.1667) Data Time: 0.0098 (0.0341) Average Loss: 1.6261 (1.6869) Average CE Loss (Source):  1.6261 ( 1.6869) Learning Rate: 0.1000 (0.1000) Top1_base: 58.5938 (54.7596) Top1_base_per_class: 60.3395 (55.1034) 
Training Epoch: [14/1000] Step: [140 / 285] Batch Time: 0.1450 (0.1664) Data Time: 0.0132 (0.0338) Average Loss: 1.6632 (1.6823) Average CE Loss (Source):  1.6632 ( 1.6823) Learning Rate: 0.1000 (0.1000) Top1_base: 57.0312 (54.8772) Top1_base_per_class: 56.5741 (55.2114) 
Training Epoch: [14/1000] Step: [150 / 285] Batch Time: 0.1438 (0.1663) Data Time: 0.0125 (0.0337) Average Loss: 1.5737 (1.6862) Average CE Loss (Source):  1.5737 ( 1.6862) Learning Rate: 0.1000 (0.1000) Top1_base: 57.0312 (54.6823) Top1_base_per_class: 50.5864 (54.9900) 
Training Epoch: [14/1000] Step: [160 / 285] Batch Time: 0.1469 (0.1651) Data Time: 0.0122 (0.0324) Average Loss: 1.7897 (1.6829) Average CE Loss (Source):  1.7897 ( 1.6829) Learning Rate: 0.1000 (0.1000) Top1_base: 50.7812 (54.6680) Top1_base_per_class: 55.4242 (55.0774) 
Training Epoch: [14/1000] Step: [170 / 285] Batch Time: 0.2189 (0.1645) Data Time: 0.0868 (0.0318) Average Loss: 1.4609 (1.6812) Average CE Loss (Source):  1.4609 ( 1.6812) Learning Rate: 0.1000 (0.1000) Top1_base: 59.3750 (54.7656) Top1_base_per_class: 57.7100 (55.2050) 
Training Epoch: [14/1000] Step: [180 / 285] Batch Time: 0.1449 (0.1639) Data Time: 0.0123 (0.0313) Average Loss: 1.4225 (1.6784) Average CE Loss (Source):  1.4225 ( 1.6784) Learning Rate: 0.1000 (0.1000) Top1_base: 64.0625 (54.8785) Top1_base_per_class: 64.4633 (55.3654) 
Training Epoch: [14/1000] Step: [190 / 285] Batch Time: 0.2194 (0.1637) Data Time: 0.0876 (0.0311) Average Loss: 1.7300 (1.6763) Average CE Loss (Source):  1.7300 ( 1.6763) Learning Rate: 0.1000 (0.1000) Top1_base: 50.0000 (54.9054) Top1_base_per_class: 49.2641 (55.4438) 
Training Epoch: [14/1000] Step: [200 / 285] Batch Time: 0.1427 (0.1639) Data Time: 0.0109 (0.0313) Average Loss: 1.6497 (1.6795) Average CE Loss (Source):  1.6497 ( 1.6795) Learning Rate: 0.1000 (0.1000) Top1_base: 54.6875 (54.8711) Top1_base_per_class: 54.5763 (55.4343) 
Training Epoch: [14/1000] Step: [210 / 285] Batch Time: 0.1788 (0.1644) Data Time: 0.0448 (0.0318) Average Loss: 1.5711 (1.6812) Average CE Loss (Source):  1.5711 ( 1.6812) Learning Rate: 0.1000 (0.1000) Top1_base: 58.5938 (54.8251) Top1_base_per_class: 55.1488 (55.3474) 
Training Epoch: [14/1000] Step: [220 / 285] Batch Time: 0.1447 (0.1643) Data Time: 0.0133 (0.0317) Average Loss: 1.6932 (1.6777) Average CE Loss (Source):  1.6932 ( 1.6777) Learning Rate: 0.1000 (0.1000) Top1_base: 54.6875 (54.9396) Top1_base_per_class: 53.6905 (55.4321) 
Training Epoch: [14/1000] Step: [230 / 285] Batch Time: 0.2316 (0.1646) Data Time: 0.0990 (0.0319) Average Loss: 1.6798 (1.6775) Average CE Loss (Source):  1.6798 ( 1.6775) Learning Rate: 0.1000 (0.1000) Top1_base: 54.6875 (54.9728) Top1_base_per_class: 57.0468 (55.5287) 
Training Epoch: [14/1000] Step: [240 / 285] Batch Time: 0.1424 (0.1654) Data Time: 0.0105 (0.0327) Average Loss: 1.8087 (1.6781) Average CE Loss (Source):  1.8087 ( 1.6781) Learning Rate: 0.1000 (0.1000) Top1_base: 52.3438 (54.9870) Top1_base_per_class: 54.4551 (55.5647) 
Training Epoch: [14/1000] Step: [250 / 285] Batch Time: 0.2506 (0.1655) Data Time: 0.1155 (0.0328) Average Loss: 1.7158 (1.6775) Average CE Loss (Source):  1.7158 ( 1.6775) Learning Rate: 0.1000 (0.1000) Top1_base: 51.5625 (54.9656) Top1_base_per_class: 59.1964 (55.5810) 
Training Epoch: [14/1000] Step: [260 / 285] Batch Time: 0.1458 (0.1652) Data Time: 0.0126 (0.0325) Average Loss: 1.5179 (1.6786) Average CE Loss (Source):  1.5179 ( 1.6786) Learning Rate: 0.1000 (0.1000) Top1_base: 59.3750 (54.9760) Top1_base_per_class: 57.1076 (55.6288) 
Training Epoch: [14/1000] Step: [270 / 285] Batch Time: 0.2328 (0.1654) Data Time: 0.1010 (0.0326) Average Loss: 1.6106 (1.6787) Average CE Loss (Source):  1.6106 ( 1.6787) Learning Rate: 0.1000 (0.1000) Top1_base: 54.6875 (54.9363) Top1_base_per_class: 57.3899 (55.5738) 
Training Epoch: [14/1000] Step: [280 / 285] Batch Time: 0.1451 (0.1654) Data Time: 0.0118 (0.0326) Average Loss: 1.8118 (1.6796) Average CE Loss (Source):  1.8118 ( 1.6796) Learning Rate: 0.1000 (0.1000) Top1_base: 53.9062 (54.9944) Top1_base_per_class: 53.5632 (55.6069) 
Training Epoch: [15/1000] Step: [0] Batch Time: 0.1392 (0.1652) Data Time: 0.0089 (0.0325) Average Loss: 1.4175 (1.6793) Average CE Loss (Source):  1.4175 ( 1.6793) Learning Rate: 0.1000 (0.1000) Top1_base: 63.2812 (54.9890) Top1_base_per_class: 66.7284 (55.6187) 
Training Epoch: [15/1000] Step: [10 / 285] Batch Time: 0.1487 (0.2299) Data Time: 0.0186 (0.0982) Average Loss: 1.4894 (1.5951) Average CE Loss (Source):  1.4894 ( 1.5951) Learning Rate: 0.1000 (0.1000) Top1_base: 58.5938 (57.0312) Top1_base_per_class: 58.6364 (55.3983) 
Training Epoch: [15/1000] Step: [20 / 285] Batch Time: 0.1453 (0.1955) Data Time: 0.0115 (0.0637) Average Loss: 1.4653 (1.5916) Average CE Loss (Source):  1.4653 ( 1.5916) Learning Rate: 0.1000 (0.1000) Top1_base: 54.6875 (57.3047) Top1_base_per_class: 56.1782 (56.4221) 
Training Epoch: [15/1000] Step: [30 / 285] Batch Time: 0.1787 (0.1882) Data Time: 0.0479 (0.0563) Average Loss: 1.3809 (1.5841) Average CE Loss (Source):  1.3809 ( 1.5841) Learning Rate: 0.1000 (0.1000) Top1_base: 67.1875 (57.5000) Top1_base_per_class: 70.3216 (57.2832) 
Training Epoch: [15/1000] Step: [40 / 285] Batch Time: 0.1416 (0.1831) Data Time: 0.0105 (0.0514) Average Loss: 1.4976 (1.5749) Average CE Loss (Source):  1.4976 ( 1.5749) Learning Rate: 0.1000 (0.1000) Top1_base: 61.7188 (58.0273) Top1_base_per_class: 61.0714 (58.0461) 
Training Epoch: [15/1000] Step: [50 / 285] Batch Time: 0.2175 (0.1783) Data Time: 0.0861 (0.0467) Average Loss: 1.6714 (1.5716) Average CE Loss (Source):  1.6714 ( 1.5716) Learning Rate: 0.1000 (0.1000) Top1_base: 56.2500 (58.0781) Top1_base_per_class: 60.3532 (58.1389) 
Training Epoch: [15/1000] Step: [60 / 285] Batch Time: 0.1422 (0.1743) Data Time: 0.0109 (0.0428) Average Loss: 1.4670 (1.5688) Average CE Loss (Source):  1.4670 ( 1.5688) Learning Rate: 0.1000 (0.1000) Top1_base: 56.2500 (58.2812) Top1_base_per_class: 58.4821 (58.5770) 
Training Epoch: [15/1000] Step: [70 / 285] Batch Time: 0.2113 (0.1723) Data Time: 0.0791 (0.0407) Average Loss: 1.5162 (1.5701) Average CE Loss (Source):  1.5162 ( 1.5701) Learning Rate: 0.1000 (0.1000) Top1_base: 59.3750 (58.1362) Top1_base_per_class: 62.4702 (58.3774) 
Training Epoch: [15/1000] Step: [80 / 285] Batch Time: 0.1409 (0.1695) Data Time: 0.0102 (0.0379) Average Loss: 1.6418 (1.5816) Average CE Loss (Source):  1.6418 ( 1.5816) Learning Rate: 0.1000 (0.1000) Top1_base: 52.3438 (57.6270) Top1_base_per_class: 55.1000 (57.9989) 
Training Epoch: [15/1000] Step: [90 / 285] Batch Time: 0.1434 (0.1677) Data Time: 0.0126 (0.0360) Average Loss: 1.6142 (1.5878) Average CE Loss (Source):  1.6142 ( 1.5878) Learning Rate: 0.1000 (0.1000) Top1_base: 56.2500 (57.5087) Top1_base_per_class: 55.9259 (57.8743) 
Training Epoch: [15/1000] Step: [100 / 285] Batch Time: 0.1410 (0.1673) Data Time: 0.0102 (0.0356) Average Loss: 1.4574 (1.5968) Average CE Loss (Source):  1.4574 ( 1.5968) Learning Rate: 0.1000 (0.1000) Top1_base: 57.0312 (57.2578) Top1_base_per_class: 58.3929 (57.6057) 
Training Epoch: [15/1000] Step: [110 / 285] Batch Time: 0.2056 (0.1666) Data Time: 0.0740 (0.0349) Average Loss: 1.7144 (1.5999) Average CE Loss (Source):  1.7144 ( 1.5999) Learning Rate: 0.1000 (0.1000) Top1_base: 52.3438 (57.1378) Top1_base_per_class: 51.6954 (57.4683) 
Training Epoch: [15/1000] Step: [120 / 285] Batch Time: 0.1429 (0.1667) Data Time: 0.0104 (0.0350) Average Loss: 1.8132 (1.6054) Average CE Loss (Source):  1.8132 ( 1.6054) Learning Rate: 0.1000 (0.1000) Top1_base: 54.6875 (57.0182) Top1_base_per_class: 53.5714 (57.3360) 
Training Epoch: [15/1000] Step: [130 / 285] Batch Time: 0.1947 (0.1659) Data Time: 0.0613 (0.0342) Average Loss: 1.6337 (1.6055) Average CE Loss (Source):  1.6337 ( 1.6055) Learning Rate: 0.1000 (0.1000) Top1_base: 60.9375 (57.0793) Top1_base_per_class: 59.4540 (57.5355) 
Training Epoch: [15/1000] Step: [140 / 285] Batch Time: 0.1410 (0.1663) Data Time: 0.0104 (0.0346) Average Loss: 1.2331 (1.6153) Average CE Loss (Source):  1.2331 ( 1.6153) Learning Rate: 0.1000 (0.1000) Top1_base: 69.5312 (56.8471) Top1_base_per_class: 68.2768 (57.4179) 
Training Epoch: [15/1000] Step: [150 / 285] Batch Time: 0.2302 (0.1665) Data Time: 0.0967 (0.0349) Average Loss: 1.8518 (1.6175) Average CE Loss (Source):  1.8518 ( 1.6175) Learning Rate: 0.1000 (0.1000) Top1_base: 49.2188 (56.8333) Top1_base_per_class: 54.5443 (57.3896) 
Training Epoch: [15/1000] Step: [160 / 285] Batch Time: 0.1433 (0.1660) Data Time: 0.0112 (0.0344) Average Loss: 1.6736 (1.6157) Average CE Loss (Source):  1.6736 ( 1.6157) Learning Rate: 0.1000 (0.1000) Top1_base: 54.6875 (56.8750) Top1_base_per_class: 54.0252 (57.3677) 
Training Epoch: [15/1000] Step: [170 / 285] Batch Time: 0.1838 (0.1656) Data Time: 0.0526 (0.0340) Average Loss: 1.8881 (1.6200) Average CE Loss (Source):  1.8881 ( 1.6200) Learning Rate: 0.1000 (0.1000) Top1_base: 52.3438 (56.7647) Top1_base_per_class: 55.7233 (57.2550) 
Training Epoch: [15/1000] Step: [180 / 285] Batch Time: 0.1418 (0.1649) Data Time: 0.0103 (0.0333) Average Loss: 1.6336 (1.6249) Average CE Loss (Source):  1.6336 ( 1.6249) Learning Rate: 0.1000 (0.1000) Top1_base: 58.5938 (56.7448) Top1_base_per_class: 56.3939 (57.2377) 
Training Epoch: [15/1000] Step: [190 / 285] Batch Time: 0.2065 (0.1649) Data Time: 0.0747 (0.0333) Average Loss: 1.7155 (1.6224) Average CE Loss (Source):  1.7155 ( 1.6224) Learning Rate: 0.1000 (0.1000) Top1_base: 51.5625 (56.7845) Top1_base_per_class: 51.9591 (57.1627) 
Training Epoch: [15/1000] Step: [200 / 285] Batch Time: 0.1429 (0.1644) Data Time: 0.0104 (0.0327) Average Loss: 1.8287 (1.6290) Average CE Loss (Source):  1.8287 ( 1.6290) Learning Rate: 0.1000 (0.1000) Top1_base: 53.1250 (56.6289) Top1_base_per_class: 53.2749 (57.0304) 
Training Epoch: [15/1000] Step: [210 / 285] Batch Time: 0.2020 (0.1639) Data Time: 0.0704 (0.0323) Average Loss: 1.5613 (1.6298) Average CE Loss (Source):  1.5613 ( 1.6298) Learning Rate: 0.1000 (0.1000) Top1_base: 53.9062 (56.5625) Top1_base_per_class: 56.7924 (56.9875) 
Training Epoch: [15/1000] Step: [220 / 285] Batch Time: 0.1439 (0.1636) Data Time: 0.0110 (0.0319) Average Loss: 1.1546 (1.6281) Average CE Loss (Source):  1.1546 ( 1.6281) Learning Rate: 0.1000 (0.1000) Top1_base: 70.3125 (56.6264) Top1_base_per_class: 70.8046 (57.0622) 
Training Epoch: [15/1000] Step: [230 / 285] Batch Time: 0.1485 (0.1633) Data Time: 0.0180 (0.0317) Average Loss: 1.6123 (1.6303) Average CE Loss (Source):  1.6123 ( 1.6303) Learning Rate: 0.1000 (0.1000) Top1_base: 50.7812 (56.5183) Top1_base_per_class: 56.5385 (57.0193) 
Training Epoch: [15/1000] Step: [240 / 285] Batch Time: 0.1441 (0.1630) Data Time: 0.0117 (0.0313) Average Loss: 1.4845 (1.6319) Average CE Loss (Source):  1.4845 ( 1.6319) Learning Rate: 0.1000 (0.1000) Top1_base: 57.8125 (56.4779) Top1_base_per_class: 62.7513 (57.0041) 
Training Epoch: [15/1000] Step: [250 / 285] Batch Time: 0.1754 (0.1627) Data Time: 0.0431 (0.0310) Average Loss: 1.3703 (1.6351) Average CE Loss (Source):  1.3703 ( 1.6351) Learning Rate: 0.1000 (0.1000) Top1_base: 64.0625 (56.4062) Top1_base_per_class: 66.4829 (56.9555) 
Training Epoch: [15/1000] Step: [260 / 285] Batch Time: 0.1422 (0.1623) Data Time: 0.0107 (0.0306) Average Loss: 1.6045 (1.6359) Average CE Loss (Source):  1.6045 ( 1.6359) Learning Rate: 0.1000 (0.1000) Top1_base: 58.5938 (56.3792) Top1_base_per_class: 52.1948 (56.9247) 
Training Epoch: [15/1000] Step: [270 / 285] Batch Time: 0.1630 (0.1622) Data Time: 0.0309 (0.0305) Average Loss: 1.7439 (1.6374) Average CE Loss (Source):  1.7439 ( 1.6374) Learning Rate: 0.1000 (0.1000) Top1_base: 57.0312 (56.3368) Top1_base_per_class: 53.6333 (56.8849) 
Training Epoch: [15/1000] Step: [280 / 285] Batch Time: 0.1420 (0.1623) Data Time: 0.0100 (0.0306) Average Loss: 1.4274 (1.6345) Average CE Loss (Source):  1.4274 ( 1.6345) Learning Rate: 0.1000 (0.1000) Top1_base: 61.7188 (56.4146) Top1_base_per_class: 61.4506 (56.9968) 
Training Epoch: [16/1000] Step: [0] Batch Time: 0.1399 (0.1624) Data Time: 0.0098 (0.0307) Average Loss: 1.7824 (1.6331) Average CE Loss (Source):  1.7824 ( 1.6331) Learning Rate: 0.1000 (0.1000) Top1_base: 53.1250 (56.4611) Top1_base_per_class: 55.3459 (57.0823) 
  2%|▏         | 16/1000 [12:53<13:13:16, 48.37s/it]  2%|▏         | 17/1000 [13:39<13:04:18, 47.87s/it]Training Epoch: [16/1000] Step: [10 / 285] Batch Time: 0.1464 (0.2323) Data Time: 0.0146 (0.1004) Average Loss: 1.6585 (1.5147) Average CE Loss (Source):  1.6585 ( 1.5147) Learning Rate: 0.1000 (0.1000) Top1_base: 52.3438 (58.2031) Top1_base_per_class: 52.0062 (59.2747) 
Training Epoch: [16/1000] Step: [20 / 285] Batch Time: 0.1440 (0.1993) Data Time: 0.0111 (0.0674) Average Loss: 1.5256 (1.5446) Average CE Loss (Source):  1.5256 ( 1.5446) Learning Rate: 0.1000 (0.1000) Top1_base: 55.4688 (57.6562) Top1_base_per_class: 55.4598 (58.1871) 
Training Epoch: [16/1000] Step: [30 / 285] Batch Time: 0.1468 (0.1882) Data Time: 0.0129 (0.0560) Average Loss: 1.7330 (1.5588) Average CE Loss (Source):  1.7330 ( 1.5588) Learning Rate: 0.1000 (0.1000) Top1_base: 56.2500 (57.7083) Top1_base_per_class: 56.2893 (58.0805) 
Training Epoch: [16/1000] Step: [40 / 285] Batch Time: 0.1461 (0.1797) Data Time: 0.0129 (0.0476) Average Loss: 1.2092 (1.5522) Average CE Loss (Source):  1.2092 ( 1.5522) Learning Rate: 0.1000 (0.1000) Top1_base: 63.2812 (57.6172) Top1_base_per_class: 68.4746 (57.9489) 
Training Epoch: [16/1000] Step: [50 / 285] Batch Time: 0.1912 (0.1756) Data Time: 0.0591 (0.0434) Average Loss: 1.7246 (1.5598) Average CE Loss (Source):  1.7246 ( 1.5598) Learning Rate: 0.1000 (0.1000) Top1_base: 52.3438 (57.4688) Top1_base_per_class: 53.5417 (57.8928) 
Training Epoch: [16/1000] Step: [60 / 285] Batch Time: 0.1426 (0.1727) Data Time: 0.0107 (0.0404) Average Loss: 1.5759 (1.5581) Average CE Loss (Source):  1.5759 ( 1.5581) Learning Rate: 0.1000 (0.1000) Top1_base: 50.7812 (57.4479) Top1_base_per_class: 55.2186 (57.9698) 
Training Epoch: [16/1000] Step: [70 / 285] Batch Time: 0.1465 (0.1707) Data Time: 0.0127 (0.0382) Average Loss: 1.3146 (1.5669) Average CE Loss (Source):  1.3146 ( 1.5669) Learning Rate: 0.1000 (0.1000) Top1_base: 64.8438 (57.3661) Top1_base_per_class: 61.8103 (57.8448) 
Training Epoch: [16/1000] Step: [80 / 285] Batch Time: 0.1459 (0.1694) Data Time: 0.0141 (0.0367) Average Loss: 1.4932 (1.5666) Average CE Loss (Source):  1.4932 ( 1.5666) Learning Rate: 0.1000 (0.1000) Top1_base: 59.3750 (57.3535) Top1_base_per_class: 58.7853 (58.1758) 
Training Epoch: [16/1000] Step: [90 / 285] Batch Time: 0.1466 (0.1700) Data Time: 0.0110 (0.0372) Average Loss: 1.4865 (1.5622) Average CE Loss (Source):  1.4865 ( 1.5622) Learning Rate: 0.1000 (0.1000) Top1_base: 55.4688 (57.4392) Top1_base_per_class: 53.3333 (58.2370) 
Training Epoch: [16/1000] Step: [100 / 285] Batch Time: 0.1424 (0.1691) Data Time: 0.0105 (0.0363) Average Loss: 1.5187 (1.5610) Average CE Loss (Source):  1.5187 ( 1.5610) Learning Rate: 0.1000 (0.1000) Top1_base: 56.2500 (57.4531) Top1_base_per_class: 50.5152 (58.0680) 
Training Epoch: [16/1000] Step: [110 / 285] Batch Time: 0.1460 (0.1682) Data Time: 0.0131 (0.0354) Average Loss: 1.4722 (1.5640) Average CE Loss (Source):  1.4722 ( 1.5640) Learning Rate: 0.1000 (0.1000) Top1_base: 60.9375 (57.4006) Top1_base_per_class: 57.6729 (57.9273) 
Training Epoch: [16/1000] Step: [120 / 285] Batch Time: 0.1435 (0.1676) Data Time: 0.0112 (0.0348) Average Loss: 1.5023 (1.5554) Average CE Loss (Source):  1.5023 ( 1.5554) Learning Rate: 0.1000 (0.1000) Top1_base: 58.5938 (57.7148) Top1_base_per_class: 62.0909 (58.3018) 
Training Epoch: [16/1000] Step: [130 / 285] Batch Time: 0.1464 (0.1666) Data Time: 0.0131 (0.0337) Average Loss: 1.5418 (1.5581) Average CE Loss (Source):  1.5418 ( 1.5581) Learning Rate: 0.1000 (0.1000) Top1_base: 60.9375 (57.7825) Top1_base_per_class: 59.8718 (58.2812) 
Training Epoch: [16/1000] Step: [140 / 285] Batch Time: 0.1414 (0.1668) Data Time: 0.0092 (0.0339) Average Loss: 1.6505 (1.5571) Average CE Loss (Source):  1.6505 ( 1.5571) Learning Rate: 0.1000 (0.1000) Top1_base: 55.4688 (57.8069) Top1_base_per_class: 63.9308 (58.3124) 
Training Epoch: [16/1000] Step: [150 / 285] Batch Time: 0.1467 (0.1668) Data Time: 0.0118 (0.0339) Average Loss: 1.3801 (1.5588) Average CE Loss (Source):  1.3801 ( 1.5588) Learning Rate: 0.1000 (0.1000) Top1_base: 64.8438 (57.9062) Top1_base_per_class: 65.8908 (58.4161) 
Training Epoch: [16/1000] Step: [160 / 285] Batch Time: 0.1474 (0.1666) Data Time: 0.0142 (0.0337) Average Loss: 1.6286 (1.5655) Average CE Loss (Source):  1.6286 ( 1.5655) Learning Rate: 0.1000 (0.1000) Top1_base: 56.2500 (57.7930) Top1_base_per_class: 57.4713 (58.3016) 
Training Epoch: [16/1000] Step: [170 / 285] Batch Time: 0.1442 (0.1660) Data Time: 0.0131 (0.0330) Average Loss: 1.6491 (1.5659) Average CE Loss (Source):  1.6491 ( 1.5659) Learning Rate: 0.1000 (0.1000) Top1_base: 55.4688 (57.7436) Top1_base_per_class: 55.6061 (58.2212) 
Training Epoch: [16/1000] Step: [180 / 285] Batch Time: 0.1450 (0.1659) Data Time: 0.0116 (0.0330) Average Loss: 1.3186 (1.5652) Average CE Loss (Source):  1.3186 ( 1.5652) Learning Rate: 0.1000 (0.1000) Top1_base: 62.5000 (57.7517) Top1_base_per_class: 61.4462 (58.2110) 
Training Epoch: [16/1000] Step: [190 / 285] Batch Time: 0.1461 (0.1650) Data Time: 0.0127 (0.0321) Average Loss: 1.6138 (1.5679) Average CE Loss (Source):  1.6138 ( 1.5679) Learning Rate: 0.1000 (0.1000) Top1_base: 57.8125 (57.6891) Top1_base_per_class: 57.2678 (58.1668) 
Training Epoch: [16/1000] Step: [200 / 285] Batch Time: 0.1449 (0.1649) Data Time: 0.0101 (0.0318) Average Loss: 1.5037 (1.5646) Average CE Loss (Source):  1.5037 ( 1.5646) Learning Rate: 0.1000 (0.1000) Top1_base: 57.0312 (57.6992) Top1_base_per_class: 54.5238 (58.1338) 
Training Epoch: [16/1000] Step: [210 / 285] Batch Time: 0.1447 (0.1646) Data Time: 0.0119 (0.0316) Average Loss: 1.7783 (1.5667) Average CE Loss (Source):  1.7783 ( 1.5667) Learning Rate: 0.1000 (0.1000) Top1_base: 53.9062 (57.6525) Top1_base_per_class: 53.5345 (58.0678) 
Training Epoch: [16/1000] Step: [220 / 285] Batch Time: 0.1483 (0.1646) Data Time: 0.0132 (0.0315) Average Loss: 1.5912 (1.5659) Average CE Loss (Source):  1.5912 ( 1.5659) Learning Rate: 0.1000 (0.1000) Top1_base: 56.2500 (57.7379) Top1_base_per_class: 55.5442 (58.2166) 
Training Epoch: [16/1000] Step: [230 / 285] Batch Time: 0.1481 (0.1641) Data Time: 0.0150 (0.0311) Average Loss: 1.5040 (1.5668) Average CE Loss (Source):  1.5040 ( 1.5668) Learning Rate: 0.1000 (0.1000) Top1_base: 56.2500 (57.6495) Top1_base_per_class: 58.0556 (58.1529) 
Training Epoch: [16/1000] Step: [240 / 285] Batch Time: 0.1459 (0.1638) Data Time: 0.0123 (0.0307) Average Loss: 1.4416 (1.5685) Average CE Loss (Source):  1.4416 ( 1.5685) Learning Rate: 0.1000 (0.1000) Top1_base: 57.0312 (57.6172) Top1_base_per_class: 57.5595 (58.1333) 
Training Epoch: [16/1000] Step: [250 / 285] Batch Time: 0.1471 (0.1635) Data Time: 0.0147 (0.0305) Average Loss: 1.2806 (1.5689) Average CE Loss (Source):  1.2806 ( 1.5689) Learning Rate: 0.1000 (0.1000) Top1_base: 63.2812 (57.5375) Top1_base_per_class: 60.3939 (58.0673) 
Training Epoch: [16/1000] Step: [260 / 285] Batch Time: 0.1479 (0.1637) Data Time: 0.0117 (0.0307) Average Loss: 1.6899 (1.5713) Average CE Loss (Source):  1.6899 ( 1.5713) Learning Rate: 0.1000 (0.1000) Top1_base: 55.4688 (57.5361) Top1_base_per_class: 54.3803 (58.1021) 
Training Epoch: [16/1000] Step: [270 / 285] Batch Time: 0.1485 (0.1637) Data Time: 0.0116 (0.0306) Average Loss: 1.5682 (1.5719) Average CE Loss (Source):  1.5682 ( 1.5719) Learning Rate: 0.1000 (0.1000) Top1_base: 54.6875 (57.4884) Top1_base_per_class: 58.5632 (58.0571) 
Training Epoch: [16/1000] Step: [280 / 285] Batch Time: 0.1456 (0.1638) Data Time: 0.0120 (0.0307) Average Loss: 1.6714 (1.5741) Average CE Loss (Source):  1.6714 ( 1.5741) Learning Rate: 0.1000 (0.1000) Top1_base: 53.9062 (57.3996) Top1_base_per_class: 55.5263 (57.9689) 
Training Epoch: [17/1000] Step: [0] Batch Time: 0.1441 (0.1637) Data Time: 0.0108 (0.0306) Average Loss: 1.5502 (1.5746) Average CE Loss (Source):  1.5502 ( 1.5746) Learning Rate: 0.1000 (0.1000) Top1_base: 60.1562 (57.4095) Top1_base_per_class: 64.9415 (58.0402) 
Training Epoch: [17/1000] Step: [10 / 285] Batch Time: 0.1419 (0.2378) Data Time: 0.0110 (0.1052) Average Loss: 1.3883 (1.5052) Average CE Loss (Source):  1.3883 ( 1.5052) Learning Rate: 0.1000 (0.1000) Top1_base: 57.0312 (59.3750) Top1_base_per_class: 57.2778 (59.5575) 
Training Epoch: [17/1000] Step: [20 / 285] Batch Time: 0.1408 (0.1985) Data Time: 0.0099 (0.0667) Average Loss: 1.5136 (1.5393) Average CE Loss (Source):  1.5136 ( 1.5393) Learning Rate: 0.1000 (0.1000) Top1_base: 60.9375 (57.8125) Top1_base_per_class: 61.9883 (58.5470) 
Training Epoch: [17/1000] Step: [30 / 285] Batch Time: 0.1468 (0.1834) Data Time: 0.0143 (0.0516) Average Loss: 1.7495 (1.5465) Average CE Loss (Source):  1.7495 ( 1.5465) Learning Rate: 0.1000 (0.1000) Top1_base: 46.8750 (58.0469) Top1_base_per_class: 42.8363 (58.8821) 
Training Epoch: [17/1000] Step: [40 / 285] Batch Time: 0.1456 (0.1800) Data Time: 0.0099 (0.0477) Average Loss: 1.9458 (1.5679) Average CE Loss (Source):  1.9458 ( 1.5679) Learning Rate: 0.1000 (0.1000) Top1_base: 48.4375 (57.5781) Top1_base_per_class: 51.9136 (58.2809) 
Training Epoch: [17/1000] Step: [50 / 285] Batch Time: 0.1481 (0.1753) Data Time: 0.0136 (0.0426) Average Loss: 1.4388 (1.5578) Average CE Loss (Source):  1.4388 ( 1.5578) Learning Rate: 0.1000 (0.1000) Top1_base: 62.5000 (57.9375) Top1_base_per_class: 62.6061 (58.3889) 
Training Epoch: [17/1000] Step: [60 / 285] Batch Time: 0.1455 (0.1715) Data Time: 0.0112 (0.0387) Average Loss: 1.3686 (1.5562) Average CE Loss (Source):  1.3686 ( 1.5562) Learning Rate: 0.1000 (0.1000) Top1_base: 64.8438 (58.3203) Top1_base_per_class: 67.1541 (58.8944) 
Training Epoch: [17/1000] Step: [70 / 285] Batch Time: 0.1460 (0.1711) Data Time: 0.0123 (0.0382) Average Loss: 1.3094 (1.5466) Average CE Loss (Source):  1.3094 ( 1.5466) Learning Rate: 0.1000 (0.1000) Top1_base: 58.5938 (58.4933) Top1_base_per_class: 58.7500 (59.0004) 
Training Epoch: [17/1000] Step: [80 / 285] Batch Time: 0.1435 (0.1688) Data Time: 0.0099 (0.0358) Average Loss: 1.6397 (1.5421) Average CE Loss (Source):  1.6397 ( 1.5421) Learning Rate: 0.1000 (0.1000) Top1_base: 53.1250 (58.4668) Top1_base_per_class: 50.4248 (58.8577) 
Training Epoch: [17/1000] Step: [90 / 285] Batch Time: 0.1460 (0.1674) Data Time: 0.0133 (0.0344) Average Loss: 1.7327 (1.5366) Average CE Loss (Source):  1.7327 ( 1.5366) Learning Rate: 0.1000 (0.1000) Top1_base: 52.3438 (58.5851) Top1_base_per_class: 50.2830 (58.9003) 
Training Epoch: [17/1000] Step: [100 / 285] Batch Time: 0.1459 (0.1668) Data Time: 0.0110 (0.0337) Average Loss: 1.3330 (1.5292) Average CE Loss (Source):  1.3330 ( 1.5292) Learning Rate: 0.1000 (0.1000) Top1_base: 61.7188 (58.8438) Top1_base_per_class: 61.1988 (59.1246) 
Training Epoch: [17/1000] Step: [110 / 285] Batch Time: 0.1448 (0.1664) Data Time: 0.0108 (0.0332) Average Loss: 1.3347 (1.5251) Average CE Loss (Source):  1.3347 ( 1.5251) Learning Rate: 0.1000 (0.1000) Top1_base: 62.5000 (58.9134) Top1_base_per_class: 67.8274 (59.1596) 
Training Epoch: [17/1000] Step: [120 / 285] Batch Time: 0.1460 (0.1652) Data Time: 0.0108 (0.0319) Average Loss: 1.5253 (1.5259) Average CE Loss (Source):  1.5253 ( 1.5259) Learning Rate: 0.1000 (0.1000) Top1_base: 58.5938 (58.8477) Top1_base_per_class: 56.2798 (59.1589) 
Training Epoch: [17/1000] Step: [130 / 285] Batch Time: 0.1885 (0.1651) Data Time: 0.0559 (0.0318) Average Loss: 1.6007 (1.5274) Average CE Loss (Source):  1.6007 ( 1.5274) Learning Rate: 0.1000 (0.1000) Top1_base: 60.1562 (58.8281) Top1_base_per_class: 62.1154 (59.2719) 
Training Epoch: [17/1000] Step: [140 / 285] Batch Time: 0.1415 (0.1648) Data Time: 0.0104 (0.0315) Average Loss: 1.8097 (1.5330) Average CE Loss (Source):  1.8097 ( 1.5330) Learning Rate: 0.1000 (0.1000) Top1_base: 51.5625 (58.6998) Top1_base_per_class: 48.3333 (59.0718) 
Training Epoch: [17/1000] Step: [150 / 285] Batch Time: 0.1586 (0.1644) Data Time: 0.0243 (0.0312) Average Loss: 1.5313 (1.5378) Average CE Loss (Source):  1.5313 ( 1.5378) Learning Rate: 0.1000 (0.1000) Top1_base: 61.7188 (58.5573) Top1_base_per_class: 60.0877 (58.8955) 
Training Epoch: [17/1000] Step: [160 / 285] Batch Time: 0.1446 (0.1636) Data Time: 0.0101 (0.0303) Average Loss: 1.4279 (1.5343) Average CE Loss (Source):  1.4279 ( 1.5343) Learning Rate: 0.1000 (0.1000) Top1_base: 60.9375 (58.6279) Top1_base_per_class: 58.5631 (58.9266) 
Training Epoch: [17/1000] Step: [170 / 285] Batch Time: 0.1464 (0.1632) Data Time: 0.0123 (0.0299) Average Loss: 1.6140 (1.5377) Average CE Loss (Source):  1.6140 ( 1.5377) Learning Rate: 0.1000 (0.1000) Top1_base: 58.5938 (58.5708) Top1_base_per_class: 58.5804 (58.8908) 
Training Epoch: [17/1000] Step: [180 / 285] Batch Time: 0.1450 (0.1627) Data Time: 0.0105 (0.0294) Average Loss: 1.4641 (1.5373) Average CE Loss (Source):  1.4641 ( 1.5373) Learning Rate: 0.1000 (0.1000) Top1_base: 57.0312 (58.4852) Top1_base_per_class: 56.5179 (58.8577) 
Training Epoch: [17/1000] Step: [190 / 285] Batch Time: 0.1428 (0.1632) Data Time: 0.0099 (0.0298) Average Loss: 1.6303 (1.5383) Average CE Loss (Source):  1.6303 ( 1.5383) Learning Rate: 0.1000 (0.1000) Top1_base: 55.4688 (58.4416) Top1_base_per_class: 56.2579 (58.8018) 
Training Epoch: [17/1000] Step: [200 / 285] Batch Time: 0.1462 (0.1626) Data Time: 0.0120 (0.0292) Average Loss: 1.6421 (1.5404) Average CE Loss (Source):  1.6421 ( 1.5404) Learning Rate: 0.1000 (0.1000) Top1_base: 56.2500 (58.4492) Top1_base_per_class: 56.5476 (58.8573) 
Training Epoch: [17/1000] Step: [210 / 285] Batch Time: 0.1456 (0.1627) Data Time: 0.0108 (0.0292) Average Loss: 1.7030 (1.5380) Average CE Loss (Source):  1.7030 ( 1.5380) Learning Rate: 0.1000 (0.1000) Top1_base: 59.3750 (58.4784) Top1_base_per_class: 63.0864 (58.9002) 
Training Epoch: [17/1000] Step: [220 / 285] Batch Time: 0.1449 (0.1622) Data Time: 0.0099 (0.0288) Average Loss: 1.6239 (1.5416) Average CE Loss (Source):  1.6239 ( 1.5416) Learning Rate: 0.1000 (0.1000) Top1_base: 57.8125 (58.4482) Top1_base_per_class: 58.3631 (58.9081) 
Training Epoch: [17/1000] Step: [230 / 285] Batch Time: 0.1446 (0.1618) Data Time: 0.0109 (0.0282) Average Loss: 1.7724 (1.5432) Average CE Loss (Source):  1.7724 ( 1.5432) Learning Rate: 0.1000 (0.1000) Top1_base: 50.7812 (58.4783) Top1_base_per_class: 52.7273 (58.9530) 
Training Epoch: [17/1000] Step: [240 / 285] Batch Time: 0.1454 (0.1614) Data Time: 0.0115 (0.0279) Average Loss: 1.7339 (1.5447) Average CE Loss (Source):  1.7339 ( 1.5447) Learning Rate: 0.1000 (0.1000) Top1_base: 52.3438 (58.4635) Top1_base_per_class: 53.4821 (58.8906) 
Training Epoch: [17/1000] Step: [250 / 285] Batch Time: 0.1446 (0.1613) Data Time: 0.0098 (0.0277) Average Loss: 1.5714 (1.5475) Average CE Loss (Source):  1.5714 ( 1.5475) Learning Rate: 0.1000 (0.1000) Top1_base: 52.3438 (58.3500) Top1_base_per_class: 54.4231 (58.7851) 
Training Epoch: [17/1000] Step: [260 / 285] Batch Time: 0.1465 (0.1608) Data Time: 0.0121 (0.0272) Average Loss: 1.6582 (1.5497) Average CE Loss (Source):  1.6582 ( 1.5497) Learning Rate: 0.1000 (0.1000) Top1_base: 56.2500 (58.2662) Top1_base_per_class: 54.9679 (58.6986) 
Training Epoch: [17/1000] Step: [270 / 285] Batch Time: 0.1438 (0.1605) Data Time: 0.0095 (0.0269) Average Loss: 1.5049 (1.5486) Average CE Loss (Source):  1.5049 ( 1.5486) Learning Rate: 0.1000 (0.1000) Top1_base: 58.5938 (58.3102) Top1_base_per_class: 60.5449 (58.7262) 
Training Epoch: [17/1000] Step: [280 / 285] Batch Time: 0.1447 (0.1603) Data Time: 0.0106 (0.0267) Average Loss: 1.4656 (1.5473) Average CE Loss (Source):  1.4656 ( 1.5473) Learning Rate: 0.1000 (0.1000) Top1_base: 60.1562 (58.3259) Top1_base_per_class: 57.9885 (58.7359) 
Training Epoch: [18/1000] Step: [0] Batch Time: 0.1556 (0.1601) Data Time: 0.0217 (0.0265) Average Loss: 1.5107 (1.5477) Average CE Loss (Source):  1.5107 ( 1.5477) Learning Rate: 0.1000 (0.1000) Top1_base: 60.1562 (58.3224) Top1_base_per_class: 59.2121 (58.7693) 
  2%|▏         | 18/1000 [14:28<13:06:45, 48.07s/it]  2%|▏         | 19/1000 [15:15<12:59:39, 47.69s/it]Training Epoch: [18/1000] Step: [10 / 285] Batch Time: 0.1456 (0.2385) Data Time: 0.0140 (0.1062) Average Loss: 1.4165 (1.4862) Average CE Loss (Source):  1.4165 ( 1.4862) Learning Rate: 0.1000 (0.1000) Top1_base: 62.5000 (60.3906) Top1_base_per_class: 63.3333 (60.6344) 
Training Epoch: [18/1000] Step: [20 / 285] Batch Time: 0.1456 (0.1988) Data Time: 0.0106 (0.0665) Average Loss: 1.4276 (1.4932) Average CE Loss (Source):  1.4276 ( 1.4932) Learning Rate: 0.1000 (0.1000) Top1_base: 60.1562 (59.9219) Top1_base_per_class: 59.2813 (60.8426) 
Training Epoch: [18/1000] Step: [30 / 285] Batch Time: 0.1461 (0.1847) Data Time: 0.0140 (0.0526) Average Loss: 1.3164 (1.5055) Average CE Loss (Source):  1.3164 ( 1.5055) Learning Rate: 0.1000 (0.1000) Top1_base: 64.8438 (59.3229) Top1_base_per_class: 62.4269 (60.0277) 
Training Epoch: [18/1000] Step: [40 / 285] Batch Time: 0.1456 (0.1775) Data Time: 0.0106 (0.0449) Average Loss: 1.3385 (1.5008) Average CE Loss (Source):  1.3385 ( 1.5008) Learning Rate: 0.1000 (0.1000) Top1_base: 63.2812 (59.5312) Top1_base_per_class: 64.8830 (60.3657) 
Training Epoch: [18/1000] Step: [50 / 285] Batch Time: 0.1453 (0.1766) Data Time: 0.0134 (0.0438) Average Loss: 1.6199 (1.4936) Average CE Loss (Source):  1.6199 ( 1.4936) Learning Rate: 0.1000 (0.1000) Top1_base: 56.2500 (59.7500) Top1_base_per_class: 58.5220 (60.7519) 
Training Epoch: [18/1000] Step: [60 / 285] Batch Time: 0.1435 (0.1735) Data Time: 0.0107 (0.0406) Average Loss: 1.7075 (1.5029) Average CE Loss (Source):  1.7075 ( 1.5029) Learning Rate: 0.1000 (0.1000) Top1_base: 60.1562 (59.6484) Top1_base_per_class: 59.0517 (60.5799) 
Training Epoch: [18/1000] Step: [70 / 285] Batch Time: 0.1489 (0.1721) Data Time: 0.0137 (0.0392) Average Loss: 1.5570 (1.4982) Average CE Loss (Source):  1.5570 ( 1.4982) Learning Rate: 0.1000 (0.1000) Top1_base: 57.8125 (59.7991) Top1_base_per_class: 61.2274 (60.7907) 
Training Epoch: [18/1000] Step: [80 / 285] Batch Time: 0.1451 (0.1709) Data Time: 0.0120 (0.0381) Average Loss: 1.5964 (1.5070) Average CE Loss (Source):  1.5964 ( 1.5070) Learning Rate: 0.1000 (0.1000) Top1_base: 57.0312 (59.8047) Top1_base_per_class: 60.1381 (60.7835) 
Training Epoch: [18/1000] Step: [90 / 285] Batch Time: 0.1444 (0.1703) Data Time: 0.0099 (0.0375) Average Loss: 1.4942 (1.5038) Average CE Loss (Source):  1.4942 ( 1.5038) Learning Rate: 0.1000 (0.1000) Top1_base: 62.5000 (59.7917) Top1_base_per_class: 64.0230 (60.7814) 
Training Epoch: [18/1000] Step: [100 / 285] Batch Time: 0.1445 (0.1690) Data Time: 0.0121 (0.0363) Average Loss: 1.5948 (1.4955) Average CE Loss (Source):  1.5948 ( 1.4955) Learning Rate: 0.1000 (0.1000) Top1_base: 60.9375 (59.9609) Top1_base_per_class: 59.8312 (60.8568) 
Training Epoch: [18/1000] Step: [110 / 285] Batch Time: 0.1452 (0.1684) Data Time: 0.0103 (0.0356) Average Loss: 1.2695 (1.4880) Average CE Loss (Source):  1.2695 ( 1.4880) Learning Rate: 0.1000 (0.1000) Top1_base: 60.1562 (60.0355) Top1_base_per_class: 60.8479 (60.9154) 
Training Epoch: [18/1000] Step: [120 / 285] Batch Time: 0.1461 (0.1675) Data Time: 0.0126 (0.0345) Average Loss: 1.5550 (1.4905) Average CE Loss (Source):  1.5550 ( 1.4905) Learning Rate: 0.1000 (0.1000) Top1_base: 58.5938 (59.9935) Top1_base_per_class: 58.5758 (60.8450) 
Training Epoch: [18/1000] Step: [130 / 285] Batch Time: 0.1436 (0.1678) Data Time: 0.0102 (0.0349) Average Loss: 1.5219 (1.4936) Average CE Loss (Source):  1.5219 ( 1.4936) Learning Rate: 0.1000 (0.1000) Top1_base: 60.1562 (59.8858) Top1_base_per_class: 59.4653 (60.5594) 
Training Epoch: [18/1000] Step: [140 / 285] Batch Time: 0.1447 (0.1665) Data Time: 0.0118 (0.0336) Average Loss: 1.8800 (1.5009) Average CE Loss (Source):  1.8800 ( 1.5009) Learning Rate: 0.1000 (0.1000) Top1_base: 51.5625 (59.6931) Top1_base_per_class: 50.6389 (60.3361) 
Training Epoch: [18/1000] Step: [150 / 285] Batch Time: 0.1477 (0.1663) Data Time: 0.0156 (0.0334) Average Loss: 1.4332 (1.5015) Average CE Loss (Source):  1.4332 ( 1.5015) Learning Rate: 0.1000 (0.1000) Top1_base: 55.4688 (59.6458) Top1_base_per_class: 56.5628 (60.3200) 
Training Epoch: [18/1000] Step: [160 / 285] Batch Time: 0.1462 (0.1662) Data Time: 0.0137 (0.0333) Average Loss: 1.3380 (1.5023) Average CE Loss (Source):  1.3380 ( 1.5023) Learning Rate: 0.1000 (0.1000) Top1_base: 61.7188 (59.5752) Top1_base_per_class: 63.9697 (60.2287) 
Training Epoch: [18/1000] Step: [170 / 285] Batch Time: 0.1474 (0.1660) Data Time: 0.0134 (0.0329) Average Loss: 1.4627 (1.5007) Average CE Loss (Source):  1.4627 ( 1.5007) Learning Rate: 0.1000 (0.1000) Top1_base: 61.7188 (59.6737) Top1_base_per_class: 65.5758 (60.3207) 
Training Epoch: [18/1000] Step: [180 / 285] Batch Time: 0.1440 (0.1669) Data Time: 0.0113 (0.0339) Average Loss: 1.2681 (1.4968) Average CE Loss (Source):  1.2681 ( 1.4968) Learning Rate: 0.1000 (0.1000) Top1_base: 65.6250 (59.7179) Top1_base_per_class: 63.1515 (60.2790) 
Training Epoch: [18/1000] Step: [190 / 285] Batch Time: 0.1451 (0.1664) Data Time: 0.0121 (0.0334) Average Loss: 1.3495 (1.4961) Average CE Loss (Source):  1.3495 ( 1.4961) Learning Rate: 0.1000 (0.1000) Top1_base: 61.7188 (59.6957) Top1_base_per_class: 63.5965 (60.2618) 
Training Epoch: [18/1000] Step: [200 / 285] Batch Time: 0.1425 (0.1660) Data Time: 0.0104 (0.0330) Average Loss: 1.7498 (1.4968) Average CE Loss (Source):  1.7498 ( 1.4968) Learning Rate: 0.1000 (0.1000) Top1_base: 56.2500 (59.6992) Top1_base_per_class: 59.4340 (60.2608) 
Training Epoch: [18/1000] Step: [210 / 285] Batch Time: 0.1455 (0.1653) Data Time: 0.0102 (0.0323) Average Loss: 1.3678 (1.4973) Average CE Loss (Source):  1.3678 ( 1.4973) Learning Rate: 0.1000 (0.1000) Top1_base: 65.6250 (59.7842) Top1_base_per_class: 63.9091 (60.3069) 
Training Epoch: [18/1000] Step: [220 / 285] Batch Time: 0.1473 (0.1648) Data Time: 0.0132 (0.0317) Average Loss: 1.3969 (1.4961) Average CE Loss (Source):  1.3969 ( 1.4961) Learning Rate: 0.1000 (0.1000) Top1_base: 60.9375 (59.7585) Top1_base_per_class: 61.2573 (60.2411) 
Training Epoch: [18/1000] Step: [230 / 285] Batch Time: 0.1471 (0.1647) Data Time: 0.0122 (0.0317) Average Loss: 1.5058 (1.4934) Average CE Loss (Source):  1.5058 ( 1.4934) Learning Rate: 0.1000 (0.1000) Top1_base: 57.0312 (59.8539) Top1_base_per_class: 58.0848 (60.3189) 
Training Epoch: [18/1000] Step: [240 / 285] Batch Time: 0.1439 (0.1647) Data Time: 0.0112 (0.0316) Average Loss: 1.7213 (1.4960) Average CE Loss (Source):  1.7213 ( 1.4960) Learning Rate: 0.1000 (0.1000) Top1_base: 55.4688 (59.8438) Top1_base_per_class: 61.6346 (60.2956) 
Training Epoch: [18/1000] Step: [250 / 285] Batch Time: 0.1449 (0.1641) Data Time: 0.0120 (0.0311) Average Loss: 1.3298 (1.4949) Average CE Loss (Source):  1.3298 ( 1.4949) Learning Rate: 0.1000 (0.1000) Top1_base: 65.6250 (59.8906) Top1_base_per_class: 67.8869 (60.3639) 
Training Epoch: [18/1000] Step: [260 / 285] Batch Time: 0.1461 (0.1642) Data Time: 0.0126 (0.0312) Average Loss: 1.5213 (1.4983) Average CE Loss (Source):  1.5213 ( 1.4983) Learning Rate: 0.1000 (0.1000) Top1_base: 59.3750 (59.7716) Top1_base_per_class: 64.9177 (60.2672) 
Training Epoch: [18/1000] Step: [270 / 285] Batch Time: 0.1447 (0.1642) Data Time: 0.0114 (0.0312) Average Loss: 1.3600 (1.4980) Average CE Loss (Source):  1.3600 ( 1.4980) Learning Rate: 0.1000 (0.1000) Top1_base: 63.2812 (59.7338) Top1_base_per_class: 63.4906 (60.2028) 
Training Epoch: [18/1000] Step: [280 / 285] Batch Time: 0.1441 (0.1643) Data Time: 0.0112 (0.0313) Average Loss: 1.4476 (1.4982) Average CE Loss (Source):  1.4476 ( 1.4982) Learning Rate: 0.1000 (0.1000) Top1_base: 58.5938 (59.7182) Top1_base_per_class: 60.6845 (60.2135) 
Training Epoch: [19/1000] Step: [0] Batch Time: 0.1415 (0.1640) Data Time: 0.0107 (0.0310) Average Loss: 1.6560 (1.4983) Average CE Loss (Source):  1.6560 ( 1.4983) Learning Rate: 0.1000 (0.1000) Top1_base: 59.3750 (59.7505) Top1_base_per_class: 57.9964 (60.2367) 
Training Epoch: [19/1000] Step: [10 / 285] Batch Time: 0.1454 (0.2309) Data Time: 0.0137 (0.0986) Average Loss: 1.4034 (1.3825) Average CE Loss (Source):  1.4034 ( 1.3825) Learning Rate: 0.1000 (0.1000) Top1_base: 60.1562 (61.4844) Top1_base_per_class: 59.5480 (61.8706) 
Training Epoch: [19/1000] Step: [20 / 285] Batch Time: 0.1432 (0.1940) Data Time: 0.0106 (0.0624) Average Loss: 1.1468 (1.4157) Average CE Loss (Source):  1.1468 ( 1.4157) Learning Rate: 0.1000 (0.1000) Top1_base: 68.7500 (60.8984) Top1_base_per_class: 68.1921 (60.5281) 
Training Epoch: [19/1000] Step: [30 / 285] Batch Time: 0.1735 (0.1864) Data Time: 0.0430 (0.0547) Average Loss: 1.2908 (1.3966) Average CE Loss (Source):  1.2908 ( 1.3966) Learning Rate: 0.1000 (0.1000) Top1_base: 66.4062 (61.9271) Top1_base_per_class: 71.1310 (61.8532) 
Training Epoch: [19/1000] Step: [40 / 285] Batch Time: 0.1441 (0.1785) Data Time: 0.0110 (0.0467) Average Loss: 1.7078 (1.4110) Average CE Loss (Source):  1.7078 ( 1.4110) Learning Rate: 0.1000 (0.1000) Top1_base: 59.3750 (61.6992) Top1_base_per_class: 56.1728 (61.8964) 
Training Epoch: [19/1000] Step: [50 / 285] Batch Time: 0.1948 (0.1752) Data Time: 0.0630 (0.0433) Average Loss: 1.3868 (1.4108) Average CE Loss (Source):  1.3868 ( 1.4108) Learning Rate: 0.1000 (0.1000) Top1_base: 58.5938 (61.5469) Top1_base_per_class: 59.5912 (61.6223) 
Training Epoch: [19/1000] Step: [60 / 285] Batch Time: 0.1437 (0.1720) Data Time: 0.0110 (0.0400) Average Loss: 1.1110 (1.4076) Average CE Loss (Source):  1.1110 ( 1.4076) Learning Rate: 0.1000 (0.1000) Top1_base: 71.8750 (61.7708) Top1_base_per_class: 70.9091 (61.8217) 
Training Epoch: [19/1000] Step: [70 / 285] Batch Time: 0.1435 (0.1704) Data Time: 0.0116 (0.0385) Average Loss: 1.1372 (1.4100) Average CE Loss (Source):  1.1372 ( 1.4100) Learning Rate: 0.1000 (0.1000) Top1_base: 68.7500 (61.7411) Top1_base_per_class: 74.4536 (61.8679) 
Training Epoch: [19/1000] Step: [80 / 285] Batch Time: 0.1438 (0.1682) Data Time: 0.0121 (0.0363) Average Loss: 1.3899 (1.4142) Average CE Loss (Source):  1.3899 ( 1.4142) Learning Rate: 0.1000 (0.1000) Top1_base: 60.9375 (61.6211) Top1_base_per_class: 62.9245 (61.8652) 
Training Epoch: [19/1000] Step: [90 / 285] Batch Time: 0.1429 (0.1674) Data Time: 0.0105 (0.0355) Average Loss: 1.6551 (1.4307) Average CE Loss (Source):  1.6551 ( 1.4307) Learning Rate: 0.1000 (0.1000) Top1_base: 53.9062 (61.2500) Top1_base_per_class: 57.3810 (61.5367) 
Training Epoch: [19/1000] Step: [100 / 285] Batch Time: 0.1464 (0.1674) Data Time: 0.0113 (0.0352) Average Loss: 1.5309 (1.4291) Average CE Loss (Source):  1.5309 ( 1.4291) Learning Rate: 0.1000 (0.1000) Top1_base: 54.6875 (61.1250) Top1_base_per_class: 53.8988 (61.4217) 
Training Epoch: [19/1000] Step: [110 / 285] Batch Time: 0.1434 (0.1679) Data Time: 0.0110 (0.0356) Average Loss: 1.5270 (1.4306) Average CE Loss (Source):  1.5270 ( 1.4306) Learning Rate: 0.1000 (0.1000) Top1_base: 56.2500 (61.2003) Top1_base_per_class: 55.2012 (61.4539) 
Training Epoch: [19/1000] Step: [120 / 285] Batch Time: 0.1459 (0.1668) Data Time: 0.0130 (0.0345) Average Loss: 1.4897 (1.4374) Average CE Loss (Source):  1.4897 ( 1.4374) Learning Rate: 0.1000 (0.1000) Top1_base: 60.9375 (61.0482) Top1_base_per_class: 67.8302 (61.4586) 
Training Epoch: [19/1000] Step: [130 / 285] Batch Time: 0.1410 (0.1656) Data Time: 0.0102 (0.0333) Average Loss: 1.6442 (1.4462) Average CE Loss (Source):  1.6442 ( 1.4462) Learning Rate: 0.1000 (0.1000) Top1_base: 59.3750 (60.7993) Top1_base_per_class: 66.2654 (61.3520) 
Training Epoch: [19/1000] Step: [140 / 285] Batch Time: 0.1447 (0.1647) Data Time: 0.0132 (0.0324) Average Loss: 1.4143 (1.4424) Average CE Loss (Source):  1.4143 ( 1.4424) Learning Rate: 0.1000 (0.1000) Top1_base: 60.9375 (60.8761) Top1_base_per_class: 64.1818 (61.4371) 
Training Epoch: [19/1000] Step: [150 / 285] Batch Time: 0.1457 (0.1643) Data Time: 0.0136 (0.0320) Average Loss: 1.4527 (1.4486) Average CE Loss (Source):  1.4527 ( 1.4486) Learning Rate: 0.1000 (0.1000) Top1_base: 58.5938 (60.8385) Top1_base_per_class: 60.2424 (61.3851) 
Training Epoch: [19/1000] Step: [160 / 285] Batch Time: 0.1453 (0.1637) Data Time: 0.0140 (0.0314) Average Loss: 1.5294 (1.4490) Average CE Loss (Source):  1.5294 ( 1.4490) Learning Rate: 0.1000 (0.1000) Top1_base: 57.8125 (60.7959) Top1_base_per_class: 61.2121 (61.4421) 
Training Epoch: [19/1000] Step: [170 / 285] Batch Time: 0.1429 (0.1629) Data Time: 0.0112 (0.0305) Average Loss: 1.6180 (1.4546) Average CE Loss (Source):  1.6180 ( 1.4546) Learning Rate: 0.1000 (0.1000) Top1_base: 57.8125 (60.6204) Top1_base_per_class: 55.7602 (61.1555) 
Training Epoch: [19/1000] Step: [180 / 285] Batch Time: 0.1431 (0.1628) Data Time: 0.0109 (0.0305) Average Loss: 1.2393 (1.4535) Average CE Loss (Source):  1.2393 ( 1.4535) Learning Rate: 0.1000 (0.1000) Top1_base: 67.9688 (60.6727) Top1_base_per_class: 65.6061 (61.1806) 
Training Epoch: [19/1000] Step: [190 / 285] Batch Time: 0.1435 (0.1627) Data Time: 0.0110 (0.0304) Average Loss: 1.6576 (1.4537) Average CE Loss (Source):  1.6576 ( 1.4537) Learning Rate: 0.1000 (0.1000) Top1_base: 54.6875 (60.5551) Top1_base_per_class: 57.3276 (60.9726) 
Training Epoch: [19/1000] Step: [200 / 285] Batch Time: 0.1477 (0.1622) Data Time: 0.0157 (0.0299) Average Loss: 1.3919 (1.4536) Average CE Loss (Source):  1.3919 ( 1.4536) Learning Rate: 0.1000 (0.1000) Top1_base: 64.0625 (60.5391) Top1_base_per_class: 67.5170 (60.9155) 
Training Epoch: [19/1000] Step: [210 / 285] Batch Time: 0.1464 (0.1615) Data Time: 0.0133 (0.0291) Average Loss: 1.3091 (1.4509) Average CE Loss (Source):  1.3091 ( 1.4509) Learning Rate: 0.1000 (0.1000) Top1_base: 67.1875 (60.6510) Top1_base_per_class: 62.9532 (60.9638) 
Training Epoch: [19/1000] Step: [220 / 285] Batch Time: 0.1439 (0.1608) Data Time: 0.0105 (0.0284) Average Loss: 1.2935 (1.4525) Average CE Loss (Source):  1.2935 ( 1.4525) Learning Rate: 0.1000 (0.1000) Top1_base: 61.7188 (60.6534) Top1_base_per_class: 62.1469 (60.9621) 
Training Epoch: [19/1000] Step: [230 / 285] Batch Time: 0.1411 (0.1611) Data Time: 0.0103 (0.0287) Average Loss: 1.2766 (1.4562) Average CE Loss (Source):  1.2766 ( 1.4562) Learning Rate: 0.1000 (0.1000) Top1_base: 65.6250 (60.5978) Top1_base_per_class: 64.8428 (60.9324) 
Training Epoch: [19/1000] Step: [240 / 285] Batch Time: 0.1436 (0.1607) Data Time: 0.0122 (0.0284) Average Loss: 1.5548 (1.4594) Average CE Loss (Source):  1.5548 ( 1.4594) Learning Rate: 0.1000 (0.1000) Top1_base: 54.6875 (60.5436) Top1_base_per_class: 53.1896 (60.8634) 
Training Epoch: [19/1000] Step: [250 / 285] Batch Time: 0.1428 (0.1609) Data Time: 0.0103 (0.0286) Average Loss: 1.6223 (1.4628) Average CE Loss (Source):  1.6223 ( 1.4628) Learning Rate: 0.1000 (0.1000) Top1_base: 51.5625 (60.4312) Top1_base_per_class: 54.9673 (60.7497) 
Training Epoch: [19/1000] Step: [260 / 285] Batch Time: 0.1425 (0.1606) Data Time: 0.0106 (0.0283) Average Loss: 1.8002 (1.4664) Average CE Loss (Source):  1.8002 ( 1.4664) Learning Rate: 0.1000 (0.1000) Top1_base: 54.6875 (60.3606) Top1_base_per_class: 54.8056 (60.6435) 
Training Epoch: [19/1000] Step: [270 / 285] Batch Time: 0.1433 (0.1601) Data Time: 0.0104 (0.0278) Average Loss: 1.5123 (1.4661) Average CE Loss (Source):  1.5123 ( 1.4661) Learning Rate: 0.1000 (0.1000) Top1_base: 59.3750 (60.4051) Top1_base_per_class: 58.9286 (60.7074) 
Training Epoch: [19/1000] Step: [280 / 285] Batch Time: 0.1433 (0.1598) Data Time: 0.0105 (0.0276) Average Loss: 1.5458 (1.4679) Average CE Loss (Source):  1.5458 ( 1.4679) Learning Rate: 0.1000 (0.1000) Top1_base: 57.0312 (60.3962) Top1_base_per_class: 57.7545 (60.6899) 
Training Epoch: [20/1000] Step: [0] Batch Time: 0.2753 (0.1600) Data Time: 0.1427 (0.0278) Average Loss: 1.6673 (1.4684) Average CE Loss (Source):  1.6673 ( 1.4684) Learning Rate: 0.1000 (0.1000) Top1_base: 58.5938 (60.4194) Top1_base_per_class: 56.5653 (60.6935) 
  2%|▏         | 20/1000 [16:03<13:03:13, 47.95s/it]  2%|▏         | 21/1000 [16:50<12:55:34, 47.53s/it]Training Epoch: [20/1000] Step: [10 / 285] Batch Time: 0.1434 (0.2310) Data Time: 0.0114 (0.0988) Average Loss: 1.3020 (1.4271) Average CE Loss (Source):  1.3020 ( 1.4271) Learning Rate: 0.1000 (0.1000) Top1_base: 64.8438 (62.4219) Top1_base_per_class: 64.5370 (62.5076) 
Training Epoch: [20/1000] Step: [20 / 285] Batch Time: 0.1404 (0.1955) Data Time: 0.0100 (0.0635) Average Loss: 1.1021 (1.3962) Average CE Loss (Source):  1.1021 ( 1.3962) Learning Rate: 0.1000 (0.1000) Top1_base: 66.4062 (62.6172) Top1_base_per_class: 70.4167 (63.2024) 
Training Epoch: [20/1000] Step: [30 / 285] Batch Time: 0.1436 (0.1844) Data Time: 0.0120 (0.0528) Average Loss: 1.1415 (1.3655) Average CE Loss (Source):  1.1415 ( 1.3655) Learning Rate: 0.1000 (0.1000) Top1_base: 67.9688 (63.2292) Top1_base_per_class: 69.4737 (64.0642) 
Training Epoch: [20/1000] Step: [40 / 285] Batch Time: 0.1426 (0.1827) Data Time: 0.0110 (0.0509) Average Loss: 1.4270 (1.3833) Average CE Loss (Source):  1.4270 ( 1.3833) Learning Rate: 0.1000 (0.1000) Top1_base: 60.9375 (62.7930) Top1_base_per_class: 63.0909 (63.3750) 
Training Epoch: [20/1000] Step: [50 / 285] Batch Time: 0.1448 (0.1802) Data Time: 0.0132 (0.0484) Average Loss: 1.2263 (1.3875) Average CE Loss (Source):  1.2263 ( 1.3875) Learning Rate: 0.1000 (0.1000) Top1_base: 70.3125 (62.4062) Top1_base_per_class: 66.6667 (62.8542) 
Training Epoch: [20/1000] Step: [60 / 285] Batch Time: 0.1410 (0.1777) Data Time: 0.0102 (0.0459) Average Loss: 1.3425 (1.3865) Average CE Loss (Source):  1.3425 ( 1.3865) Learning Rate: 0.1000 (0.1000) Top1_base: 58.5938 (62.3438) Top1_base_per_class: 59.5679 (62.7617) 
Training Epoch: [20/1000] Step: [70 / 285] Batch Time: 0.1443 (0.1745) Data Time: 0.0128 (0.0428) Average Loss: 1.6009 (1.3996) Average CE Loss (Source):  1.6009 ( 1.3996) Learning Rate: 0.1000 (0.1000) Top1_base: 48.4375 (61.8973) Top1_base_per_class: 47.9167 (62.3787) 
Training Epoch: [20/1000] Step: [80 / 285] Batch Time: 0.1425 (0.1733) Data Time: 0.0110 (0.0417) Average Loss: 1.1970 (1.4017) Average CE Loss (Source):  1.1970 ( 1.4017) Learning Rate: 0.1000 (0.1000) Top1_base: 67.9688 (61.8164) Top1_base_per_class: 69.7024 (62.2267) 
Training Epoch: [20/1000] Step: [90 / 285] Batch Time: 0.1450 (0.1716) Data Time: 0.0137 (0.0400) Average Loss: 1.3424 (1.4092) Average CE Loss (Source):  1.3424 ( 1.4092) Learning Rate: 0.1000 (0.1000) Top1_base: 61.7188 (61.6840) Top1_base_per_class: 63.1173 (62.1603) 
Training Epoch: [20/1000] Step: [100 / 285] Batch Time: 0.1442 (0.1710) Data Time: 0.0108 (0.0393) Average Loss: 1.1791 (1.4150) Average CE Loss (Source):  1.1791 ( 1.4150) Learning Rate: 0.1000 (0.1000) Top1_base: 72.6562 (61.6328) Top1_base_per_class: 72.2701 (62.0335) 
Training Epoch: [20/1000] Step: [110 / 285] Batch Time: 0.1425 (0.1697) Data Time: 0.0108 (0.0380) Average Loss: 1.5979 (1.4129) Average CE Loss (Source):  1.5979 ( 1.4129) Learning Rate: 0.1000 (0.1000) Top1_base: 50.7812 (61.6264) Top1_base_per_class: 52.3718 (62.0497) 
Training Epoch: [20/1000] Step: [120 / 285] Batch Time: 0.1429 (0.1686) Data Time: 0.0104 (0.0368) Average Loss: 1.4387 (1.4136) Average CE Loss (Source):  1.4387 ( 1.4136) Learning Rate: 0.1000 (0.1000) Top1_base: 63.2812 (61.5885) Top1_base_per_class: 66.2573 (62.0569) 
Training Epoch: [20/1000] Step: [130 / 285] Batch Time: 0.1451 (0.1673) Data Time: 0.0107 (0.0355) Average Loss: 1.5242 (1.4157) Average CE Loss (Source):  1.5242 ( 1.4157) Learning Rate: 0.1000 (0.1000) Top1_base: 59.3750 (61.4603) Top1_base_per_class: 62.4383 (62.0112) 
Training Epoch: [20/1000] Step: [140 / 285] Batch Time: 0.1457 (0.1662) Data Time: 0.0114 (0.0343) Average Loss: 1.5379 (1.4184) Average CE Loss (Source):  1.5379 ( 1.4184) Learning Rate: 0.1000 (0.1000) Top1_base: 60.1562 (61.4900) Top1_base_per_class: 62.6190 (62.0836) 
Training Epoch: [20/1000] Step: [150 / 285] Batch Time: 0.1477 (0.1653) Data Time: 0.0110 (0.0334) Average Loss: 1.5192 (1.4201) Average CE Loss (Source):  1.5192 ( 1.4201) Learning Rate: 0.1000 (0.1000) Top1_base: 57.0312 (61.3906) Top1_base_per_class: 59.1813 (62.0494) 
Training Epoch: [20/1000] Step: [160 / 285] Batch Time: 0.1443 (0.1659) Data Time: 0.0099 (0.0338) Average Loss: 1.5979 (1.4237) Average CE Loss (Source):  1.5979 ( 1.4237) Learning Rate: 0.1000 (0.1000) Top1_base: 61.7188 (61.2646) Top1_base_per_class: 61.3095 (61.9338) 
Training Epoch: [20/1000] Step: [170 / 285] Batch Time: 0.1471 (0.1651) Data Time: 0.0146 (0.0328) Average Loss: 1.4358 (1.4266) Average CE Loss (Source):  1.4358 ( 1.4266) Learning Rate: 0.1000 (0.1000) Top1_base: 63.2812 (61.1765) Top1_base_per_class: 61.5179 (61.8185) 
Training Epoch: [20/1000] Step: [180 / 285] Batch Time: 0.1439 (0.1648) Data Time: 0.0106 (0.0325) Average Loss: 1.6441 (1.4293) Average CE Loss (Source):  1.6441 ( 1.4293) Learning Rate: 0.1000 (0.1000) Top1_base: 56.2500 (60.9896) Top1_base_per_class: 51.9940 (61.5550) 
Training Epoch: [20/1000] Step: [190 / 285] Batch Time: 0.1456 (0.1653) Data Time: 0.0107 (0.0329) Average Loss: 1.5931 (1.4340) Average CE Loss (Source):  1.5931 ( 1.4340) Learning Rate: 0.1000 (0.1000) Top1_base: 54.6875 (60.8512) Top1_base_per_class: 54.8718 (61.4422) 
Training Epoch: [20/1000] Step: [200 / 285] Batch Time: 0.1447 (0.1656) Data Time: 0.0129 (0.0332) Average Loss: 1.4246 (1.4333) Average CE Loss (Source):  1.4246 ( 1.4333) Learning Rate: 0.1000 (0.1000) Top1_base: 58.5938 (60.8438) Top1_base_per_class: 58.4187 (61.4419) 
Training Epoch: [20/1000] Step: [210 / 285] Batch Time: 0.1460 (0.1651) Data Time: 0.0133 (0.0327) Average Loss: 1.2864 (1.4341) Average CE Loss (Source):  1.2864 ( 1.4341) Learning Rate: 0.1000 (0.1000) Top1_base: 62.5000 (60.8631) Top1_base_per_class: 57.8869 (61.4662) 
Training Epoch: [20/1000] Step: [220 / 285] Batch Time: 0.1421 (0.1650) Data Time: 0.0104 (0.0326) Average Loss: 1.5748 (1.4350) Average CE Loss (Source):  1.5748 ( 1.4350) Learning Rate: 0.1000 (0.1000) Top1_base: 61.7188 (60.8416) Top1_base_per_class: 62.1552 (61.4521) 
Training Epoch: [20/1000] Step: [230 / 285] Batch Time: 0.1445 (0.1645) Data Time: 0.0123 (0.0321) Average Loss: 1.2553 (1.4338) Average CE Loss (Source):  1.2553 ( 1.4338) Learning Rate: 0.1000 (0.1000) Top1_base: 64.0625 (60.8424) Top1_base_per_class: 66.2424 (61.3796) 
Training Epoch: [20/1000] Step: [240 / 285] Batch Time: 0.1425 (0.1642) Data Time: 0.0114 (0.0317) Average Loss: 1.4666 (1.4323) Average CE Loss (Source):  1.4666 ( 1.4323) Learning Rate: 0.1000 (0.1000) Top1_base: 60.1562 (60.8659) Top1_base_per_class: 60.4012 (61.3745) 
Training Epoch: [20/1000] Step: [250 / 285] Batch Time: 0.1489 (0.1638) Data Time: 0.0170 (0.0313) Average Loss: 1.5448 (1.4345) Average CE Loss (Source):  1.5448 ( 1.4345) Learning Rate: 0.1000 (0.1000) Top1_base: 60.9375 (60.8062) Top1_base_per_class: 61.8182 (61.3176) 
Training Epoch: [20/1000] Step: [260 / 285] Batch Time: 0.1413 (0.1637) Data Time: 0.0108 (0.0312) Average Loss: 1.4643 (1.4360) Average CE Loss (Source):  1.4643 ( 1.4360) Learning Rate: 0.1000 (0.1000) Top1_base: 63.2812 (60.7993) Top1_base_per_class: 59.9697 (61.3173) 
Training Epoch: [20/1000] Step: [270 / 285] Batch Time: 0.1466 (0.1635) Data Time: 0.0143 (0.0311) Average Loss: 1.2535 (1.4358) Average CE Loss (Source):  1.2535 ( 1.4358) Learning Rate: 0.1000 (0.1000) Top1_base: 64.0625 (60.8044) Top1_base_per_class: 69.1585 (61.3388) 
Training Epoch: [20/1000] Step: [280 / 285] Batch Time: 0.1424 (0.1633) Data Time: 0.0112 (0.0309) Average Loss: 1.5728 (1.4343) Average CE Loss (Source):  1.5728 ( 1.4343) Learning Rate: 0.1000 (0.1000) Top1_base: 58.5938 (60.8761) Top1_base_per_class: 60.6725 (61.4498) 
Training Epoch: [21/1000] Step: [0] Batch Time: 0.1404 (0.1631) Data Time: 0.0099 (0.0307) Average Loss: 1.3879 (1.4332) Average CE Loss (Source):  1.3879 ( 1.4332) Learning Rate: 0.1000 (0.1000) Top1_base: 62.5000 (60.8772) Top1_base_per_class: 62.9938 (61.4495) 
Training Epoch: [21/1000] Step: [10 / 285] Batch Time: 0.1456 (0.2368) Data Time: 0.0134 (0.1056) Average Loss: 1.4538 (1.3367) Average CE Loss (Source):  1.4538 ( 1.3367) Learning Rate: 0.1000 (0.1000) Top1_base: 61.7188 (63.0469) Top1_base_per_class: 60.2874 (62.0839) 
Training Epoch: [21/1000] Step: [20 / 285] Batch Time: 0.1399 (0.1987) Data Time: 0.0102 (0.0675) Average Loss: 1.1576 (1.4047) Average CE Loss (Source):  1.1576 ( 1.4047) Learning Rate: 0.1000 (0.1000) Top1_base: 69.5312 (61.6797) Top1_base_per_class: 69.0833 (61.1835) 
Training Epoch: [21/1000] Step: [30 / 285] Batch Time: 0.1448 (0.1889) Data Time: 0.0125 (0.0577) Average Loss: 1.2011 (1.3836) Average CE Loss (Source):  1.2011 ( 1.3836) Learning Rate: 0.1000 (0.1000) Top1_base: 66.4062 (62.2656) Top1_base_per_class: 67.5000 (61.9607) 
Training Epoch: [21/1000] Step: [40 / 285] Batch Time: 0.1445 (0.1834) Data Time: 0.0113 (0.0518) Average Loss: 1.6618 (1.4092) Average CE Loss (Source):  1.6618 ( 1.4092) Learning Rate: 0.1000 (0.1000) Top1_base: 57.8125 (61.7578) Top1_base_per_class: 60.2934 (61.7914) 
Training Epoch: [21/1000] Step: [50 / 285] Batch Time: 0.2284 (0.1790) Data Time: 0.0963 (0.0470) Average Loss: 1.0783 (1.3949) Average CE Loss (Source):  1.0783 ( 1.3949) Learning Rate: 0.1000 (0.1000) Top1_base: 71.8750 (62.3906) Top1_base_per_class: 74.2560 (62.5306) 
Training Epoch: [21/1000] Step: [60 / 285] Batch Time: 0.1459 (0.1756) Data Time: 0.0102 (0.0431) Average Loss: 1.6389 (1.3984) Average CE Loss (Source):  1.6389 ( 1.3984) Learning Rate: 0.1000 (0.1000) Top1_base: 60.9375 (62.2135) Top1_base_per_class: 62.8814 (62.4401) 
Training Epoch: [21/1000] Step: [70 / 285] Batch Time: 0.3090 (0.1763) Data Time: 0.1761 (0.0435) Average Loss: 1.5108 (1.4077) Average CE Loss (Source):  1.5108 ( 1.4077) Learning Rate: 0.1000 (0.1000) Top1_base: 60.9375 (62.1429) Top1_base_per_class: 59.1975 (62.4343) 
Training Epoch: [21/1000] Step: [80 / 285] Batch Time: 0.1447 (0.1734) Data Time: 0.0108 (0.0404) Average Loss: 1.3227 (1.4007) Average CE Loss (Source):  1.3227 ( 1.4007) Learning Rate: 0.1000 (0.1000) Top1_base: 62.5000 (62.2754) Top1_base_per_class: 65.3636 (62.6777) 
Training Epoch: [21/1000] Step: [90 / 285] Batch Time: 0.1815 (0.1713) Data Time: 0.0473 (0.0382) Average Loss: 1.3798 (1.3985) Average CE Loss (Source):  1.3798 ( 1.3985) Learning Rate: 0.1000 (0.1000) Top1_base: 63.2812 (62.3698) Top1_base_per_class: 65.5263 (62.9966) 
Training Epoch: [21/1000] Step: [100 / 285] Batch Time: 0.1447 (0.1702) Data Time: 0.0114 (0.0370) Average Loss: 1.5675 (1.4013) Average CE Loss (Source):  1.5675 ( 1.4013) Learning Rate: 0.1000 (0.1000) Top1_base: 56.2500 (62.3047) Top1_base_per_class: 53.4591 (63.0867) 
Training Epoch: [21/1000] Step: [110 / 285] Batch Time: 0.1890 (0.1688) Data Time: 0.0558 (0.0356) Average Loss: 1.4066 (1.4121) Average CE Loss (Source):  1.4066 ( 1.4121) Learning Rate: 0.1000 (0.1000) Top1_base: 64.0625 (61.9815) Top1_base_per_class: 65.1235 (62.7604) 
Training Epoch: [21/1000] Step: [120 / 285] Batch Time: 0.1461 (0.1673) Data Time: 0.0106 (0.0340) Average Loss: 1.0406 (1.4083) Average CE Loss (Source):  1.0406 ( 1.4083) Learning Rate: 0.1000 (0.1000) Top1_base: 68.7500 (62.0378) Top1_base_per_class: 69.1092 (62.7510) 
Training Epoch: [21/1000] Step: [130 / 285] Batch Time: 0.1911 (0.1667) Data Time: 0.0562 (0.0332) Average Loss: 1.4758 (1.4140) Average CE Loss (Source):  1.4758 ( 1.4140) Learning Rate: 0.1000 (0.1000) Top1_base: 63.2812 (61.8510) Top1_base_per_class: 63.9583 (62.4872) 
Training Epoch: [21/1000] Step: [140 / 285] Batch Time: 0.1462 (0.1654) Data Time: 0.0107 (0.0319) Average Loss: 1.2436 (1.4177) Average CE Loss (Source):  1.2436 ( 1.4177) Learning Rate: 0.1000 (0.1000) Top1_base: 71.8750 (61.8471) Top1_base_per_class: 70.6173 (62.4330) 
Training Epoch: [21/1000] Step: [150 / 285] Batch Time: 0.1474 (0.1646) Data Time: 0.0160 (0.0311) Average Loss: 1.4052 (1.4167) Average CE Loss (Source):  1.4052 ( 1.4167) Learning Rate: 0.1000 (0.1000) Top1_base: 60.1562 (61.8073) Top1_base_per_class: 58.7273 (62.3859) 
Training Epoch: [21/1000] Step: [160 / 285] Batch Time: 0.1472 (0.1647) Data Time: 0.0124 (0.0311) Average Loss: 1.1847 (1.4133) Average CE Loss (Source):  1.1847 ( 1.4133) Learning Rate: 0.1000 (0.1000) Top1_base: 65.6250 (61.7725) Top1_base_per_class: 60.3704 (62.3827) 
Training Epoch: [21/1000] Step: [170 / 285] Batch Time: 0.1506 (0.1640) Data Time: 0.0150 (0.0304) Average Loss: 1.7237 (1.4120) Average CE Loss (Source):  1.7237 ( 1.4120) Learning Rate: 0.1000 (0.1000) Top1_base: 50.7812 (61.8428) Top1_base_per_class: 52.0833 (62.4362) 
Training Epoch: [21/1000] Step: [180 / 285] Batch Time: 0.1432 (0.1633) Data Time: 0.0114 (0.0298) Average Loss: 1.2137 (1.4107) Average CE Loss (Source):  1.2137 ( 1.4107) Learning Rate: 0.1000 (0.1000) Top1_base: 68.7500 (61.9141) Top1_base_per_class: 68.2727 (62.4475) 
Training Epoch: [21/1000] Step: [190 / 285] Batch Time: 0.1449 (0.1626) Data Time: 0.0132 (0.0292) Average Loss: 1.3385 (1.4050) Average CE Loss (Source):  1.3385 ( 1.4050) Learning Rate: 0.1000 (0.1000) Top1_base: 61.7188 (62.0600) Top1_base_per_class: 60.7440 (62.5655) 
Training Epoch: [21/1000] Step: [200 / 285] Batch Time: 0.1440 (0.1625) Data Time: 0.0113 (0.0291) Average Loss: 1.3369 (1.4034) Average CE Loss (Source):  1.3369 ( 1.4034) Learning Rate: 0.1000 (0.1000) Top1_base: 62.5000 (62.0703) Top1_base_per_class: 57.5731 (62.5752) 
Training Epoch: [21/1000] Step: [210 / 285] Batch Time: 0.2016 (0.1622) Data Time: 0.0694 (0.0289) Average Loss: 1.2324 (1.4009) Average CE Loss (Source):  1.2324 ( 1.4009) Learning Rate: 0.1000 (0.1000) Top1_base: 67.1875 (62.1838) Top1_base_per_class: 69.9346 (62.6532) 
Training Epoch: [21/1000] Step: [220 / 285] Batch Time: 0.1427 (0.1621) Data Time: 0.0104 (0.0289) Average Loss: 1.6611 (1.4041) Average CE Loss (Source):  1.6611 ( 1.4041) Learning Rate: 0.1000 (0.1000) Top1_base: 53.9062 (62.0774) Top1_base_per_class: 53.4210 (62.4937) 
Training Epoch: [21/1000] Step: [230 / 285] Batch Time: 0.1950 (0.1620) Data Time: 0.0623 (0.0289) Average Loss: 1.4418 (1.4041) Average CE Loss (Source):  1.4418 ( 1.4041) Learning Rate: 0.1000 (0.1000) Top1_base: 57.0312 (62.0822) Top1_base_per_class: 56.5625 (62.4733) 
Training Epoch: [21/1000] Step: [240 / 285] Batch Time: 0.1425 (0.1614) Data Time: 0.0112 (0.0283) Average Loss: 1.5014 (1.4034) Average CE Loss (Source):  1.5014 ( 1.4034) Learning Rate: 0.1000 (0.1000) Top1_base: 56.2500 (62.0964) Top1_base_per_class: 53.9308 (62.4811) 
Training Epoch: [21/1000] Step: [250 / 285] Batch Time: 0.2297 (0.1615) Data Time: 0.0969 (0.0285) Average Loss: 1.5399 (1.4025) Average CE Loss (Source):  1.5399 ( 1.4025) Learning Rate: 0.1000 (0.1000) Top1_base: 60.1562 (62.1406) Top1_base_per_class: 62.0690 (62.5365) 
Training Epoch: [21/1000] Step: [260 / 285] Batch Time: 0.1436 (0.1615) Data Time: 0.0105 (0.0284) Average Loss: 1.3265 (1.4030) Average CE Loss (Source):  1.3265 ( 1.4030) Learning Rate: 0.1000 (0.1000) Top1_base: 66.4062 (62.1725) Top1_base_per_class: 65.2516 (62.6006) 
Training Epoch: [21/1000] Step: [270 / 285] Batch Time: 0.1482 (0.1612) Data Time: 0.0149 (0.0281) Average Loss: 1.3886 (1.4016) Average CE Loss (Source):  1.3886 ( 1.4016) Learning Rate: 0.1000 (0.1000) Top1_base: 58.5938 (62.1441) Top1_base_per_class: 58.4795 (62.5625) 
Training Epoch: [21/1000] Step: [280 / 285] Batch Time: 0.1453 (0.1611) Data Time: 0.0106 (0.0280) Average Loss: 1.2221 (1.3998) Average CE Loss (Source):  1.2221 ( 1.3998) Learning Rate: 0.1000 (0.1000) Top1_base: 65.6250 (62.1875) Top1_base_per_class: 63.8611 (62.5131) 
Training Epoch: [22/1000] Step: [0] Batch Time: 0.1429 (0.1608) Data Time: 0.0103 (0.0277) Average Loss: 1.4815 (1.3987) Average CE Loss (Source):  1.4815 ( 1.3987) Learning Rate: 0.1000 (0.1000) Top1_base: 60.1562 (62.2341) Top1_base_per_class: 58.0247 (62.5725) 
  2%|▏         | 22/1000 [17:38<13:00:04, 47.86s/it]  2%|▏         | 23/1000 [18:24<12:49:51, 47.28s/it]Training Epoch: [22/1000] Step: [10 / 285] Batch Time: 0.1425 (0.2336) Data Time: 0.0117 (0.1017) Average Loss: 1.3377 (1.3897) Average CE Loss (Source):  1.3377 ( 1.3897) Learning Rate: 0.1000 (0.1000) Top1_base: 60.9375 (62.1094) Top1_base_per_class: 59.9691 (63.6573) 
Training Epoch: [22/1000] Step: [20 / 285] Batch Time: 0.1430 (0.1952) Data Time: 0.0099 (0.0630) Average Loss: 1.6723 (1.4108) Average CE Loss (Source):  1.6723 ( 1.4108) Learning Rate: 0.1000 (0.1000) Top1_base: 54.6875 (62.3828) Top1_base_per_class: 55.6140 (63.8268) 
Training Epoch: [22/1000] Step: [30 / 285] Batch Time: 0.1463 (0.1833) Data Time: 0.0141 (0.0508) Average Loss: 1.3625 (1.3981) Average CE Loss (Source):  1.3625 ( 1.3981) Learning Rate: 0.1000 (0.1000) Top1_base: 63.2812 (62.5781) Top1_base_per_class: 64.8162 (63.6271) 
Training Epoch: [22/1000] Step: [40 / 285] Batch Time: 0.1431 (0.1782) Data Time: 0.0108 (0.0454) Average Loss: 1.2932 (1.3653) Average CE Loss (Source):  1.2932 ( 1.3653) Learning Rate: 0.1000 (0.1000) Top1_base: 67.1875 (62.7734) Top1_base_per_class: 65.4545 (63.6677) 
Training Epoch: [22/1000] Step: [50 / 285] Batch Time: 0.1427 (0.1752) Data Time: 0.0113 (0.0427) Average Loss: 1.3441 (1.3840) Average CE Loss (Source):  1.3441 ( 1.3840) Learning Rate: 0.1000 (0.1000) Top1_base: 55.4688 (62.0938) Top1_base_per_class: 57.3270 (63.0388) 
Training Epoch: [22/1000] Step: [60 / 285] Batch Time: 0.1425 (0.1714) Data Time: 0.0102 (0.0391) Average Loss: 1.1566 (1.3734) Average CE Loss (Source):  1.1566 ( 1.3734) Learning Rate: 0.1000 (0.1000) Top1_base: 63.2812 (62.4089) Top1_base_per_class: 62.2424 (63.2569) 
Training Epoch: [22/1000] Step: [70 / 285] Batch Time: 0.1445 (0.1711) Data Time: 0.0119 (0.0387) Average Loss: 1.6602 (1.3826) Average CE Loss (Source):  1.6602 ( 1.3826) Learning Rate: 0.1000 (0.1000) Top1_base: 55.4688 (62.0982) Top1_base_per_class: 57.2013 (62.9463) 
Training Epoch: [22/1000] Step: [80 / 285] Batch Time: 0.1469 (0.1692) Data Time: 0.0144 (0.0368) Average Loss: 1.5715 (1.3821) Average CE Loss (Source):  1.5715 ( 1.3821) Learning Rate: 0.1000 (0.1000) Top1_base: 60.1562 (62.1191) Top1_base_per_class: 59.4025 (63.0375) 
Training Epoch: [22/1000] Step: [90 / 285] Batch Time: 0.1451 (0.1673) Data Time: 0.0135 (0.0347) Average Loss: 1.3736 (1.3818) Average CE Loss (Source):  1.3736 ( 1.3818) Learning Rate: 0.1000 (0.1000) Top1_base: 62.5000 (62.2743) Top1_base_per_class: 63.1845 (63.0372) 
Training Epoch: [22/1000] Step: [100 / 285] Batch Time: 0.1437 (0.1659) Data Time: 0.0115 (0.0334) Average Loss: 1.4680 (1.3795) Average CE Loss (Source):  1.4680 ( 1.3795) Learning Rate: 0.1000 (0.1000) Top1_base: 61.7188 (62.3438) Top1_base_per_class: 62.5298 (63.2128) 
Training Epoch: [22/1000] Step: [110 / 285] Batch Time: 0.2201 (0.1654) Data Time: 0.0890 (0.0329) Average Loss: 1.2587 (1.3746) Average CE Loss (Source):  1.2587 ( 1.3746) Learning Rate: 0.1000 (0.1000) Top1_base: 65.6250 (62.4929) Top1_base_per_class: 67.6488 (63.3367) 
Training Epoch: [22/1000] Step: [120 / 285] Batch Time: 0.1446 (0.1643) Data Time: 0.0118 (0.0319) Average Loss: 1.4629 (1.3748) Average CE Loss (Source):  1.4629 ( 1.3748) Learning Rate: 0.1000 (0.1000) Top1_base: 57.8125 (62.5521) Top1_base_per_class: 61.0000 (63.4348) 
Training Epoch: [22/1000] Step: [130 / 285] Batch Time: 0.1861 (0.1650) Data Time: 0.0527 (0.0326) Average Loss: 1.3091 (1.3796) Average CE Loss (Source):  1.3091 ( 1.3796) Learning Rate: 0.1000 (0.1000) Top1_base: 59.3750 (62.3858) Top1_base_per_class: 55.4762 (63.2080) 
Training Epoch: [22/1000] Step: [140 / 285] Batch Time: 0.1464 (0.1648) Data Time: 0.0124 (0.0323) Average Loss: 1.4297 (1.3820) Average CE Loss (Source):  1.4297 ( 1.3820) Learning Rate: 0.1000 (0.1000) Top1_base: 58.5938 (62.3326) Top1_base_per_class: 59.5455 (63.0656) 
Training Epoch: [22/1000] Step: [150 / 285] Batch Time: 0.1880 (0.1643) Data Time: 0.0565 (0.0319) Average Loss: 1.3654 (1.3830) Average CE Loss (Source):  1.3654 ( 1.3830) Learning Rate: 0.1000 (0.1000) Top1_base: 64.8438 (62.3281) Top1_base_per_class: 64.1954 (62.9998) 
Training Epoch: [22/1000] Step: [160 / 285] Batch Time: 0.1444 (0.1638) Data Time: 0.0127 (0.0315) Average Loss: 1.4954 (1.3825) Average CE Loss (Source):  1.4954 ( 1.3825) Learning Rate: 0.1000 (0.1000) Top1_base: 60.1562 (62.3096) Top1_base_per_class: 60.8128 (63.0199) 
Training Epoch: [22/1000] Step: [170 / 285] Batch Time: 0.1469 (0.1632) Data Time: 0.0142 (0.0308) Average Loss: 1.4779 (1.3808) Average CE Loss (Source):  1.4779 ( 1.3808) Learning Rate: 0.1000 (0.1000) Top1_base: 59.3750 (62.2794) Top1_base_per_class: 58.9080 (63.0065) 
Training Epoch: [22/1000] Step: [180 / 285] Batch Time: 0.1472 (0.1625) Data Time: 0.0140 (0.0300) Average Loss: 1.1036 (1.3765) Average CE Loss (Source):  1.1036 ( 1.3765) Learning Rate: 0.1000 (0.1000) Top1_base: 71.8750 (62.4479) Top1_base_per_class: 74.7449 (63.1017) 
Training Epoch: [22/1000] Step: [190 / 285] Batch Time: 0.1740 (0.1620) Data Time: 0.0412 (0.0295) Average Loss: 1.6746 (1.3809) Average CE Loss (Source):  1.6746 ( 1.3809) Learning Rate: 0.1000 (0.1000) Top1_base: 57.0312 (62.3273) Top1_base_per_class: 54.6575 (62.9038) 
Training Epoch: [22/1000] Step: [200 / 285] Batch Time: 0.1432 (0.1626) Data Time: 0.0119 (0.0302) Average Loss: 1.3626 (1.3788) Average CE Loss (Source):  1.3626 ( 1.3788) Learning Rate: 0.1000 (0.1000) Top1_base: 64.8438 (62.4531) Top1_base_per_class: 66.1864 (63.0246) 
Training Epoch: [22/1000] Step: [210 / 285] Batch Time: 0.2245 (0.1630) Data Time: 0.0925 (0.0306) Average Loss: 1.2904 (1.3751) Average CE Loss (Source):  1.2904 ( 1.3751) Learning Rate: 0.1000 (0.1000) Top1_base: 70.3125 (62.5446) Top1_base_per_class: 73.9623 (63.1664) 
Training Epoch: [22/1000] Step: [220 / 285] Batch Time: 0.1454 (0.1626) Data Time: 0.0116 (0.0302) Average Loss: 1.3541 (1.3766) Average CE Loss (Source):  1.3541 ( 1.3766) Learning Rate: 0.1000 (0.1000) Top1_base: 59.3750 (62.5639) Top1_base_per_class: 57.8984 (63.1270) 
Training Epoch: [22/1000] Step: [230 / 285] Batch Time: 0.2122 (0.1626) Data Time: 0.0809 (0.0302) Average Loss: 1.3520 (1.3776) Average CE Loss (Source):  1.3520 ( 1.3776) Learning Rate: 0.1000 (0.1000) Top1_base: 61.7188 (62.5204) Top1_base_per_class: 64.8457 (63.1120) 
Training Epoch: [22/1000] Step: [240 / 285] Batch Time: 0.1434 (0.1620) Data Time: 0.0110 (0.0297) Average Loss: 1.3518 (1.3755) Average CE Loss (Source):  1.3518 ( 1.3755) Learning Rate: 0.1000 (0.1000) Top1_base: 67.9688 (62.6172) Top1_base_per_class: 63.3333 (63.1572) 
Training Epoch: [22/1000] Step: [250 / 285] Batch Time: 0.1587 (0.1619) Data Time: 0.0266 (0.0296) Average Loss: 1.4755 (1.3729) Average CE Loss (Source):  1.4755 ( 1.3729) Learning Rate: 0.1000 (0.1000) Top1_base: 55.4688 (62.7031) Top1_base_per_class: 55.9164 (63.2287) 
Training Epoch: [22/1000] Step: [260 / 285] Batch Time: 0.1473 (0.1615) Data Time: 0.0155 (0.0292) Average Loss: 1.3838 (1.3758) Average CE Loss (Source):  1.3838 ( 1.3758) Learning Rate: 0.1000 (0.1000) Top1_base: 64.8438 (62.6472) Top1_base_per_class: 62.6364 (63.1625) 
Training Epoch: [22/1000] Step: [270 / 285] Batch Time: 0.2007 (0.1614) Data Time: 0.0706 (0.0291) Average Loss: 1.6906 (1.3788) Average CE Loss (Source):  1.6906 ( 1.3788) Learning Rate: 0.1000 (0.1000) Top1_base: 60.9375 (62.6273) Top1_base_per_class: 62.7186 (63.0957) 
Training Epoch: [22/1000] Step: [280 / 285] Batch Time: 0.1464 (0.1610) Data Time: 0.0123 (0.0287) Average Loss: 1.1217 (1.3766) Average CE Loss (Source):  1.1217 ( 1.3766) Learning Rate: 0.1000 (0.1000) Top1_base: 66.4062 (62.6925) Top1_base_per_class: 63.7134 (63.1260) 
Training Epoch: [23/1000] Step: [0] Batch Time: 0.1692 (0.1609) Data Time: 0.0382 (0.0286) Average Loss: 1.3757 (1.3768) Average CE Loss (Source):  1.3757 ( 1.3768) Learning Rate: 0.1000 (0.1000) Top1_base: 59.3750 (62.6617) Top1_base_per_class: 58.9474 (63.1153) 
Training Epoch: [23/1000] Step: [10 / 285] Batch Time: 0.1391 (0.2474) Data Time: 0.0089 (0.1165) Average Loss: 1.3469 (1.3099) Average CE Loss (Source):  1.3469 ( 1.3099) Learning Rate: 0.1000 (0.1000) Top1_base: 62.5000 (62.5781) Top1_base_per_class: 62.9808 (63.5048) 
Training Epoch: [23/1000] Step: [20 / 285] Batch Time: 0.1419 (0.2022) Data Time: 0.0103 (0.0715) Average Loss: 1.5453 (1.3319) Average CE Loss (Source):  1.5453 ( 1.3319) Learning Rate: 0.1000 (0.1000) Top1_base: 59.3750 (62.9688) Top1_base_per_class: 58.8218 (63.4424) 
Training Epoch: [23/1000] Step: [30 / 285] Batch Time: 0.1418 (0.1916) Data Time: 0.0100 (0.0606) Average Loss: 1.4664 (1.3037) Average CE Loss (Source):  1.4664 ( 1.3037) Learning Rate: 0.1000 (0.1000) Top1_base: 65.6250 (64.0365) Top1_base_per_class: 62.7083 (64.3842) 
Training Epoch: [23/1000] Step: [40 / 285] Batch Time: 0.1442 (0.1849) Data Time: 0.0120 (0.0535) Average Loss: 1.2877 (1.2798) Average CE Loss (Source):  1.2877 ( 1.2798) Learning Rate: 0.1000 (0.1000) Top1_base: 64.0625 (64.7656) Top1_base_per_class: 64.4633 (64.9213) 
Training Epoch: [23/1000] Step: [50 / 285] Batch Time: 0.1411 (0.1814) Data Time: 0.0094 (0.0499) Average Loss: 1.4337 (1.2903) Average CE Loss (Source):  1.4337 ( 1.2903) Learning Rate: 0.1000 (0.1000) Top1_base: 64.0625 (64.7188) Top1_base_per_class: 64.6364 (65.1429) 
Training Epoch: [23/1000] Step: [60 / 285] Batch Time: 0.1451 (0.1759) Data Time: 0.0119 (0.0443) Average Loss: 0.9736 (1.2930) Average CE Loss (Source):  0.9736 ( 1.2930) Learning Rate: 0.1000 (0.1000) Top1_base: 72.6562 (64.4922) Top1_base_per_class: 72.9310 (65.1398) 
Training Epoch: [23/1000] Step: [70 / 285] Batch Time: 0.1432 (0.1729) Data Time: 0.0118 (0.0412) Average Loss: 1.3000 (1.2979) Average CE Loss (Source):  1.3000 ( 1.2979) Learning Rate: 0.1000 (0.1000) Top1_base: 61.7188 (64.2634) Top1_base_per_class: 62.1333 (64.7684) 
Training Epoch: [23/1000] Step: [80 / 285] Batch Time: 0.1435 (0.1714) Data Time: 0.0117 (0.0396) Average Loss: 1.3594 (1.3011) Average CE Loss (Source):  1.3594 ( 1.3011) Learning Rate: 0.1000 (0.1000) Top1_base: 64.8438 (64.2773) Top1_base_per_class: 62.9321 (64.8727) 
Training Epoch: [23/1000] Step: [90 / 285] Batch Time: 0.1439 (0.1703) Data Time: 0.0100 (0.0384) Average Loss: 1.0024 (1.3043) Average CE Loss (Source):  1.0024 ( 1.3043) Learning Rate: 0.1000 (0.1000) Top1_base: 71.8750 (64.1667) Top1_base_per_class: 71.5819 (64.6482) 
Training Epoch: [23/1000] Step: [100 / 285] Batch Time: 0.1435 (0.1688) Data Time: 0.0113 (0.0369) Average Loss: 1.2900 (1.3142) Average CE Loss (Source):  1.2900 ( 1.3142) Learning Rate: 0.1000 (0.1000) Top1_base: 65.6250 (64.0625) Top1_base_per_class: 65.9091 (64.5094) 
Training Epoch: [23/1000] Step: [110 / 285] Batch Time: 0.1459 (0.1678) Data Time: 0.0121 (0.0359) Average Loss: 1.4175 (1.3174) Average CE Loss (Source):  1.4175 ( 1.3174) Learning Rate: 0.1000 (0.1000) Top1_base: 59.3750 (63.8849) Top1_base_per_class: 54.3275 (64.3072) 
Training Epoch: [23/1000] Step: [120 / 285] Batch Time: 0.1440 (0.1665) Data Time: 0.0120 (0.0346) Average Loss: 1.3679 (1.3190) Average CE Loss (Source):  1.3679 ( 1.3190) Learning Rate: 0.1000 (0.1000) Top1_base: 60.9375 (63.8542) Top1_base_per_class: 67.4892 (64.3318) 
Training Epoch: [23/1000] Step: [130 / 285] Batch Time: 0.1417 (0.1656) Data Time: 0.0105 (0.0337) Average Loss: 1.2723 (1.3186) Average CE Loss (Source):  1.2723 ( 1.3186) Learning Rate: 0.1000 (0.1000) Top1_base: 66.4062 (63.8462) Top1_base_per_class: 69.4545 (64.2321) 
Training Epoch: [23/1000] Step: [140 / 285] Batch Time: 0.1438 (0.1657) Data Time: 0.0113 (0.0338) Average Loss: 1.3742 (1.3285) Average CE Loss (Source):  1.3742 ( 1.3285) Learning Rate: 0.1000 (0.1000) Top1_base: 63.2812 (63.7667) Top1_base_per_class: 58.8000 (64.0858) 
Training Epoch: [23/1000] Step: [150 / 285] Batch Time: 0.1430 (0.1652) Data Time: 0.0101 (0.0333) Average Loss: 1.3271 (1.3256) Average CE Loss (Source):  1.3271 ( 1.3256) Learning Rate: 0.1000 (0.1000) Top1_base: 66.4062 (63.8854) Top1_base_per_class: 65.2425 (64.2717) 
Training Epoch: [23/1000] Step: [160 / 285] Batch Time: 0.1438 (0.1640) Data Time: 0.0123 (0.0321) Average Loss: 1.4713 (1.3278) Average CE Loss (Source):  1.4713 ( 1.3278) Learning Rate: 0.1000 (0.1000) Top1_base: 62.5000 (63.9502) Top1_base_per_class: 64.3750 (64.3569) 
Training Epoch: [23/1000] Step: [170 / 285] Batch Time: 0.1440 (0.1634) Data Time: 0.0120 (0.0315) Average Loss: 1.0979 (1.3311) Average CE Loss (Source):  1.0979 ( 1.3311) Learning Rate: 0.1000 (0.1000) Top1_base: 71.0938 (63.9292) Top1_base_per_class: 68.3626 (64.3099) 
Training Epoch: [23/1000] Step: [180 / 285] Batch Time: 0.1431 (0.1626) Data Time: 0.0123 (0.0307) Average Loss: 1.2279 (1.3331) Average CE Loss (Source):  1.2279 ( 1.3331) Learning Rate: 0.1000 (0.1000) Top1_base: 69.5312 (63.9236) Top1_base_per_class: 64.4025 (64.2770) 
Training Epoch: [23/1000] Step: [190 / 285] Batch Time: 0.1488 (0.1624) Data Time: 0.0157 (0.0305) Average Loss: 1.4671 (1.3326) Average CE Loss (Source):  1.4671 ( 1.3326) Learning Rate: 0.1000 (0.1000) Top1_base: 60.1562 (63.9021) Top1_base_per_class: 62.5706 (64.2806) 
Training Epoch: [23/1000] Step: [200 / 285] Batch Time: 0.1424 (0.1622) Data Time: 0.0109 (0.0302) Average Loss: 1.5518 (1.3365) Average CE Loss (Source):  1.5518 ( 1.3365) Learning Rate: 0.1000 (0.1000) Top1_base: 56.2500 (63.7734) Top1_base_per_class: 52.2327 (64.1258) 
Training Epoch: [23/1000] Step: [210 / 285] Batch Time: 0.1419 (0.1620) Data Time: 0.0113 (0.0301) Average Loss: 1.5179 (1.3400) Average CE Loss (Source):  1.5179 ( 1.3400) Learning Rate: 0.1000 (0.1000) Top1_base: 63.2812 (63.7463) Top1_base_per_class: 63.1909 (64.0982) 
Training Epoch: [23/1000] Step: [220 / 285] Batch Time: 0.1442 (0.1617) Data Time: 0.0129 (0.0298) Average Loss: 1.4350 (1.3449) Average CE Loss (Source):  1.4350 ( 1.3449) Learning Rate: 0.1000 (0.1000) Top1_base: 64.0625 (63.6470) Top1_base_per_class: 64.5238 (64.0391) 
Training Epoch: [23/1000] Step: [230 / 285] Batch Time: 0.1423 (0.1618) Data Time: 0.0108 (0.0299) Average Loss: 1.5059 (1.3464) Average CE Loss (Source):  1.5059 ( 1.3464) Learning Rate: 0.1000 (0.1000) Top1_base: 62.5000 (63.5564) Top1_base_per_class: 66.3333 (63.9028) 
Training Epoch: [23/1000] Step: [240 / 285] Batch Time: 0.1439 (0.1615) Data Time: 0.0105 (0.0296) Average Loss: 1.3352 (1.3478) Average CE Loss (Source):  1.3352 ( 1.3478) Learning Rate: 0.1000 (0.1000) Top1_base: 64.8438 (63.5742) Top1_base_per_class: 65.1977 (63.8966) 
Training Epoch: [23/1000] Step: [250 / 285] Batch Time: 0.1476 (0.1614) Data Time: 0.0131 (0.0295) Average Loss: 1.5064 (1.3477) Average CE Loss (Source):  1.5064 ( 1.3477) Learning Rate: 0.1000 (0.1000) Top1_base: 60.9375 (63.5812) Top1_base_per_class: 61.3095 (63.8976) 
Training Epoch: [23/1000] Step: [260 / 285] Batch Time: 0.1479 (0.1611) Data Time: 0.0163 (0.0291) Average Loss: 1.4240 (1.3537) Average CE Loss (Source):  1.4240 ( 1.3537) Learning Rate: 0.1000 (0.1000) Top1_base: 62.5000 (63.4135) Top1_base_per_class: 61.4848 (63.6928) 
Training Epoch: [23/1000] Step: [270 / 285] Batch Time: 0.1433 (0.1609) Data Time: 0.0115 (0.0289) Average Loss: 1.3340 (1.3562) Average CE Loss (Source):  1.3340 ( 1.3562) Learning Rate: 0.1000 (0.1000) Top1_base: 59.3750 (63.2784) Top1_base_per_class: 57.5146 (63.5780) 
Training Epoch: [23/1000] Step: [280 / 285] Batch Time: 0.1970 (0.1611) Data Time: 0.0664 (0.0291) Average Loss: 1.5138 (1.3562) Average CE Loss (Source):  1.5138 ( 1.3562) Learning Rate: 0.1000 (0.1000) Top1_base: 60.9375 (63.2645) Top1_base_per_class: 62.8312 (63.5395) 
Training Epoch: [24/1000] Step: [0] Batch Time: 0.1403 (0.1608) Data Time: 0.0104 (0.0288) Average Loss: 1.5377 (1.3563) Average CE Loss (Source):  1.5377 ( 1.3563) Learning Rate: 0.1000 (0.1000) Top1_base: 60.1562 (63.2922) Top1_base_per_class: 61.2654 (63.5620) 
  2%|▏         | 24/1000 [19:13<12:55:52, 47.70s/it]  2%|▎         | 25/1000 [20:00<12:51:28, 47.48s/it]Training Epoch: [24/1000] Step: [10 / 285] Batch Time: 0.1402 (0.2639) Data Time: 0.0093 (0.1330) Average Loss: 1.3237 (1.2873) Average CE Loss (Source):  1.3237 ( 1.2873) Learning Rate: 0.1000 (0.1000) Top1_base: 66.4062 (65.3125) Top1_base_per_class: 69.7175 (64.6851) 
Training Epoch: [24/1000] Step: [20 / 285] Batch Time: 0.1416 (0.2079) Data Time: 0.0112 (0.0769) Average Loss: 1.3137 (1.2658) Average CE Loss (Source):  1.3137 ( 1.2658) Learning Rate: 0.1000 (0.1000) Top1_base: 62.5000 (65.6250) Top1_base_per_class: 61.1012 (65.4533) 
Training Epoch: [24/1000] Step: [30 / 285] Batch Time: 0.1406 (0.1941) Data Time: 0.0095 (0.0630) Average Loss: 1.4324 (1.2605) Average CE Loss (Source):  1.4324 ( 1.2605) Learning Rate: 0.1000 (0.1000) Top1_base: 59.3750 (65.6250) Top1_base_per_class: 60.6725 (65.2005) 
Training Epoch: [24/1000] Step: [40 / 285] Batch Time: 0.1456 (0.1893) Data Time: 0.0114 (0.0579) Average Loss: 1.3694 (1.2613) Average CE Loss (Source):  1.3694 ( 1.2613) Learning Rate: 0.1000 (0.1000) Top1_base: 60.9375 (65.8398) Top1_base_per_class: 63.5151 (65.9690) 
Training Epoch: [24/1000] Step: [50 / 285] Batch Time: 0.1459 (0.1867) Data Time: 0.0104 (0.0546) Average Loss: 1.0747 (1.2533) Average CE Loss (Source):  1.0747 ( 1.2533) Learning Rate: 0.1000 (0.1000) Top1_base: 69.5312 (65.8906) Top1_base_per_class: 67.9096 (66.0048) 
Training Epoch: [24/1000] Step: [60 / 285] Batch Time: 0.1451 (0.1818) Data Time: 0.0097 (0.0494) Average Loss: 1.2945 (1.2779) Average CE Loss (Source):  1.2945 ( 1.2779) Learning Rate: 0.1000 (0.1000) Top1_base: 63.2812 (65.1823) Top1_base_per_class: 60.0298 (65.4677) 
Training Epoch: [24/1000] Step: [70 / 285] Batch Time: 0.1447 (0.1782) Data Time: 0.0117 (0.0454) Average Loss: 1.6480 (1.2949) Average CE Loss (Source):  1.6480 ( 1.2949) Learning Rate: 0.1000 (0.1000) Top1_base: 57.0312 (64.8214) Top1_base_per_class: 54.8366 (65.0807) 
Training Epoch: [24/1000] Step: [80 / 285] Batch Time: 0.1447 (0.1744) Data Time: 0.0117 (0.0416) Average Loss: 1.4489 (1.2992) Average CE Loss (Source):  1.4489 ( 1.2992) Learning Rate: 0.1000 (0.1000) Top1_base: 59.3750 (64.6680) Top1_base_per_class: 61.3056 (65.0869) 
Training Epoch: [24/1000] Step: [90 / 285] Batch Time: 0.1526 (0.1728) Data Time: 0.0183 (0.0400) Average Loss: 1.1063 (1.2954) Average CE Loss (Source):  1.1063 ( 1.2954) Learning Rate: 0.1000 (0.1000) Top1_base: 69.5312 (64.7309) Top1_base_per_class: 70.9195 (65.1654) 
Training Epoch: [24/1000] Step: [100 / 285] Batch Time: 0.1434 (0.1707) Data Time: 0.0114 (0.0380) Average Loss: 1.3277 (1.3034) Average CE Loss (Source):  1.3277 ( 1.3034) Learning Rate: 0.1000 (0.1000) Top1_base: 60.1562 (64.5391) Top1_base_per_class: 63.4524 (65.0190) 
Training Epoch: [24/1000] Step: [110 / 285] Batch Time: 0.2309 (0.1704) Data Time: 0.0977 (0.0377) Average Loss: 1.3176 (1.3022) Average CE Loss (Source):  1.3176 ( 1.3022) Learning Rate: 0.1000 (0.1000) Top1_base: 65.6250 (64.6378) Top1_base_per_class: 66.5094 (65.0410) 
Training Epoch: [24/1000] Step: [120 / 285] Batch Time: 0.1448 (0.1690) Data Time: 0.0105 (0.0363) Average Loss: 1.4539 (1.3038) Average CE Loss (Source):  1.4539 ( 1.3038) Learning Rate: 0.1000 (0.1000) Top1_base: 58.5938 (64.6484) Top1_base_per_class: 62.8697 (65.0290) 
Training Epoch: [24/1000] Step: [130 / 285] Batch Time: 0.1785 (0.1684) Data Time: 0.0455 (0.0357) Average Loss: 1.4075 (1.3058) Average CE Loss (Source):  1.4075 ( 1.3058) Learning Rate: 0.1000 (0.1000) Top1_base: 59.3750 (64.5433) Top1_base_per_class: 56.9663 (64.8989) 
Training Epoch: [24/1000] Step: [140 / 285] Batch Time: 0.1452 (0.1682) Data Time: 0.0124 (0.0356) Average Loss: 1.2516 (1.3058) Average CE Loss (Source):  1.2516 ( 1.3058) Learning Rate: 0.1000 (0.1000) Top1_base: 68.7500 (64.4866) Top1_base_per_class: 66.6026 (64.7461) 
Training Epoch: [24/1000] Step: [150 / 285] Batch Time: 0.1988 (0.1681) Data Time: 0.0676 (0.0354) Average Loss: 1.3323 (1.3036) Average CE Loss (Source):  1.3323 ( 1.3036) Learning Rate: 0.1000 (0.1000) Top1_base: 64.8438 (64.5417) Top1_base_per_class: 66.0165 (64.8628) 
Training Epoch: [24/1000] Step: [160 / 285] Batch Time: 0.1436 (0.1676) Data Time: 0.0114 (0.0349) Average Loss: 1.2930 (1.3109) Average CE Loss (Source):  1.2930 ( 1.3109) Learning Rate: 0.1000 (0.1000) Top1_base: 64.8438 (64.3945) Top1_base_per_class: 64.8397 (64.6868) 
Training Epoch: [24/1000] Step: [170 / 285] Batch Time: 0.2834 (0.1680) Data Time: 0.1500 (0.0352) Average Loss: 1.2908 (1.3122) Average CE Loss (Source):  1.2908 ( 1.3122) Learning Rate: 0.1000 (0.1000) Top1_base: 60.1562 (64.3612) Top1_base_per_class: 59.9686 (64.6442) 
Training Epoch: [24/1000] Step: [180 / 285] Batch Time: 0.1461 (0.1681) Data Time: 0.0126 (0.0353) Average Loss: 1.2735 (1.3124) Average CE Loss (Source):  1.2735 ( 1.3124) Learning Rate: 0.1000 (0.1000) Top1_base: 67.9688 (64.4010) Top1_base_per_class: 72.6608 (64.7184) 
Training Epoch: [24/1000] Step: [190 / 285] Batch Time: 0.1832 (0.1678) Data Time: 0.0510 (0.0351) Average Loss: 1.1518 (1.3100) Average CE Loss (Source):  1.1518 ( 1.3100) Learning Rate: 0.1000 (0.1000) Top1_base: 68.7500 (64.3873) Top1_base_per_class: 65.2516 (64.6372) 
Training Epoch: [24/1000] Step: [200 / 285] Batch Time: 0.1446 (0.1676) Data Time: 0.0125 (0.0348) Average Loss: 1.3398 (1.3113) Average CE Loss (Source):  1.3398 ( 1.3113) Learning Rate: 0.1000 (0.1000) Top1_base: 59.3750 (64.3477) Top1_base_per_class: 61.6061 (64.5258) 
Training Epoch: [24/1000] Step: [210 / 285] Batch Time: 0.1823 (0.1671) Data Time: 0.0502 (0.0344) Average Loss: 1.4432 (1.3141) Average CE Loss (Source):  1.4432 ( 1.3141) Learning Rate: 0.1000 (0.1000) Top1_base: 60.9375 (64.3006) Top1_base_per_class: 58.8788 (64.4759) 
Training Epoch: [24/1000] Step: [220 / 285] Batch Time: 0.1447 (0.1665) Data Time: 0.0121 (0.0338) Average Loss: 1.1420 (1.3153) Average CE Loss (Source):  1.1420 ( 1.3153) Learning Rate: 0.1000 (0.1000) Top1_base: 71.0938 (64.2969) Top1_base_per_class: 73.0172 (64.5186) 
Training Epoch: [24/1000] Step: [230 / 285] Batch Time: 0.2316 (0.1667) Data Time: 0.0998 (0.0341) Average Loss: 1.1946 (1.3160) Average CE Loss (Source):  1.1946 ( 1.3160) Learning Rate: 0.1000 (0.1000) Top1_base: 69.5312 (64.3105) Top1_base_per_class: 66.8333 (64.4920) 
Training Epoch: [24/1000] Step: [240 / 285] Batch Time: 0.1424 (0.1660) Data Time: 0.0108 (0.0333) Average Loss: 1.3330 (1.3169) Average CE Loss (Source):  1.3330 ( 1.3169) Learning Rate: 0.1000 (0.1000) Top1_base: 62.5000 (64.3034) Top1_base_per_class: 64.2992 (64.5312) 
Training Epoch: [24/1000] Step: [250 / 285] Batch Time: 0.1920 (0.1655) Data Time: 0.0599 (0.0329) Average Loss: 1.2183 (1.3180) Average CE Loss (Source):  1.2183 ( 1.3180) Learning Rate: 0.1000 (0.1000) Top1_base: 67.9688 (64.2750) Top1_base_per_class: 65.6780 (64.5043) 
Training Epoch: [24/1000] Step: [260 / 285] Batch Time: 0.1460 (0.1651) Data Time: 0.0135 (0.0325) Average Loss: 1.5341 (1.3199) Average CE Loss (Source):  1.5341 ( 1.3199) Learning Rate: 0.1000 (0.1000) Top1_base: 61.7188 (64.2097) Top1_base_per_class: 65.1961 (64.3830) 
Training Epoch: [24/1000] Step: [270 / 285] Batch Time: 0.2838 (0.1653) Data Time: 0.1520 (0.0327) Average Loss: 1.4064 (1.3222) Average CE Loss (Source):  1.4064 ( 1.3222) Learning Rate: 0.1000 (0.1000) Top1_base: 65.6250 (64.1551) Top1_base_per_class: 62.0536 (64.3821) 
Training Epoch: [24/1000] Step: [280 / 285] Batch Time: 0.1445 (0.1648) Data Time: 0.0125 (0.0323) Average Loss: 1.1954 (1.3225) Average CE Loss (Source):  1.1954 ( 1.3225) Learning Rate: 0.1000 (0.1000) Top1_base: 67.1875 (64.1657) Top1_base_per_class: 72.7994 (64.3923) 
Training Epoch: [25/1000] Step: [0] Batch Time: 0.1407 (0.1646) Data Time: 0.0105 (0.0320) Average Loss: 1.3678 (1.3211) Average CE Loss (Source):  1.3678 ( 1.3211) Learning Rate: 0.1000 (0.1000) Top1_base: 63.2812 (64.2160) Top1_base_per_class: 64.3750 (64.4180) 
Training Epoch: [25/1000] Step: [10 / 285] Batch Time: 0.1411 (0.2366) Data Time: 0.0113 (0.1051) Average Loss: 1.2005 (1.2577) Average CE Loss (Source):  1.2005 ( 1.2577) Learning Rate: 0.1000 (0.1000) Top1_base: 67.9688 (65.3906) Top1_base_per_class: 69.4828 (65.8105) 
Training Epoch: [25/1000] Step: [20 / 285] Batch Time: 0.1422 (0.1978) Data Time: 0.0122 (0.0669) Average Loss: 1.1943 (1.3039) Average CE Loss (Source):  1.1943 ( 1.3039) Learning Rate: 0.1000 (0.1000) Top1_base: 68.7500 (64.1797) Top1_base_per_class: 72.1726 (64.2454) 
Training Epoch: [25/1000] Step: [30 / 285] Batch Time: 0.1417 (0.1876) Data Time: 0.0103 (0.0564) Average Loss: 1.2024 (1.2630) Average CE Loss (Source):  1.2024 ( 1.2630) Learning Rate: 0.1000 (0.1000) Top1_base: 64.0625 (65.0260) Top1_base_per_class: 66.3416 (65.5093) 
Training Epoch: [25/1000] Step: [40 / 285] Batch Time: 0.1438 (0.1778) Data Time: 0.0129 (0.0464) Average Loss: 1.0859 (1.2624) Average CE Loss (Source):  1.0859 ( 1.2624) Learning Rate: 0.1000 (0.1000) Top1_base: 68.7500 (64.8828) Top1_base_per_class: 66.6987 (65.3722) 
Training Epoch: [25/1000] Step: [50 / 285] Batch Time: 0.1450 (0.1751) Data Time: 0.0124 (0.0435) Average Loss: 1.1738 (1.2604) Average CE Loss (Source):  1.1738 ( 1.2604) Learning Rate: 0.1000 (0.1000) Top1_base: 67.1875 (65.0625) Top1_base_per_class: 68.3898 (65.3833) 
Training Epoch: [25/1000] Step: [60 / 285] Batch Time: 0.1460 (0.1727) Data Time: 0.0138 (0.0410) Average Loss: 1.3161 (1.2635) Average CE Loss (Source):  1.3161 ( 1.2635) Learning Rate: 0.1000 (0.1000) Top1_base: 59.3750 (64.8177) Top1_base_per_class: 56.0303 (65.0819) 
Training Epoch: [25/1000] Step: [70 / 285] Batch Time: 0.1424 (0.1699) Data Time: 0.0107 (0.0381) Average Loss: 1.4676 (1.2696) Average CE Loss (Source):  1.4676 ( 1.2696) Learning Rate: 0.1000 (0.1000) Top1_base: 58.5938 (64.6987) Top1_base_per_class: 58.8889 (64.9879) 
Training Epoch: [25/1000] Step: [80 / 285] Batch Time: 0.1427 (0.1682) Data Time: 0.0108 (0.0364) Average Loss: 1.2414 (1.2718) Average CE Loss (Source):  1.2414 ( 1.2718) Learning Rate: 0.1000 (0.1000) Top1_base: 65.6250 (64.7168) Top1_base_per_class: 62.9038 (64.9237) 
Training Epoch: [25/1000] Step: [90 / 285] Batch Time: 0.1430 (0.1665) Data Time: 0.0105 (0.0347) Average Loss: 1.6976 (1.2715) Average CE Loss (Source):  1.6976 ( 1.2715) Learning Rate: 0.1000 (0.1000) Top1_base: 48.4375 (64.7483) Top1_base_per_class: 50.8621 (65.0281) 
Training Epoch: [25/1000] Step: [100 / 285] Batch Time: 0.1417 (0.1653) Data Time: 0.0096 (0.0335) Average Loss: 1.0742 (1.2740) Average CE Loss (Source):  1.0742 ( 1.2740) Learning Rate: 0.1000 (0.1000) Top1_base: 69.5312 (64.8516) Top1_base_per_class: 71.5805 (65.1424) 
Training Epoch: [25/1000] Step: [110 / 285] Batch Time: 0.1417 (0.1649) Data Time: 0.0105 (0.0332) Average Loss: 1.1115 (1.2728) Average CE Loss (Source):  1.1115 ( 1.2728) Learning Rate: 0.1000 (0.1000) Top1_base: 69.5312 (64.8864) Top1_base_per_class: 69.9960 (65.2309) 
Training Epoch: [25/1000] Step: [120 / 285] Batch Time: 0.1426 (0.1652) Data Time: 0.0110 (0.0334) Average Loss: 1.4946 (1.2774) Average CE Loss (Source):  1.4946 ( 1.2774) Learning Rate: 0.1000 (0.1000) Top1_base: 63.2812 (64.8568) Top1_base_per_class: 65.6000 (65.2152) 
Training Epoch: [25/1000] Step: [130 / 285] Batch Time: 0.1419 (0.1644) Data Time: 0.0107 (0.0327) Average Loss: 1.2950 (1.2850) Average CE Loss (Source):  1.2950 ( 1.2850) Learning Rate: 0.1000 (0.1000) Top1_base: 64.0625 (64.6274) Top1_base_per_class: 62.6515 (64.9421) 
Training Epoch: [25/1000] Step: [140 / 285] Batch Time: 0.1421 (0.1644) Data Time: 0.0099 (0.0327) Average Loss: 1.3548 (1.2863) Average CE Loss (Source):  1.3548 ( 1.2863) Learning Rate: 0.1000 (0.1000) Top1_base: 61.7188 (64.6708) Top1_base_per_class: 60.7440 (65.0118) 
Training Epoch: [25/1000] Step: [150 / 285] Batch Time: 0.1462 (0.1636) Data Time: 0.0132 (0.0318) Average Loss: 1.4254 (1.2896) Average CE Loss (Source):  1.4254 ( 1.2896) Learning Rate: 0.1000 (0.1000) Top1_base: 62.5000 (64.5990) Top1_base_per_class: 63.5108 (64.9304) 
Training Epoch: [25/1000] Step: [160 / 285] Batch Time: 0.1416 (0.1627) Data Time: 0.0104 (0.0310) Average Loss: 1.3332 (1.2919) Average CE Loss (Source):  1.3332 ( 1.2919) Learning Rate: 0.1000 (0.1000) Top1_base: 63.2812 (64.5605) Top1_base_per_class: 59.9680 (64.8087) 
Training Epoch: [25/1000] Step: [170 / 285] Batch Time: 0.1422 (0.1618) Data Time: 0.0109 (0.0301) Average Loss: 1.1326 (1.2883) Average CE Loss (Source):  1.1326 ( 1.2883) Learning Rate: 0.1000 (0.1000) Top1_base: 68.7500 (64.6691) Top1_base_per_class: 67.4859 (65.0070) 
Training Epoch: [25/1000] Step: [180 / 285] Batch Time: 0.1418 (0.1619) Data Time: 0.0105 (0.0302) Average Loss: 1.3951 (1.2894) Average CE Loss (Source):  1.3951 ( 1.2894) Learning Rate: 0.1000 (0.1000) Top1_base: 64.0625 (64.6050) Top1_base_per_class: 57.9321 (64.9714) 
Training Epoch: [25/1000] Step: [190 / 285] Batch Time: 0.1435 (0.1614) Data Time: 0.0110 (0.0297) Average Loss: 1.1636 (1.2906) Average CE Loss (Source):  1.1636 ( 1.2906) Learning Rate: 0.1000 (0.1000) Top1_base: 67.1875 (64.5559) Top1_base_per_class: 70.0321 (64.9440) 
Training Epoch: [25/1000] Step: [200 / 285] Batch Time: 0.1428 (0.1617) Data Time: 0.0110 (0.0300) Average Loss: 1.2101 (1.2892) Average CE Loss (Source):  1.2101 ( 1.2892) Learning Rate: 0.1000 (0.1000) Top1_base: 69.5312 (64.5664) Top1_base_per_class: 66.8611 (64.9453) 
Training Epoch: [25/1000] Step: [210 / 285] Batch Time: 0.1415 (0.1619) Data Time: 0.0098 (0.0302) Average Loss: 1.2353 (1.2894) Average CE Loss (Source):  1.2353 ( 1.2894) Learning Rate: 0.1000 (0.1000) Top1_base: 64.8438 (64.5982) Top1_base_per_class: 66.3842 (64.9220) 
Training Epoch: [25/1000] Step: [220 / 285] Batch Time: 0.1416 (0.1617) Data Time: 0.0097 (0.0301) Average Loss: 1.2535 (1.2890) Average CE Loss (Source):  1.2535 ( 1.2890) Learning Rate: 0.1000 (0.1000) Top1_base: 63.2812 (64.6768) Top1_base_per_class: 66.8129 (65.0071) 
Training Epoch: [25/1000] Step: [230 / 285] Batch Time: 0.1432 (0.1613) Data Time: 0.0097 (0.0296) Average Loss: 1.3250 (1.2904) Average CE Loss (Source):  1.3250 ( 1.2904) Learning Rate: 0.1000 (0.1000) Top1_base: 64.8438 (64.5550) Top1_base_per_class: 67.1667 (64.9274) 
Training Epoch: [25/1000] Step: [240 / 285] Batch Time: 0.1462 (0.1613) Data Time: 0.0143 (0.0297) Average Loss: 1.4499 (1.2931) Average CE Loss (Source):  1.4499 ( 1.2931) Learning Rate: 0.1000 (0.1000) Top1_base: 58.5938 (64.4661) Top1_base_per_class: 60.9877 (64.8556) 
Training Epoch: [25/1000] Step: [250 / 285] Batch Time: 0.1430 (0.1612) Data Time: 0.0103 (0.0295) Average Loss: 1.1331 (1.2927) Average CE Loss (Source):  1.1331 ( 1.2927) Learning Rate: 0.1000 (0.1000) Top1_base: 70.3125 (64.4938) Top1_base_per_class: 70.0847 (64.8694) 
Training Epoch: [25/1000] Step: [260 / 285] Batch Time: 0.1425 (0.1620) Data Time: 0.0096 (0.0303) Average Loss: 1.1764 (1.2915) Average CE Loss (Source):  1.1764 ( 1.2915) Learning Rate: 0.1000 (0.1000) Top1_base: 63.2812 (64.4651) Top1_base_per_class: 68.6441 (64.8819) 
Training Epoch: [25/1000] Step: [270 / 285] Batch Time: 0.1439 (0.1617) Data Time: 0.0105 (0.0300) Average Loss: 1.3844 (1.2924) Average CE Loss (Source):  1.3844 ( 1.2924) Learning Rate: 0.1000 (0.1000) Top1_base: 60.1562 (64.4618) Top1_base_per_class: 57.2599 (64.8576) 
Training Epoch: [25/1000] Step: [280 / 285] Batch Time: 0.1400 (0.1620) Data Time: 0.0091 (0.0303) Average Loss: 1.2509 (1.2944) Average CE Loss (Source):  1.2509 ( 1.2944) Learning Rate: 0.1000 (0.1000) Top1_base: 67.1875 (64.3890) Top1_base_per_class: 62.9762 (64.7841) 
Training Epoch: [26/1000] Step: [0] Batch Time: 0.1381 (0.1619) Data Time: 0.0092 (0.0302) Average Loss: 1.4818 (1.2951) Average CE Loss (Source):  1.4818 ( 1.2951) Learning Rate: 0.1000 (0.1000) Top1_base: 59.3750 (64.3777) Top1_base_per_class: 58.1675 (64.8180) 
  3%|▎         | 26/1000 [20:49<12:58:04, 47.93s/it]  3%|▎         | 27/1000 [21:35<12:50:20, 47.50s/it]Training Epoch: [26/1000] Step: [10 / 285] Batch Time: 0.1464 (0.2283) Data Time: 0.0129 (0.0963) Average Loss: 1.2360 (1.2352) Average CE Loss (Source):  1.2360 ( 1.2352) Learning Rate: 0.1000 (0.1000) Top1_base: 65.6250 (67.6562) Top1_base_per_class: 63.5876 (68.4344) 
Training Epoch: [26/1000] Step: [20 / 285] Batch Time: 0.1419 (0.1966) Data Time: 0.0105 (0.0648) Average Loss: 1.2978 (1.2577) Average CE Loss (Source):  1.2978 ( 1.2577) Learning Rate: 0.1000 (0.1000) Top1_base: 58.5938 (66.4453) Top1_base_per_class: 57.9739 (67.1584) 
Training Epoch: [26/1000] Step: [30 / 285] Batch Time: 0.1431 (0.1860) Data Time: 0.0113 (0.0543) Average Loss: 1.2389 (1.2683) Average CE Loss (Source):  1.2389 ( 1.2683) Learning Rate: 0.1000 (0.1000) Top1_base: 67.9688 (66.1979) Top1_base_per_class: 68.9583 (66.4687) 
Training Epoch: [26/1000] Step: [40 / 285] Batch Time: 0.1429 (0.1791) Data Time: 0.0105 (0.0475) Average Loss: 1.3569 (1.2778) Average CE Loss (Source):  1.3569 ( 1.2778) Learning Rate: 0.1000 (0.1000) Top1_base: 66.4062 (65.7227) Top1_base_per_class: 70.8333 (66.3191) 
Training Epoch: [26/1000] Step: [50 / 285] Batch Time: 0.1528 (0.1754) Data Time: 0.0218 (0.0437) Average Loss: 1.3380 (1.2773) Average CE Loss (Source):  1.3380 ( 1.2773) Learning Rate: 0.1000 (0.1000) Top1_base: 65.6250 (65.5156) Top1_base_per_class: 67.6852 (65.9976) 
Training Epoch: [26/1000] Step: [60 / 285] Batch Time: 0.1464 (0.1722) Data Time: 0.0127 (0.0404) Average Loss: 1.3328 (1.2837) Average CE Loss (Source):  1.3328 ( 1.2837) Learning Rate: 0.1000 (0.1000) Top1_base: 62.5000 (65.2995) Top1_base_per_class: 68.6364 (66.0413) 
Training Epoch: [26/1000] Step: [70 / 285] Batch Time: 0.1824 (0.1708) Data Time: 0.0500 (0.0388) Average Loss: 0.9486 (1.2749) Average CE Loss (Source):  0.9486 ( 1.2749) Learning Rate: 0.1000 (0.1000) Top1_base: 75.7812 (65.3683) Top1_base_per_class: 76.9253 (66.0789) 
Training Epoch: [26/1000] Step: [80 / 285] Batch Time: 0.1444 (0.1685) Data Time: 0.0123 (0.0365) Average Loss: 1.0425 (1.2730) Average CE Loss (Source):  1.0425 ( 1.2730) Learning Rate: 0.1000 (0.1000) Top1_base: 73.4375 (65.2930) Top1_base_per_class: 72.3392 (66.0545) 
Training Epoch: [26/1000] Step: [90 / 285] Batch Time: 0.2405 (0.1690) Data Time: 0.1074 (0.0369) Average Loss: 1.2823 (1.2689) Average CE Loss (Source):  1.2823 ( 1.2689) Learning Rate: 0.1000 (0.1000) Top1_base: 65.6250 (65.3993) Top1_base_per_class: 68.6859 (66.2039) 
Training Epoch: [26/1000] Step: [100 / 285] Batch Time: 0.1452 (0.1678) Data Time: 0.0129 (0.0356) Average Loss: 1.0973 (1.2642) Average CE Loss (Source):  1.0973 ( 1.2642) Learning Rate: 0.1000 (0.1000) Top1_base: 70.3125 (65.5312) Top1_base_per_class: 70.7619 (66.3319) 
Training Epoch: [26/1000] Step: [110 / 285] Batch Time: 0.2449 (0.1677) Data Time: 0.1134 (0.0356) Average Loss: 1.3254 (1.2673) Average CE Loss (Source):  1.3254 ( 1.2673) Learning Rate: 0.1000 (0.1000) Top1_base: 64.8438 (65.4332) Top1_base_per_class: 62.0536 (66.2737) 
Training Epoch: [26/1000] Step: [120 / 285] Batch Time: 0.1438 (0.1663) Data Time: 0.0108 (0.0341) Average Loss: 1.1985 (1.2678) Average CE Loss (Source):  1.1985 ( 1.2678) Learning Rate: 0.1000 (0.1000) Top1_base: 63.2812 (65.2995) Top1_base_per_class: 66.0672 (66.1099) 
Training Epoch: [26/1000] Step: [130 / 285] Batch Time: 0.1571 (0.1660) Data Time: 0.0246 (0.0338) Average Loss: 1.3335 (1.2709) Average CE Loss (Source):  1.3335 ( 1.2709) Learning Rate: 0.1000 (0.1000) Top1_base: 63.2812 (65.2043) Top1_base_per_class: 63.7755 (66.0167) 
Training Epoch: [26/1000] Step: [140 / 285] Batch Time: 0.1430 (0.1662) Data Time: 0.0113 (0.0340) Average Loss: 1.4488 (1.2704) Average CE Loss (Source):  1.4488 ( 1.2704) Learning Rate: 0.1000 (0.1000) Top1_base: 64.0625 (65.1786) Top1_base_per_class: 63.4524 (65.9241) 
Training Epoch: [26/1000] Step: [150 / 285] Batch Time: 0.1972 (0.1664) Data Time: 0.0661 (0.0342) Average Loss: 1.1012 (1.2759) Average CE Loss (Source):  1.1012 ( 1.2759) Learning Rate: 0.1000 (0.1000) Top1_base: 67.1875 (65.0260) Top1_base_per_class: 67.5000 (65.7233) 
Training Epoch: [26/1000] Step: [160 / 285] Batch Time: 0.1455 (0.1657) Data Time: 0.0130 (0.0336) Average Loss: 0.9629 (1.2715) Average CE Loss (Source):  0.9629 ( 1.2715) Learning Rate: 0.1000 (0.1000) Top1_base: 75.0000 (65.1221) Top1_base_per_class: 72.9464 (65.7337) 
Training Epoch: [26/1000] Step: [170 / 285] Batch Time: 0.1890 (0.1660) Data Time: 0.0569 (0.0337) Average Loss: 1.3101 (1.2683) Average CE Loss (Source):  1.3101 ( 1.2683) Learning Rate: 0.1000 (0.1000) Top1_base: 58.5938 (65.1425) Top1_base_per_class: 58.4111 (65.7799) 
Training Epoch: [26/1000] Step: [180 / 285] Batch Time: 0.1488 (0.1658) Data Time: 0.0135 (0.0335) Average Loss: 1.1945 (1.2707) Average CE Loss (Source):  1.1945 ( 1.2707) Learning Rate: 0.1000 (0.1000) Top1_base: 65.6250 (65.0174) Top1_base_per_class: 66.8079 (65.6822) 
Training Epoch: [26/1000] Step: [190 / 285] Batch Time: 0.2129 (0.1654) Data Time: 0.0826 (0.0331) Average Loss: 1.4784 (1.2729) Average CE Loss (Source):  1.4784 ( 1.2729) Learning Rate: 0.1000 (0.1000) Top1_base: 63.2812 (65.0781) Top1_base_per_class: 61.9689 (65.7015) 
Training Epoch: [26/1000] Step: [200 / 285] Batch Time: 0.1435 (0.1648) Data Time: 0.0114 (0.0325) Average Loss: 1.1920 (1.2744) Average CE Loss (Source):  1.1920 ( 1.2744) Learning Rate: 0.1000 (0.1000) Top1_base: 71.8750 (65.0820) Top1_base_per_class: 73.0864 (65.7030) 
Training Epoch: [26/1000] Step: [210 / 285] Batch Time: 0.2012 (0.1652) Data Time: 0.0694 (0.0329) Average Loss: 1.3343 (1.2741) Average CE Loss (Source):  1.3343 ( 1.2741) Learning Rate: 0.1000 (0.1000) Top1_base: 64.8438 (65.1339) Top1_base_per_class: 66.2919 (65.7391) 
Training Epoch: [26/1000] Step: [220 / 285] Batch Time: 0.1444 (0.1645) Data Time: 0.0113 (0.0323) Average Loss: 1.0133 (1.2746) Average CE Loss (Source):  1.0133 ( 1.2746) Learning Rate: 0.1000 (0.1000) Top1_base: 72.6562 (65.0817) Top1_base_per_class: 72.2881 (65.6444) 
Training Epoch: [26/1000] Step: [230 / 285] Batch Time: 0.1727 (0.1646) Data Time: 0.0413 (0.0323) Average Loss: 1.0223 (1.2743) Average CE Loss (Source):  1.0223 ( 1.2743) Learning Rate: 0.1000 (0.1000) Top1_base: 75.7812 (65.0883) Top1_base_per_class: 73.8690 (65.6597) 
Training Epoch: [26/1000] Step: [240 / 285] Batch Time: 0.1430 (0.1638) Data Time: 0.0108 (0.0316) Average Loss: 0.9129 (1.2708) Average CE Loss (Source):  0.9129 ( 1.2708) Learning Rate: 0.1000 (0.1000) Top1_base: 74.2188 (65.2018) Top1_base_per_class: 76.5723 (65.7948) 
Training Epoch: [26/1000] Step: [250 / 285] Batch Time: 0.2066 (0.1639) Data Time: 0.0746 (0.0316) Average Loss: 1.1646 (1.2719) Average CE Loss (Source):  1.1646 ( 1.2719) Learning Rate: 0.1000 (0.1000) Top1_base: 65.6250 (65.1531) Top1_base_per_class: 61.2418 (65.7045) 
Training Epoch: [26/1000] Step: [260 / 285] Batch Time: 0.1469 (0.1639) Data Time: 0.0125 (0.0316) Average Loss: 1.3008 (1.2758) Average CE Loss (Source):  1.3008 ( 1.2758) Learning Rate: 0.1000 (0.1000) Top1_base: 64.8438 (65.0811) Top1_base_per_class: 64.1358 (65.6446) 
Training Epoch: [26/1000] Step: [270 / 285] Batch Time: 0.1740 (0.1637) Data Time: 0.0401 (0.0313) Average Loss: 1.5757 (1.2811) Average CE Loss (Source):  1.5757 ( 1.2811) Learning Rate: 0.1000 (0.1000) Top1_base: 61.7188 (64.9826) Top1_base_per_class: 61.5136 (65.5382) 
Training Epoch: [26/1000] Step: [280 / 285] Batch Time: 0.1486 (0.1632) Data Time: 0.0133 (0.0307) Average Loss: 1.4097 (1.2826) Average CE Loss (Source):  1.4097 ( 1.2826) Learning Rate: 0.1000 (0.1000) Top1_base: 67.1875 (64.9749) Top1_base_per_class: 65.9483 (65.5475) 
Training Epoch: [27/1000] Step: [0] Batch Time: 0.1404 (0.1629) Data Time: 0.0094 (0.0305) Average Loss: 1.5435 (1.2849) Average CE Loss (Source):  1.5435 ( 1.2849) Learning Rate: 0.1000 (0.1000) Top1_base: 58.5938 (64.9178) Top1_base_per_class: 57.9023 (65.4651) 
Training Epoch: [27/1000] Step: [10 / 285] Batch Time: 0.1430 (0.2374) Data Time: 0.0127 (0.1060) Average Loss: 1.0485 (1.2083) Average CE Loss (Source):  1.0485 ( 1.2083) Learning Rate: 0.1000 (0.1000) Top1_base: 72.6562 (66.8750) Top1_base_per_class: 72.7987 (67.1528) 
Training Epoch: [27/1000] Step: [20 / 285] Batch Time: 0.1448 (0.1998) Data Time: 0.0134 (0.0684) Average Loss: 1.0781 (1.1844) Average CE Loss (Source):  1.0781 ( 1.1844) Learning Rate: 0.1000 (0.1000) Top1_base: 71.8750 (67.8125) Top1_base_per_class: 72.6323 (68.0359) 
Training Epoch: [27/1000] Step: [30 / 285] Batch Time: 0.1446 (0.1899) Data Time: 0.0122 (0.0583) Average Loss: 1.2398 (1.1920) Average CE Loss (Source):  1.2398 ( 1.1920) Learning Rate: 0.1000 (0.1000) Top1_base: 64.8438 (67.6562) Top1_base_per_class: 66.1342 (67.6923) 
Training Epoch: [27/1000] Step: [40 / 285] Batch Time: 0.1443 (0.1819) Data Time: 0.0120 (0.0501) Average Loss: 1.2388 (1.2055) Average CE Loss (Source):  1.2388 ( 1.2055) Learning Rate: 0.1000 (0.1000) Top1_base: 68.7500 (67.1484) Top1_base_per_class: 64.4133 (67.2174) 
Training Epoch: [27/1000] Step: [50 / 285] Batch Time: 0.1477 (0.1772) Data Time: 0.0137 (0.0453) Average Loss: 1.0746 (1.2173) Average CE Loss (Source):  1.0746 ( 1.2173) Learning Rate: 0.1000 (0.1000) Top1_base: 66.4062 (66.8125) Top1_base_per_class: 67.0402 (66.9309) 
Training Epoch: [27/1000] Step: [60 / 285] Batch Time: 0.1438 (0.1737) Data Time: 0.0137 (0.0416) Average Loss: 1.2857 (1.2271) Average CE Loss (Source):  1.2857 ( 1.2271) Learning Rate: 0.1000 (0.1000) Top1_base: 62.5000 (66.4583) Top1_base_per_class: 60.1923 (66.5936) 
Training Epoch: [27/1000] Step: [70 / 285] Batch Time: 0.1431 (0.1731) Data Time: 0.0110 (0.0410) Average Loss: 1.2228 (1.2287) Average CE Loss (Source):  1.2228 ( 1.2287) Learning Rate: 0.1000 (0.1000) Top1_base: 68.7500 (66.4844) Top1_base_per_class: 68.9327 (66.5298) 
Training Epoch: [27/1000] Step: [80 / 285] Batch Time: 0.1435 (0.1707) Data Time: 0.0120 (0.0387) Average Loss: 1.3696 (1.2389) Average CE Loss (Source):  1.3696 ( 1.2389) Learning Rate: 0.1000 (0.1000) Top1_base: 63.2812 (66.2207) Top1_base_per_class: 60.5848 (66.1961) 
Training Epoch: [27/1000] Step: [90 / 285] Batch Time: 0.1421 (0.1703) Data Time: 0.0104 (0.0383) Average Loss: 1.2871 (1.2424) Average CE Loss (Source):  1.2871 ( 1.2424) Learning Rate: 0.1000 (0.1000) Top1_base: 61.7188 (66.1111) Top1_base_per_class: 67.2013 (66.1580) 
Training Epoch: [27/1000] Step: [100 / 285] Batch Time: 0.1435 (0.1688) Data Time: 0.0112 (0.0368) Average Loss: 1.1056 (1.2414) Average CE Loss (Source):  1.1056 ( 1.2414) Learning Rate: 0.1000 (0.1000) Top1_base: 71.8750 (66.0703) Top1_base_per_class: 71.6945 (66.0870) 
Training Epoch: [27/1000] Step: [110 / 285] Batch Time: 0.1433 (0.1679) Data Time: 0.0118 (0.0360) Average Loss: 1.3988 (1.2481) Average CE Loss (Source):  1.3988 ( 1.2481) Learning Rate: 0.1000 (0.1000) Top1_base: 64.8438 (65.9091) Top1_base_per_class: 62.8182 (65.9393) 
Training Epoch: [27/1000] Step: [120 / 285] Batch Time: 0.1429 (0.1668) Data Time: 0.0109 (0.0348) Average Loss: 1.2059 (1.2526) Average CE Loss (Source):  1.2059 ( 1.2526) Learning Rate: 0.1000 (0.1000) Top1_base: 66.4062 (65.8789) Top1_base_per_class: 71.9091 (66.0630) 
Training Epoch: [27/1000] Step: [130 / 285] Batch Time: 0.1438 (0.1657) Data Time: 0.0115 (0.0337) Average Loss: 1.3869 (1.2537) Average CE Loss (Source):  1.3869 ( 1.2537) Learning Rate: 0.1000 (0.1000) Top1_base: 65.6250 (65.8594) Top1_base_per_class: 67.9938 (66.1057) 
Training Epoch: [27/1000] Step: [140 / 285] Batch Time: 0.1451 (0.1645) Data Time: 0.0133 (0.0324) Average Loss: 1.2990 (1.2486) Average CE Loss (Source):  1.2990 ( 1.2486) Learning Rate: 0.1000 (0.1000) Top1_base: 64.0625 (65.9989) Top1_base_per_class: 60.9392 (66.1426) 
Training Epoch: [27/1000] Step: [150 / 285] Batch Time: 0.1459 (0.1648) Data Time: 0.0131 (0.0327) Average Loss: 1.5030 (1.2466) Average CE Loss (Source):  1.5030 ( 1.2466) Learning Rate: 0.1000 (0.1000) Top1_base: 64.0625 (66.0885) Top1_base_per_class: 62.0238 (66.3134) 
Training Epoch: [27/1000] Step: [160 / 285] Batch Time: 0.1429 (0.1644) Data Time: 0.0119 (0.0323) Average Loss: 1.2256 (1.2482) Average CE Loss (Source):  1.2256 ( 1.2482) Learning Rate: 0.1000 (0.1000) Top1_base: 63.2812 (65.9766) Top1_base_per_class: 66.5179 (66.1589) 
Training Epoch: [27/1000] Step: [170 / 285] Batch Time: 0.1446 (0.1638) Data Time: 0.0117 (0.0317) Average Loss: 1.2291 (1.2460) Average CE Loss (Source):  1.2291 ( 1.2460) Learning Rate: 0.1000 (0.1000) Top1_base: 66.4062 (66.0616) Top1_base_per_class: 71.7857 (66.3146) 
Training Epoch: [27/1000] Step: [180 / 285] Batch Time: 0.1449 (0.1633) Data Time: 0.0117 (0.0311) Average Loss: 1.0850 (1.2442) Average CE Loss (Source):  1.0850 ( 1.2442) Learning Rate: 0.1000 (0.1000) Top1_base: 71.8750 (66.1372) Top1_base_per_class: 69.5322 (66.3705) 
Training Epoch: [27/1000] Step: [190 / 285] Batch Time: 0.1457 (0.1633) Data Time: 0.0133 (0.0311) Average Loss: 1.3949 (1.2478) Average CE Loss (Source):  1.3949 ( 1.2478) Learning Rate: 0.1000 (0.1000) Top1_base: 64.8438 (66.0814) Top1_base_per_class: 66.2994 (66.3534) 
Training Epoch: [27/1000] Step: [200 / 285] Batch Time: 0.1483 (0.1627) Data Time: 0.0139 (0.0305) Average Loss: 1.0413 (1.2475) Average CE Loss (Source):  1.0413 ( 1.2475) Learning Rate: 0.1000 (0.1000) Top1_base: 70.3125 (66.0312) Top1_base_per_class: 71.2202 (66.3298) 
Training Epoch: [27/1000] Step: [210 / 285] Batch Time: 0.1450 (0.1624) Data Time: 0.0120 (0.0302) Average Loss: 1.1220 (1.2467) Average CE Loss (Source):  1.1220 ( 1.2467) Learning Rate: 0.1000 (0.1000) Top1_base: 69.5312 (66.0938) Top1_base_per_class: 71.0556 (66.3655) 
Training Epoch: [27/1000] Step: [220 / 285] Batch Time: 0.1462 (0.1626) Data Time: 0.0136 (0.0304) Average Loss: 1.1895 (1.2487) Average CE Loss (Source):  1.1895 ( 1.2487) Learning Rate: 0.1000 (0.1000) Top1_base: 66.4062 (66.0085) Top1_base_per_class: 67.6701 (66.3210) 
Training Epoch: [27/1000] Step: [230 / 285] Batch Time: 0.1414 (0.1631) Data Time: 0.0101 (0.0309) Average Loss: 1.2440 (1.2478) Average CE Loss (Source):  1.2440 ( 1.2478) Learning Rate: 0.1000 (0.1000) Top1_base: 65.6250 (66.0530) Top1_base_per_class: 67.2727 (66.3858) 
Training Epoch: [27/1000] Step: [240 / 285] Batch Time: 0.1441 (0.1626) Data Time: 0.0126 (0.0304) Average Loss: 1.1872 (1.2469) Average CE Loss (Source):  1.1872 ( 1.2469) Learning Rate: 0.1000 (0.1000) Top1_base: 66.4062 (66.1133) Top1_base_per_class: 67.8947 (66.4682) 
Training Epoch: [27/1000] Step: [250 / 285] Batch Time: 0.1427 (0.1623) Data Time: 0.0101 (0.0301) Average Loss: 1.1756 (1.2494) Average CE Loss (Source):  1.1756 ( 1.2494) Learning Rate: 0.1000 (0.1000) Top1_base: 70.3125 (65.9813) Top1_base_per_class: 67.2321 (66.2776) 
Training Epoch: [27/1000] Step: [260 / 285] Batch Time: 0.1445 (0.1622) Data Time: 0.0125 (0.0300) Average Loss: 1.3575 (1.2501) Average CE Loss (Source):  1.3575 ( 1.2501) Learning Rate: 0.1000 (0.1000) Top1_base: 64.8438 (65.9225) Top1_base_per_class: 65.3863 (66.2122) 
Training Epoch: [27/1000] Step: [270 / 285] Batch Time: 0.1432 (0.1621) Data Time: 0.0101 (0.0299) Average Loss: 1.2566 (1.2508) Average CE Loss (Source):  1.2566 ( 1.2508) Learning Rate: 0.1000 (0.1000) Top1_base: 67.1875 (65.9433) Top1_base_per_class: 63.9583 (66.2034) 
Training Epoch: [27/1000] Step: [280 / 285] Batch Time: 0.1444 (0.1615) Data Time: 0.0125 (0.0293) Average Loss: 1.2404 (1.2515) Average CE Loss (Source):  1.2404 ( 1.2515) Learning Rate: 0.1000 (0.1000) Top1_base: 62.5000 (65.8984) Top1_base_per_class: 60.9295 (66.1759) 
Training Epoch: [28/1000] Step: [0] Batch Time: 0.1571 (0.1613) Data Time: 0.0248 (0.0291) Average Loss: 1.5259 (1.2534) Average CE Loss (Source):  1.5259 ( 1.2534) Learning Rate: 0.1000 (0.1000) Top1_base: 59.3750 (65.8525) Top1_base_per_class: 60.0909 (66.1335) 
  3%|▎         | 28/1000 [22:24<12:56:21, 47.92s/it]  3%|▎         | 29/1000 [23:11<12:49:12, 47.53s/it]Training Epoch: [28/1000] Step: [10 / 285] Batch Time: 0.2303 (0.2359) Data Time: 0.1012 (0.1048) Average Loss: 1.3522 (1.2258) Average CE Loss (Source):  1.3522 ( 1.2258) Learning Rate: 0.1000 (0.1000) Top1_base: 62.5000 (67.1094) Top1_base_per_class: 59.0000 (66.7328) 
Training Epoch: [28/1000] Step: [20 / 285] Batch Time: 0.1424 (0.1933) Data Time: 0.0108 (0.0622) Average Loss: 1.2024 (1.2324) Average CE Loss (Source):  1.2024 ( 1.2324) Learning Rate: 0.1000 (0.1000) Top1_base: 65.6250 (66.5234) Top1_base_per_class: 66.1607 (66.8230) 
Training Epoch: [28/1000] Step: [30 / 285] Batch Time: 0.2555 (0.1851) Data Time: 0.1221 (0.0534) Average Loss: 0.9874 (1.2163) Average CE Loss (Source):  0.9874 ( 1.2163) Learning Rate: 0.1000 (0.1000) Top1_base: 73.4375 (66.9010) Top1_base_per_class: 71.8899 (67.2087) 
Training Epoch: [28/1000] Step: [40 / 285] Batch Time: 0.1498 (0.1774) Data Time: 0.0147 (0.0450) Average Loss: 1.2797 (1.2218) Average CE Loss (Source):  1.2797 ( 1.2218) Learning Rate: 0.1000 (0.1000) Top1_base: 66.4062 (66.7578) Top1_base_per_class: 66.3054 (66.9049) 
Training Epoch: [28/1000] Step: [50 / 285] Batch Time: 0.1476 (0.1766) Data Time: 0.0118 (0.0439) Average Loss: 1.2135 (1.2231) Average CE Loss (Source):  1.2135 ( 1.2231) Learning Rate: 0.1000 (0.1000) Top1_base: 68.7500 (66.6094) Top1_base_per_class: 68.8539 (66.8093) 
Training Epoch: [28/1000] Step: [60 / 285] Batch Time: 0.1454 (0.1718) Data Time: 0.0113 (0.0389) Average Loss: 1.2477 (1.2069) Average CE Loss (Source):  1.2477 ( 1.2069) Learning Rate: 0.1000 (0.1000) Top1_base: 69.5312 (67.1484) Top1_base_per_class: 69.6552 (67.3254) 
Training Epoch: [28/1000] Step: [70 / 285] Batch Time: 0.1463 (0.1713) Data Time: 0.0116 (0.0381) Average Loss: 1.4114 (1.2093) Average CE Loss (Source):  1.4114 ( 1.2093) Learning Rate: 0.1000 (0.1000) Top1_base: 60.9375 (67.0982) Top1_base_per_class: 65.3030 (67.3046) 
Training Epoch: [28/1000] Step: [80 / 285] Batch Time: 0.1449 (0.1699) Data Time: 0.0109 (0.0366) Average Loss: 1.3659 (1.2132) Average CE Loss (Source):  1.3659 ( 1.2132) Learning Rate: 0.1000 (0.1000) Top1_base: 66.4062 (66.8848) Top1_base_per_class: 67.9697 (67.0588) 
Training Epoch: [28/1000] Step: [90 / 285] Batch Time: 0.1437 (0.1694) Data Time: 0.0094 (0.0361) Average Loss: 1.1809 (1.2150) Average CE Loss (Source):  1.1809 ( 1.2150) Learning Rate: 0.1000 (0.1000) Top1_base: 69.5312 (66.9184) Top1_base_per_class: 70.8333 (67.0463) 
Training Epoch: [28/1000] Step: [100 / 285] Batch Time: 0.1425 (0.1686) Data Time: 0.0110 (0.0354) Average Loss: 1.2868 (1.2196) Average CE Loss (Source):  1.2868 ( 1.2196) Learning Rate: 0.1000 (0.1000) Top1_base: 59.3750 (66.6797) Top1_base_per_class: 62.8363 (66.8796) 
Training Epoch: [28/1000] Step: [110 / 285] Batch Time: 0.1429 (0.1680) Data Time: 0.0111 (0.0349) Average Loss: 0.9407 (1.2213) Average CE Loss (Source):  0.9407 ( 1.2213) Learning Rate: 0.1000 (0.1000) Top1_base: 79.6875 (66.6264) Top1_base_per_class: 80.2222 (66.8323) 
Training Epoch: [28/1000] Step: [120 / 285] Batch Time: 0.1410 (0.1669) Data Time: 0.0107 (0.0340) Average Loss: 1.2508 (1.2146) Average CE Loss (Source):  1.2508 ( 1.2146) Learning Rate: 0.1000 (0.1000) Top1_base: 64.0625 (66.8164) Top1_base_per_class: 63.2251 (66.9272) 
Training Epoch: [28/1000] Step: [130 / 285] Batch Time: 0.1422 (0.1663) Data Time: 0.0095 (0.0335) Average Loss: 1.4370 (1.2198) Average CE Loss (Source):  1.4370 ( 1.2198) Learning Rate: 0.1000 (0.1000) Top1_base: 61.7188 (66.6346) Top1_base_per_class: 62.9885 (66.7944) 
Training Epoch: [28/1000] Step: [140 / 285] Batch Time: 0.1446 (0.1651) Data Time: 0.0126 (0.0324) Average Loss: 1.2947 (1.2227) Average CE Loss (Source):  1.2947 ( 1.2227) Learning Rate: 0.1000 (0.1000) Top1_base: 66.4062 (66.7020) Top1_base_per_class: 66.3450 (66.9207) 
Training Epoch: [28/1000] Step: [150 / 285] Batch Time: 0.1415 (0.1650) Data Time: 0.0095 (0.0323) Average Loss: 1.1801 (1.2250) Average CE Loss (Source):  1.1801 ( 1.2250) Learning Rate: 0.1000 (0.1000) Top1_base: 64.8438 (66.5573) Top1_base_per_class: 63.6905 (66.7748) 
Training Epoch: [28/1000] Step: [160 / 285] Batch Time: 0.1457 (0.1642) Data Time: 0.0118 (0.0315) Average Loss: 1.2956 (1.2275) Average CE Loss (Source):  1.2956 ( 1.2275) Learning Rate: 0.1000 (0.1000) Top1_base: 59.3750 (66.4941) Top1_base_per_class: 61.3030 (66.7493) 
Training Epoch: [28/1000] Step: [170 / 285] Batch Time: 0.1431 (0.1640) Data Time: 0.0106 (0.0314) Average Loss: 1.3915 (1.2308) Average CE Loss (Source):  1.3915 ( 1.2308) Learning Rate: 0.1000 (0.1000) Top1_base: 60.1562 (66.3695) Top1_base_per_class: 57.5146 (66.6444) 
Training Epoch: [28/1000] Step: [180 / 285] Batch Time: 0.1420 (0.1630) Data Time: 0.0106 (0.0304) Average Loss: 1.3793 (1.2326) Average CE Loss (Source):  1.3793 ( 1.2326) Learning Rate: 0.1000 (0.1000) Top1_base: 64.8438 (66.3325) Top1_base_per_class: 68.3951 (66.6552) 
Training Epoch: [28/1000] Step: [190 / 285] Batch Time: 0.1418 (0.1625) Data Time: 0.0103 (0.0299) Average Loss: 1.1507 (1.2341) Average CE Loss (Source):  1.1507 ( 1.2341) Learning Rate: 0.1000 (0.1000) Top1_base: 64.8438 (66.2664) Top1_base_per_class: 68.2030 (66.6327) 
Training Epoch: [28/1000] Step: [200 / 285] Batch Time: 0.1419 (0.1623) Data Time: 0.0105 (0.0298) Average Loss: 1.4716 (1.2377) Average CE Loss (Source):  1.4716 ( 1.2377) Learning Rate: 0.1000 (0.1000) Top1_base: 62.5000 (66.1953) Top1_base_per_class: 67.4383 (66.6252) 
Training Epoch: [28/1000] Step: [210 / 285] Batch Time: 0.1403 (0.1624) Data Time: 0.0099 (0.0300) Average Loss: 1.0396 (1.2387) Average CE Loss (Source):  1.0396 ( 1.2387) Learning Rate: 0.1000 (0.1000) Top1_base: 70.3125 (66.1793) Top1_base_per_class: 69.9057 (66.5980) 
Training Epoch: [28/1000] Step: [220 / 285] Batch Time: 0.1416 (0.1621) Data Time: 0.0104 (0.0297) Average Loss: 1.4155 (1.2387) Average CE Loss (Source):  1.4155 ( 1.2387) Learning Rate: 0.1000 (0.1000) Top1_base: 62.5000 (66.1754) Top1_base_per_class: 64.6541 (66.5862) 
Training Epoch: [28/1000] Step: [230 / 285] Batch Time: 0.1417 (0.1626) Data Time: 0.0096 (0.0303) Average Loss: 1.3993 (1.2409) Average CE Loss (Source):  1.3993 ( 1.2409) Learning Rate: 0.1000 (0.1000) Top1_base: 63.2812 (66.0496) Top1_base_per_class: 67.9310 (66.5001) 
Training Epoch: [28/1000] Step: [240 / 285] Batch Time: 0.1437 (0.1628) Data Time: 0.0121 (0.0304) Average Loss: 1.2722 (1.2426) Average CE Loss (Source):  1.2722 ( 1.2426) Learning Rate: 0.1000 (0.1000) Top1_base: 64.0625 (65.9668) Top1_base_per_class: 61.1905 (66.4143) 
Training Epoch: [28/1000] Step: [250 / 285] Batch Time: 0.1440 (0.1632) Data Time: 0.0133 (0.0308) Average Loss: 1.3321 (1.2423) Average CE Loss (Source):  1.3321 ( 1.2423) Learning Rate: 0.1000 (0.1000) Top1_base: 64.0625 (65.9594) Top1_base_per_class: 65.0000 (66.3964) 
Training Epoch: [28/1000] Step: [260 / 285] Batch Time: 0.1416 (0.1630) Data Time: 0.0106 (0.0307) Average Loss: 1.1214 (1.2403) Average CE Loss (Source):  1.1214 ( 1.2403) Learning Rate: 0.1000 (0.1000) Top1_base: 67.1875 (65.9495) Top1_base_per_class: 67.6603 (66.3842) 
Training Epoch: [28/1000] Step: [270 / 285] Batch Time: 0.1413 (0.1637) Data Time: 0.0100 (0.0313) Average Loss: 1.1831 (1.2396) Average CE Loss (Source):  1.1831 ( 1.2396) Learning Rate: 0.1000 (0.1000) Top1_base: 67.1875 (65.9317) Top1_base_per_class: 68.5606 (66.3243) 
Training Epoch: [28/1000] Step: [280 / 285] Batch Time: 0.1428 (0.1633) Data Time: 0.0102 (0.0309) Average Loss: 1.2534 (1.2396) Average CE Loss (Source):  1.2534 ( 1.2396) Learning Rate: 0.1000 (0.1000) Top1_base: 63.2812 (65.9570) Top1_base_per_class: 67.2424 (66.3443) 
Training Epoch: [29/1000] Step: [0] Batch Time: 0.1817 (0.1634) Data Time: 0.0496 (0.0310) Average Loss: 1.5268 (1.2409) Average CE Loss (Source):  1.5268 ( 1.2409) Learning Rate: 0.1000 (0.1000) Top1_base: 60.1562 (65.9265) Top1_base_per_class: 64.0741 (66.3548) 
Training Epoch: [29/1000] Step: [10 / 285] Batch Time: 0.1410 (0.2354) Data Time: 0.0099 (0.1035) Average Loss: 1.2702 (1.1822) Average CE Loss (Source):  1.2702 ( 1.1822) Learning Rate: 0.1000 (0.1000) Top1_base: 57.8125 (66.5625) Top1_base_per_class: 59.4828 (67.3846) 
Training Epoch: [29/1000] Step: [20 / 285] Batch Time: 0.1408 (0.1963) Data Time: 0.0102 (0.0653) Average Loss: 1.0485 (1.1947) Average CE Loss (Source):  1.0485 ( 1.1947) Learning Rate: 0.1000 (0.1000) Top1_base: 71.0938 (66.7969) Top1_base_per_class: 74.2816 (68.1385) 
Training Epoch: [29/1000] Step: [30 / 285] Batch Time: 0.1477 (0.1898) Data Time: 0.0121 (0.0582) Average Loss: 1.2152 (1.1852) Average CE Loss (Source):  1.2152 ( 1.1852) Learning Rate: 0.1000 (0.1000) Top1_base: 61.7188 (67.1875) Top1_base_per_class: 62.2577 (67.7934) 
Training Epoch: [29/1000] Step: [40 / 285] Batch Time: 0.1433 (0.1850) Data Time: 0.0107 (0.0532) Average Loss: 1.3039 (1.1867) Average CE Loss (Source):  1.3039 ( 1.1867) Learning Rate: 0.1000 (0.1000) Top1_base: 64.0625 (67.0898) Top1_base_per_class: 63.8050 (67.6846) 
Training Epoch: [29/1000] Step: [50 / 285] Batch Time: 0.1405 (0.1803) Data Time: 0.0091 (0.0486) Average Loss: 1.4269 (1.1828) Average CE Loss (Source):  1.4269 ( 1.1828) Learning Rate: 0.1000 (0.1000) Top1_base: 63.2812 (67.0469) Top1_base_per_class: 61.8155 (67.6499) 
Training Epoch: [29/1000] Step: [60 / 285] Batch Time: 0.1428 (0.1778) Data Time: 0.0111 (0.0460) Average Loss: 1.0324 (1.1884) Average CE Loss (Source):  1.0324 ( 1.1884) Learning Rate: 0.1000 (0.1000) Top1_base: 74.2188 (66.9531) Top1_base_per_class: 74.2560 (67.6029) 
Training Epoch: [29/1000] Step: [70 / 285] Batch Time: 0.1412 (0.1746) Data Time: 0.0094 (0.0428) Average Loss: 1.2928 (1.1864) Average CE Loss (Source):  1.2928 ( 1.1864) Learning Rate: 0.1000 (0.1000) Top1_base: 68.7500 (67.1763) Top1_base_per_class: 69.8246 (67.8217) 
Training Epoch: [29/1000] Step: [80 / 285] Batch Time: 0.1409 (0.1733) Data Time: 0.0103 (0.0415) Average Loss: 1.2646 (1.1870) Average CE Loss (Source):  1.2646 ( 1.1870) Learning Rate: 0.1000 (0.1000) Top1_base: 69.5312 (67.2461) Top1_base_per_class: 69.2949 (67.9457) 
Training Epoch: [29/1000] Step: [90 / 285] Batch Time: 0.1430 (0.1716) Data Time: 0.0103 (0.0397) Average Loss: 1.1059 (1.1930) Average CE Loss (Source):  1.1059 ( 1.1930) Learning Rate: 0.1000 (0.1000) Top1_base: 72.6562 (67.2222) Top1_base_per_class: 68.1537 (67.7212) 
Training Epoch: [29/1000] Step: [100 / 285] Batch Time: 0.1469 (0.1704) Data Time: 0.0131 (0.0384) Average Loss: 1.3488 (1.1954) Average CE Loss (Source):  1.3488 ( 1.1954) Learning Rate: 0.1000 (0.1000) Top1_base: 60.9375 (67.1797) Top1_base_per_class: 62.2002 (67.5865) 
Training Epoch: [29/1000] Step: [110 / 285] Batch Time: 0.1455 (0.1719) Data Time: 0.0105 (0.0396) Average Loss: 1.5681 (1.1995) Average CE Loss (Source):  1.5681 ( 1.1995) Learning Rate: 0.1000 (0.1000) Top1_base: 58.5938 (67.0739) Top1_base_per_class: 59.4737 (67.4172) 
Training Epoch: [29/1000] Step: [120 / 285] Batch Time: 0.1431 (0.1707) Data Time: 0.0104 (0.0384) Average Loss: 1.2895 (1.2060) Average CE Loss (Source):  1.2895 ( 1.2060) Learning Rate: 0.1000 (0.1000) Top1_base: 62.5000 (66.8099) Top1_base_per_class: 64.2121 (67.0223) 
Training Epoch: [29/1000] Step: [130 / 285] Batch Time: 0.1422 (0.1697) Data Time: 0.0097 (0.0373) Average Loss: 1.0285 (1.2077) Average CE Loss (Source):  1.0285 ( 1.2077) Learning Rate: 0.1000 (0.1000) Top1_base: 71.8750 (66.8690) Top1_base_per_class: 68.9548 (67.0951) 
Training Epoch: [29/1000] Step: [140 / 285] Batch Time: 0.1428 (0.1685) Data Time: 0.0124 (0.0362) Average Loss: 1.4066 (1.2124) Average CE Loss (Source):  1.4066 ( 1.2124) Learning Rate: 0.1000 (0.1000) Top1_base: 60.9375 (66.7243) Top1_base_per_class: 60.0943 (66.9640) 
Training Epoch: [29/1000] Step: [150 / 285] Batch Time: 0.1415 (0.1679) Data Time: 0.0108 (0.0357) Average Loss: 1.1233 (1.2130) Average CE Loss (Source):  1.1233 ( 1.2130) Learning Rate: 0.1000 (0.1000) Top1_base: 70.3125 (66.7240) Top1_base_per_class: 61.6352 (66.8201) 
Training Epoch: [29/1000] Step: [160 / 285] Batch Time: 0.1451 (0.1672) Data Time: 0.0129 (0.0351) Average Loss: 1.2419 (1.2131) Average CE Loss (Source):  1.2419 ( 1.2131) Learning Rate: 0.1000 (0.1000) Top1_base: 67.9688 (66.8066) Top1_base_per_class: 67.5961 (66.9329) 
Training Epoch: [29/1000] Step: [170 / 285] Batch Time: 0.1426 (0.1664) Data Time: 0.0123 (0.0343) Average Loss: 0.9592 (1.2114) Average CE Loss (Source):  0.9592 ( 1.2114) Learning Rate: 0.1000 (0.1000) Top1_base: 71.8750 (66.8244) Top1_base_per_class: 71.7262 (66.9830) 
Training Epoch: [29/1000] Step: [180 / 285] Batch Time: 0.1438 (0.1659) Data Time: 0.0117 (0.0339) Average Loss: 1.5081 (1.2098) Average CE Loss (Source):  1.5081 ( 1.2098) Learning Rate: 0.1000 (0.1000) Top1_base: 60.1562 (66.8967) Top1_base_per_class: 63.8262 (67.1413) 
Training Epoch: [29/1000] Step: [190 / 285] Batch Time: 0.1417 (0.1661) Data Time: 0.0108 (0.0340) Average Loss: 1.4171 (1.2118) Average CE Loss (Source):  1.4171 ( 1.2118) Learning Rate: 0.1000 (0.1000) Top1_base: 58.5938 (66.8627) Top1_base_per_class: 59.1346 (67.1972) 
Training Epoch: [29/1000] Step: [200 / 285] Batch Time: 0.1457 (0.1655) Data Time: 0.0140 (0.0335) Average Loss: 1.2661 (1.2131) Average CE Loss (Source):  1.2661 ( 1.2131) Learning Rate: 0.1000 (0.1000) Top1_base: 71.0938 (66.9727) Top1_base_per_class: 72.0915 (67.3166) 
Training Epoch: [29/1000] Step: [210 / 285] Batch Time: 0.1425 (0.1654) Data Time: 0.0107 (0.0334) Average Loss: 1.2548 (1.2120) Average CE Loss (Source):  1.2548 ( 1.2120) Learning Rate: 0.1000 (0.1000) Top1_base: 66.4062 (66.9903) Top1_base_per_class: 63.0357 (67.3360) 
Training Epoch: [29/1000] Step: [220 / 285] Batch Time: 0.1455 (0.1650) Data Time: 0.0122 (0.0330) Average Loss: 1.0127 (1.2112) Average CE Loss (Source):  1.0127 ( 1.2112) Learning Rate: 0.1000 (0.1000) Top1_base: 71.8750 (66.9780) Top1_base_per_class: 70.4269 (67.3139) 
Training Epoch: [29/1000] Step: [230 / 285] Batch Time: 0.1425 (0.1642) Data Time: 0.0102 (0.0322) Average Loss: 1.3204 (1.2069) Average CE Loss (Source):  1.3204 ( 1.2069) Learning Rate: 0.1000 (0.1000) Top1_base: 67.1875 (67.0856) Top1_base_per_class: 64.5029 (67.3465) 
Training Epoch: [29/1000] Step: [240 / 285] Batch Time: 0.1554 (0.1635) Data Time: 0.0216 (0.0315) Average Loss: 1.1665 (1.2080) Average CE Loss (Source):  1.1665 ( 1.2080) Learning Rate: 0.1000 (0.1000) Top1_base: 63.2812 (67.0540) Top1_base_per_class: 65.0376 (67.3545) 
Training Epoch: [29/1000] Step: [250 / 285] Batch Time: 0.1419 (0.1635) Data Time: 0.0103 (0.0315) Average Loss: 1.4102 (1.2111) Average CE Loss (Source):  1.4102 ( 1.2111) Learning Rate: 0.1000 (0.1000) Top1_base: 58.5938 (66.9625) Top1_base_per_class: 56.5497 (67.2876) 
Training Epoch: [29/1000] Step: [260 / 285] Batch Time: 0.1477 (0.1629) Data Time: 0.0156 (0.0308) Average Loss: 1.1792 (1.2123) Average CE Loss (Source):  1.1792 ( 1.2123) Learning Rate: 0.1000 (0.1000) Top1_base: 67.1875 (66.9321) Top1_base_per_class: 69.7321 (67.2795) 
Training Epoch: [29/1000] Step: [270 / 285] Batch Time: 0.1413 (0.1636) Data Time: 0.0103 (0.0316) Average Loss: 1.0622 (1.2124) Average CE Loss (Source):  1.0622 ( 1.2124) Learning Rate: 0.1000 (0.1000) Top1_base: 70.3125 (66.9213) Top1_base_per_class: 67.8814 (67.2282) 
Training Epoch: [29/1000] Step: [280 / 285] Batch Time: 0.1423 (0.1636) Data Time: 0.0111 (0.0316) Average Loss: 1.3227 (1.2113) Average CE Loss (Source):  1.3227 ( 1.2113) Learning Rate: 0.1000 (0.1000) Top1_base: 66.4062 (66.9699) Top1_base_per_class: 68.7556 (67.2874) 
Training Epoch: [30/1000] Step: [0] Batch Time: 0.1621 (0.1634) Data Time: 0.0317 (0.0314) Average Loss: 1.1865 (1.2103) Average CE Loss (Source):  1.1865 ( 1.2103) Learning Rate: 0.1000 (0.1000) Top1_base: 66.4062 (66.9572) Top1_base_per_class: 67.6235 (67.2898) 
  3%|▎         | 30/1000 [24:00<12:57:53, 48.12s/it]  3%|▎         | 31/1000 [24:48<12:54:46, 47.97s/it]Training Epoch: [30/1000] Step: [10 / 285] Batch Time: 0.2375 (0.2340) Data Time: 0.1069 (0.1031) Average Loss: 1.2885 (1.2114) Average CE Loss (Source):  1.2885 ( 1.2114) Learning Rate: 0.1000 (0.1000) Top1_base: 64.8438 (66.3281) Top1_base_per_class: 67.7763 (65.9596) 
Training Epoch: [30/1000] Step: [20 / 285] Batch Time: 0.1431 (0.1958) Data Time: 0.0107 (0.0649) Average Loss: 1.3206 (1.2196) Average CE Loss (Source):  1.3206 ( 1.2196) Learning Rate: 0.1000 (0.1000) Top1_base: 63.2812 (65.5859) Top1_base_per_class: 64.8148 (65.1212) 
Training Epoch: [30/1000] Step: [30 / 285] Batch Time: 0.1409 (0.1883) Data Time: 0.0091 (0.0571) Average Loss: 1.1578 (1.2091) Average CE Loss (Source):  1.1578 ( 1.2091) Learning Rate: 0.1000 (0.1000) Top1_base: 64.0625 (65.7292) Top1_base_per_class: 61.1905 (65.0114) 
Training Epoch: [30/1000] Step: [40 / 285] Batch Time: 0.1399 (0.1795) Data Time: 0.0098 (0.0482) Average Loss: 1.2628 (1.2001) Average CE Loss (Source):  1.2628 ( 1.2001) Learning Rate: 0.1000 (0.1000) Top1_base: 60.1562 (66.2109) Top1_base_per_class: 67.3077 (65.7317) 
Training Epoch: [30/1000] Step: [50 / 285] Batch Time: 0.1421 (0.1754) Data Time: 0.0095 (0.0440) Average Loss: 1.0553 (1.1862) Average CE Loss (Source):  1.0553 ( 1.1862) Learning Rate: 0.1000 (0.1000) Top1_base: 70.3125 (66.4375) Top1_base_per_class: 70.5172 (66.1780) 
Training Epoch: [30/1000] Step: [60 / 285] Batch Time: 0.1431 (0.1719) Data Time: 0.0107 (0.0405) Average Loss: 1.2913 (1.1823) Average CE Loss (Source):  1.2913 ( 1.1823) Learning Rate: 0.1000 (0.1000) Top1_base: 67.9688 (66.6797) Top1_base_per_class: 66.6384 (66.4686) 
Training Epoch: [30/1000] Step: [70 / 285] Batch Time: 0.1429 (0.1708) Data Time: 0.0107 (0.0393) Average Loss: 1.0682 (1.1952) Average CE Loss (Source):  1.0682 ( 1.1952) Learning Rate: 0.1000 (0.1000) Top1_base: 66.4062 (66.4062) Top1_base_per_class: 60.2333 (66.2995) 
Training Epoch: [30/1000] Step: [80 / 285] Batch Time: 0.1438 (0.1712) Data Time: 0.0121 (0.0397) Average Loss: 1.1490 (1.1961) Average CE Loss (Source):  1.1490 ( 1.1961) Learning Rate: 0.1000 (0.1000) Top1_base: 68.7500 (66.4453) Top1_base_per_class: 68.9943 (66.4514) 
Training Epoch: [30/1000] Step: [90 / 285] Batch Time: 0.1417 (0.1692) Data Time: 0.0096 (0.0378) Average Loss: 1.0852 (1.1955) Average CE Loss (Source):  1.0852 ( 1.1955) Learning Rate: 0.1000 (0.1000) Top1_base: 71.0938 (66.5365) Top1_base_per_class: 71.2281 (66.5960) 
Training Epoch: [30/1000] Step: [100 / 285] Batch Time: 0.1457 (0.1691) Data Time: 0.0123 (0.0376) Average Loss: 0.9646 (1.1921) Average CE Loss (Source):  0.9646 ( 1.1921) Learning Rate: 0.1000 (0.1000) Top1_base: 71.8750 (66.7344) Top1_base_per_class: 71.9006 (66.9015) 
Training Epoch: [30/1000] Step: [110 / 285] Batch Time: 0.1415 (0.1685) Data Time: 0.0100 (0.0370) Average Loss: 1.0948 (1.1904) Average CE Loss (Source):  1.0948 ( 1.1904) Learning Rate: 0.1000 (0.1000) Top1_base: 68.7500 (66.8395) Top1_base_per_class: 68.4848 (67.0181) 
Training Epoch: [30/1000] Step: [120 / 285] Batch Time: 0.1434 (0.1686) Data Time: 0.0110 (0.0371) Average Loss: 1.2792 (1.1957) Average CE Loss (Source):  1.2792 ( 1.1957) Learning Rate: 0.1000 (0.1000) Top1_base: 64.0625 (66.7578) Top1_base_per_class: 64.1228 (67.0484) 
Training Epoch: [30/1000] Step: [130 / 285] Batch Time: 0.1471 (0.1679) Data Time: 0.0135 (0.0362) Average Loss: 1.1541 (1.1924) Average CE Loss (Source):  1.1541 ( 1.1924) Learning Rate: 0.1000 (0.1000) Top1_base: 71.0938 (66.8870) Top1_base_per_class: 71.1111 (67.1356) 
Training Epoch: [30/1000] Step: [140 / 285] Batch Time: 0.1422 (0.1689) Data Time: 0.0110 (0.0372) Average Loss: 1.1410 (1.1962) Average CE Loss (Source):  1.1410 ( 1.1962) Learning Rate: 0.1000 (0.1000) Top1_base: 71.0938 (66.6797) Top1_base_per_class: 71.7544 (67.0257) 
Training Epoch: [30/1000] Step: [150 / 285] Batch Time: 0.1436 (0.1681) Data Time: 0.0107 (0.0365) Average Loss: 1.2804 (1.1949) Average CE Loss (Source):  1.2804 ( 1.1949) Learning Rate: 0.1000 (0.1000) Top1_base: 66.4062 (66.7917) Top1_base_per_class: 68.9286 (67.2317) 
Training Epoch: [30/1000] Step: [160 / 285] Batch Time: 0.1435 (0.1689) Data Time: 0.0114 (0.0372) Average Loss: 1.3018 (1.1977) Average CE Loss (Source):  1.3018 ( 1.1977) Learning Rate: 0.1000 (0.1000) Top1_base: 63.2812 (66.7578) Top1_base_per_class: 68.0556 (67.2024) 
Training Epoch: [30/1000] Step: [170 / 285] Batch Time: 0.1419 (0.1684) Data Time: 0.0112 (0.0367) Average Loss: 1.3084 (1.2010) Average CE Loss (Source):  1.3084 ( 1.2010) Learning Rate: 0.1000 (0.1000) Top1_base: 65.6250 (66.6820) Top1_base_per_class: 65.1258 (67.1653) 
Training Epoch: [30/1000] Step: [180 / 285] Batch Time: 0.1445 (0.1683) Data Time: 0.0129 (0.0366) Average Loss: 1.2787 (1.2027) Average CE Loss (Source):  1.2787 ( 1.2027) Learning Rate: 0.1000 (0.1000) Top1_base: 71.0938 (66.7491) Top1_base_per_class: 66.4912 (67.1651) 
Training Epoch: [30/1000] Step: [190 / 285] Batch Time: 0.1420 (0.1680) Data Time: 0.0100 (0.0364) Average Loss: 0.9069 (1.2015) Average CE Loss (Source):  0.9069 ( 1.2015) Learning Rate: 0.1000 (0.1000) Top1_base: 75.0000 (66.7804) Top1_base_per_class: 77.9762 (67.2225) 
Training Epoch: [30/1000] Step: [200 / 285] Batch Time: 0.1423 (0.1675) Data Time: 0.0117 (0.0359) Average Loss: 1.2948 (1.2011) Average CE Loss (Source):  1.2948 ( 1.2011) Learning Rate: 0.1000 (0.1000) Top1_base: 61.7188 (66.7852) Top1_base_per_class: 62.6505 (67.1979) 
Training Epoch: [30/1000] Step: [210 / 285] Batch Time: 0.1431 (0.1675) Data Time: 0.0109 (0.0358) Average Loss: 1.1850 (1.1997) Average CE Loss (Source):  1.1850 ( 1.1997) Learning Rate: 0.1000 (0.1000) Top1_base: 68.7500 (66.8155) Top1_base_per_class: 67.7273 (67.1962) 
Training Epoch: [30/1000] Step: [220 / 285] Batch Time: 0.1451 (0.1673) Data Time: 0.0115 (0.0356) Average Loss: 1.0979 (1.1996) Average CE Loss (Source):  1.0979 ( 1.1996) Learning Rate: 0.1000 (0.1000) Top1_base: 71.8750 (66.9354) Top1_base_per_class: 73.9181 (67.2856) 
Training Epoch: [30/1000] Step: [230 / 285] Batch Time: 0.1434 (0.1671) Data Time: 0.0111 (0.0354) Average Loss: 1.1183 (1.1981) Average CE Loss (Source):  1.1183 ( 1.1981) Learning Rate: 0.1000 (0.1000) Top1_base: 65.6250 (66.9599) Top1_base_per_class: 67.0468 (67.3818) 
Training Epoch: [30/1000] Step: [240 / 285] Batch Time: 0.1438 (0.1675) Data Time: 0.0125 (0.0358) Average Loss: 1.0384 (1.2007) Average CE Loss (Source):  1.0384 ( 1.2007) Learning Rate: 0.1000 (0.1000) Top1_base: 71.8750 (66.9271) Top1_base_per_class: 73.3019 (67.3700) 
Training Epoch: [30/1000] Step: [250 / 285] Batch Time: 0.1437 (0.1672) Data Time: 0.0113 (0.0355) Average Loss: 1.2900 (1.2052) Average CE Loss (Source):  1.2900 ( 1.2052) Learning Rate: 0.1000 (0.1000) Top1_base: 70.3125 (66.8438) Top1_base_per_class: 67.9023 (67.3334) 
Training Epoch: [30/1000] Step: [260 / 285] Batch Time: 0.1429 (0.1671) Data Time: 0.0107 (0.0354) Average Loss: 1.2469 (1.2061) Average CE Loss (Source):  1.2469 ( 1.2061) Learning Rate: 0.1000 (0.1000) Top1_base: 64.8438 (66.8119) Top1_base_per_class: 68.8596 (67.2715) 
Training Epoch: [30/1000] Step: [270 / 285] Batch Time: 0.1438 (0.1671) Data Time: 0.0118 (0.0353) Average Loss: 1.0714 (1.2043) Average CE Loss (Source):  1.0714 ( 1.2043) Learning Rate: 0.1000 (0.1000) Top1_base: 68.7500 (66.8605) Top1_base_per_class: 63.3459 (67.2638) 
Training Epoch: [30/1000] Step: [280 / 285] Batch Time: 0.1431 (0.1672) Data Time: 0.0112 (0.0355) Average Loss: 1.3661 (1.2039) Average CE Loss (Source):  1.3661 ( 1.2039) Learning Rate: 0.1000 (0.1000) Top1_base: 65.6250 (66.9085) Top1_base_per_class: 61.5517 (67.2887) 
Training Epoch: [31/1000] Step: [0] Batch Time: 0.1373 (0.1669) Data Time: 0.0090 (0.0352) Average Loss: 1.2189 (1.2038) Average CE Loss (Source):  1.2189 ( 1.2038) Learning Rate: 0.1000 (0.1000) Top1_base: 65.6250 (66.9161) Top1_base_per_class: 68.3951 (67.3004) 
Training Epoch: [31/1000] Step: [10 / 285] Batch Time: 0.1434 (0.2331) Data Time: 0.0120 (0.1014) Average Loss: 1.0136 (1.1472) Average CE Loss (Source):  1.0136 ( 1.1472) Learning Rate: 0.1000 (0.1000) Top1_base: 72.6562 (67.5781) Top1_base_per_class: 71.3290 (68.5450) 
Training Epoch: [31/1000] Step: [20 / 285] Batch Time: 0.1476 (0.1992) Data Time: 0.0144 (0.0672) Average Loss: 1.0157 (1.1525) Average CE Loss (Source):  1.0157 ( 1.1525) Learning Rate: 0.1000 (0.1000) Top1_base: 74.2188 (67.7734) Top1_base_per_class: 72.5108 (68.9302) 
Training Epoch: [31/1000] Step: [30 / 285] Batch Time: 0.1457 (0.1857) Data Time: 0.0130 (0.0536) Average Loss: 1.1548 (1.1291) Average CE Loss (Source):  1.1548 ( 1.1291) Learning Rate: 0.1000 (0.1000) Top1_base: 62.5000 (68.1510) Top1_base_per_class: 64.4048 (69.2084) 
Training Epoch: [31/1000] Step: [40 / 285] Batch Time: 0.1447 (0.1761) Data Time: 0.0105 (0.0436) Average Loss: 0.9121 (1.1319) Average CE Loss (Source):  0.9121 ( 1.1319) Learning Rate: 0.1000 (0.1000) Top1_base: 74.2188 (68.2031) Top1_base_per_class: 79.9394 (69.3498) 
Training Epoch: [31/1000] Step: [50 / 285] Batch Time: 0.1526 (0.1748) Data Time: 0.0176 (0.0420) Average Loss: 1.1330 (1.1394) Average CE Loss (Source):  1.1330 ( 1.1394) Learning Rate: 0.1000 (0.1000) Top1_base: 69.5312 (67.8438) Top1_base_per_class: 70.3107 (68.9482) 
Training Epoch: [31/1000] Step: [60 / 285] Batch Time: 0.1446 (0.1722) Data Time: 0.0099 (0.0392) Average Loss: 1.1752 (1.1479) Average CE Loss (Source):  1.1752 ( 1.1479) Learning Rate: 0.1000 (0.1000) Top1_base: 67.1875 (67.8125) Top1_base_per_class: 69.6784 (68.9157) 
Training Epoch: [31/1000] Step: [70 / 285] Batch Time: 0.1938 (0.1703) Data Time: 0.0592 (0.0372) Average Loss: 1.1475 (1.1553) Average CE Loss (Source):  1.1475 ( 1.1553) Learning Rate: 0.1000 (0.1000) Top1_base: 67.9688 (67.7232) Top1_base_per_class: 69.0643 (68.6119) 
Training Epoch: [31/1000] Step: [80 / 285] Batch Time: 0.1450 (0.1685) Data Time: 0.0112 (0.0352) Average Loss: 1.1342 (1.1556) Average CE Loss (Source):  1.1342 ( 1.1556) Learning Rate: 0.1000 (0.1000) Top1_base: 67.9688 (67.6562) Top1_base_per_class: 73.1212 (68.5467) 
Training Epoch: [31/1000] Step: [90 / 285] Batch Time: 0.2176 (0.1697) Data Time: 0.0857 (0.0366) Average Loss: 1.4076 (1.1674) Average CE Loss (Source):  1.4076 ( 1.1674) Learning Rate: 0.1000 (0.1000) Top1_base: 56.2500 (67.3003) Top1_base_per_class: 58.3046 (68.1716) 
Training Epoch: [31/1000] Step: [100 / 285] Batch Time: 0.1446 (0.1689) Data Time: 0.0120 (0.0358) Average Loss: 1.0475 (1.1675) Average CE Loss (Source):  1.0475 ( 1.1675) Learning Rate: 0.1000 (0.1000) Top1_base: 68.7500 (67.1641) Top1_base_per_class: 71.9643 (68.0292) 
Training Epoch: [31/1000] Step: [110 / 285] Batch Time: 0.1698 (0.1679) Data Time: 0.0381 (0.0348) Average Loss: 1.2004 (1.1648) Average CE Loss (Source):  1.2004 ( 1.1648) Learning Rate: 0.1000 (0.1000) Top1_base: 67.1875 (67.2869) Top1_base_per_class: 67.2619 (68.1363) 
Training Epoch: [31/1000] Step: [120 / 285] Batch Time: 0.1440 (0.1661) Data Time: 0.0103 (0.0331) Average Loss: 1.2867 (1.1686) Average CE Loss (Source):  1.2867 ( 1.1686) Learning Rate: 0.1000 (0.1000) Top1_base: 67.9688 (67.3112) Top1_base_per_class: 67.3563 (68.0366) 
Training Epoch: [31/1000] Step: [130 / 285] Batch Time: 0.1478 (0.1651) Data Time: 0.0144 (0.0321) Average Loss: 1.1104 (1.1684) Average CE Loss (Source):  1.1104 ( 1.1684) Learning Rate: 0.1000 (0.1000) Top1_base: 64.0625 (67.2716) Top1_base_per_class: 61.0502 (68.0502) 
Training Epoch: [31/1000] Step: [140 / 285] Batch Time: 0.1441 (0.1639) Data Time: 0.0113 (0.0309) Average Loss: 1.2774 (1.1700) Average CE Loss (Source):  1.2774 ( 1.1700) Learning Rate: 0.1000 (0.1000) Top1_base: 67.1875 (67.2712) Top1_base_per_class: 66.6092 (68.0989) 
Training Epoch: [31/1000] Step: [150 / 285] Batch Time: 0.1942 (0.1634) Data Time: 0.0612 (0.0304) Average Loss: 1.2543 (1.1704) Average CE Loss (Source):  1.2543 ( 1.1704) Learning Rate: 0.1000 (0.1000) Top1_base: 69.5312 (67.4323) Top1_base_per_class: 66.5789 (68.2746) 
Training Epoch: [31/1000] Step: [160 / 285] Batch Time: 0.1475 (0.1626) Data Time: 0.0132 (0.0297) Average Loss: 1.0318 (1.1693) Average CE Loss (Source):  1.0318 ( 1.1693) Learning Rate: 0.1000 (0.1000) Top1_base: 71.8750 (67.5391) Top1_base_per_class: 73.8180 (68.3229) 
Training Epoch: [31/1000] Step: [170 / 285] Batch Time: 0.2083 (0.1625) Data Time: 0.0764 (0.0296) Average Loss: 1.3030 (1.1713) Average CE Loss (Source):  1.3030 ( 1.1713) Learning Rate: 0.1000 (0.1000) Top1_base: 67.1875 (67.5873) Top1_base_per_class: 72.2989 (68.3496) 
Training Epoch: [31/1000] Step: [180 / 285] Batch Time: 0.1435 (0.1622) Data Time: 0.0104 (0.0293) Average Loss: 1.0262 (1.1682) Average CE Loss (Source):  1.0262 ( 1.1682) Learning Rate: 0.1000 (0.1000) Top1_base: 69.5312 (67.6693) Top1_base_per_class: 74.1667 (68.4301) 
Training Epoch: [31/1000] Step: [190 / 285] Batch Time: 0.3071 (0.1623) Data Time: 0.1756 (0.0295) Average Loss: 1.0707 (1.1648) Average CE Loss (Source):  1.0707 ( 1.1648) Learning Rate: 0.1000 (0.1000) Top1_base: 71.0938 (67.7590) Top1_base_per_class: 72.8437 (68.5283) 
Training Epoch: [31/1000] Step: [200 / 285] Batch Time: 0.1430 (0.1617) Data Time: 0.0106 (0.0289) Average Loss: 1.4684 (1.1690) Average CE Loss (Source):  1.4684 ( 1.1690) Learning Rate: 0.1000 (0.1000) Top1_base: 62.5000 (67.6289) Top1_base_per_class: 59.3939 (68.3313) 
Training Epoch: [31/1000] Step: [210 / 285] Batch Time: 0.2205 (0.1620) Data Time: 0.0874 (0.0293) Average Loss: 0.9912 (1.1711) Average CE Loss (Source):  0.9912 ( 1.1711) Learning Rate: 0.1000 (0.1000) Top1_base: 69.5312 (67.5521) Top1_base_per_class: 70.7964 (68.2214) 
Training Epoch: [31/1000] Step: [220 / 285] Batch Time: 0.1407 (0.1616) Data Time: 0.0097 (0.0289) Average Loss: 1.4003 (1.1730) Average CE Loss (Source):  1.4003 ( 1.1730) Learning Rate: 0.1000 (0.1000) Top1_base: 63.2812 (67.5781) Top1_base_per_class: 63.5494 (68.2378) 
Training Epoch: [31/1000] Step: [230 / 285] Batch Time: 0.1458 (0.1612) Data Time: 0.0148 (0.0286) Average Loss: 1.0800 (1.1713) Average CE Loss (Source):  1.0800 ( 1.1713) Learning Rate: 0.1000 (0.1000) Top1_base: 68.7500 (67.5985) Top1_base_per_class: 69.3906 (68.1975) 
Training Epoch: [31/1000] Step: [240 / 285] Batch Time: 0.1428 (0.1611) Data Time: 0.0104 (0.0285) Average Loss: 1.1960 (1.1714) Average CE Loss (Source):  1.1960 ( 1.1714) Learning Rate: 0.1000 (0.1000) Top1_base: 63.2812 (67.5716) Top1_base_per_class: 63.1548 (68.1230) 
Training Epoch: [31/1000] Step: [250 / 285] Batch Time: 0.2639 (0.1615) Data Time: 0.1326 (0.0289) Average Loss: 1.0689 (1.1714) Average CE Loss (Source):  1.0689 ( 1.1714) Learning Rate: 0.1000 (0.1000) Top1_base: 68.7500 (67.5781) Top1_base_per_class: 68.3621 (68.0905) 
Training Epoch: [31/1000] Step: [260 / 285] Batch Time: 0.1471 (0.1612) Data Time: 0.0124 (0.0286) Average Loss: 1.1414 (1.1710) Average CE Loss (Source):  1.1414 ( 1.1710) Learning Rate: 0.1000 (0.1000) Top1_base: 67.9688 (67.5931) Top1_base_per_class: 68.4821 (68.0495) 
Training Epoch: [31/1000] Step: [270 / 285] Batch Time: 0.1684 (0.1610) Data Time: 0.0336 (0.0283) Average Loss: 1.4774 (1.1754) Average CE Loss (Source):  1.4774 ( 1.1754) Learning Rate: 0.1000 (0.1000) Top1_base: 63.2812 (67.4797) Top1_base_per_class: 67.9245 (67.9846) 
Training Epoch: [31/1000] Step: [280 / 285] Batch Time: 0.1420 (0.1605) Data Time: 0.0099 (0.0278) Average Loss: 1.1260 (1.1782) Average CE Loss (Source):  1.1260 ( 1.1782) Learning Rate: 0.1000 (0.1000) Top1_base: 64.8438 (67.3354) Top1_base_per_class: 63.0357 (67.9014) 
Training Epoch: [32/1000] Step: [0] Batch Time: 0.1402 (0.1603) Data Time: 0.0092 (0.0276) Average Loss: 1.0350 (1.1792) Average CE Loss (Source):  1.0350 ( 1.1792) Learning Rate: 0.1000 (0.1000) Top1_base: 73.4375 (67.3383) Top1_base_per_class: 76.7544 (67.9421) 
  3%|▎         | 32/1000 [25:37<12:56:42, 48.14s/it]  3%|▎         | 33/1000 [26:24<12:51:58, 47.90s/it]Training Epoch: [32/1000] Step: [10 / 285] Batch Time: 0.1387 (0.2392) Data Time: 0.0090 (0.1085) Average Loss: 1.0559 (1.1155) Average CE Loss (Source):  1.0559 ( 1.1155) Learning Rate: 0.1000 (0.1000) Top1_base: 72.6562 (68.8281) Top1_base_per_class: 70.6215 (68.6159) 
Training Epoch: [32/1000] Step: [20 / 285] Batch Time: 0.1419 (0.1990) Data Time: 0.0108 (0.0685) Average Loss: 1.0652 (1.1126) Average CE Loss (Source):  1.0652 ( 1.1126) Learning Rate: 0.1000 (0.1000) Top1_base: 66.4062 (69.0625) Top1_base_per_class: 68.6364 (69.1946) 
Training Epoch: [32/1000] Step: [30 / 285] Batch Time: 0.1442 (0.1952) Data Time: 0.0104 (0.0639) Average Loss: 1.1372 (1.1344) Average CE Loss (Source):  1.1372 ( 1.1344) Learning Rate: 0.1000 (0.1000) Top1_base: 70.3125 (68.2552) Top1_base_per_class: 71.0484 (68.7123) 
Training Epoch: [32/1000] Step: [40 / 285] Batch Time: 0.1459 (0.1864) Data Time: 0.0122 (0.0546) Average Loss: 0.9797 (1.1278) Average CE Loss (Source):  0.9797 ( 1.1278) Learning Rate: 0.1000 (0.1000) Top1_base: 71.0938 (68.2812) Top1_base_per_class: 71.2264 (68.6320) 
Training Epoch: [32/1000] Step: [50 / 285] Batch Time: 0.1439 (0.1810) Data Time: 0.0103 (0.0490) Average Loss: 1.0788 (1.1406) Average CE Loss (Source):  1.0788 ( 1.1406) Learning Rate: 0.1000 (0.1000) Top1_base: 69.5312 (67.7812) Top1_base_per_class: 70.0606 (67.9350) 
Training Epoch: [32/1000] Step: [60 / 285] Batch Time: 0.1441 (0.1781) Data Time: 0.0112 (0.0460) Average Loss: 1.0404 (1.1270) Average CE Loss (Source):  1.0404 ( 1.1270) Learning Rate: 0.1000 (0.1000) Top1_base: 70.3125 (68.2422) Top1_base_per_class: 71.1309 (68.4549) 
Training Epoch: [32/1000] Step: [70 / 285] Batch Time: 0.1419 (0.1753) Data Time: 0.0096 (0.0431) Average Loss: 0.9492 (1.1383) Average CE Loss (Source):  0.9492 ( 1.1383) Learning Rate: 0.1000 (0.1000) Top1_base: 67.9688 (67.7344) Top1_base_per_class: 68.2768 (68.1819) 
Training Epoch: [32/1000] Step: [80 / 285] Batch Time: 0.1457 (0.1721) Data Time: 0.0111 (0.0398) Average Loss: 0.9755 (1.1294) Average CE Loss (Source):  0.9755 ( 1.1294) Learning Rate: 0.1000 (0.1000) Top1_base: 70.3125 (67.9883) Top1_base_per_class: 71.4156 (68.4383) 
Training Epoch: [32/1000] Step: [90 / 285] Batch Time: 0.1463 (0.1711) Data Time: 0.0115 (0.0385) Average Loss: 0.9945 (1.1290) Average CE Loss (Source):  0.9945 ( 1.1290) Learning Rate: 0.1000 (0.1000) Top1_base: 71.0938 (68.0382) Top1_base_per_class: 73.5454 (68.5132) 
Training Epoch: [32/1000] Step: [100 / 285] Batch Time: 0.1455 (0.1691) Data Time: 0.0111 (0.0363) Average Loss: 1.1194 (1.1310) Average CE Loss (Source):  1.1194 ( 1.1310) Learning Rate: 0.1000 (0.1000) Top1_base: 71.8750 (68.1172) Top1_base_per_class: 71.3277 (68.6748) 
Training Epoch: [32/1000] Step: [110 / 285] Batch Time: 0.1450 (0.1680) Data Time: 0.0107 (0.0350) Average Loss: 1.0619 (1.1382) Average CE Loss (Source):  1.0619 ( 1.1382) Learning Rate: 0.1000 (0.1000) Top1_base: 71.0938 (68.0043) Top1_base_per_class: 70.6845 (68.5487) 
Training Epoch: [32/1000] Step: [120 / 285] Batch Time: 0.1469 (0.1668) Data Time: 0.0109 (0.0338) Average Loss: 1.0273 (1.1351) Average CE Loss (Source):  1.0273 ( 1.1351) Learning Rate: 0.1000 (0.1000) Top1_base: 72.6562 (68.1641) Top1_base_per_class: 75.4321 (68.7044) 
Training Epoch: [32/1000] Step: [130 / 285] Batch Time: 0.1469 (0.1671) Data Time: 0.0119 (0.0339) Average Loss: 1.1355 (1.1335) Average CE Loss (Source):  1.1355 ( 1.1335) Learning Rate: 0.1000 (0.1000) Top1_base: 65.6250 (68.2392) Top1_base_per_class: 66.7627 (68.7584) 
Training Epoch: [32/1000] Step: [140 / 285] Batch Time: 0.1454 (0.1673) Data Time: 0.0110 (0.0340) Average Loss: 0.8019 (1.1337) Average CE Loss (Source):  0.8019 ( 1.1337) Learning Rate: 0.1000 (0.1000) Top1_base: 78.9062 (68.2366) Top1_base_per_class: 77.2554 (68.7371) 
Training Epoch: [32/1000] Step: [150 / 285] Batch Time: 0.1454 (0.1669) Data Time: 0.0110 (0.0336) Average Loss: 1.1678 (1.1360) Average CE Loss (Source):  1.1678 ( 1.1360) Learning Rate: 0.1000 (0.1000) Top1_base: 69.5312 (68.1771) Top1_base_per_class: 75.9615 (68.7078) 
Training Epoch: [32/1000] Step: [160 / 285] Batch Time: 0.1452 (0.1675) Data Time: 0.0100 (0.0340) Average Loss: 1.2788 (1.1412) Average CE Loss (Source):  1.2788 ( 1.1412) Learning Rate: 0.1000 (0.1000) Top1_base: 61.7188 (68.0615) Top1_base_per_class: 61.4881 (68.5525) 
Training Epoch: [32/1000] Step: [170 / 285] Batch Time: 0.1436 (0.1673) Data Time: 0.0110 (0.0338) Average Loss: 1.1451 (1.1414) Average CE Loss (Source):  1.1451 ( 1.1414) Learning Rate: 0.1000 (0.1000) Top1_base: 68.7500 (68.0974) Top1_base_per_class: 72.1726 (68.6484) 
Training Epoch: [32/1000] Step: [180 / 285] Batch Time: 0.1489 (0.1667) Data Time: 0.0137 (0.0333) Average Loss: 1.2765 (1.1409) Average CE Loss (Source):  1.2765 ( 1.1409) Learning Rate: 0.1000 (0.1000) Top1_base: 59.3750 (68.0208) Top1_base_per_class: 57.6316 (68.5509) 
Training Epoch: [32/1000] Step: [190 / 285] Batch Time: 0.1437 (0.1660) Data Time: 0.0104 (0.0325) Average Loss: 1.2078 (1.1443) Average CE Loss (Source):  1.2078 ( 1.1443) Learning Rate: 0.1000 (0.1000) Top1_base: 74.2188 (68.0674) Top1_base_per_class: 72.7679 (68.6097) 
Training Epoch: [32/1000] Step: [200 / 285] Batch Time: 0.1494 (0.1656) Data Time: 0.0129 (0.0320) Average Loss: 1.1068 (1.1470) Average CE Loss (Source):  1.1068 ( 1.1470) Learning Rate: 0.1000 (0.1000) Top1_base: 64.8438 (68.0156) Top1_base_per_class: 69.6726 (68.6254) 
Training Epoch: [32/1000] Step: [210 / 285] Batch Time: 0.1545 (0.1654) Data Time: 0.0189 (0.0317) Average Loss: 1.0726 (1.1495) Average CE Loss (Source):  1.0726 ( 1.1495) Learning Rate: 0.1000 (0.1000) Top1_base: 64.0625 (68.0134) Top1_base_per_class: 64.4253 (68.6710) 
Training Epoch: [32/1000] Step: [220 / 285] Batch Time: 0.1555 (0.1657) Data Time: 0.0195 (0.0318) Average Loss: 1.1721 (1.1530) Average CE Loss (Source):  1.1721 ( 1.1530) Learning Rate: 0.1000 (0.1000) Top1_base: 65.6250 (67.8729) Top1_base_per_class: 65.6035 (68.5279) 
Training Epoch: [32/1000] Step: [230 / 285] Batch Time: 0.1582 (0.1654) Data Time: 0.0254 (0.0314) Average Loss: 1.2331 (1.1545) Average CE Loss (Source):  1.2331 ( 1.1545) Learning Rate: 0.1000 (0.1000) Top1_base: 67.1875 (67.8804) Top1_base_per_class: 66.1012 (68.5747) 
Training Epoch: [32/1000] Step: [240 / 285] Batch Time: 0.1660 (0.1654) Data Time: 0.0298 (0.0314) Average Loss: 1.0898 (1.1589) Average CE Loss (Source):  1.0898 ( 1.1589) Learning Rate: 0.1000 (0.1000) Top1_base: 70.3125 (67.7604) Top1_base_per_class: 72.8788 (68.4287) 
Training Epoch: [32/1000] Step: [250 / 285] Batch Time: 0.1645 (0.1657) Data Time: 0.0289 (0.0316) Average Loss: 1.2551 (1.1615) Average CE Loss (Source):  1.2551 ( 1.1615) Learning Rate: 0.1000 (0.1000) Top1_base: 65.6250 (67.7000) Top1_base_per_class: 64.5115 (68.4103) 
Training Epoch: [32/1000] Step: [260 / 285] Batch Time: 0.1775 (0.1659) Data Time: 0.0431 (0.0318) Average Loss: 1.3365 (1.1636) Average CE Loss (Source):  1.3365 ( 1.1636) Learning Rate: 0.1000 (0.1000) Top1_base: 59.3750 (67.6112) Top1_base_per_class: 58.6008 (68.3076) 
Training Epoch: [32/1000] Step: [270 / 285] Batch Time: 0.1528 (0.1659) Data Time: 0.0195 (0.0318) Average Loss: 1.0892 (1.1633) Average CE Loss (Source):  1.0892 ( 1.1633) Learning Rate: 0.1000 (0.1000) Top1_base: 67.9688 (67.6331) Top1_base_per_class: 70.3774 (68.3004) 
Training Epoch: [32/1000] Step: [280 / 285] Batch Time: 0.1780 (0.1660) Data Time: 0.0468 (0.0319) Average Loss: 1.2251 (1.1637) Average CE Loss (Source):  1.2251 ( 1.1637) Learning Rate: 0.1000 (0.1000) Top1_base: 63.2812 (67.6256) Top1_base_per_class: 62.1451 (68.2500) 
Training Epoch: [33/1000] Step: [0] Batch Time: 0.1457 (0.1658) Data Time: 0.0110 (0.0317) Average Loss: 1.2554 (1.1632) Average CE Loss (Source):  1.2554 ( 1.1632) Learning Rate: 0.1000 (0.1000) Top1_base: 58.5938 (67.6151) Top1_base_per_class: 56.8129 (68.2415) 
Training Epoch: [33/1000] Step: [10 / 285] Batch Time: 0.1467 (0.2304) Data Time: 0.0141 (0.0973) Average Loss: 1.1557 (1.0869) Average CE Loss (Source):  1.1557 ( 1.0869) Learning Rate: 0.1000 (0.1000) Top1_base: 69.5312 (70.2344) Top1_base_per_class: 68.5669 (69.9796) 
Training Epoch: [33/1000] Step: [20 / 285] Batch Time: 0.1506 (0.1971) Data Time: 0.0125 (0.0630) Average Loss: 1.2337 (1.0882) Average CE Loss (Source):  1.2337 ( 1.0882) Learning Rate: 0.1000 (0.1000) Top1_base: 64.0625 (69.8828) Top1_base_per_class: 67.1944 (69.0005) 
Training Epoch: [33/1000] Step: [30 / 285] Batch Time: 0.1457 (0.1854) Data Time: 0.0123 (0.0515) Average Loss: 1.1039 (1.0869) Average CE Loss (Source):  1.1039 ( 1.0869) Learning Rate: 0.1000 (0.1000) Top1_base: 68.7500 (70.0260) Top1_base_per_class: 67.7778 (69.7737) 
Training Epoch: [33/1000] Step: [40 / 285] Batch Time: 0.1492 (0.1776) Data Time: 0.0108 (0.0435) Average Loss: 1.0279 (1.0949) Average CE Loss (Source):  1.0279 ( 1.0949) Learning Rate: 0.1000 (0.1000) Top1_base: 73.4375 (69.9023) Top1_base_per_class: 77.9023 (69.8113) 
Training Epoch: [33/1000] Step: [50 / 285] Batch Time: 0.1505 (0.1734) Data Time: 0.0139 (0.0392) Average Loss: 0.9066 (1.0866) Average CE Loss (Source):  0.9066 ( 1.0866) Learning Rate: 0.1000 (0.1000) Top1_base: 75.7812 (70.1875) Top1_base_per_class: 76.3842 (70.3669) 
Training Epoch: [33/1000] Step: [60 / 285] Batch Time: 0.1471 (0.1723) Data Time: 0.0129 (0.0377) Average Loss: 1.5124 (1.0970) Average CE Loss (Source):  1.5124 ( 1.0970) Learning Rate: 0.1000 (0.1000) Top1_base: 60.1562 (69.8307) Top1_base_per_class: 63.1548 (69.9763) 
Training Epoch: [33/1000] Step: [70 / 285] Batch Time: 0.1464 (0.1705) Data Time: 0.0114 (0.0359) Average Loss: 1.3160 (1.1071) Average CE Loss (Source):  1.3160 ( 1.1071) Learning Rate: 0.1000 (0.1000) Top1_base: 62.5000 (69.3638) Top1_base_per_class: 61.6975 (69.4223) 
Training Epoch: [33/1000] Step: [80 / 285] Batch Time: 0.1551 (0.1683) Data Time: 0.0150 (0.0338) Average Loss: 1.2000 (1.1156) Average CE Loss (Source):  1.2000 ( 1.1156) Learning Rate: 0.1000 (0.1000) Top1_base: 64.8438 (69.0820) Top1_base_per_class: 63.9128 (69.0839) 
Training Epoch: [33/1000] Step: [90 / 285] Batch Time: 0.1456 (0.1667) Data Time: 0.0121 (0.0319) Average Loss: 1.0761 (1.1189) Average CE Loss (Source):  1.0761 ( 1.1189) Learning Rate: 0.1000 (0.1000) Top1_base: 68.7500 (68.9844) Top1_base_per_class: 71.3218 (69.1612) 
Training Epoch: [33/1000] Step: [100 / 285] Batch Time: 0.1498 (0.1656) Data Time: 0.0119 (0.0307) Average Loss: 1.0089 (1.1207) Average CE Loss (Source):  1.0089 ( 1.1207) Learning Rate: 0.1000 (0.1000) Top1_base: 71.0938 (69.0938) Top1_base_per_class: 70.4094 (69.3691) 
Training Epoch: [33/1000] Step: [110 / 285] Batch Time: 0.1480 (0.1649) Data Time: 0.0138 (0.0299) Average Loss: 1.0477 (1.1257) Average CE Loss (Source):  1.0477 ( 1.1257) Learning Rate: 0.1000 (0.1000) Top1_base: 64.8438 (69.0057) Top1_base_per_class: 65.3333 (69.2082) 
Training Epoch: [33/1000] Step: [120 / 285] Batch Time: 0.1536 (0.1641) Data Time: 0.0123 (0.0290) Average Loss: 0.9958 (1.1265) Average CE Loss (Source):  0.9958 ( 1.1265) Learning Rate: 0.1000 (0.1000) Top1_base: 73.4375 (68.9062) Top1_base_per_class: 76.1207 (69.1956) 
Training Epoch: [33/1000] Step: [130 / 285] Batch Time: 0.1498 (0.1646) Data Time: 0.0133 (0.0295) Average Loss: 1.3685 (1.1346) Average CE Loss (Source):  1.3685 ( 1.1346) Learning Rate: 0.1000 (0.1000) Top1_base: 67.9688 (68.7560) Top1_base_per_class: 70.2469 (69.1148) 
Training Epoch: [33/1000] Step: [140 / 285] Batch Time: 0.1447 (0.1637) Data Time: 0.0140 (0.0286) Average Loss: 1.1200 (1.1315) Average CE Loss (Source):  1.1200 ( 1.1315) Learning Rate: 0.1000 (0.1000) Top1_base: 72.6562 (68.8560) Top1_base_per_class: 73.6970 (69.2407) 
Training Epoch: [33/1000] Step: [150 / 285] Batch Time: 0.1440 (0.1628) Data Time: 0.0113 (0.0277) Average Loss: 0.7656 (1.1320) Average CE Loss (Source):  0.7656 ( 1.1320) Learning Rate: 0.1000 (0.1000) Top1_base: 79.6875 (68.8958) Top1_base_per_class: 79.9138 (69.2719) 
Training Epoch: [33/1000] Step: [160 / 285] Batch Time: 0.1489 (0.1621) Data Time: 0.0139 (0.0271) Average Loss: 1.2054 (1.1294) Average CE Loss (Source):  1.2054 ( 1.1294) Learning Rate: 0.1000 (0.1000) Top1_base: 65.6250 (68.9941) Top1_base_per_class: 67.9167 (69.3277) 
Training Epoch: [33/1000] Step: [170 / 285] Batch Time: 0.1466 (0.1625) Data Time: 0.0110 (0.0274) Average Loss: 1.2298 (1.1373) Average CE Loss (Source):  1.2298 ( 1.1373) Learning Rate: 0.1000 (0.1000) Top1_base: 67.1875 (68.8787) Top1_base_per_class: 67.7160 (69.3050) 
Training Epoch: [33/1000] Step: [180 / 285] Batch Time: 0.1514 (0.1620) Data Time: 0.0163 (0.0269) Average Loss: 1.1896 (1.1387) Average CE Loss (Source):  1.1896 ( 1.1387) Learning Rate: 0.1000 (0.1000) Top1_base: 67.9688 (68.7934) Top1_base_per_class: 67.7469 (69.1679) 
Training Epoch: [33/1000] Step: [190 / 285] Batch Time: 0.1495 (0.1616) Data Time: 0.0139 (0.0265) Average Loss: 1.1581 (1.1377) Average CE Loss (Source):  1.1581 ( 1.1377) Learning Rate: 0.1000 (0.1000) Top1_base: 67.1875 (68.8281) Top1_base_per_class: 64.5556 (69.2022) 
Training Epoch: [33/1000] Step: [200 / 285] Batch Time: 0.1553 (0.1616) Data Time: 0.0174 (0.0265) Average Loss: 1.2238 (1.1382) Average CE Loss (Source):  1.2238 ( 1.1382) Learning Rate: 0.1000 (0.1000) Top1_base: 69.5312 (68.7461) Top1_base_per_class: 66.3522 (69.1093) 
Training Epoch: [33/1000] Step: [210 / 285] Batch Time: 0.1476 (0.1611) Data Time: 0.0127 (0.0259) Average Loss: 0.9858 (1.1418) Average CE Loss (Source):  0.9858 ( 1.1418) Learning Rate: 0.1000 (0.1000) Top1_base: 70.3125 (68.6458) Top1_base_per_class: 73.8424 (69.0415) 
Training Epoch: [33/1000] Step: [220 / 285] Batch Time: 0.1464 (0.1607) Data Time: 0.0157 (0.0254) Average Loss: 1.2531 (1.1455) Average CE Loss (Source):  1.2531 ( 1.1455) Learning Rate: 0.1000 (0.1000) Top1_base: 64.0625 (68.5618) Top1_base_per_class: 67.0468 (68.9921) 
Training Epoch: [33/1000] Step: [230 / 285] Batch Time: 0.1486 (0.1602) Data Time: 0.0131 (0.0249) Average Loss: 1.2566 (1.1492) Average CE Loss (Source):  1.2566 ( 1.1492) Learning Rate: 0.1000 (0.1000) Top1_base: 65.6250 (68.4069) Top1_base_per_class: 70.1796 (68.8108) 
Training Epoch: [33/1000] Step: [240 / 285] Batch Time: 0.1436 (0.1597) Data Time: 0.0132 (0.0245) Average Loss: 1.2388 (1.1519) Average CE Loss (Source):  1.2388 ( 1.1519) Learning Rate: 0.1000 (0.1000) Top1_base: 67.1875 (68.3691) Top1_base_per_class: 65.1818 (68.6796) 
Training Epoch: [33/1000] Step: [250 / 285] Batch Time: 0.1487 (0.1594) Data Time: 0.0134 (0.0241) Average Loss: 1.2604 (1.1503) Average CE Loss (Source):  1.2604 ( 1.1503) Learning Rate: 0.1000 (0.1000) Top1_base: 66.4062 (68.4750) Top1_base_per_class: 65.2679 (68.8103) 
Training Epoch: [33/1000] Step: [260 / 285] Batch Time: 0.1536 (0.1591) Data Time: 0.0159 (0.0238) Average Loss: 1.1412 (1.1500) Average CE Loss (Source):  1.1412 ( 1.1500) Learning Rate: 0.1000 (0.1000) Top1_base: 70.3125 (68.4736) Top1_base_per_class: 71.1458 (68.8676) 
Training Epoch: [33/1000] Step: [270 / 285] Batch Time: 0.1469 (0.1587) Data Time: 0.0123 (0.0234) Average Loss: 1.1194 (1.1505) Average CE Loss (Source):  1.1194 ( 1.1505) Learning Rate: 0.1000 (0.1000) Top1_base: 64.8438 (68.4606) Top1_base_per_class: 66.0909 (68.8991) 
Training Epoch: [33/1000] Step: [280 / 285] Batch Time: 0.1503 (0.1584) Data Time: 0.0146 (0.0231) Average Loss: 1.1690 (1.1501) Average CE Loss (Source):  1.1690 ( 1.1501) Learning Rate: 0.1000 (0.1000) Top1_base: 70.3125 (68.4961) Top1_base_per_class: 69.9686 (68.9141) 
Training Epoch: [34/1000] Step: [0] Batch Time: 0.1425 (0.1582) Data Time: 0.0118 (0.0229) Average Loss: 1.0513 (1.1504) Average CE Loss (Source):  1.0513 ( 1.1504) Learning Rate: 0.1000 (0.1000) Top1_base: 70.3125 (68.4841) Top1_base_per_class: 72.0339 (68.8910) 
  3%|▎         | 34/1000 [27:12<12:51:24, 47.91s/it]  4%|▎         | 35/1000 [27:56<12:34:50, 46.93s/it]Training Epoch: [34/1000] Step: [10 / 285] Batch Time: 0.1486 (0.2296) Data Time: 0.0135 (0.0961) Average Loss: 0.8494 (1.1297) Average CE Loss (Source):  0.8494 ( 1.1297) Learning Rate: 0.1000 (0.1000) Top1_base: 73.4375 (67.8125) Top1_base_per_class: 70.3216 (68.3119) 
Training Epoch: [34/1000] Step: [20 / 285] Batch Time: 0.1453 (0.1942) Data Time: 0.0112 (0.0607) Average Loss: 1.2457 (1.1292) Average CE Loss (Source):  1.2457 ( 1.1292) Learning Rate: 0.1000 (0.1000) Top1_base: 67.9688 (67.9688) Top1_base_per_class: 69.2764 (68.4658) 
Training Epoch: [34/1000] Step: [30 / 285] Batch Time: 0.1480 (0.1828) Data Time: 0.0132 (0.0493) Average Loss: 0.9253 (1.1187) Average CE Loss (Source):  0.9253 ( 1.1187) Learning Rate: 0.1000 (0.1000) Top1_base: 74.2188 (68.5677) Top1_base_per_class: 79.3651 (69.1778) 
Training Epoch: [34/1000] Step: [40 / 285] Batch Time: 0.1463 (0.1760) Data Time: 0.0108 (0.0425) Average Loss: 1.0818 (1.1194) Average CE Loss (Source):  1.0818 ( 1.1194) Learning Rate: 0.1000 (0.1000) Top1_base: 75.7812 (68.4570) Top1_base_per_class: 78.1255 (69.1807) 
Training Epoch: [34/1000] Step: [50 / 285] Batch Time: 0.1469 (0.1735) Data Time: 0.0111 (0.0401) Average Loss: 1.0753 (1.1178) Average CE Loss (Source):  1.0753 ( 1.1178) Learning Rate: 0.1000 (0.1000) Top1_base: 67.9688 (68.6562) Top1_base_per_class: 69.7458 (69.3109) 
Training Epoch: [34/1000] Step: [60 / 285] Batch Time: 0.1441 (0.1698) Data Time: 0.0125 (0.0364) Average Loss: 1.0234 (1.1190) Average CE Loss (Source):  1.0234 ( 1.1190) Learning Rate: 0.1000 (0.1000) Top1_base: 69.5312 (68.7891) Top1_base_per_class: 70.6790 (69.5002) 
Training Epoch: [34/1000] Step: [70 / 285] Batch Time: 0.1476 (0.1691) Data Time: 0.0113 (0.0358) Average Loss: 1.1950 (1.1135) Average CE Loss (Source):  1.1950 ( 1.1135) Learning Rate: 0.1000 (0.1000) Top1_base: 66.4062 (68.9174) Top1_base_per_class: 63.7755 (69.6395) 
Training Epoch: [34/1000] Step: [80 / 285] Batch Time: 0.1443 (0.1677) Data Time: 0.0126 (0.0344) Average Loss: 1.0540 (1.1083) Average CE Loss (Source):  1.0540 ( 1.1083) Learning Rate: 0.1000 (0.1000) Top1_base: 71.0938 (68.9941) Top1_base_per_class: 68.9394 (69.6680) 
Training Epoch: [34/1000] Step: [90 / 285] Batch Time: 0.1463 (0.1660) Data Time: 0.0129 (0.0327) Average Loss: 1.1530 (1.1182) Average CE Loss (Source):  1.1530 ( 1.1182) Learning Rate: 0.1000 (0.1000) Top1_base: 71.8750 (68.9149) Top1_base_per_class: 74.0517 (69.6162) 
Training Epoch: [34/1000] Step: [100 / 285] Batch Time: 0.1459 (0.1649) Data Time: 0.0110 (0.0316) Average Loss: 1.0635 (1.1129) Average CE Loss (Source):  1.0635 ( 1.1129) Learning Rate: 0.1000 (0.1000) Top1_base: 75.7812 (69.1094) Top1_base_per_class: 77.8070 (69.7536) 
Training Epoch: [34/1000] Step: [110 / 285] Batch Time: 0.1475 (0.1636) Data Time: 0.0121 (0.0303) Average Loss: 1.0913 (1.1165) Average CE Loss (Source):  1.0913 ( 1.1165) Learning Rate: 0.1000 (0.1000) Top1_base: 72.6562 (69.0696) Top1_base_per_class: 70.7143 (69.7930) 
Training Epoch: [34/1000] Step: [120 / 285] Batch Time: 0.1457 (0.1627) Data Time: 0.0110 (0.0294) Average Loss: 1.0390 (1.1141) Average CE Loss (Source):  1.0390 ( 1.1141) Learning Rate: 0.1000 (0.1000) Top1_base: 67.9688 (69.2513) Top1_base_per_class: 67.3684 (69.8724) 
Training Epoch: [34/1000] Step: [130 / 285] Batch Time: 0.1446 (0.1622) Data Time: 0.0128 (0.0289) Average Loss: 0.9615 (1.1144) Average CE Loss (Source):  0.9615 ( 1.1144) Learning Rate: 0.1000 (0.1000) Top1_base: 71.0938 (69.2548) Top1_base_per_class: 74.3553 (69.7879) 
Training Epoch: [34/1000] Step: [140 / 285] Batch Time: 0.1487 (0.1615) Data Time: 0.0113 (0.0281) Average Loss: 0.9645 (1.1126) Average CE Loss (Source):  0.9645 ( 1.1126) Learning Rate: 0.1000 (0.1000) Top1_base: 75.0000 (69.2467) Top1_base_per_class: 75.1212 (69.7470) 
Training Epoch: [34/1000] Step: [150 / 285] Batch Time: 0.1491 (0.1607) Data Time: 0.0110 (0.0272) Average Loss: 1.1966 (1.1130) Average CE Loss (Source):  1.1966 ( 1.1130) Learning Rate: 0.1000 (0.1000) Top1_base: 67.9688 (69.2031) Top1_base_per_class: 71.9394 (69.6852) 
Training Epoch: [34/1000] Step: [160 / 285] Batch Time: 0.1467 (0.1600) Data Time: 0.0121 (0.0263) Average Loss: 1.0371 (1.1156) Average CE Loss (Source):  1.0371 ( 1.1156) Learning Rate: 0.1000 (0.1000) Top1_base: 73.4375 (69.1602) Top1_base_per_class: 71.9766 (69.6059) 
Training Epoch: [34/1000] Step: [170 / 285] Batch Time: 0.1491 (0.1594) Data Time: 0.0102 (0.0256) Average Loss: 1.1350 (1.1205) Average CE Loss (Source):  1.1350 ( 1.1205) Learning Rate: 0.1000 (0.1000) Top1_base: 67.1875 (69.0303) Top1_base_per_class: 67.3446 (69.4807) 
Training Epoch: [34/1000] Step: [180 / 285] Batch Time: 0.1480 (0.1588) Data Time: 0.0135 (0.0250) Average Loss: 1.0457 (1.1221) Average CE Loss (Source):  1.0457 ( 1.1221) Learning Rate: 0.1000 (0.1000) Top1_base: 69.5312 (68.9453) Top1_base_per_class: 68.9423 (69.3562) 
Training Epoch: [34/1000] Step: [190 / 285] Batch Time: 0.1458 (0.1584) Data Time: 0.0109 (0.0246) Average Loss: 1.2183 (1.1273) Average CE Loss (Source):  1.2183 ( 1.1273) Learning Rate: 0.1000 (0.1000) Top1_base: 70.3125 (68.8775) Top1_base_per_class: 67.9619 (69.2196) 
Training Epoch: [34/1000] Step: [200 / 285] Batch Time: 0.1473 (0.1579) Data Time: 0.0135 (0.0241) Average Loss: 1.3727 (1.1327) Average CE Loss (Source):  1.3727 ( 1.1327) Learning Rate: 0.1000 (0.1000) Top1_base: 68.7500 (68.7656) Top1_base_per_class: 67.9240 (69.1726) 
Training Epoch: [34/1000] Step: [210 / 285] Batch Time: 0.1458 (0.1574) Data Time: 0.0109 (0.0236) Average Loss: 1.1398 (1.1312) Average CE Loss (Source):  1.1398 ( 1.1312) Learning Rate: 0.1000 (0.1000) Top1_base: 66.4062 (68.7723) Top1_base_per_class: 70.5655 (69.2190) 
Training Epoch: [34/1000] Step: [220 / 285] Batch Time: 0.1502 (0.1570) Data Time: 0.0131 (0.0232) Average Loss: 1.0387 (1.1301) Average CE Loss (Source):  1.0387 ( 1.1301) Learning Rate: 0.1000 (0.1000) Top1_base: 68.7500 (68.8068) Top1_base_per_class: 67.8611 (69.2776) 
Training Epoch: [34/1000] Step: [230 / 285] Batch Time: 0.1464 (0.1573) Data Time: 0.0109 (0.0234) Average Loss: 1.2609 (1.1309) Average CE Loss (Source):  1.2609 ( 1.1309) Learning Rate: 0.1000 (0.1000) Top1_base: 67.9688 (68.7806) Top1_base_per_class: 71.0025 (69.2808) 
Training Epoch: [34/1000] Step: [240 / 285] Batch Time: 0.1501 (0.1569) Data Time: 0.0121 (0.0230) Average Loss: 1.0177 (1.1328) Average CE Loss (Source):  1.0177 ( 1.1328) Learning Rate: 0.1000 (0.1000) Top1_base: 73.4375 (68.7565) Top1_base_per_class: 73.6728 (69.2747) 
Training Epoch: [34/1000] Step: [250 / 285] Batch Time: 0.1483 (0.1566) Data Time: 0.0113 (0.0227) Average Loss: 1.3259 (1.1360) Average CE Loss (Source):  1.3259 ( 1.1360) Learning Rate: 0.1000 (0.1000) Top1_base: 65.6250 (68.7281) Top1_base_per_class: 69.4643 (69.2708) 
Training Epoch: [34/1000] Step: [260 / 285] Batch Time: 0.1477 (0.1567) Data Time: 0.0119 (0.0228) Average Loss: 1.2134 (1.1400) Average CE Loss (Source):  1.2134 ( 1.1400) Learning Rate: 0.1000 (0.1000) Top1_base: 66.4062 (68.6298) Top1_base_per_class: 71.0452 (69.2080) 
Training Epoch: [34/1000] Step: [270 / 285] Batch Time: 0.1490 (0.1566) Data Time: 0.0108 (0.0226) Average Loss: 1.3189 (1.1413) Average CE Loss (Source):  1.3189 ( 1.1413) Learning Rate: 0.1000 (0.1000) Top1_base: 65.6250 (68.5532) Top1_base_per_class: 71.8055 (69.0949) 
Training Epoch: [34/1000] Step: [280 / 285] Batch Time: 0.1477 (0.1566) Data Time: 0.0107 (0.0227) Average Loss: 1.0301 (1.1404) Average CE Loss (Source):  1.0301 ( 1.1404) Learning Rate: 0.1000 (0.1000) Top1_base: 71.0938 (68.5352) Top1_base_per_class: 71.7262 (69.0669) 
Training Epoch: [35/1000] Step: [0] Batch Time: 0.1484 (0.1564) Data Time: 0.0149 (0.0225) Average Loss: 1.4134 (1.1423) Average CE Loss (Source):  1.4134 ( 1.1423) Learning Rate: 0.1000 (0.1000) Top1_base: 60.1562 (68.4786) Top1_base_per_class: 60.0585 (69.0393) 
Training Epoch: [35/1000] Step: [10 / 285] Batch Time: 0.1451 (0.2499) Data Time: 0.0105 (0.1164) Average Loss: 0.8769 (1.0931) Average CE Loss (Source):  0.8769 ( 1.0931) Learning Rate: 0.1000 (0.1000) Top1_base: 69.5312 (69.0625) Top1_base_per_class: 69.8765 (69.2127) 
Training Epoch: [35/1000] Step: [20 / 285] Batch Time: 0.1444 (0.2043) Data Time: 0.0135 (0.0710) Average Loss: 1.0907 (1.0648) Average CE Loss (Source):  1.0907 ( 1.0648) Learning Rate: 0.1000 (0.1000) Top1_base: 72.6562 (70.5859) Top1_base_per_class: 75.9722 (70.4303) 
Training Epoch: [35/1000] Step: [30 / 285] Batch Time: 0.1463 (0.1898) Data Time: 0.0113 (0.0564) Average Loss: 1.2007 (1.0466) Average CE Loss (Source):  1.2007 ( 1.0466) Learning Rate: 0.1000 (0.1000) Top1_base: 65.6250 (71.1458) Top1_base_per_class: 68.9266 (71.0238) 
Training Epoch: [35/1000] Step: [40 / 285] Batch Time: 0.1471 (0.1796) Data Time: 0.0135 (0.0466) Average Loss: 1.1271 (1.0471) Average CE Loss (Source):  1.1271 ( 1.0471) Learning Rate: 0.1000 (0.1000) Top1_base: 68.7500 (71.2500) Top1_base_per_class: 65.5952 (71.0406) 
Training Epoch: [35/1000] Step: [50 / 285] Batch Time: 0.1447 (0.1732) Data Time: 0.0106 (0.0401) Average Loss: 0.9806 (1.0549) Average CE Loss (Source):  0.9806 ( 1.0549) Learning Rate: 0.1000 (0.1000) Top1_base: 72.6562 (70.9531) Top1_base_per_class: 75.5460 (70.8956) 
Training Epoch: [35/1000] Step: [60 / 285] Batch Time: 0.1506 (0.1690) Data Time: 0.0181 (0.0359) Average Loss: 1.1027 (1.0621) Average CE Loss (Source):  1.1027 ( 1.0621) Learning Rate: 0.1000 (0.1000) Top1_base: 68.7500 (71.1328) Top1_base_per_class: 74.8810 (71.4546) 
Training Epoch: [35/1000] Step: [70 / 285] Batch Time: 0.1451 (0.1668) Data Time: 0.0106 (0.0336) Average Loss: 0.8697 (1.0624) Average CE Loss (Source):  0.8697 ( 1.0624) Learning Rate: 0.1000 (0.1000) Top1_base: 77.3438 (71.1830) Top1_base_per_class: 78.3987 (71.5199) 
Training Epoch: [35/1000] Step: [80 / 285] Batch Time: 0.1787 (0.1660) Data Time: 0.0459 (0.0328) Average Loss: 0.9299 (1.0694) Average CE Loss (Source):  0.9299 ( 1.0694) Learning Rate: 0.1000 (0.1000) Top1_base: 73.4375 (71.0645) Top1_base_per_class: 76.3743 (71.4465) 
Training Epoch: [35/1000] Step: [90 / 285] Batch Time: 0.1459 (0.1645) Data Time: 0.0116 (0.0313) Average Loss: 1.0297 (1.0798) Average CE Loss (Source):  1.0297 ( 1.0798) Learning Rate: 0.1000 (0.1000) Top1_base: 67.1875 (70.8160) Top1_base_per_class: 67.6852 (71.2947) 
Training Epoch: [35/1000] Step: [100 / 285] Batch Time: 0.1629 (0.1640) Data Time: 0.0313 (0.0307) Average Loss: 1.0573 (1.0767) Average CE Loss (Source):  1.0573 ( 1.0767) Learning Rate: 0.1000 (0.1000) Top1_base: 71.8750 (70.9219) Top1_base_per_class: 72.1100 (71.4141) 
Training Epoch: [35/1000] Step: [110 / 285] Batch Time: 0.1454 (0.1626) Data Time: 0.0112 (0.0294) Average Loss: 1.1079 (1.0809) Average CE Loss (Source):  1.1079 ( 1.0809) Learning Rate: 0.1000 (0.1000) Top1_base: 69.5312 (70.7599) Top1_base_per_class: 69.6541 (71.3083) 
Training Epoch: [35/1000] Step: [120 / 285] Batch Time: 0.2144 (0.1627) Data Time: 0.0823 (0.0295) Average Loss: 1.0747 (1.0833) Average CE Loss (Source):  1.0747 ( 1.0833) Learning Rate: 0.1000 (0.1000) Top1_base: 70.3125 (70.6445) Top1_base_per_class: 70.5975 (71.3304) 
Training Epoch: [35/1000] Step: [130 / 285] Batch Time: 0.1448 (0.1623) Data Time: 0.0131 (0.0292) Average Loss: 1.0177 (1.0860) Average CE Loss (Source):  1.0177 ( 1.0860) Learning Rate: 0.1000 (0.1000) Top1_base: 75.0000 (70.5889) Top1_base_per_class: 75.1307 (71.2567) 
Training Epoch: [35/1000] Step: [140 / 285] Batch Time: 0.2179 (0.1626) Data Time: 0.0852 (0.0295) Average Loss: 1.1652 (1.0921) Average CE Loss (Source):  1.1652 ( 1.0921) Learning Rate: 0.1000 (0.1000) Top1_base: 68.7500 (70.3571) Top1_base_per_class: 73.7434 (71.0262) 
Training Epoch: [35/1000] Step: [150 / 285] Batch Time: 0.1469 (0.1619) Data Time: 0.0115 (0.0289) Average Loss: 1.3277 (1.0961) Average CE Loss (Source):  1.3277 ( 1.0961) Learning Rate: 0.1000 (0.1000) Top1_base: 62.5000 (70.1510) Top1_base_per_class: 66.0345 (70.7289) 
Training Epoch: [35/1000] Step: [160 / 285] Batch Time: 0.2222 (0.1620) Data Time: 0.0901 (0.0290) Average Loss: 1.2601 (1.0994) Average CE Loss (Source):  1.2601 ( 1.0994) Learning Rate: 0.1000 (0.1000) Top1_base: 63.2812 (70.0879) Top1_base_per_class: 68.0449 (70.7091) 
Training Epoch: [35/1000] Step: [170 / 285] Batch Time: 0.1472 (0.1625) Data Time: 0.0108 (0.0294) Average Loss: 0.8796 (1.1011) Average CE Loss (Source):  0.8796 ( 1.1011) Learning Rate: 0.1000 (0.1000) Top1_base: 78.1250 (70.0092) Top1_base_per_class: 75.3955 (70.6565) 
Training Epoch: [35/1000] Step: [180 / 285] Batch Time: 0.1943 (0.1623) Data Time: 0.0625 (0.0292) Average Loss: 1.0302 (1.0973) Average CE Loss (Source):  1.0302 ( 1.0973) Learning Rate: 0.1000 (0.1000) Top1_base: 70.3125 (70.0911) Top1_base_per_class: 73.9583 (70.7340) 
Training Epoch: [35/1000] Step: [190 / 285] Batch Time: 0.1453 (0.1620) Data Time: 0.0105 (0.0289) Average Loss: 0.9717 (1.0990) Average CE Loss (Source):  0.9717 ( 1.0990) Learning Rate: 0.1000 (0.1000) Top1_base: 75.7812 (70.0370) Top1_base_per_class: 76.7879 (70.6704) 
Training Epoch: [35/1000] Step: [200 / 285] Batch Time: 0.1859 (0.1617) Data Time: 0.0543 (0.0286) Average Loss: 0.9282 (1.1029) Average CE Loss (Source):  0.9282 ( 1.1029) Learning Rate: 0.1000 (0.1000) Top1_base: 74.2188 (69.9141) Top1_base_per_class: 71.4943 (70.4532) 
Training Epoch: [35/1000] Step: [210 / 285] Batch Time: 0.1473 (0.1612) Data Time: 0.0109 (0.0281) Average Loss: 1.3158 (1.1027) Average CE Loss (Source):  1.3158 ( 1.1027) Learning Rate: 0.1000 (0.1000) Top1_base: 61.7188 (69.8921) Top1_base_per_class: 62.1726 (70.4250) 
Training Epoch: [35/1000] Step: [220 / 285] Batch Time: 0.2262 (0.1614) Data Time: 0.0936 (0.0282) Average Loss: 1.3074 (1.1072) Average CE Loss (Source):  1.3074 ( 1.1072) Learning Rate: 0.1000 (0.1000) Top1_base: 66.4062 (69.7266) Top1_base_per_class: 67.8788 (70.2202) 
Training Epoch: [35/1000] Step: [230 / 285] Batch Time: 0.1462 (0.1609) Data Time: 0.0102 (0.0278) Average Loss: 1.1286 (1.1080) Average CE Loss (Source):  1.1286 ( 1.1080) Learning Rate: 0.1000 (0.1000) Top1_base: 71.0938 (69.7283) Top1_base_per_class: 72.2974 (70.2419) 
Training Epoch: [35/1000] Step: [240 / 285] Batch Time: 0.1722 (0.1609) Data Time: 0.0406 (0.0278) Average Loss: 1.4673 (1.1106) Average CE Loss (Source):  1.4673 ( 1.1106) Learning Rate: 0.1000 (0.1000) Top1_base: 60.9375 (69.5833) Top1_base_per_class: 62.9293 (70.1475) 
Training Epoch: [35/1000] Step: [250 / 285] Batch Time: 0.1448 (0.1607) Data Time: 0.0103 (0.0276) Average Loss: 1.0642 (1.1120) Average CE Loss (Source):  1.0642 ( 1.1120) Learning Rate: 0.1000 (0.1000) Top1_base: 68.7500 (69.5344) Top1_base_per_class: 69.2121 (70.0746) 
Training Epoch: [35/1000] Step: [260 / 285] Batch Time: 0.1503 (0.1606) Data Time: 0.0169 (0.0274) Average Loss: 0.9240 (1.1124) Average CE Loss (Source):  0.9240 ( 1.1124) Learning Rate: 0.1000 (0.1000) Top1_base: 71.0938 (69.5252) Top1_base_per_class: 73.7479 (70.0307) 
Training Epoch: [35/1000] Step: [270 / 285] Batch Time: 0.1418 (0.1601) Data Time: 0.0113 (0.0270) Average Loss: 1.0023 (1.1145) Average CE Loss (Source):  1.0023 ( 1.1145) Learning Rate: 0.1000 (0.1000) Top1_base: 73.4375 (69.4647) Top1_base_per_class: 72.0915 (69.9645) 
Training Epoch: [35/1000] Step: [280 / 285] Batch Time: 0.1783 (0.1603) Data Time: 0.0466 (0.0271) Average Loss: 1.2469 (1.1163) Average CE Loss (Source):  1.2469 ( 1.1163) Learning Rate: 0.1000 (0.1000) Top1_base: 64.8438 (69.4308) Top1_base_per_class: 65.5128 (69.9403) 
Training Epoch: [36/1000] Step: [0] Batch Time: 0.1410 (0.1603) Data Time: 0.0107 (0.0272) Average Loss: 1.1860 (1.1174) Average CE Loss (Source):  1.1860 ( 1.1174) Learning Rate: 0.1000 (0.1000) Top1_base: 60.9375 (69.3695) Top1_base_per_class: 63.0000 (69.8747) 
  4%|▎         | 36/1000 [28:45<12:41:12, 47.38s/it]  4%|▎         | 37/1000 [29:30<12:28:41, 46.65s/it]Training Epoch: [36/1000] Step: [10 / 285] Batch Time: 0.1440 (0.2412) Data Time: 0.0116 (0.1086) Average Loss: 1.1678 (1.0787) Average CE Loss (Source):  1.1678 ( 1.0787) Learning Rate: 0.1000 (0.1000) Top1_base: 71.8750 (71.2500) Top1_base_per_class: 72.4979 (71.2544) 
Training Epoch: [36/1000] Step: [20 / 285] Batch Time: 0.1485 (0.2049) Data Time: 0.0147 (0.0720) Average Loss: 0.9110 (1.0589) Average CE Loss (Source):  0.9110 ( 1.0589) Learning Rate: 0.1000 (0.1000) Top1_base: 74.2188 (70.6641) Top1_base_per_class: 70.5758 (70.7704) 
Training Epoch: [36/1000] Step: [30 / 285] Batch Time: 0.1456 (0.1916) Data Time: 0.0124 (0.0587) Average Loss: 0.9483 (1.0530) Average CE Loss (Source):  0.9483 ( 1.0530) Learning Rate: 0.1000 (0.1000) Top1_base: 76.5625 (71.0156) Top1_base_per_class: 73.2759 (71.4899) 
Training Epoch: [36/1000] Step: [40 / 285] Batch Time: 0.1466 (0.1816) Data Time: 0.0144 (0.0485) Average Loss: 1.3449 (1.0759) Average CE Loss (Source):  1.3449 ( 1.0759) Learning Rate: 0.1000 (0.1000) Top1_base: 62.5000 (70.2734) Top1_base_per_class: 62.3164 (70.5770) 
Training Epoch: [36/1000] Step: [50 / 285] Batch Time: 0.1467 (0.1772) Data Time: 0.0145 (0.0439) Average Loss: 1.2126 (1.0749) Average CE Loss (Source):  1.2126 ( 1.0749) Learning Rate: 0.1000 (0.1000) Top1_base: 64.8438 (70.4844) Top1_base_per_class: 61.5556 (70.7779) 
Training Epoch: [36/1000] Step: [60 / 285] Batch Time: 0.1484 (0.1740) Data Time: 0.0157 (0.0406) Average Loss: 1.0513 (1.0675) Average CE Loss (Source):  1.0513 ( 1.0675) Learning Rate: 0.1000 (0.1000) Top1_base: 69.5312 (70.6120) Top1_base_per_class: 73.9450 (70.9775) 
Training Epoch: [36/1000] Step: [70 / 285] Batch Time: 0.1438 (0.1718) Data Time: 0.0105 (0.0384) Average Loss: 1.1246 (1.0669) Average CE Loss (Source):  1.1246 ( 1.0669) Learning Rate: 0.1000 (0.1000) Top1_base: 69.5312 (70.5246) Top1_base_per_class: 65.0585 (70.9306) 
Training Epoch: [36/1000] Step: [80 / 285] Batch Time: 0.1457 (0.1695) Data Time: 0.0146 (0.0361) Average Loss: 1.2601 (1.0684) Average CE Loss (Source):  1.2601 ( 1.0684) Learning Rate: 0.1000 (0.1000) Top1_base: 66.4062 (70.4199) Top1_base_per_class: 68.9308 (70.9443) 
Training Epoch: [36/1000] Step: [90 / 285] Batch Time: 0.1473 (0.1682) Data Time: 0.0127 (0.0348) Average Loss: 1.1883 (1.0774) Average CE Loss (Source):  1.1883 ( 1.0774) Learning Rate: 0.1000 (0.1000) Top1_base: 68.7500 (70.3125) Top1_base_per_class: 65.7862 (70.7697) 
Training Epoch: [36/1000] Step: [100 / 285] Batch Time: 0.1457 (0.1667) Data Time: 0.0149 (0.0333) Average Loss: 1.2461 (1.0858) Average CE Loss (Source):  1.2461 ( 1.0858) Learning Rate: 0.1000 (0.1000) Top1_base: 66.4062 (70.0938) Top1_base_per_class: 64.7619 (70.5678) 
Training Epoch: [36/1000] Step: [110 / 285] Batch Time: 0.1493 (0.1663) Data Time: 0.0166 (0.0329) Average Loss: 1.2726 (1.0967) Average CE Loss (Source):  1.2726 ( 1.0967) Learning Rate: 0.1000 (0.1000) Top1_base: 67.1875 (69.9290) Top1_base_per_class: 67.9394 (70.4257) 
Training Epoch: [36/1000] Step: [120 / 285] Batch Time: 0.1451 (0.1654) Data Time: 0.0116 (0.0320) Average Loss: 1.0978 (1.1016) Average CE Loss (Source):  1.0978 ( 1.1016) Learning Rate: 0.1000 (0.1000) Top1_base: 68.7500 (69.7982) Top1_base_per_class: 69.3275 (70.3650) 
Training Epoch: [36/1000] Step: [130 / 285] Batch Time: 0.1465 (0.1645) Data Time: 0.0141 (0.0310) Average Loss: 1.0096 (1.0995) Average CE Loss (Source):  1.0096 ( 1.0995) Learning Rate: 0.1000 (0.1000) Top1_base: 71.8750 (69.8137) Top1_base_per_class: 75.0496 (70.3921) 
Training Epoch: [36/1000] Step: [140 / 285] Batch Time: 0.1490 (0.1644) Data Time: 0.0145 (0.0308) Average Loss: 1.1599 (1.1003) Average CE Loss (Source):  1.1599 ( 1.1003) Learning Rate: 0.1000 (0.1000) Top1_base: 67.9688 (69.8549) Top1_base_per_class: 67.8161 (70.4736) 
Training Epoch: [36/1000] Step: [150 / 285] Batch Time: 0.1470 (0.1635) Data Time: 0.0121 (0.0297) Average Loss: 1.1552 (1.1032) Average CE Loss (Source):  1.1552 ( 1.1032) Learning Rate: 0.1000 (0.1000) Top1_base: 64.8438 (69.7708) Top1_base_per_class: 66.2117 (70.4459) 
Training Epoch: [36/1000] Step: [160 / 285] Batch Time: 0.1471 (0.1634) Data Time: 0.0146 (0.0295) Average Loss: 0.9707 (1.1064) Average CE Loss (Source):  0.9707 ( 1.1064) Learning Rate: 0.1000 (0.1000) Top1_base: 70.3125 (69.6924) Top1_base_per_class: 68.8268 (70.3269) 
Training Epoch: [36/1000] Step: [170 / 285] Batch Time: 0.1485 (0.1628) Data Time: 0.0140 (0.0289) Average Loss: 1.2915 (1.1074) Average CE Loss (Source):  1.2915 ( 1.1074) Learning Rate: 0.1000 (0.1000) Top1_base: 65.6250 (69.6829) Top1_base_per_class: 62.1839 (70.2868) 
Training Epoch: [36/1000] Step: [180 / 285] Batch Time: 0.1468 (0.1621) Data Time: 0.0123 (0.0281) Average Loss: 1.1449 (1.1073) Average CE Loss (Source):  1.1449 ( 1.1073) Learning Rate: 0.1000 (0.1000) Top1_base: 67.1875 (69.6354) Top1_base_per_class: 68.9506 (70.1831) 
Training Epoch: [36/1000] Step: [190 / 285] Batch Time: 0.1461 (0.1614) Data Time: 0.0146 (0.0274) Average Loss: 1.0154 (1.1118) Average CE Loss (Source):  1.0154 ( 1.1118) Learning Rate: 0.1000 (0.1000) Top1_base: 70.3125 (69.5230) Top1_base_per_class: 71.0234 (70.1088) 
Training Epoch: [36/1000] Step: [200 / 285] Batch Time: 0.1469 (0.1608) Data Time: 0.0124 (0.0267) Average Loss: 1.1970 (1.1120) Average CE Loss (Source):  1.1970 ( 1.1120) Learning Rate: 0.1000 (0.1000) Top1_base: 65.6250 (69.5430) Top1_base_per_class: 64.9435 (70.1051) 
Training Epoch: [36/1000] Step: [210 / 285] Batch Time: 0.1485 (0.1602) Data Time: 0.0115 (0.0262) Average Loss: 0.9444 (1.1122) Average CE Loss (Source):  0.9444 ( 1.1122) Learning Rate: 0.1000 (0.1000) Top1_base: 71.8750 (69.5052) Top1_base_per_class: 73.1212 (70.0908) 
Training Epoch: [36/1000] Step: [220 / 285] Batch Time: 0.1544 (0.1598) Data Time: 0.0187 (0.0257) Average Loss: 1.0424 (1.1136) Average CE Loss (Source):  1.0424 ( 1.1136) Learning Rate: 0.1000 (0.1000) Top1_base: 74.2188 (69.4673) Top1_base_per_class: 77.9885 (70.0686) 
Training Epoch: [36/1000] Step: [230 / 285] Batch Time: 0.1497 (0.1594) Data Time: 0.0151 (0.0252) Average Loss: 1.3764 (1.1153) Average CE Loss (Source):  1.3764 ( 1.1153) Learning Rate: 0.1000 (0.1000) Top1_base: 63.2812 (69.4293) Top1_base_per_class: 58.6667 (69.9902) 
Training Epoch: [36/1000] Step: [240 / 285] Batch Time: 0.1484 (0.1590) Data Time: 0.0153 (0.0247) Average Loss: 1.0646 (1.1156) Average CE Loss (Source):  1.0646 ( 1.1156) Learning Rate: 0.1000 (0.1000) Top1_base: 66.4062 (69.3848) Top1_base_per_class: 67.8274 (69.9800) 
Training Epoch: [36/1000] Step: [250 / 285] Batch Time: 0.1479 (0.1586) Data Time: 0.0142 (0.0244) Average Loss: 0.9762 (1.1120) Average CE Loss (Source):  0.9762 ( 1.1120) Learning Rate: 0.1000 (0.1000) Top1_base: 67.9688 (69.4437) Top1_base_per_class: 65.0607 (70.0236) 
Training Epoch: [36/1000] Step: [260 / 285] Batch Time: 0.1445 (0.1582) Data Time: 0.0119 (0.0240) Average Loss: 1.0695 (1.1130) Average CE Loss (Source):  1.0695 ( 1.1130) Learning Rate: 0.1000 (0.1000) Top1_base: 66.4062 (69.4050) Top1_base_per_class: 66.3223 (69.9841) 
Training Epoch: [36/1000] Step: [270 / 285] Batch Time: 0.1457 (0.1581) Data Time: 0.0140 (0.0239) Average Loss: 0.8992 (1.1131) Average CE Loss (Source):  0.8992 ( 1.1131) Learning Rate: 0.1000 (0.1000) Top1_base: 73.4375 (69.3779) Top1_base_per_class: 73.8141 (69.9338) 
Training Epoch: [36/1000] Step: [280 / 285] Batch Time: 0.1463 (0.1577) Data Time: 0.0145 (0.0235) Average Loss: 1.3004 (1.1155) Average CE Loss (Source):  1.3004 ( 1.1155) Learning Rate: 0.1000 (0.1000) Top1_base: 60.9375 (69.3527) Top1_base_per_class: 63.2184 (69.9099) 
Training Epoch: [37/1000] Step: [0] Batch Time: 0.1417 (0.1575) Data Time: 0.0104 (0.0233) Average Loss: 1.1802 (1.1157) Average CE Loss (Source):  1.1802 ( 1.1157) Learning Rate: 0.1000 (0.1000) Top1_base: 66.4062 (69.3503) Top1_base_per_class: 67.9167 (69.9104) 
Training Epoch: [37/1000] Step: [10 / 285] Batch Time: 0.1493 (0.2377) Data Time: 0.0135 (0.1040) Average Loss: 1.2228 (1.0877) Average CE Loss (Source):  1.2228 ( 1.0877) Learning Rate: 0.1000 (0.1000) Top1_base: 68.7500 (70.1562) Top1_base_per_class: 70.0292 (70.5147) 
Training Epoch: [37/1000] Step: [20 / 285] Batch Time: 0.1473 (0.2013) Data Time: 0.0138 (0.0678) Average Loss: 1.0954 (1.0939) Average CE Loss (Source):  1.0954 ( 1.0939) Learning Rate: 0.1000 (0.1000) Top1_base: 68.7500 (70.1562) Top1_base_per_class: 68.9167 (70.5878) 
Training Epoch: [37/1000] Step: [30 / 285] Batch Time: 0.1497 (0.1852) Data Time: 0.0115 (0.0505) Average Loss: 1.0447 (1.0753) Average CE Loss (Source):  1.0447 ( 1.0753) Learning Rate: 0.1000 (0.1000) Top1_base: 71.8750 (70.1562) Top1_base_per_class: 74.5238 (70.8265) 
Training Epoch: [37/1000] Step: [40 / 285] Batch Time: 0.1499 (0.1768) Data Time: 0.0130 (0.0415) Average Loss: 1.2487 (1.0780) Average CE Loss (Source):  1.2487 ( 1.0780) Learning Rate: 0.1000 (0.1000) Top1_base: 67.9688 (69.8242) Top1_base_per_class: 72.7358 (70.7469) 
Training Epoch: [37/1000] Step: [50 / 285] Batch Time: 0.1478 (0.1725) Data Time: 0.0140 (0.0376) Average Loss: 1.1187 (1.0771) Average CE Loss (Source):  1.1187 ( 1.0771) Learning Rate: 0.1000 (0.1000) Top1_base: 67.1875 (69.9219) Top1_base_per_class: 67.1131 (70.5935) 
Training Epoch: [37/1000] Step: [60 / 285] Batch Time: 0.1482 (0.1700) Data Time: 0.0115 (0.0348) Average Loss: 1.1882 (1.0813) Average CE Loss (Source):  1.1882 ( 1.0813) Learning Rate: 0.1000 (0.1000) Top1_base: 67.9688 (69.8698) Top1_base_per_class: 66.0069 (70.5456) 
Training Epoch: [37/1000] Step: [70 / 285] Batch Time: 0.1487 (0.1673) Data Time: 0.0152 (0.0320) Average Loss: 1.0016 (1.0954) Average CE Loss (Source):  1.0016 ( 1.0954) Learning Rate: 0.1000 (0.1000) Top1_base: 72.6562 (69.6205) Top1_base_per_class: 70.1603 (70.3201) 
Training Epoch: [37/1000] Step: [80 / 285] Batch Time: 0.1463 (0.1652) Data Time: 0.0140 (0.0302) Average Loss: 1.0656 (1.0975) Average CE Loss (Source):  1.0656 ( 1.0975) Learning Rate: 0.1000 (0.1000) Top1_base: 68.7500 (69.5703) Top1_base_per_class: 69.4540 (70.2492) 
Training Epoch: [37/1000] Step: [90 / 285] Batch Time: 0.1511 (0.1634) Data Time: 0.0177 (0.0285) Average Loss: 1.1082 (1.1003) Average CE Loss (Source):  1.1082 ( 1.1003) Learning Rate: 0.1000 (0.1000) Top1_base: 73.4375 (69.4878) Top1_base_per_class: 76.4881 (70.0387) 
Training Epoch: [37/1000] Step: [100 / 285] Batch Time: 0.1480 (0.1623) Data Time: 0.0154 (0.0275) Average Loss: 0.8123 (1.0983) Average CE Loss (Source):  0.8123 ( 1.0983) Learning Rate: 0.1000 (0.1000) Top1_base: 73.4375 (69.6641) Top1_base_per_class: 72.9532 (70.1327) 
Training Epoch: [37/1000] Step: [110 / 285] Batch Time: 0.1488 (0.1618) Data Time: 0.0127 (0.0271) Average Loss: 1.0039 (1.0965) Average CE Loss (Source):  1.0039 ( 1.0965) Learning Rate: 0.1000 (0.1000) Top1_base: 71.8750 (69.6662) Top1_base_per_class: 74.6474 (70.1107) 
Training Epoch: [37/1000] Step: [120 / 285] Batch Time: 0.1471 (0.1611) Data Time: 0.0149 (0.0264) Average Loss: 0.9218 (1.0946) Average CE Loss (Source):  0.9218 ( 1.0946) Learning Rate: 0.1000 (0.1000) Top1_base: 74.2188 (69.6745) Top1_base_per_class: 72.4214 (70.0538) 
Training Epoch: [37/1000] Step: [130 / 285] Batch Time: 0.1500 (0.1603) Data Time: 0.0126 (0.0257) Average Loss: 1.0246 (1.0933) Average CE Loss (Source):  1.0246 ( 1.0933) Learning Rate: 0.1000 (0.1000) Top1_base: 75.0000 (69.7897) Top1_base_per_class: 76.4545 (70.1682) 
Training Epoch: [37/1000] Step: [140 / 285] Batch Time: 0.1472 (0.1605) Data Time: 0.0127 (0.0259) Average Loss: 0.9911 (1.0964) Average CE Loss (Source):  0.9911 ( 1.0964) Learning Rate: 0.1000 (0.1000) Top1_base: 77.3438 (69.7489) Top1_base_per_class: 78.5220 (70.1195) 
Training Epoch: [37/1000] Step: [150 / 285] Batch Time: 0.1486 (0.1605) Data Time: 0.0123 (0.0259) Average Loss: 1.2847 (1.0982) Average CE Loss (Source):  1.2847 ( 1.0982) Learning Rate: 0.1000 (0.1000) Top1_base: 66.4062 (69.7500) Top1_base_per_class: 68.2456 (70.1594) 
Training Epoch: [37/1000] Step: [160 / 285] Batch Time: 0.1499 (0.1599) Data Time: 0.0120 (0.0251) Average Loss: 1.0298 (1.0999) Average CE Loss (Source):  1.0298 ( 1.0999) Learning Rate: 0.1000 (0.1000) Top1_base: 67.9688 (69.7314) Top1_base_per_class: 69.3636 (70.1671) 
Training Epoch: [37/1000] Step: [170 / 285] Batch Time: 0.1489 (0.1593) Data Time: 0.0108 (0.0245) Average Loss: 1.0319 (1.1031) Average CE Loss (Source):  1.0319 ( 1.1031) Learning Rate: 0.1000 (0.1000) Top1_base: 68.7500 (69.6875) Top1_base_per_class: 68.6859 (70.2184) 
Training Epoch: [37/1000] Step: [180 / 285] Batch Time: 0.1469 (0.1589) Data Time: 0.0129 (0.0241) Average Loss: 1.0109 (1.1046) Average CE Loss (Source):  1.0109 ( 1.1046) Learning Rate: 0.1000 (0.1000) Top1_base: 73.4375 (69.6484) Top1_base_per_class: 73.1638 (70.1617) 
Training Epoch: [37/1000] Step: [190 / 285] Batch Time: 0.1498 (0.1584) Data Time: 0.0135 (0.0236) Average Loss: 1.1391 (1.1034) Average CE Loss (Source):  1.1391 ( 1.1034) Learning Rate: 0.1000 (0.1000) Top1_base: 71.0938 (69.6587) Top1_base_per_class: 71.6082 (70.1921) 
Training Epoch: [37/1000] Step: [200 / 285] Batch Time: 0.1479 (0.1579) Data Time: 0.0138 (0.0231) Average Loss: 0.9429 (1.1035) Average CE Loss (Source):  0.9429 ( 1.1035) Learning Rate: 0.1000 (0.1000) Top1_base: 74.2188 (69.6562) Top1_base_per_class: 76.7262 (70.2094) 
Training Epoch: [37/1000] Step: [210 / 285] Batch Time: 0.1530 (0.1577) Data Time: 0.0144 (0.0228) Average Loss: 1.0494 (1.1011) Average CE Loss (Source):  1.0494 ( 1.1011) Learning Rate: 0.1000 (0.1000) Top1_base: 73.4375 (69.6912) Top1_base_per_class: 69.7531 (70.1718) 
Training Epoch: [37/1000] Step: [220 / 285] Batch Time: 0.1495 (0.1574) Data Time: 0.0110 (0.0224) Average Loss: 1.4240 (1.1018) Average CE Loss (Source):  1.4240 ( 1.1018) Learning Rate: 0.1000 (0.1000) Top1_base: 60.9375 (69.6236) Top1_base_per_class: 62.5472 (70.0578) 
Training Epoch: [37/1000] Step: [230 / 285] Batch Time: 0.1505 (0.1571) Data Time: 0.0126 (0.0221) Average Loss: 1.0718 (1.1016) Average CE Loss (Source):  1.0718 ( 1.1016) Learning Rate: 0.1000 (0.1000) Top1_base: 72.6562 (69.6026) Top1_base_per_class: 70.3939 (70.0310) 
Training Epoch: [37/1000] Step: [240 / 285] Batch Time: 0.1495 (0.1571) Data Time: 0.0105 (0.0220) Average Loss: 1.3832 (1.1028) Average CE Loss (Source):  1.3832 ( 1.1028) Learning Rate: 0.1000 (0.1000) Top1_base: 68.7500 (69.6322) Top1_base_per_class: 75.9524 (70.0774) 
Training Epoch: [37/1000] Step: [250 / 285] Batch Time: 0.1518 (0.1569) Data Time: 0.0135 (0.0217) Average Loss: 1.0687 (1.1014) Average CE Loss (Source):  1.0687 ( 1.1014) Learning Rate: 0.1000 (0.1000) Top1_base: 71.0938 (69.6750) Top1_base_per_class: 74.0909 (70.1365) 
Training Epoch: [37/1000] Step: [260 / 285] Batch Time: 0.1471 (0.1571) Data Time: 0.0132 (0.0219) Average Loss: 0.9074 (1.1011) Average CE Loss (Source):  0.9074 ( 1.1011) Learning Rate: 0.1000 (0.1000) Top1_base: 78.1250 (69.6785) Top1_base_per_class: 79.9708 (70.1570) 
Training Epoch: [37/1000] Step: [270 / 285] Batch Time: 0.1748 (0.1571) Data Time: 0.0358 (0.0219) Average Loss: 1.0946 (1.1052) Average CE Loss (Source):  1.0946 ( 1.1052) Learning Rate: 0.1000 (0.1000) Top1_base: 70.3125 (69.5747) Top1_base_per_class: 72.4383 (70.0778) 
Training Epoch: [37/1000] Step: [280 / 285] Batch Time: 0.1461 (0.1568) Data Time: 0.0133 (0.0217) Average Loss: 1.2647 (1.1071) Average CE Loss (Source):  1.2647 ( 1.1071) Learning Rate: 0.1000 (0.1000) Top1_base: 65.6250 (69.5145) Top1_base_per_class: 63.1636 (69.9776) 
Training Epoch: [38/1000] Step: [0] Batch Time: 0.1461 (0.1566) Data Time: 0.0125 (0.0215) Average Loss: 1.2593 (1.1074) Average CE Loss (Source):  1.2593 ( 1.1074) Learning Rate: 0.1000 (0.1000) Top1_base: 67.1875 (69.5175) Top1_base_per_class: 65.5864 (69.9771) 
  4%|▍         | 38/1000 [30:17<12:31:57, 46.90s/it]  4%|▍         | 39/1000 [31:03<12:25:18, 46.53s/it]Training Epoch: [38/1000] Step: [10 / 285] Batch Time: 0.1521 (0.2273) Data Time: 0.0157 (0.0916) Average Loss: 0.9243 (1.1353) Average CE Loss (Source):  0.9243 ( 1.1353) Learning Rate: 0.1000 (0.1000) Top1_base: 76.5625 (67.1875) Top1_base_per_class: 76.5094 (67.1510) 
Training Epoch: [38/1000] Step: [20 / 285] Batch Time: 0.1448 (0.1890) Data Time: 0.0142 (0.0546) Average Loss: 1.3213 (1.0807) Average CE Loss (Source):  1.3213 ( 1.0807) Learning Rate: 0.1000 (0.1000) Top1_base: 66.4062 (69.3359) Top1_base_per_class: 68.1173 (69.7903) 
Training Epoch: [38/1000] Step: [30 / 285] Batch Time: 0.1512 (0.1818) Data Time: 0.0148 (0.0474) Average Loss: 0.9907 (1.0599) Average CE Loss (Source):  0.9907 ( 1.0599) Learning Rate: 0.1000 (0.1000) Top1_base: 67.9688 (70.0521) Top1_base_per_class: 70.3216 (70.7890) 
Training Epoch: [38/1000] Step: [40 / 285] Batch Time: 0.1467 (0.1744) Data Time: 0.0139 (0.0399) Average Loss: 0.9637 (1.0596) Average CE Loss (Source):  0.9637 ( 1.0596) Learning Rate: 0.1000 (0.1000) Top1_base: 73.4375 (70.1367) Top1_base_per_class: 74.5758 (71.0269) 
Training Epoch: [38/1000] Step: [50 / 285] Batch Time: 0.1501 (0.1716) Data Time: 0.0143 (0.0371) Average Loss: 0.9084 (1.0551) Average CE Loss (Source):  0.9084 ( 1.0551) Learning Rate: 0.1000 (0.1000) Top1_base: 72.6562 (70.2969) Top1_base_per_class: 72.1795 (71.0151) 
Training Epoch: [38/1000] Step: [60 / 285] Batch Time: 0.1434 (0.1694) Data Time: 0.0106 (0.0351) Average Loss: 1.0460 (1.0493) Average CE Loss (Source):  1.0460 ( 1.0493) Learning Rate: 0.1000 (0.1000) Top1_base: 67.9688 (70.4167) Top1_base_per_class: 65.6780 (70.8839) 
Training Epoch: [38/1000] Step: [70 / 285] Batch Time: 0.1482 (0.1681) Data Time: 0.0135 (0.0338) Average Loss: 0.9037 (1.0409) Average CE Loss (Source):  0.9037 ( 1.0409) Learning Rate: 0.1000 (0.1000) Top1_base: 77.3438 (70.6696) Top1_base_per_class: 77.7684 (70.9317) 
Training Epoch: [38/1000] Step: [80 / 285] Batch Time: 0.1442 (0.1691) Data Time: 0.0109 (0.0350) Average Loss: 1.0983 (1.0473) Average CE Loss (Source):  1.0983 ( 1.0473) Learning Rate: 0.1000 (0.1000) Top1_base: 67.9688 (70.4785) Top1_base_per_class: 65.5650 (70.6757) 
Training Epoch: [38/1000] Step: [90 / 285] Batch Time: 0.1467 (0.1693) Data Time: 0.0125 (0.0352) Average Loss: 1.2054 (1.0466) Average CE Loss (Source):  1.2054 ( 1.0466) Learning Rate: 0.1000 (0.1000) Top1_base: 64.8438 (70.4774) Top1_base_per_class: 65.6930 (70.7514) 
Training Epoch: [38/1000] Step: [100 / 285] Batch Time: 0.1429 (0.1690) Data Time: 0.0108 (0.0350) Average Loss: 1.0113 (1.0459) Average CE Loss (Source):  1.0113 ( 1.0459) Learning Rate: 0.1000 (0.1000) Top1_base: 71.0938 (70.6016) Top1_base_per_class: 70.3571 (70.9195) 
Training Epoch: [38/1000] Step: [110 / 285] Batch Time: 0.1482 (0.1681) Data Time: 0.0148 (0.0341) Average Loss: 1.2155 (1.0464) Average CE Loss (Source):  1.2155 ( 1.0464) Learning Rate: 0.1000 (0.1000) Top1_base: 67.1875 (70.6250) Top1_base_per_class: 67.7493 (71.0166) 
Training Epoch: [38/1000] Step: [120 / 285] Batch Time: 0.1448 (0.1668) Data Time: 0.0137 (0.0329) Average Loss: 1.2522 (1.0478) Average CE Loss (Source):  1.2522 ( 1.0478) Learning Rate: 0.1000 (0.1000) Top1_base: 67.1875 (70.5208) Top1_base_per_class: 71.8210 (70.9568) 
Training Epoch: [38/1000] Step: [130 / 285] Batch Time: 0.1496 (0.1656) Data Time: 0.0144 (0.0316) Average Loss: 1.0696 (1.0572) Average CE Loss (Source):  1.0696 ( 1.0572) Learning Rate: 0.1000 (0.1000) Top1_base: 71.0938 (70.2644) Top1_base_per_class: 68.6061 (70.6697) 
Training Epoch: [38/1000] Step: [140 / 285] Batch Time: 0.1425 (0.1649) Data Time: 0.0114 (0.0310) Average Loss: 0.8268 (1.0564) Average CE Loss (Source):  0.8268 ( 1.0564) Learning Rate: 0.1000 (0.1000) Top1_base: 75.7812 (70.2567) Top1_base_per_class: 77.1518 (70.7270) 
Training Epoch: [38/1000] Step: [150 / 285] Batch Time: 0.1503 (0.1637) Data Time: 0.0143 (0.0299) Average Loss: 1.2316 (1.0623) Average CE Loss (Source):  1.2316 ( 1.0623) Learning Rate: 0.1000 (0.1000) Top1_base: 60.9375 (70.1198) Top1_base_per_class: 60.7266 (70.6236) 
Training Epoch: [38/1000] Step: [160 / 285] Batch Time: 0.1450 (0.1633) Data Time: 0.0132 (0.0295) Average Loss: 1.0203 (1.0643) Average CE Loss (Source):  1.0203 ( 1.0643) Learning Rate: 0.1000 (0.1000) Top1_base: 72.6562 (70.1855) Top1_base_per_class: 72.2597 (70.6555) 
Training Epoch: [38/1000] Step: [170 / 285] Batch Time: 0.1493 (0.1629) Data Time: 0.0154 (0.0290) Average Loss: 1.1506 (1.0655) Average CE Loss (Source):  1.1506 ( 1.0655) Learning Rate: 0.1000 (0.1000) Top1_base: 69.5312 (70.2941) Top1_base_per_class: 73.3333 (70.8077) 
Training Epoch: [38/1000] Step: [180 / 285] Batch Time: 0.1600 (0.1625) Data Time: 0.0284 (0.0287) Average Loss: 1.0238 (1.0689) Average CE Loss (Source):  1.0238 ( 1.0689) Learning Rate: 0.1000 (0.1000) Top1_base: 71.0938 (70.2995) Top1_base_per_class: 67.4848 (70.7289) 
Training Epoch: [38/1000] Step: [190 / 285] Batch Time: 0.1482 (0.1625) Data Time: 0.0144 (0.0286) Average Loss: 1.1910 (1.0691) Average CE Loss (Source):  1.1910 ( 1.0691) Learning Rate: 0.1000 (0.1000) Top1_base: 68.7500 (70.3331) Top1_base_per_class: 69.6970 (70.7391) 
Training Epoch: [38/1000] Step: [200 / 285] Batch Time: 0.1988 (0.1629) Data Time: 0.0678 (0.0291) Average Loss: 1.1677 (1.0738) Average CE Loss (Source):  1.1677 ( 1.0738) Learning Rate: 0.1000 (0.1000) Top1_base: 70.3125 (70.1914) Top1_base_per_class: 70.2924 (70.5919) 
Training Epoch: [38/1000] Step: [210 / 285] Batch Time: 0.1517 (0.1625) Data Time: 0.0152 (0.0287) Average Loss: 0.9276 (1.0748) Average CE Loss (Source):  0.9276 ( 1.0748) Learning Rate: 0.1000 (0.1000) Top1_base: 76.5625 (70.1674) Top1_base_per_class: 78.7135 (70.6491) 
Training Epoch: [38/1000] Step: [220 / 285] Batch Time: 0.1738 (0.1622) Data Time: 0.0414 (0.0284) Average Loss: 1.0053 (1.0738) Average CE Loss (Source):  1.0053 ( 1.0738) Learning Rate: 0.1000 (0.1000) Top1_base: 70.3125 (70.1776) Top1_base_per_class: 69.0341 (70.6358) 
Training Epoch: [38/1000] Step: [230 / 285] Batch Time: 0.1468 (0.1616) Data Time: 0.0146 (0.0278) Average Loss: 1.2322 (1.0728) Average CE Loss (Source):  1.2322 ( 1.0728) Learning Rate: 0.1000 (0.1000) Top1_base: 66.4062 (70.1902) Top1_base_per_class: 66.6949 (70.5917) 
Training Epoch: [38/1000] Step: [240 / 285] Batch Time: 0.1884 (0.1612) Data Time: 0.0554 (0.0275) Average Loss: 1.1118 (1.0734) Average CE Loss (Source):  1.1118 ( 1.0734) Learning Rate: 0.1000 (0.1000) Top1_base: 73.4375 (70.1790) Top1_base_per_class: 71.0512 (70.5535) 
Training Epoch: [38/1000] Step: [250 / 285] Batch Time: 0.1455 (0.1607) Data Time: 0.0131 (0.0270) Average Loss: 1.1299 (1.0728) Average CE Loss (Source):  1.1299 ( 1.0728) Learning Rate: 0.1000 (0.1000) Top1_base: 65.6250 (70.2094) Top1_base_per_class: 67.5439 (70.6246) 
Training Epoch: [38/1000] Step: [260 / 285] Batch Time: 0.1677 (0.1603) Data Time: 0.0370 (0.0266) Average Loss: 1.1809 (1.0773) Average CE Loss (Source):  1.1809 ( 1.0773) Learning Rate: 0.1000 (0.1000) Top1_base: 68.7500 (70.1052) Top1_base_per_class: 67.1515 (70.5222) 
Training Epoch: [38/1000] Step: [270 / 285] Batch Time: 0.1430 (0.1602) Data Time: 0.0122 (0.0266) Average Loss: 1.2969 (1.0782) Average CE Loss (Source):  1.2969 ( 1.0782) Learning Rate: 0.1000 (0.1000) Top1_base: 66.4062 (70.0897) Top1_base_per_class: 66.6970 (70.5066) 
Training Epoch: [38/1000] Step: [280 / 285] Batch Time: 0.2693 (0.1603) Data Time: 0.1378 (0.0267) Average Loss: 1.1013 (1.0791) Average CE Loss (Source):  1.1013 ( 1.0791) Learning Rate: 0.1000 (0.1000) Top1_base: 70.3125 (70.0586) Top1_base_per_class: 72.1429 (70.4453) 
Training Epoch: [39/1000] Step: [0] Batch Time: 0.1415 (0.1601) Data Time: 0.0108 (0.0265) Average Loss: 1.0583 (1.0792) Average CE Loss (Source):  1.0583 ( 1.0792) Learning Rate: 0.1000 (0.1000) Top1_base: 71.8750 (70.0493) Top1_base_per_class: 72.4854 (70.4432) 
Training Epoch: [39/1000] Step: [10 / 285] Batch Time: 0.1795 (0.2295) Data Time: 0.0487 (0.0971) Average Loss: 0.9221 (1.0220) Average CE Loss (Source):  0.9221 ( 1.0220) Learning Rate: 0.1000 (0.1000) Top1_base: 73.4375 (72.3438) Top1_base_per_class: 76.8519 (73.1021) 
Training Epoch: [39/1000] Step: [20 / 285] Batch Time: 0.1483 (0.1975) Data Time: 0.0122 (0.0642) Average Loss: 0.9572 (1.0391) Average CE Loss (Source):  0.9572 ( 1.0391) Learning Rate: 0.1000 (0.1000) Top1_base: 75.7812 (72.3047) Top1_base_per_class: 75.8000 (72.8789) 
Training Epoch: [39/1000] Step: [30 / 285] Batch Time: 0.1694 (0.1846) Data Time: 0.0372 (0.0509) Average Loss: 1.2549 (1.0714) Average CE Loss (Source):  1.2549 ( 1.0714) Learning Rate: 0.1000 (0.1000) Top1_base: 68.7500 (71.4583) Top1_base_per_class: 70.5932 (71.9385) 
Training Epoch: [39/1000] Step: [40 / 285] Batch Time: 0.1461 (0.1769) Data Time: 0.0110 (0.0431) Average Loss: 0.8910 (1.0557) Average CE Loss (Source):  0.8910 ( 1.0557) Learning Rate: 0.1000 (0.1000) Top1_base: 74.2188 (71.9922) Top1_base_per_class: 72.6730 (72.7713) 
Training Epoch: [39/1000] Step: [50 / 285] Batch Time: 0.1732 (0.1756) Data Time: 0.0398 (0.0418) Average Loss: 1.0711 (1.0597) Average CE Loss (Source):  1.0711 ( 1.0597) Learning Rate: 0.1000 (0.1000) Top1_base: 71.0938 (71.5781) Top1_base_per_class: 68.3908 (72.1445) 
Training Epoch: [39/1000] Step: [60 / 285] Batch Time: 0.1463 (0.1724) Data Time: 0.0127 (0.0385) Average Loss: 1.0563 (1.0548) Average CE Loss (Source):  1.0563 ( 1.0548) Learning Rate: 0.1000 (0.1000) Top1_base: 73.4375 (71.6406) Top1_base_per_class: 71.3242 (72.1095) 
Training Epoch: [39/1000] Step: [70 / 285] Batch Time: 0.1513 (0.1694) Data Time: 0.0184 (0.0354) Average Loss: 1.1256 (1.0535) Average CE Loss (Source):  1.1256 ( 1.0535) Learning Rate: 0.1000 (0.1000) Top1_base: 68.7500 (71.5067) Top1_base_per_class: 71.2865 (71.9716) 
Training Epoch: [39/1000] Step: [80 / 285] Batch Time: 0.1467 (0.1674) Data Time: 0.0116 (0.0335) Average Loss: 1.2046 (1.0517) Average CE Loss (Source):  1.2046 ( 1.0517) Learning Rate: 0.1000 (0.1000) Top1_base: 71.8750 (71.5234) Top1_base_per_class: 72.7678 (71.8888) 
Training Epoch: [39/1000] Step: [90 / 285] Batch Time: 0.1514 (0.1667) Data Time: 0.0188 (0.0327) Average Loss: 0.8316 (1.0504) Average CE Loss (Source):  0.8316 ( 1.0504) Learning Rate: 0.1000 (0.1000) Top1_base: 78.9062 (71.5799) Top1_base_per_class: 78.9198 (71.9443) 
Training Epoch: [39/1000] Step: [100 / 285] Batch Time: 0.1450 (0.1667) Data Time: 0.0112 (0.0329) Average Loss: 1.0437 (1.0507) Average CE Loss (Source):  1.0437 ( 1.0507) Learning Rate: 0.1000 (0.1000) Top1_base: 75.0000 (71.5625) Top1_base_per_class: 75.9222 (71.8080) 
Training Epoch: [39/1000] Step: [110 / 285] Batch Time: 0.1494 (0.1656) Data Time: 0.0167 (0.0317) Average Loss: 1.3391 (1.0473) Average CE Loss (Source):  1.3391 ( 1.0473) Learning Rate: 0.1000 (0.1000) Top1_base: 63.2812 (71.6122) Top1_base_per_class: 63.3616 (71.7029) 
Training Epoch: [39/1000] Step: [120 / 285] Batch Time: 0.1467 (0.1650) Data Time: 0.0106 (0.0312) Average Loss: 1.2647 (1.0469) Average CE Loss (Source):  1.2647 ( 1.0469) Learning Rate: 0.1000 (0.1000) Top1_base: 67.9688 (71.5755) Top1_base_per_class: 67.7866 (71.7759) 
Training Epoch: [39/1000] Step: [130 / 285] Batch Time: 0.1488 (0.1640) Data Time: 0.0167 (0.0302) Average Loss: 1.1440 (1.0502) Average CE Loss (Source):  1.1440 ( 1.0502) Learning Rate: 0.1000 (0.1000) Top1_base: 71.8750 (71.5024) Top1_base_per_class: 69.9074 (71.7328) 
Training Epoch: [39/1000] Step: [140 / 285] Batch Time: 0.1450 (0.1632) Data Time: 0.0107 (0.0294) Average Loss: 1.0768 (1.0505) Average CE Loss (Source):  1.0768 ( 1.0505) Learning Rate: 0.1000 (0.1000) Top1_base: 66.4062 (71.5123) Top1_base_per_class: 63.6164 (71.7976) 
Training Epoch: [39/1000] Step: [150 / 285] Batch Time: 0.1492 (0.1623) Data Time: 0.0163 (0.0286) Average Loss: 1.0111 (1.0491) Average CE Loss (Source):  1.0111 ( 1.0491) Learning Rate: 0.1000 (0.1000) Top1_base: 71.8750 (71.5729) Top1_base_per_class: 71.2429 (71.8430) 
Training Epoch: [39/1000] Step: [160 / 285] Batch Time: 0.1463 (0.1614) Data Time: 0.0111 (0.0277) Average Loss: 1.1802 (1.0477) Average CE Loss (Source):  1.1802 ( 1.0477) Learning Rate: 0.1000 (0.1000) Top1_base: 67.9688 (71.5820) Top1_base_per_class: 69.5833 (71.8701) 
Training Epoch: [39/1000] Step: [170 / 285] Batch Time: 0.1501 (0.1607) Data Time: 0.0175 (0.0269) Average Loss: 1.1697 (1.0533) Average CE Loss (Source):  1.1697 ( 1.0533) Learning Rate: 0.1000 (0.1000) Top1_base: 71.0938 (71.4292) Top1_base_per_class: 73.3333 (71.7434) 
Training Epoch: [39/1000] Step: [180 / 285] Batch Time: 0.1474 (0.1601) Data Time: 0.0114 (0.0262) Average Loss: 1.1602 (1.0538) Average CE Loss (Source):  1.1602 ( 1.0538) Learning Rate: 0.1000 (0.1000) Top1_base: 67.9688 (71.2891) Top1_base_per_class: 68.5034 (71.6492) 
Training Epoch: [39/1000] Step: [190 / 285] Batch Time: 0.1525 (0.1596) Data Time: 0.0171 (0.0258) Average Loss: 1.1204 (1.0574) Average CE Loss (Source):  1.1204 ( 1.0574) Learning Rate: 0.1000 (0.1000) Top1_base: 71.8750 (71.1883) Top1_base_per_class: 74.5906 (71.6113) 
Training Epoch: [39/1000] Step: [200 / 285] Batch Time: 0.1461 (0.1591) Data Time: 0.0113 (0.0253) Average Loss: 1.2695 (1.0607) Average CE Loss (Source):  1.2695 ( 1.0607) Learning Rate: 0.1000 (0.1000) Top1_base: 68.7500 (71.0820) Top1_base_per_class: 69.2453 (71.4482) 
Training Epoch: [39/1000] Step: [210 / 285] Batch Time: 0.1662 (0.1589) Data Time: 0.0336 (0.0252) Average Loss: 1.1088 (1.0659) Average CE Loss (Source):  1.1088 ( 1.0659) Learning Rate: 0.1000 (0.1000) Top1_base: 67.9688 (70.9263) Top1_base_per_class: 70.4971 (71.3074) 
Training Epoch: [39/1000] Step: [220 / 285] Batch Time: 0.1458 (0.1594) Data Time: 0.0107 (0.0257) Average Loss: 1.3994 (1.0675) Average CE Loss (Source):  1.3994 ( 1.0675) Learning Rate: 0.1000 (0.1000) Top1_base: 61.7188 (70.8381) Top1_base_per_class: 64.0179 (71.2160) 
Training Epoch: [39/1000] Step: [230 / 285] Batch Time: 0.1489 (0.1588) Data Time: 0.0166 (0.0252) Average Loss: 1.1746 (1.0716) Average CE Loss (Source):  1.1746 ( 1.0716) Learning Rate: 0.1000 (0.1000) Top1_base: 67.9688 (70.7303) Top1_base_per_class: 68.0782 (71.1304) 
Training Epoch: [39/1000] Step: [240 / 285] Batch Time: 0.1454 (0.1583) Data Time: 0.0106 (0.0247) Average Loss: 1.0145 (1.0746) Average CE Loss (Source):  1.0145 ( 1.0746) Learning Rate: 0.1000 (0.1000) Top1_base: 71.8750 (70.6348) Top1_base_per_class: 72.4038 (71.0323) 
Training Epoch: [39/1000] Step: [250 / 285] Batch Time: 0.1486 (0.1584) Data Time: 0.0163 (0.0248) Average Loss: 1.2208 (1.0739) Average CE Loss (Source):  1.2208 ( 1.0739) Learning Rate: 0.1000 (0.1000) Top1_base: 62.5000 (70.6125) Top1_base_per_class: 60.3704 (70.9718) 
Training Epoch: [39/1000] Step: [260 / 285] Batch Time: 0.1445 (0.1581) Data Time: 0.0106 (0.0245) Average Loss: 0.9898 (1.0720) Average CE Loss (Source):  0.9898 ( 1.0720) Learning Rate: 0.1000 (0.1000) Top1_base: 68.7500 (70.6731) Top1_base_per_class: 70.6116 (71.0978) 
Training Epoch: [39/1000] Step: [270 / 285] Batch Time: 0.1476 (0.1577) Data Time: 0.0153 (0.0241) Average Loss: 1.0302 (1.0741) Average CE Loss (Source):  1.0302 ( 1.0741) Learning Rate: 0.1000 (0.1000) Top1_base: 72.6562 (70.5845) Top1_base_per_class: 71.1012 (70.9463) 
Training Epoch: [39/1000] Step: [280 / 285] Batch Time: 0.1455 (0.1573) Data Time: 0.0107 (0.0238) Average Loss: 1.0179 (1.0745) Average CE Loss (Source):  1.0179 ( 1.0745) Learning Rate: 0.1000 (0.1000) Top1_base: 71.8750 (70.5497) Top1_base_per_class: 70.8182 (70.8650) 
Training Epoch: [40/1000] Step: [0] Batch Time: 0.1462 (0.1571) Data Time: 0.0130 (0.0236) Average Loss: 1.1788 (1.0752) Average CE Loss (Source):  1.1788 ( 1.0752) Learning Rate: 0.1000 (0.1000) Top1_base: 66.4062 (70.5482) Top1_base_per_class: 65.8654 (70.8512) 
  4%|▍         | 40/1000 [31:51<12:29:52, 46.87s/it]  4%|▍         | 41/1000 [32:35<12:17:49, 46.16s/it]Training Epoch: [40/1000] Step: [10 / 285] Batch Time: 0.1470 (0.2375) Data Time: 0.0108 (0.1033) Average Loss: 1.0603 (0.9912) Average CE Loss (Source):  1.0603 ( 0.9912) Learning Rate: 0.1000 (0.1000) Top1_base: 71.0938 (72.5000) Top1_base_per_class: 72.0390 (72.9976) 
Training Epoch: [40/1000] Step: [20 / 285] Batch Time: 0.1478 (0.1969) Data Time: 0.0170 (0.0636) Average Loss: 1.1577 (1.0391) Average CE Loss (Source):  1.1577 ( 1.0391) Learning Rate: 0.1000 (0.1000) Top1_base: 68.7500 (70.9375) Top1_base_per_class: 65.0327 (71.2723) 
Training Epoch: [40/1000] Step: [30 / 285] Batch Time: 0.1461 (0.1818) Data Time: 0.0125 (0.0487) Average Loss: 1.0981 (1.0426) Average CE Loss (Source):  1.0981 ( 1.0426) Learning Rate: 0.1000 (0.1000) Top1_base: 67.1875 (70.5208) Top1_base_per_class: 68.3626 (71.0475) 
Training Epoch: [40/1000] Step: [40 / 285] Batch Time: 0.1510 (0.1738) Data Time: 0.0160 (0.0401) Average Loss: 1.1594 (1.0556) Average CE Loss (Source):  1.1594 ( 1.0556) Learning Rate: 0.1000 (0.1000) Top1_base: 69.5312 (70.1562) Top1_base_per_class: 69.6491 (70.5678) 
Training Epoch: [40/1000] Step: [50 / 285] Batch Time: 0.1429 (0.1685) Data Time: 0.0117 (0.0349) Average Loss: 0.8889 (1.0456) Average CE Loss (Source):  0.8889 ( 1.0456) Learning Rate: 0.1000 (0.1000) Top1_base: 75.7812 (70.5312) Top1_base_per_class: 74.1228 (71.0369) 
Training Epoch: [40/1000] Step: [60 / 285] Batch Time: 0.1477 (0.1649) Data Time: 0.0158 (0.0314) Average Loss: 0.8402 (1.0429) Average CE Loss (Source):  0.8402 ( 1.0429) Learning Rate: 0.1000 (0.1000) Top1_base: 75.7812 (70.6250) Top1_base_per_class: 73.1508 (71.1897) 
Training Epoch: [40/1000] Step: [70 / 285] Batch Time: 0.1458 (0.1623) Data Time: 0.0131 (0.0289) Average Loss: 1.0905 (1.0487) Average CE Loss (Source):  1.0905 ( 1.0487) Learning Rate: 0.1000 (0.1000) Top1_base: 71.8750 (70.6920) Top1_base_per_class: 71.5819 (71.2972) 
Training Epoch: [40/1000] Step: [80 / 285] Batch Time: 0.2124 (0.1615) Data Time: 0.0779 (0.0278) Average Loss: 0.9611 (1.0487) Average CE Loss (Source):  0.9611 ( 1.0487) Learning Rate: 0.1000 (0.1000) Top1_base: 71.8750 (70.6445) Top1_base_per_class: 73.3631 (71.2792) 
Training Epoch: [40/1000] Step: [90 / 285] Batch Time: 0.1480 (0.1612) Data Time: 0.0106 (0.0272) Average Loss: 1.0747 (1.0524) Average CE Loss (Source):  1.0747 ( 1.0524) Learning Rate: 0.1000 (0.1000) Top1_base: 71.8750 (70.6771) Top1_base_per_class: 75.1323 (71.2821) 
Training Epoch: [40/1000] Step: [100 / 285] Batch Time: 0.1504 (0.1600) Data Time: 0.0165 (0.0258) Average Loss: 0.9813 (1.0580) Average CE Loss (Source):  0.9813 ( 1.0580) Learning Rate: 0.1000 (0.1000) Top1_base: 70.3125 (70.5469) Top1_base_per_class: 71.7836 (71.1540) 
Training Epoch: [40/1000] Step: [110 / 285] Batch Time: 0.1488 (0.1590) Data Time: 0.0116 (0.0249) Average Loss: 1.1144 (1.0570) Average CE Loss (Source):  1.1144 ( 1.0570) Learning Rate: 0.1000 (0.1000) Top1_base: 67.1875 (70.6108) Top1_base_per_class: 69.0196 (71.1112) 
Training Epoch: [40/1000] Step: [120 / 285] Batch Time: 0.1768 (0.1584) Data Time: 0.0418 (0.0242) Average Loss: 1.0526 (1.0534) Average CE Loss (Source):  1.0526 ( 1.0534) Learning Rate: 0.1000 (0.1000) Top1_base: 68.7500 (70.7422) Top1_base_per_class: 69.1813 (71.2522) 
Training Epoch: [40/1000] Step: [130 / 285] Batch Time: 0.1516 (0.1582) Data Time: 0.0145 (0.0239) Average Loss: 0.9813 (1.0539) Average CE Loss (Source):  0.9813 ( 1.0539) Learning Rate: 0.1000 (0.1000) Top1_base: 71.0938 (70.6851) Top1_base_per_class: 69.2262 (71.2501) 
Training Epoch: [40/1000] Step: [140 / 285] Batch Time: 0.1867 (0.1585) Data Time: 0.0549 (0.0241) Average Loss: 0.8336 (1.0545) Average CE Loss (Source):  0.8336 ( 1.0545) Learning Rate: 0.1000 (0.1000) Top1_base: 77.3438 (70.7087) Top1_base_per_class: 79.6491 (71.3280) 
Training Epoch: [40/1000] Step: [150 / 285] Batch Time: 0.1490 (0.1577) Data Time: 0.0126 (0.0235) Average Loss: 0.9745 (1.0552) Average CE Loss (Source):  0.9745 ( 1.0552) Learning Rate: 0.1000 (0.1000) Top1_base: 71.8750 (70.7708) Top1_base_per_class: 72.1914 (71.5856) 
Training Epoch: [40/1000] Step: [160 / 285] Batch Time: 0.1572 (0.1573) Data Time: 0.0240 (0.0230) Average Loss: 1.1063 (1.0525) Average CE Loss (Source):  1.1063 ( 1.0525) Learning Rate: 0.1000 (0.1000) Top1_base: 71.0938 (70.8740) Top1_base_per_class: 74.6364 (71.7479) 
Training Epoch: [40/1000] Step: [170 / 285] Batch Time: 0.1496 (0.1570) Data Time: 0.0109 (0.0226) Average Loss: 1.3683 (1.0541) Average CE Loss (Source):  1.3683 ( 1.0541) Learning Rate: 0.1000 (0.1000) Top1_base: 60.1562 (70.9099) Top1_base_per_class: 62.5439 (71.7995) 
Training Epoch: [40/1000] Step: [180 / 285] Batch Time: 0.1523 (0.1566) Data Time: 0.0189 (0.0222) Average Loss: 1.1026 (1.0541) Average CE Loss (Source):  1.1026 ( 1.0541) Learning Rate: 0.1000 (0.1000) Top1_base: 71.0938 (70.8984) Top1_base_per_class: 70.7273 (71.7887) 
Training Epoch: [40/1000] Step: [190 / 285] Batch Time: 0.1462 (0.1561) Data Time: 0.0105 (0.0217) Average Loss: 0.9478 (1.0550) Average CE Loss (Source):  0.9478 ( 1.0550) Learning Rate: 0.1000 (0.1000) Top1_base: 74.2188 (70.8059) Top1_base_per_class: 72.5472 (71.6686) 
Training Epoch: [40/1000] Step: [200 / 285] Batch Time: 0.1520 (0.1558) Data Time: 0.0182 (0.0213) Average Loss: 0.8866 (1.0523) Average CE Loss (Source):  0.8866 ( 1.0523) Learning Rate: 0.1000 (0.1000) Top1_base: 72.6562 (70.8320) Top1_base_per_class: 70.3571 (71.6241) 
Training Epoch: [40/1000] Step: [210 / 285] Batch Time: 0.1500 (0.1555) Data Time: 0.0119 (0.0210) Average Loss: 1.1042 (1.0509) Average CE Loss (Source):  1.1042 ( 1.0509) Learning Rate: 0.1000 (0.1000) Top1_base: 71.0938 (70.9301) Top1_base_per_class: 73.9737 (71.6996) 
Training Epoch: [40/1000] Step: [220 / 285] Batch Time: 0.1503 (0.1553) Data Time: 0.0165 (0.0207) Average Loss: 1.4113 (1.0530) Average CE Loss (Source):  1.4113 ( 1.0530) Learning Rate: 0.1000 (0.1000) Top1_base: 60.1562 (70.8381) Top1_base_per_class: 54.7321 (71.5688) 
Training Epoch: [40/1000] Step: [230 / 285] Batch Time: 0.1469 (0.1552) Data Time: 0.0106 (0.0206) Average Loss: 0.9379 (1.0522) Average CE Loss (Source):  0.9379 ( 1.0522) Learning Rate: 0.1000 (0.1000) Top1_base: 72.6562 (70.9137) Top1_base_per_class: 72.4074 (71.6253) 
Training Epoch: [40/1000] Step: [240 / 285] Batch Time: 0.1527 (0.1558) Data Time: 0.0179 (0.0211) Average Loss: 1.0359 (1.0551) Average CE Loss (Source):  1.0359 ( 1.0551) Learning Rate: 0.1000 (0.1000) Top1_base: 70.3125 (70.8496) Top1_base_per_class: 68.2749 (71.5735) 
Training Epoch: [40/1000] Step: [250 / 285] Batch Time: 0.1441 (0.1554) Data Time: 0.0127 (0.0208) Average Loss: 1.1119 (1.0567) Average CE Loss (Source):  1.1119 ( 1.0567) Learning Rate: 0.1000 (0.1000) Top1_base: 71.0938 (70.8469) Top1_base_per_class: 72.0081 (71.5465) 
Training Epoch: [40/1000] Step: [260 / 285] Batch Time: 0.1456 (0.1557) Data Time: 0.0148 (0.0212) Average Loss: 1.0458 (1.0594) Average CE Loss (Source):  1.0458 ( 1.0594) Learning Rate: 0.1000 (0.1000) Top1_base: 67.9688 (70.7632) Top1_base_per_class: 65.3672 (71.4480) 
Training Epoch: [40/1000] Step: [270 / 285] Batch Time: 0.1431 (0.1558) Data Time: 0.0103 (0.0213) Average Loss: 1.3370 (1.0641) Average CE Loss (Source):  1.3370 ( 1.0641) Learning Rate: 0.1000 (0.1000) Top1_base: 64.0625 (70.6510) Top1_base_per_class: 65.0629 (71.3585) 
Training Epoch: [40/1000] Step: [280 / 285] Batch Time: 0.1426 (0.1559) Data Time: 0.0101 (0.0215) Average Loss: 0.8647 (1.0645) Average CE Loss (Source):  0.8647 ( 1.0645) Learning Rate: 0.1000 (0.1000) Top1_base: 72.6562 (70.6529) Top1_base_per_class: 75.4762 (71.3380) 
Training Epoch: [41/1000] Step: [0] Batch Time: 0.1929 (0.1560) Data Time: 0.0626 (0.0216) Average Loss: 1.0848 (1.0639) Average CE Loss (Source):  1.0848 ( 1.0639) Learning Rate: 0.1000 (0.1000) Top1_base: 70.3125 (70.6689) Top1_base_per_class: 67.8245 (71.3684) 
Training Epoch: [41/1000] Step: [10 / 285] Batch Time: 0.1474 (0.2295) Data Time: 0.0134 (0.0959) Average Loss: 1.2639 (1.0470) Average CE Loss (Source):  1.2639 ( 1.0470) Learning Rate: 0.1000 (0.1000) Top1_base: 64.0625 (70.3125) Top1_base_per_class: 67.1914 (72.0782) 
Training Epoch: [41/1000] Step: [20 / 285] Batch Time: 0.1490 (0.1968) Data Time: 0.0150 (0.0632) Average Loss: 1.0660 (1.0407) Average CE Loss (Source):  1.0660 ( 1.0407) Learning Rate: 0.1000 (0.1000) Top1_base: 70.3125 (70.9766) Top1_base_per_class: 68.6000 (71.8380) 
Training Epoch: [41/1000] Step: [30 / 285] Batch Time: 0.1726 (0.1855) Data Time: 0.0399 (0.0519) Average Loss: 1.1481 (1.0253) Average CE Loss (Source):  1.1481 ( 1.0253) Learning Rate: 0.1000 (0.1000) Top1_base: 73.4375 (71.3542) Top1_base_per_class: 73.3333 (72.0717) 
Training Epoch: [41/1000] Step: [40 / 285] Batch Time: 0.1488 (0.1779) Data Time: 0.0136 (0.0445) Average Loss: 1.0125 (1.0291) Average CE Loss (Source):  1.0125 ( 1.0291) Learning Rate: 0.1000 (0.1000) Top1_base: 71.8750 (71.3281) Top1_base_per_class: 75.7233 (71.6409) 
Training Epoch: [41/1000] Step: [50 / 285] Batch Time: 0.1658 (0.1740) Data Time: 0.0343 (0.0406) Average Loss: 1.0745 (1.0285) Average CE Loss (Source):  1.0745 ( 1.0285) Learning Rate: 0.1000 (0.1000) Top1_base: 66.4062 (70.8594) Top1_base_per_class: 62.0175 (71.1342) 
Training Epoch: [41/1000] Step: [60 / 285] Batch Time: 0.1434 (0.1726) Data Time: 0.0121 (0.0392) Average Loss: 0.9905 (1.0221) Average CE Loss (Source):  0.9905 ( 1.0221) Learning Rate: 0.1000 (0.1000) Top1_base: 67.1875 (71.1719) Top1_base_per_class: 64.7024 (71.2468) 
Training Epoch: [41/1000] Step: [70 / 285] Batch Time: 0.2682 (0.1710) Data Time: 0.1366 (0.0377) Average Loss: 1.1993 (1.0248) Average CE Loss (Source):  1.1993 ( 1.0248) Learning Rate: 0.1000 (0.1000) Top1_base: 68.7500 (71.1496) Top1_base_per_class: 67.5926 (71.0505) 
Training Epoch: [41/1000] Step: [80 / 285] Batch Time: 0.1435 (0.1689) Data Time: 0.0125 (0.0357) Average Loss: 0.8118 (1.0271) Average CE Loss (Source):  0.8118 ( 1.0271) Learning Rate: 0.1000 (0.1000) Top1_base: 73.4375 (71.0840) Top1_base_per_class: 77.6389 (71.1572) 
Training Epoch: [41/1000] Step: [90 / 285] Batch Time: 0.1538 (0.1667) Data Time: 0.0196 (0.0335) Average Loss: 1.2032 (1.0335) Average CE Loss (Source):  1.2032 ( 1.0335) Learning Rate: 0.1000 (0.1000) Top1_base: 65.6250 (70.9896) Top1_base_per_class: 68.5455 (71.2178) 
Training Epoch: [41/1000] Step: [100 / 285] Batch Time: 0.1479 (0.1650) Data Time: 0.0148 (0.0317) Average Loss: 1.2365 (1.0412) Average CE Loss (Source):  1.2365 ( 1.0412) Learning Rate: 0.1000 (0.1000) Top1_base: 66.4062 (70.8984) Top1_base_per_class: 67.2876 (71.1498) 
Training Epoch: [41/1000] Step: [110 / 285] Batch Time: 0.1921 (0.1656) Data Time: 0.0594 (0.0323) Average Loss: 1.0272 (1.0389) Average CE Loss (Source):  1.0272 ( 1.0389) Learning Rate: 0.1000 (0.1000) Top1_base: 75.0000 (70.9446) Top1_base_per_class: 73.9091 (71.2038) 
Training Epoch: [41/1000] Step: [120 / 285] Batch Time: 0.1432 (0.1647) Data Time: 0.0119 (0.0314) Average Loss: 1.2938 (1.0363) Average CE Loss (Source):  1.2938 ( 1.0363) Learning Rate: 0.1000 (0.1000) Top1_base: 64.8438 (71.0091) Top1_base_per_class: 61.0672 (71.2273) 
Training Epoch: [41/1000] Step: [130 / 285] Batch Time: 0.1941 (0.1636) Data Time: 0.0610 (0.0304) Average Loss: 0.9967 (1.0333) Average CE Loss (Source):  0.9967 ( 1.0333) Learning Rate: 0.1000 (0.1000) Top1_base: 71.0938 (71.1538) Top1_base_per_class: 71.0452 (71.3046) 
Training Epoch: [41/1000] Step: [140 / 285] Batch Time: 0.1431 (0.1632) Data Time: 0.0123 (0.0300) Average Loss: 1.2776 (1.0336) Average CE Loss (Source):  1.2776 ( 1.0336) Learning Rate: 0.1000 (0.1000) Top1_base: 65.6250 (71.1217) Top1_base_per_class: 66.4771 (71.3114) 
Training Epoch: [41/1000] Step: [150 / 285] Batch Time: 0.1492 (0.1621) Data Time: 0.0175 (0.0289) Average Loss: 1.1466 (1.0368) Average CE Loss (Source):  1.1466 ( 1.0368) Learning Rate: 0.1000 (0.1000) Top1_base: 67.1875 (71.0625) Top1_base_per_class: 65.6494 (71.2114) 
Training Epoch: [41/1000] Step: [160 / 285] Batch Time: 0.1457 (0.1614) Data Time: 0.0137 (0.0283) Average Loss: 0.9314 (1.0411) Average CE Loss (Source):  0.9314 ( 1.0411) Learning Rate: 0.1000 (0.1000) Top1_base: 70.3125 (71.0010) Top1_base_per_class: 66.6667 (71.2129) 
Training Epoch: [41/1000] Step: [170 / 285] Batch Time: 0.1773 (0.1608) Data Time: 0.0439 (0.0277) Average Loss: 0.9721 (1.0423) Average CE Loss (Source):  0.9721 ( 1.0423) Learning Rate: 0.1000 (0.1000) Top1_base: 71.8750 (70.9191) Top1_base_per_class: 74.7090 (71.2202) 
Training Epoch: [41/1000] Step: [180 / 285] Batch Time: 0.1499 (0.1605) Data Time: 0.0151 (0.0273) Average Loss: 1.1525 (1.0477) Average CE Loss (Source):  1.1525 ( 1.0477) Learning Rate: 0.1000 (0.1000) Top1_base: 71.0938 (70.7335) Top1_base_per_class: 71.4545 (71.0414) 
Training Epoch: [41/1000] Step: [190 / 285] Batch Time: 0.1656 (0.1604) Data Time: 0.0345 (0.0272) Average Loss: 1.1101 (1.0527) Average CE Loss (Source):  1.1101 ( 1.0527) Learning Rate: 0.1000 (0.1000) Top1_base: 68.7500 (70.6497) Top1_base_per_class: 67.7679 (71.0262) 
Training Epoch: [41/1000] Step: [200 / 285] Batch Time: 0.1471 (0.1601) Data Time: 0.0139 (0.0269) Average Loss: 1.0056 (1.0552) Average CE Loss (Source):  1.0056 ( 1.0552) Learning Rate: 0.1000 (0.1000) Top1_base: 70.3125 (70.4961) Top1_base_per_class: 72.2327 (70.8355) 
Training Epoch: [41/1000] Step: [210 / 285] Batch Time: 0.2071 (0.1597) Data Time: 0.0749 (0.0266) Average Loss: 1.0646 (1.0557) Average CE Loss (Source):  1.0646 ( 1.0557) Learning Rate: 0.1000 (0.1000) Top1_base: 71.8750 (70.4688) Top1_base_per_class: 72.2414 (70.8269) 
Training Epoch: [41/1000] Step: [220 / 285] Batch Time: 0.1466 (0.1591) Data Time: 0.0121 (0.0260) Average Loss: 1.1000 (1.0594) Average CE Loss (Source):  1.1000 ( 1.0594) Learning Rate: 0.1000 (0.1000) Top1_base: 71.0938 (70.3480) Top1_base_per_class: 70.3369 (70.7210) 
Training Epoch: [41/1000] Step: [230 / 285] Batch Time: 0.2381 (0.1590) Data Time: 0.1065 (0.0259) Average Loss: 0.9502 (1.0582) Average CE Loss (Source):  0.9502 ( 1.0582) Learning Rate: 0.1000 (0.1000) Top1_base: 75.0000 (70.4042) Top1_base_per_class: 79.4242 (70.8093) 
Training Epoch: [41/1000] Step: [240 / 285] Batch Time: 0.1477 (0.1586) Data Time: 0.0136 (0.0255) Average Loss: 0.8855 (1.0626) Average CE Loss (Source):  0.8855 ( 1.0626) Learning Rate: 0.1000 (0.1000) Top1_base: 75.0000 (70.3288) Top1_base_per_class: 78.7000 (70.7189) 
Training Epoch: [41/1000] Step: [250 / 285] Batch Time: 0.1489 (0.1584) Data Time: 0.0144 (0.0253) Average Loss: 1.3247 (1.0665) Average CE Loss (Source):  1.3247 ( 1.0665) Learning Rate: 0.1000 (0.1000) Top1_base: 63.2812 (70.2094) Top1_base_per_class: 62.8268 (70.6118) 
Training Epoch: [41/1000] Step: [260 / 285] Batch Time: 0.1487 (0.1583) Data Time: 0.0140 (0.0252) Average Loss: 1.0686 (1.0667) Average CE Loss (Source):  1.0686 ( 1.0667) Learning Rate: 0.1000 (0.1000) Top1_base: 71.8750 (70.1653) Top1_base_per_class: 70.7759 (70.5551) 
Training Epoch: [41/1000] Step: [270 / 285] Batch Time: 0.1491 (0.1579) Data Time: 0.0163 (0.0248) Average Loss: 1.1505 (1.0657) Average CE Loss (Source):  1.1505 ( 1.0657) Learning Rate: 0.1000 (0.1000) Top1_base: 67.9688 (70.2228) Top1_base_per_class: 67.5383 (70.6158) 
Training Epoch: [41/1000] Step: [280 / 285] Batch Time: 0.1494 (0.1581) Data Time: 0.0134 (0.0249) Average Loss: 1.1211 (1.0658) Average CE Loss (Source):  1.1211 ( 1.0658) Learning Rate: 0.1000 (0.1000) Top1_base: 68.7500 (70.2539) Top1_base_per_class: 70.5952 (70.6487) 
Training Epoch: [42/1000] Step: [0] Batch Time: 0.1420 (0.1579) Data Time: 0.0098 (0.0247) Average Loss: 1.1570 (1.0653) Average CE Loss (Source):  1.1570 ( 1.0653) Learning Rate: 0.1000 (0.1000) Top1_base: 67.9688 (70.2659) Top1_base_per_class: 69.4444 (70.6575) 
  4%|▍         | 42/1000 [33:23<12:25:06, 46.67s/it]  4%|▍         | 43/1000 [34:08<12:14:06, 46.03s/it]Training Epoch: [42/1000] Step: [10 / 285] Batch Time: 0.1524 (0.2273) Data Time: 0.0146 (0.0926) Average Loss: 1.0656 (1.0450) Average CE Loss (Source):  1.0656 ( 1.0450) Learning Rate: 0.1000 (0.1000) Top1_base: 70.3125 (71.5625) Top1_base_per_class: 70.6548 (72.0270) 
Training Epoch: [42/1000] Step: [20 / 285] Batch Time: 0.1536 (0.1932) Data Time: 0.0162 (0.0581) Average Loss: 1.2173 (1.0100) Average CE Loss (Source):  1.2173 ( 1.0100) Learning Rate: 0.1000 (0.1000) Top1_base: 68.7500 (72.1875) Top1_base_per_class: 68.5220 (72.6099) 
Training Epoch: [42/1000] Step: [30 / 285] Batch Time: 0.1477 (0.1812) Data Time: 0.0148 (0.0458) Average Loss: 1.2172 (1.0487) Average CE Loss (Source):  1.2172 ( 1.0487) Learning Rate: 0.1000 (0.1000) Top1_base: 70.3125 (71.4583) Top1_base_per_class: 71.2179 (71.8736) 
Training Epoch: [42/1000] Step: [40 / 285] Batch Time: 0.1555 (0.1751) Data Time: 0.0174 (0.0391) Average Loss: 0.9195 (1.0406) Average CE Loss (Source):  0.9195 ( 1.0406) Learning Rate: 0.1000 (0.1000) Top1_base: 77.3438 (71.8164) Top1_base_per_class: 82.7423 (72.5284) 
Training Epoch: [42/1000] Step: [50 / 285] Batch Time: 0.1478 (0.1704) Data Time: 0.0137 (0.0345) Average Loss: 1.1005 (1.0490) Average CE Loss (Source):  1.1005 ( 1.0490) Learning Rate: 0.1000 (0.1000) Top1_base: 73.4375 (71.5156) Top1_base_per_class: 75.8333 (72.2296) 
Training Epoch: [42/1000] Step: [60 / 285] Batch Time: 0.1557 (0.1673) Data Time: 0.0174 (0.0312) Average Loss: 1.0392 (1.0409) Average CE Loss (Source):  1.0392 ( 1.0409) Learning Rate: 0.1000 (0.1000) Top1_base: 70.3125 (71.5885) Top1_base_per_class: 65.6289 (72.2694) 
Training Epoch: [42/1000] Step: [70 / 285] Batch Time: 0.1497 (0.1646) Data Time: 0.0127 (0.0287) Average Loss: 0.9803 (1.0369) Average CE Loss (Source):  0.9803 ( 1.0369) Learning Rate: 0.1000 (0.1000) Top1_base: 70.3125 (71.7076) Top1_base_per_class: 68.5246 (72.4711) 
Training Epoch: [42/1000] Step: [80 / 285] Batch Time: 0.1465 (0.1625) Data Time: 0.0146 (0.0269) Average Loss: 0.8842 (1.0276) Average CE Loss (Source):  0.8842 ( 1.0276) Learning Rate: 0.1000 (0.1000) Top1_base: 79.6875 (72.0020) Top1_base_per_class: 82.2876 (72.5982) 
Training Epoch: [42/1000] Step: [90 / 285] Batch Time: 0.1455 (0.1609) Data Time: 0.0137 (0.0255) Average Loss: 0.9334 (1.0264) Average CE Loss (Source):  0.9334 ( 1.0264) Learning Rate: 0.1000 (0.1000) Top1_base: 75.7812 (71.9618) Top1_base_per_class: 77.5146 (72.6548) 
Training Epoch: [42/1000] Step: [100 / 285] Batch Time: 0.1553 (0.1598) Data Time: 0.0175 (0.0244) Average Loss: 0.9666 (1.0298) Average CE Loss (Source):  0.9666 ( 1.0298) Learning Rate: 0.1000 (0.1000) Top1_base: 75.7812 (71.8438) Top1_base_per_class: 76.2346 (72.5148) 
Training Epoch: [42/1000] Step: [110 / 285] Batch Time: 0.1423 (0.1594) Data Time: 0.0106 (0.0240) Average Loss: 0.9078 (1.0303) Average CE Loss (Source):  0.9078 ( 1.0303) Learning Rate: 0.1000 (0.1000) Top1_base: 75.7812 (71.7472) Top1_base_per_class: 71.9048 (72.2980) 
Training Epoch: [42/1000] Step: [120 / 285] Batch Time: 0.1557 (0.1585) Data Time: 0.0188 (0.0232) Average Loss: 0.9072 (1.0342) Average CE Loss (Source):  0.9072 ( 1.0342) Learning Rate: 0.1000 (0.1000) Top1_base: 77.3438 (71.6797) Top1_base_per_class: 76.1905 (72.2149) 
Training Epoch: [42/1000] Step: [130 / 285] Batch Time: 0.1444 (0.1594) Data Time: 0.0103 (0.0240) Average Loss: 0.8703 (1.0295) Average CE Loss (Source):  0.8703 ( 1.0295) Learning Rate: 0.1000 (0.1000) Top1_base: 74.2188 (71.7067) Top1_base_per_class: 72.1923 (72.2422) 
Training Epoch: [42/1000] Step: [140 / 285] Batch Time: 0.1569 (0.1591) Data Time: 0.0175 (0.0236) Average Loss: 1.1165 (1.0289) Average CE Loss (Source):  1.1165 ( 1.0289) Learning Rate: 0.1000 (0.1000) Top1_base: 71.0938 (71.7411) Top1_base_per_class: 69.3350 (72.2586) 
Training Epoch: [42/1000] Step: [150 / 285] Batch Time: 0.1441 (0.1585) Data Time: 0.0112 (0.0230) Average Loss: 0.8184 (1.0289) Average CE Loss (Source):  0.8184 ( 1.0289) Learning Rate: 0.1000 (0.1000) Top1_base: 73.4375 (71.6979) Top1_base_per_class: 72.8931 (72.2029) 
Training Epoch: [42/1000] Step: [160 / 285] Batch Time: 0.1532 (0.1579) Data Time: 0.0178 (0.0225) Average Loss: 0.9929 (1.0315) Average CE Loss (Source):  0.9929 ( 1.0315) Learning Rate: 0.1000 (0.1000) Top1_base: 71.0938 (71.6260) Top1_base_per_class: 68.6172 (72.1601) 
Training Epoch: [42/1000] Step: [170 / 285] Batch Time: 0.1464 (0.1575) Data Time: 0.0147 (0.0222) Average Loss: 1.0492 (1.0361) Average CE Loss (Source):  1.0492 ( 1.0361) Learning Rate: 0.1000 (0.1000) Top1_base: 71.0938 (71.5303) Top1_base_per_class: 75.7692 (72.0853) 
Training Epoch: [42/1000] Step: [180 / 285] Batch Time: 0.1518 (0.1570) Data Time: 0.0173 (0.0218) Average Loss: 0.9731 (1.0379) Average CE Loss (Source):  0.9731 ( 1.0379) Learning Rate: 0.1000 (0.1000) Top1_base: 71.8750 (71.4453) Top1_base_per_class: 69.7663 (72.0336) 
Training Epoch: [42/1000] Step: [190 / 285] Batch Time: 0.1421 (0.1569) Data Time: 0.0103 (0.0218) Average Loss: 0.9321 (1.0411) Average CE Loss (Source):  0.9321 ( 1.0411) Learning Rate: 0.1000 (0.1000) Top1_base: 74.2188 (71.3158) Top1_base_per_class: 75.7008 (71.8393) 
Training Epoch: [42/1000] Step: [200 / 285] Batch Time: 0.1525 (0.1567) Data Time: 0.0186 (0.0217) Average Loss: 0.8414 (1.0421) Average CE Loss (Source):  0.8414 ( 1.0421) Learning Rate: 0.1000 (0.1000) Top1_base: 76.5625 (71.3008) Top1_base_per_class: 79.0756 (71.8422) 
Training Epoch: [42/1000] Step: [210 / 285] Batch Time: 0.1426 (0.1572) Data Time: 0.0108 (0.0222) Average Loss: 1.0094 (1.0416) Average CE Loss (Source):  1.0094 ( 1.0416) Learning Rate: 0.1000 (0.1000) Top1_base: 70.3125 (71.3542) Top1_base_per_class: 72.2222 (71.8778) 
Training Epoch: [42/1000] Step: [220 / 285] Batch Time: 0.1512 (0.1567) Data Time: 0.0145 (0.0218) Average Loss: 1.0677 (1.0415) Average CE Loss (Source):  1.0677 ( 1.0415) Learning Rate: 0.1000 (0.1000) Top1_base: 71.8750 (71.3601) Top1_base_per_class: 71.9209 (71.8604) 
Training Epoch: [42/1000] Step: [230 / 285] Batch Time: 0.1421 (0.1563) Data Time: 0.0103 (0.0215) Average Loss: 0.9419 (1.0425) Average CE Loss (Source):  0.9419 ( 1.0425) Learning Rate: 0.1000 (0.1000) Top1_base: 75.0000 (71.3111) Top1_base_per_class: 76.6082 (71.8273) 
Training Epoch: [42/1000] Step: [240 / 285] Batch Time: 0.1506 (0.1568) Data Time: 0.0152 (0.0220) Average Loss: 1.1643 (1.0410) Average CE Loss (Source):  1.1643 ( 1.0410) Learning Rate: 0.1000 (0.1000) Top1_base: 67.9688 (71.3802) Top1_base_per_class: 64.7619 (71.8948) 
Training Epoch: [42/1000] Step: [250 / 285] Batch Time: 0.1429 (0.1567) Data Time: 0.0112 (0.0220) Average Loss: 1.2050 (1.0432) Average CE Loss (Source):  1.2050 ( 1.0432) Learning Rate: 0.1000 (0.1000) Top1_base: 67.1875 (71.3031) Top1_base_per_class: 69.5455 (71.8472) 
Training Epoch: [42/1000] Step: [260 / 285] Batch Time: 0.1515 (0.1568) Data Time: 0.0153 (0.0221) Average Loss: 1.0231 (1.0461) Average CE Loss (Source):  1.0231 ( 1.0461) Learning Rate: 0.1000 (0.1000) Top1_base: 69.5312 (71.2230) Top1_base_per_class: 73.7288 (71.8238) 
Training Epoch: [42/1000] Step: [270 / 285] Batch Time: 0.1423 (0.1565) Data Time: 0.0103 (0.0219) Average Loss: 1.3224 (1.0472) Average CE Loss (Source):  1.3224 ( 1.0472) Learning Rate: 0.1000 (0.1000) Top1_base: 62.5000 (71.1603) Top1_base_per_class: 58.2222 (71.7179) 
Training Epoch: [42/1000] Step: [280 / 285] Batch Time: 0.1492 (0.1562) Data Time: 0.0145 (0.0216) Average Loss: 1.4185 (1.0499) Average CE Loss (Source):  1.4185 ( 1.0499) Learning Rate: 0.1000 (0.1000) Top1_base: 61.7188 (71.1300) Top1_base_per_class: 63.4524 (71.6815) 
Training Epoch: [43/1000] Step: [0] Batch Time: 0.1488 (0.1560) Data Time: 0.0159 (0.0215) Average Loss: 1.2010 (1.0501) Average CE Loss (Source):  1.2010 ( 1.0501) Learning Rate: 0.1000 (0.1000) Top1_base: 68.7500 (71.1294) Top1_base_per_class: 69.4654 (71.7005) 
Training Epoch: [43/1000] Step: [10 / 285] Batch Time: 0.1445 (0.2378) Data Time: 0.0122 (0.1039) Average Loss: 1.2423 (1.0113) Average CE Loss (Source):  1.2423 ( 1.0113) Learning Rate: 0.1000 (0.1000) Top1_base: 67.1875 (71.8750) Top1_base_per_class: 71.6369 (73.4200) 
Training Epoch: [43/1000] Step: [20 / 285] Batch Time: 0.1444 (0.2010) Data Time: 0.0130 (0.0676) Average Loss: 1.2025 (1.0298) Average CE Loss (Source):  1.2025 ( 1.0298) Learning Rate: 0.1000 (0.1000) Top1_base: 70.3125 (71.0547) Top1_base_per_class: 75.3216 (71.7664) 
Training Epoch: [43/1000] Step: [30 / 285] Batch Time: 0.1495 (0.1912) Data Time: 0.0138 (0.0577) Average Loss: 0.6918 (1.0005) Average CE Loss (Source):  0.6918 ( 1.0005) Learning Rate: 0.1000 (0.1000) Top1_base: 79.6875 (71.9792) Top1_base_per_class: 78.3333 (72.3065) 
Training Epoch: [43/1000] Step: [40 / 285] Batch Time: 0.1429 (0.1832) Data Time: 0.0122 (0.0499) Average Loss: 0.8806 (1.0019) Average CE Loss (Source):  0.8806 ( 1.0019) Learning Rate: 0.1000 (0.1000) Top1_base: 71.0938 (71.8750) Top1_base_per_class: 75.3160 (72.3864) 
Training Epoch: [43/1000] Step: [50 / 285] Batch Time: 0.1436 (0.1810) Data Time: 0.0123 (0.0479) Average Loss: 1.1577 (1.0139) Average CE Loss (Source):  1.1577 ( 1.0139) Learning Rate: 0.1000 (0.1000) Top1_base: 67.1875 (71.7188) Top1_base_per_class: 66.2356 (72.3441) 
Training Epoch: [43/1000] Step: [60 / 285] Batch Time: 0.1428 (0.1782) Data Time: 0.0115 (0.0452) Average Loss: 1.0706 (1.0121) Average CE Loss (Source):  1.0706 ( 1.0121) Learning Rate: 0.1000 (0.1000) Top1_base: 71.8750 (71.6016) Top1_base_per_class: 71.8713 (72.1555) 
Training Epoch: [43/1000] Step: [70 / 285] Batch Time: 0.1505 (0.1755) Data Time: 0.0158 (0.0425) Average Loss: 1.1958 (1.0091) Average CE Loss (Source):  1.1958 ( 1.0091) Learning Rate: 0.1000 (0.1000) Top1_base: 70.3125 (71.5067) Top1_base_per_class: 70.3448 (71.9824) 
Training Epoch: [43/1000] Step: [80 / 285] Batch Time: 0.1435 (0.1722) Data Time: 0.0109 (0.0390) Average Loss: 1.0323 (1.0084) Average CE Loss (Source):  1.0323 ( 1.0084) Learning Rate: 0.1000 (0.1000) Top1_base: 71.8750 (71.6309) Top1_base_per_class: 74.3590 (72.2604) 
Training Epoch: [43/1000] Step: [90 / 285] Batch Time: 0.1450 (0.1703) Data Time: 0.0138 (0.0368) Average Loss: 0.8229 (1.0120) Average CE Loss (Source):  0.8229 ( 1.0120) Learning Rate: 0.1000 (0.1000) Top1_base: 77.3438 (71.6233) Top1_base_per_class: 76.3272 (72.0818) 
Training Epoch: [43/1000] Step: [100 / 285] Batch Time: 0.1453 (0.1684) Data Time: 0.0131 (0.0349) Average Loss: 0.9820 (1.0100) Average CE Loss (Source):  0.9820 ( 1.0100) Learning Rate: 0.1000 (0.1000) Top1_base: 71.8750 (71.6016) Top1_base_per_class: 70.5247 (72.1216) 
Training Epoch: [43/1000] Step: [110 / 285] Batch Time: 0.1510 (0.1669) Data Time: 0.0157 (0.0334) Average Loss: 1.2099 (1.0103) Average CE Loss (Source):  1.2099 ( 1.0103) Learning Rate: 0.1000 (0.1000) Top1_base: 63.2812 (71.5554) Top1_base_per_class: 65.0309 (72.0790) 
Training Epoch: [43/1000] Step: [120 / 285] Batch Time: 0.1451 (0.1652) Data Time: 0.0121 (0.0318) Average Loss: 0.9352 (1.0141) Average CE Loss (Source):  0.9352 ( 1.0141) Learning Rate: 0.1000 (0.1000) Top1_base: 67.9688 (71.4323) Top1_base_per_class: 68.6441 (71.9357) 
Training Epoch: [43/1000] Step: [130 / 285] Batch Time: 0.1517 (0.1644) Data Time: 0.0149 (0.0308) Average Loss: 1.0422 (1.0129) Average CE Loss (Source):  1.0422 ( 1.0129) Learning Rate: 0.1000 (0.1000) Top1_base: 69.5312 (71.4784) Top1_base_per_class: 72.4675 (72.0263) 
Training Epoch: [43/1000] Step: [140 / 285] Batch Time: 0.1427 (0.1632) Data Time: 0.0115 (0.0297) Average Loss: 1.0607 (1.0136) Average CE Loss (Source):  1.0607 ( 1.0136) Learning Rate: 0.1000 (0.1000) Top1_base: 67.1875 (71.4286) Top1_base_per_class: 68.6017 (71.9070) 
Training Epoch: [43/1000] Step: [150 / 285] Batch Time: 0.1439 (0.1622) Data Time: 0.0128 (0.0287) Average Loss: 0.9659 (1.0118) Average CE Loss (Source):  0.9659 ( 1.0118) Learning Rate: 0.1000 (0.1000) Top1_base: 71.8750 (71.5000) Top1_base_per_class: 70.5357 (71.9407) 
Training Epoch: [43/1000] Step: [160 / 285] Batch Time: 0.1422 (0.1613) Data Time: 0.0107 (0.0278) Average Loss: 1.1376 (1.0112) Average CE Loss (Source):  1.1376 ( 1.0112) Learning Rate: 0.1000 (0.1000) Top1_base: 70.3125 (71.5820) Top1_base_per_class: 72.1914 (72.0975) 
Training Epoch: [43/1000] Step: [170 / 285] Batch Time: 0.1459 (0.1605) Data Time: 0.0141 (0.0270) Average Loss: 0.9671 (1.0103) Average CE Loss (Source):  0.9671 ( 1.0103) Learning Rate: 0.1000 (0.1000) Top1_base: 73.4375 (71.6452) Top1_base_per_class: 74.1520 (72.1067) 
Training Epoch: [43/1000] Step: [180 / 285] Batch Time: 0.1462 (0.1601) Data Time: 0.0121 (0.0266) Average Loss: 1.0282 (1.0167) Average CE Loss (Source):  1.0282 ( 1.0167) Learning Rate: 0.1000 (0.1000) Top1_base: 73.4375 (71.5321) Top1_base_per_class: 76.0377 (71.9743) 
Training Epoch: [43/1000] Step: [190 / 285] Batch Time: 0.1457 (0.1594) Data Time: 0.0130 (0.0260) Average Loss: 1.0310 (1.0198) Average CE Loss (Source):  1.0310 ( 1.0198) Learning Rate: 0.1000 (0.1000) Top1_base: 69.5312 (71.4433) Top1_base_per_class: 69.9425 (71.8471) 
Training Epoch: [43/1000] Step: [200 / 285] Batch Time: 0.1434 (0.1588) Data Time: 0.0107 (0.0254) Average Loss: 1.1296 (1.0179) Average CE Loss (Source):  1.1296 ( 1.0179) Learning Rate: 0.1000 (0.1000) Top1_base: 67.1875 (71.5195) Top1_base_per_class: 64.9691 (71.8855) 
Training Epoch: [43/1000] Step: [210 / 285] Batch Time: 0.1448 (0.1585) Data Time: 0.0121 (0.0251) Average Loss: 0.9588 (1.0199) Average CE Loss (Source):  0.9588 ( 1.0199) Learning Rate: 0.1000 (0.1000) Top1_base: 74.2188 (71.5216) Top1_base_per_class: 70.2381 (71.8482) 
Training Epoch: [43/1000] Step: [220 / 285] Batch Time: 0.1462 (0.1584) Data Time: 0.0123 (0.0250) Average Loss: 0.9675 (1.0171) Average CE Loss (Source):  0.9675 ( 1.0171) Learning Rate: 0.1000 (0.1000) Top1_base: 75.7812 (71.6229) Top1_base_per_class: 71.4151 (71.9074) 
Training Epoch: [43/1000] Step: [230 / 285] Batch Time: 0.1462 (0.1580) Data Time: 0.0125 (0.0245) Average Loss: 1.1173 (1.0184) Average CE Loss (Source):  1.1173 ( 1.0184) Learning Rate: 0.1000 (0.1000) Top1_base: 73.4375 (71.6610) Top1_base_per_class: 74.9820 (71.9841) 
Training Epoch: [43/1000] Step: [240 / 285] Batch Time: 0.1482 (0.1575) Data Time: 0.0155 (0.0241) Average Loss: 0.8886 (1.0191) Average CE Loss (Source):  0.8886 ( 1.0191) Learning Rate: 0.1000 (0.1000) Top1_base: 80.4688 (71.6895) Top1_base_per_class: 81.5741 (72.0199) 
Training Epoch: [43/1000] Step: [250 / 285] Batch Time: 0.1495 (0.1573) Data Time: 0.0154 (0.0238) Average Loss: 1.1228 (1.0207) Average CE Loss (Source):  1.1228 ( 1.0207) Learning Rate: 0.1000 (0.1000) Top1_base: 70.3125 (71.6344) Top1_base_per_class: 68.2026 (71.9344) 
Training Epoch: [43/1000] Step: [260 / 285] Batch Time: 0.1446 (0.1569) Data Time: 0.0134 (0.0235) Average Loss: 1.2142 (1.0252) Average CE Loss (Source):  1.2142 ( 1.0252) Learning Rate: 0.1000 (0.1000) Top1_base: 64.8438 (71.4904) Top1_base_per_class: 69.2529 (71.8307) 
Training Epoch: [43/1000] Step: [270 / 285] Batch Time: 0.1507 (0.1573) Data Time: 0.0151 (0.0239) Average Loss: 0.8966 (1.0280) Average CE Loss (Source):  0.8966 ( 1.0280) Learning Rate: 0.1000 (0.1000) Top1_base: 75.7812 (71.4236) Top1_base_per_class: 74.7894 (71.7618) 
Training Epoch: [43/1000] Step: [280 / 285] Batch Time: 0.1886 (0.1570) Data Time: 0.0569 (0.0237) Average Loss: 0.9793 (1.0251) Average CE Loss (Source):  0.9793 ( 1.0251) Learning Rate: 0.1000 (0.1000) Top1_base: 71.8750 (71.5346) Top1_base_per_class: 73.3333 (71.8782) 
Training Epoch: [44/1000] Step: [0] Batch Time: 0.1437 (0.1569) Data Time: 0.0096 (0.0235) Average Loss: 0.9098 (1.0251) Average CE Loss (Source):  0.9098 ( 1.0251) Learning Rate: 0.1000 (0.1000) Top1_base: 75.7812 (71.5515) Top1_base_per_class: 76.6667 (71.8978) 
  4%|▍         | 44/1000 [34:55<12:20:27, 46.47s/it]  4%|▍         | 45/1000 [35:40<12:11:12, 45.94s/it]Training Epoch: [44/1000] Step: [10 / 285] Batch Time: 0.1432 (0.2372) Data Time: 0.0138 (0.1037) Average Loss: 1.0518 (0.9764) Average CE Loss (Source):  1.0518 ( 0.9764) Learning Rate: 0.1000 (0.1000) Top1_base: 76.5625 (73.1250) Top1_base_per_class: 75.7759 (73.9691) 
Training Epoch: [44/1000] Step: [20 / 285] Batch Time: 0.1446 (0.1962) Data Time: 0.0116 (0.0635) Average Loss: 0.8745 (0.9982) Average CE Loss (Source):  0.8745 ( 0.9982) Learning Rate: 0.1000 (0.1000) Top1_base: 75.7812 (72.3438) Top1_base_per_class: 74.8023 (73.0229) 
Training Epoch: [44/1000] Step: [30 / 285] Batch Time: 0.2043 (0.1853) Data Time: 0.0655 (0.0526) Average Loss: 1.0435 (1.0036) Average CE Loss (Source):  1.0435 ( 1.0036) Learning Rate: 0.1000 (0.1000) Top1_base: 71.0938 (72.2656) Top1_base_per_class: 73.8272 (72.9089) 
Training Epoch: [44/1000] Step: [40 / 285] Batch Time: 0.1510 (0.1780) Data Time: 0.0147 (0.0447) Average Loss: 0.9850 (1.0040) Average CE Loss (Source):  0.9850 ( 1.0040) Learning Rate: 0.1000 (0.1000) Top1_base: 75.0000 (72.1680) Top1_base_per_class: 76.3228 (72.9656) 
Training Epoch: [44/1000] Step: [50 / 285] Batch Time: 0.1590 (0.1734) Data Time: 0.0289 (0.0401) Average Loss: 0.7660 (0.9992) Average CE Loss (Source):  0.7660 ( 0.9992) Learning Rate: 0.1000 (0.1000) Top1_base: 77.3438 (72.3594) Top1_base_per_class: 78.2500 (73.0281) 
Training Epoch: [44/1000] Step: [60 / 285] Batch Time: 0.1498 (0.1706) Data Time: 0.0141 (0.0373) Average Loss: 1.1074 (1.0086) Average CE Loss (Source):  1.1074 ( 1.0086) Learning Rate: 0.1000 (0.1000) Top1_base: 71.8750 (72.3307) Top1_base_per_class: 75.3869 (73.0276) 
Training Epoch: [44/1000] Step: [70 / 285] Batch Time: 0.1923 (0.1708) Data Time: 0.0553 (0.0372) Average Loss: 0.9356 (1.0017) Average CE Loss (Source):  0.9356 ( 1.0017) Learning Rate: 0.1000 (0.1000) Top1_base: 72.6562 (72.5000) Top1_base_per_class: 72.6235 (73.0736) 
Training Epoch: [44/1000] Step: [80 / 285] Batch Time: 0.1450 (0.1688) Data Time: 0.0141 (0.0351) Average Loss: 1.1213 (1.0038) Average CE Loss (Source):  1.1213 ( 1.0038) Learning Rate: 0.1000 (0.1000) Top1_base: 69.5312 (72.3633) Top1_base_per_class: 70.3030 (73.0271) 
Training Epoch: [44/1000] Step: [90 / 285] Batch Time: 0.1497 (0.1664) Data Time: 0.0185 (0.0329) Average Loss: 1.3432 (1.0179) Average CE Loss (Source):  1.3432 ( 1.0179) Learning Rate: 0.1000 (0.1000) Top1_base: 64.0625 (72.0139) Top1_base_per_class: 66.0169 (72.7602) 
Training Epoch: [44/1000] Step: [100 / 285] Batch Time: 0.1452 (0.1649) Data Time: 0.0134 (0.0315) Average Loss: 1.0038 (1.0182) Average CE Loss (Source):  1.0038 ( 1.0182) Learning Rate: 0.1000 (0.1000) Top1_base: 73.4375 (72.0000) Top1_base_per_class: 71.3580 (72.6700) 
Training Epoch: [44/1000] Step: [110 / 285] Batch Time: 0.1486 (0.1638) Data Time: 0.0184 (0.0304) Average Loss: 1.0136 (1.0226) Average CE Loss (Source):  1.0136 ( 1.0226) Learning Rate: 0.1000 (0.1000) Top1_base: 71.8750 (71.8182) Top1_base_per_class: 73.2684 (72.4604) 
Training Epoch: [44/1000] Step: [120 / 285] Batch Time: 0.1468 (0.1624) Data Time: 0.0121 (0.0290) Average Loss: 0.8996 (1.0199) Average CE Loss (Source):  0.8996 ( 1.0199) Learning Rate: 0.1000 (0.1000) Top1_base: 74.2188 (71.8945) Top1_base_per_class: 73.2641 (72.5234) 
Training Epoch: [44/1000] Step: [130 / 285] Batch Time: 0.1530 (0.1618) Data Time: 0.0159 (0.0282) Average Loss: 0.8652 (1.0149) Average CE Loss (Source):  0.8652 ( 1.0149) Learning Rate: 0.1000 (0.1000) Top1_base: 73.4375 (72.0012) Top1_base_per_class: 73.2692 (72.5309) 
Training Epoch: [44/1000] Step: [140 / 285] Batch Time: 0.1480 (0.1609) Data Time: 0.0137 (0.0272) Average Loss: 0.9402 (1.0158) Average CE Loss (Source):  0.9402 ( 1.0158) Learning Rate: 0.1000 (0.1000) Top1_base: 75.0000 (72.0536) Top1_base_per_class: 75.0121 (72.5692) 
Training Epoch: [44/1000] Step: [150 / 285] Batch Time: 0.1478 (0.1604) Data Time: 0.0167 (0.0266) Average Loss: 0.8121 (1.0174) Average CE Loss (Source):  0.8121 ( 1.0174) Learning Rate: 0.1000 (0.1000) Top1_base: 78.9062 (71.9688) Top1_base_per_class: 77.6235 (72.4218) 
Training Epoch: [44/1000] Step: [160 / 285] Batch Time: 0.1448 (0.1598) Data Time: 0.0116 (0.0261) Average Loss: 1.0549 (1.0194) Average CE Loss (Source):  1.0549 ( 1.0194) Learning Rate: 0.1000 (0.1000) Top1_base: 72.6562 (71.8945) Top1_base_per_class: 74.6131 (72.3501) 
Training Epoch: [44/1000] Step: [170 / 285] Batch Time: 0.1817 (0.1592) Data Time: 0.0447 (0.0255) Average Loss: 0.9428 (1.0186) Average CE Loss (Source):  0.9428 ( 1.0186) Learning Rate: 0.1000 (0.1000) Top1_base: 74.2188 (71.9164) Top1_base_per_class: 75.8176 (72.4442) 
Training Epoch: [44/1000] Step: [180 / 285] Batch Time: 0.1460 (0.1587) Data Time: 0.0141 (0.0249) Average Loss: 0.9831 (1.0163) Average CE Loss (Source):  0.9831 ( 1.0163) Learning Rate: 0.1000 (0.1000) Top1_base: 71.8750 (72.0052) Top1_base_per_class: 68.1034 (72.5196) 
Training Epoch: [44/1000] Step: [190 / 285] Batch Time: 0.1480 (0.1584) Data Time: 0.0136 (0.0247) Average Loss: 1.1057 (1.0198) Average CE Loss (Source):  1.1057 ( 1.0198) Learning Rate: 0.1000 (0.1000) Top1_base: 70.3125 (71.8709) Top1_base_per_class: 72.9560 (72.4463) 
Training Epoch: [44/1000] Step: [200 / 285] Batch Time: 0.1457 (0.1581) Data Time: 0.0141 (0.0244) Average Loss: 1.0043 (1.0212) Average CE Loss (Source):  1.0043 ( 1.0212) Learning Rate: 0.1000 (0.1000) Top1_base: 74.2188 (71.8125) Top1_base_per_class: 79.0741 (72.4077) 
Training Epoch: [44/1000] Step: [210 / 285] Batch Time: 0.1512 (0.1578) Data Time: 0.0131 (0.0240) Average Loss: 1.0659 (1.0241) Average CE Loss (Source):  1.0659 ( 1.0241) Learning Rate: 0.1000 (0.1000) Top1_base: 73.4375 (71.7708) Top1_base_per_class: 75.8929 (72.3584) 
Training Epoch: [44/1000] Step: [220 / 285] Batch Time: 0.1474 (0.1576) Data Time: 0.0139 (0.0237) Average Loss: 0.9132 (1.0259) Average CE Loss (Source):  0.9132 ( 1.0259) Learning Rate: 0.1000 (0.1000) Top1_base: 74.2188 (71.7365) Top1_base_per_class: 78.5806 (72.3170) 
Training Epoch: [44/1000] Step: [230 / 285] Batch Time: 0.1470 (0.1571) Data Time: 0.0165 (0.0233) Average Loss: 1.2258 (1.0298) Average CE Loss (Source):  1.2258 ( 1.0298) Learning Rate: 0.1000 (0.1000) Top1_base: 63.2812 (71.6101) Top1_base_per_class: 62.4679 (72.2760) 
Training Epoch: [44/1000] Step: [240 / 285] Batch Time: 0.1446 (0.1573) Data Time: 0.0116 (0.0236) Average Loss: 0.9563 (1.0341) Average CE Loss (Source):  0.9563 ( 1.0341) Learning Rate: 0.1000 (0.1000) Top1_base: 76.5625 (71.4876) Top1_base_per_class: 79.0517 (72.1447) 
Training Epoch: [44/1000] Step: [250 / 285] Batch Time: 0.1512 (0.1574) Data Time: 0.0163 (0.0237) Average Loss: 1.0605 (1.0357) Average CE Loss (Source):  1.0605 ( 1.0357) Learning Rate: 0.1000 (0.1000) Top1_base: 71.8750 (71.4594) Top1_base_per_class: 75.0909 (72.1021) 
Training Epoch: [44/1000] Step: [260 / 285] Batch Time: 0.1463 (0.1574) Data Time: 0.0142 (0.0237) Average Loss: 0.9645 (1.0335) Average CE Loss (Source):  0.9645 ( 1.0335) Learning Rate: 0.1000 (0.1000) Top1_base: 71.8750 (71.4934) Top1_base_per_class: 77.3810 (72.1578) 
Training Epoch: [44/1000] Step: [270 / 285] Batch Time: 0.1507 (0.1571) Data Time: 0.0160 (0.0235) Average Loss: 1.1819 (1.0344) Average CE Loss (Source):  1.1819 ( 1.0344) Learning Rate: 0.1000 (0.1000) Top1_base: 64.8438 (71.4525) Top1_base_per_class: 67.1818 (72.1221) 
Training Epoch: [44/1000] Step: [280 / 285] Batch Time: 0.1456 (0.1568) Data Time: 0.0116 (0.0233) Average Loss: 1.2087 (1.0350) Average CE Loss (Source):  1.2087 ( 1.0350) Learning Rate: 0.1000 (0.1000) Top1_base: 70.3125 (71.4369) Top1_base_per_class: 68.2749 (72.1050) 
Training Epoch: [45/1000] Step: [0] Batch Time: 0.1381 (0.1566) Data Time: 0.0100 (0.0231) Average Loss: 1.0807 (1.0381) Average CE Loss (Source):  1.0807 ( 1.0381) Learning Rate: 0.1000 (0.1000) Top1_base: 71.8750 (71.3624) Top1_base_per_class: 71.6358 (72.0286) 
Training Epoch: [45/1000] Step: [10 / 285] Batch Time: 0.1456 (0.2355) Data Time: 0.0126 (0.1022) Average Loss: 0.9899 (1.0203) Average CE Loss (Source):  0.9899 ( 1.0203) Learning Rate: 0.1000 (0.1000) Top1_base: 70.3125 (71.8750) Top1_base_per_class: 72.1345 (72.0865) 
Training Epoch: [45/1000] Step: [20 / 285] Batch Time: 0.1443 (0.1996) Data Time: 0.0126 (0.0662) Average Loss: 0.8920 (0.9883) Average CE Loss (Source):  0.8920 ( 0.9883) Learning Rate: 0.1000 (0.1000) Top1_base: 76.5625 (72.8516) Top1_base_per_class: 73.5119 (72.5696) 
Training Epoch: [45/1000] Step: [30 / 285] Batch Time: 0.1451 (0.1843) Data Time: 0.0131 (0.0511) Average Loss: 1.0084 (0.9805) Average CE Loss (Source):  1.0084 ( 0.9805) Learning Rate: 0.1000 (0.1000) Top1_base: 68.7500 (73.2292) Top1_base_per_class: 69.3030 (73.1074) 
Training Epoch: [45/1000] Step: [40 / 285] Batch Time: 0.1492 (0.1753) Data Time: 0.0152 (0.0420) Average Loss: 1.0390 (0.9955) Average CE Loss (Source):  1.0390 ( 0.9955) Learning Rate: 0.1000 (0.1000) Top1_base: 70.3125 (72.9492) Top1_base_per_class: 73.2748 (73.1522) 
Training Epoch: [45/1000] Step: [50 / 285] Batch Time: 0.1582 (0.1725) Data Time: 0.0242 (0.0392) Average Loss: 1.0250 (0.9861) Average CE Loss (Source):  1.0250 ( 0.9861) Learning Rate: 0.1000 (0.1000) Top1_base: 71.8750 (73.2500) Top1_base_per_class: 72.4713 (73.7559) 
Training Epoch: [45/1000] Step: [60 / 285] Batch Time: 0.1478 (0.1686) Data Time: 0.0157 (0.0351) Average Loss: 1.1267 (0.9902) Average CE Loss (Source):  1.1267 ( 0.9902) Learning Rate: 0.1000 (0.1000) Top1_base: 67.9688 (72.9297) Top1_base_per_class: 67.2024 (73.4730) 
Training Epoch: [45/1000] Step: [70 / 285] Batch Time: 0.1484 (0.1657) Data Time: 0.0152 (0.0321) Average Loss: 0.7377 (0.9949) Average CE Loss (Source):  0.7377 ( 0.9949) Learning Rate: 0.1000 (0.1000) Top1_base: 78.9062 (72.7790) Top1_base_per_class: 77.2839 (73.1767) 
Training Epoch: [45/1000] Step: [80 / 285] Batch Time: 0.1486 (0.1635) Data Time: 0.0153 (0.0300) Average Loss: 0.9511 (0.9921) Average CE Loss (Source):  0.9511 ( 0.9921) Learning Rate: 0.1000 (0.1000) Top1_base: 73.4375 (73.0371) Top1_base_per_class: 74.2424 (73.3748) 
Training Epoch: [45/1000] Step: [90 / 285] Batch Time: 0.1706 (0.1635) Data Time: 0.0358 (0.0301) Average Loss: 0.7715 (0.9902) Average CE Loss (Source):  0.7715 ( 0.9902) Learning Rate: 0.1000 (0.1000) Top1_base: 77.3438 (72.9427) Top1_base_per_class: 77.7879 (73.1550) 
Training Epoch: [45/1000] Step: [100 / 285] Batch Time: 0.1482 (0.1620) Data Time: 0.0145 (0.0285) Average Loss: 0.8874 (0.9908) Average CE Loss (Source):  0.8874 ( 0.9908) Learning Rate: 0.1000 (0.1000) Top1_base: 73.4375 (72.8125) Top1_base_per_class: 73.3051 (72.9922) 
Training Epoch: [45/1000] Step: [110 / 285] Batch Time: 0.1442 (0.1611) Data Time: 0.0131 (0.0277) Average Loss: 0.9170 (0.9935) Average CE Loss (Source):  0.9170 ( 0.9935) Learning Rate: 0.1000 (0.1000) Top1_base: 79.6875 (72.7202) Top1_base_per_class: 78.0556 (72.8796) 
Training Epoch: [45/1000] Step: [120 / 285] Batch Time: 0.1438 (0.1610) Data Time: 0.0137 (0.0276) Average Loss: 0.8593 (0.9947) Average CE Loss (Source):  0.8593 ( 0.9947) Learning Rate: 0.1000 (0.1000) Top1_base: 79.6875 (72.7799) Top1_base_per_class: 77.1227 (72.9302) 
Training Epoch: [45/1000] Step: [130 / 285] Batch Time: 0.1556 (0.1605) Data Time: 0.0240 (0.0272) Average Loss: 1.0319 (0.9948) Average CE Loss (Source):  1.0319 ( 0.9948) Learning Rate: 0.1000 (0.1000) Top1_base: 71.8750 (72.8425) Top1_base_per_class: 72.6970 (73.0479) 
Training Epoch: [45/1000] Step: [140 / 285] Batch Time: 0.2210 (0.1607) Data Time: 0.0900 (0.0274) Average Loss: 0.9444 (0.9947) Average CE Loss (Source):  0.9444 ( 0.9947) Learning Rate: 0.1000 (0.1000) Top1_base: 75.0000 (72.7623) Top1_base_per_class: 73.8580 (72.9451) 
Training Epoch: [45/1000] Step: [150 / 285] Batch Time: 0.1447 (0.1598) Data Time: 0.0130 (0.0265) Average Loss: 1.1952 (1.0007) Average CE Loss (Source):  1.1952 ( 1.0007) Learning Rate: 0.1000 (0.1000) Top1_base: 67.9688 (72.5938) Top1_base_per_class: 69.3275 (72.8158) 
Training Epoch: [45/1000] Step: [160 / 285] Batch Time: 0.1468 (0.1597) Data Time: 0.0135 (0.0265) Average Loss: 1.4112 (1.0051) Average CE Loss (Source):  1.4112 ( 1.0051) Learning Rate: 0.1000 (0.1000) Top1_base: 65.6250 (72.4316) Top1_base_per_class: 66.5094 (72.6979) 
Training Epoch: [45/1000] Step: [170 / 285] Batch Time: 0.1509 (0.1590) Data Time: 0.0166 (0.0258) Average Loss: 1.0413 (1.0051) Average CE Loss (Source):  1.0413 ( 1.0051) Learning Rate: 0.1000 (0.1000) Top1_base: 74.2188 (72.4540) Top1_base_per_class: 74.4545 (72.7207) 
Training Epoch: [45/1000] Step: [180 / 285] Batch Time: 0.1468 (0.1587) Data Time: 0.0149 (0.0255) Average Loss: 0.9320 (1.0065) Average CE Loss (Source):  0.9320 ( 1.0065) Learning Rate: 0.1000 (0.1000) Top1_base: 78.9062 (72.4479) Top1_base_per_class: 76.9697 (72.7461) 
Training Epoch: [45/1000] Step: [190 / 285] Batch Time: 0.1502 (0.1588) Data Time: 0.0157 (0.0256) Average Loss: 0.8891 (1.0051) Average CE Loss (Source):  0.8891 ( 1.0051) Learning Rate: 0.1000 (0.1000) Top1_base: 71.8750 (72.4137) Top1_base_per_class: 75.3593 (72.6970) 
Training Epoch: [45/1000] Step: [200 / 285] Batch Time: 0.1469 (0.1587) Data Time: 0.0155 (0.0255) Average Loss: 0.9731 (1.0065) Average CE Loss (Source):  0.9731 ( 1.0065) Learning Rate: 0.1000 (0.1000) Top1_base: 71.0938 (72.2891) Top1_base_per_class: 74.8305 (72.6052) 
Training Epoch: [45/1000] Step: [210 / 285] Batch Time: 0.1513 (0.1583) Data Time: 0.0151 (0.0250) Average Loss: 1.2141 (1.0049) Average CE Loss (Source):  1.2141 ( 1.0049) Learning Rate: 0.1000 (0.1000) Top1_base: 67.9688 (72.3438) Top1_base_per_class: 71.4780 (72.7274) 
Training Epoch: [45/1000] Step: [220 / 285] Batch Time: 0.1569 (0.1581) Data Time: 0.0245 (0.0249) Average Loss: 1.2356 (1.0061) Average CE Loss (Source):  1.2356 ( 1.0061) Learning Rate: 0.1000 (0.1000) Top1_base: 68.7500 (72.3047) Top1_base_per_class: 68.4545 (72.6793) 
Training Epoch: [45/1000] Step: [230 / 285] Batch Time: 0.1505 (0.1578) Data Time: 0.0145 (0.0245) Average Loss: 0.8838 (1.0048) Average CE Loss (Source):  0.8838 ( 1.0048) Learning Rate: 0.1000 (0.1000) Top1_base: 78.1250 (72.2996) Top1_base_per_class: 80.3611 (72.6748) 
Training Epoch: [45/1000] Step: [240 / 285] Batch Time: 0.2250 (0.1579) Data Time: 0.0939 (0.0247) Average Loss: 1.0066 (1.0057) Average CE Loss (Source):  1.0066 ( 1.0057) Learning Rate: 0.1000 (0.1000) Top1_base: 70.3125 (72.2689) Top1_base_per_class: 73.5143 (72.6755) 
Training Epoch: [45/1000] Step: [250 / 285] Batch Time: 0.1486 (0.1575) Data Time: 0.0141 (0.0243) Average Loss: 0.9880 (1.0063) Average CE Loss (Source):  0.9880 ( 1.0063) Learning Rate: 0.1000 (0.1000) Top1_base: 70.3125 (72.1937) Top1_base_per_class: 69.5029 (72.5803) 
Training Epoch: [45/1000] Step: [260 / 285] Batch Time: 0.1488 (0.1572) Data Time: 0.0166 (0.0239) Average Loss: 0.9480 (1.0048) Average CE Loss (Source):  0.9480 ( 1.0048) Learning Rate: 0.1000 (0.1000) Top1_base: 73.4375 (72.2416) Top1_base_per_class: 75.2932 (72.6121) 
Training Epoch: [45/1000] Step: [270 / 285] Batch Time: 0.1515 (0.1568) Data Time: 0.0157 (0.0236) Average Loss: 1.1325 (1.0091) Average CE Loss (Source):  1.1325 ( 1.0091) Learning Rate: 0.1000 (0.1000) Top1_base: 76.5625 (72.1209) Top1_base_per_class: 75.9893 (72.4869) 
Training Epoch: [45/1000] Step: [280 / 285] Batch Time: 0.1488 (0.1569) Data Time: 0.0188 (0.0236) Average Loss: 1.0209 (1.0091) Average CE Loss (Source):  1.0209 ( 1.0091) Learning Rate: 0.1000 (0.1000) Top1_base: 76.5625 (72.1624) Top1_base_per_class: 76.7901 (72.5247) 
Training Epoch: [46/1000] Step: [0] Batch Time: 0.1426 (0.1568) Data Time: 0.0116 (0.0236) Average Loss: 0.9147 (1.0098) Average CE Loss (Source):  0.9147 ( 1.0098) Learning Rate: 0.1000 (0.1000) Top1_base: 76.5625 (72.1409) Top1_base_per_class: 73.8793 (72.4751) 
  5%|▍         | 46/1000 [36:27<12:17:24, 46.38s/it]  5%|▍         | 47/1000 [37:12<12:11:14, 46.04s/it]Training Epoch: [46/1000] Step: [10 / 285] Batch Time: 0.1466 (0.2388) Data Time: 0.0100 (0.1033) Average Loss: 0.8763 (0.9306) Average CE Loss (Source):  0.8763 ( 0.9306) Learning Rate: 0.1000 (0.1000) Top1_base: 72.6562 (73.7500) Top1_base_per_class: 72.9056 (74.2437) 
Training Epoch: [46/1000] Step: [20 / 285] Batch Time: 0.1468 (0.1966) Data Time: 0.0134 (0.0617) Average Loss: 0.8439 (0.9681) Average CE Loss (Source):  0.8439 ( 0.9681) Learning Rate: 0.1000 (0.1000) Top1_base: 78.1250 (72.9297) Top1_base_per_class: 83.2653 (73.5592) 
Training Epoch: [46/1000] Step: [30 / 285] Batch Time: 0.1472 (0.1836) Data Time: 0.0102 (0.0488) Average Loss: 0.9787 (0.9615) Average CE Loss (Source):  0.9787 ( 0.9615) Learning Rate: 0.1000 (0.1000) Top1_base: 71.8750 (73.3333) Top1_base_per_class: 75.3395 (74.1511) 
Training Epoch: [46/1000] Step: [40 / 285] Batch Time: 0.1505 (0.1755) Data Time: 0.0172 (0.0405) Average Loss: 1.1080 (0.9602) Average CE Loss (Source):  1.1080 ( 0.9602) Learning Rate: 0.1000 (0.1000) Top1_base: 67.1875 (73.0664) Top1_base_per_class: 68.7037 (73.9224) 
Training Epoch: [46/1000] Step: [50 / 285] Batch Time: 0.1514 (0.1709) Data Time: 0.0135 (0.0357) Average Loss: 0.9851 (0.9719) Average CE Loss (Source):  0.9851 ( 0.9719) Learning Rate: 0.1000 (0.1000) Top1_base: 74.2188 (72.8750) Top1_base_per_class: 71.4937 (73.8013) 
Training Epoch: [46/1000] Step: [60 / 285] Batch Time: 0.1511 (0.1675) Data Time: 0.0172 (0.0322) Average Loss: 1.1491 (0.9773) Average CE Loss (Source):  1.1491 ( 0.9773) Learning Rate: 0.1000 (0.1000) Top1_base: 71.0938 (72.7995) Top1_base_per_class: 76.2121 (73.6339) 
Training Epoch: [46/1000] Step: [70 / 285] Batch Time: 0.1508 (0.1651) Data Time: 0.0152 (0.0297) Average Loss: 0.7758 (0.9778) Average CE Loss (Source):  0.7758 ( 0.9778) Learning Rate: 0.1000 (0.1000) Top1_base: 78.9062 (72.7567) Top1_base_per_class: 76.8362 (73.5762) 
Training Epoch: [46/1000] Step: [80 / 285] Batch Time: 0.1491 (0.1630) Data Time: 0.0144 (0.0279) Average Loss: 0.9951 (0.9785) Average CE Loss (Source):  0.9951 ( 0.9785) Learning Rate: 0.1000 (0.1000) Top1_base: 73.4375 (72.6855) Top1_base_per_class: 76.4848 (73.4688) 
Training Epoch: [46/1000] Step: [90 / 285] Batch Time: 0.1482 (0.1613) Data Time: 0.0128 (0.0263) Average Loss: 1.0496 (0.9786) Average CE Loss (Source):  1.0496 ( 0.9786) Learning Rate: 0.1000 (0.1000) Top1_base: 72.6562 (72.5781) Top1_base_per_class: 76.6038 (73.2943) 
Training Epoch: [46/1000] Step: [100 / 285] Batch Time: 0.2892 (0.1616) Data Time: 0.1574 (0.0268) Average Loss: 1.0217 (0.9849) Average CE Loss (Source):  1.0217 ( 0.9849) Learning Rate: 0.1000 (0.1000) Top1_base: 71.0938 (72.3594) Top1_base_per_class: 71.9298 (73.0193) 
Training Epoch: [46/1000] Step: [110 / 285] Batch Time: 0.1483 (0.1608) Data Time: 0.0128 (0.0261) Average Loss: 1.1094 (0.9812) Average CE Loss (Source):  1.1094 ( 0.9812) Learning Rate: 0.1000 (0.1000) Top1_base: 67.1875 (72.3793) Top1_base_per_class: 70.0556 (73.0611) 
Training Epoch: [46/1000] Step: [120 / 285] Batch Time: 0.1585 (0.1610) Data Time: 0.0260 (0.0265) Average Loss: 0.9533 (0.9838) Average CE Loss (Source):  0.9533 ( 0.9838) Learning Rate: 0.1000 (0.1000) Top1_base: 73.4375 (72.3047) Top1_base_per_class: 78.1286 (73.0423) 
Training Epoch: [46/1000] Step: [130 / 285] Batch Time: 0.1466 (0.1603) Data Time: 0.0115 (0.0258) Average Loss: 1.1055 (0.9833) Average CE Loss (Source):  1.1055 ( 0.9833) Learning Rate: 0.1000 (0.1000) Top1_base: 70.3125 (72.3678) Top1_base_per_class: 63.9368 (73.0021) 
Training Epoch: [46/1000] Step: [140 / 285] Batch Time: 0.1623 (0.1603) Data Time: 0.0302 (0.0259) Average Loss: 0.8047 (0.9822) Average CE Loss (Source):  0.8047 ( 0.9822) Learning Rate: 0.1000 (0.1000) Top1_base: 78.9062 (72.4609) Top1_base_per_class: 80.1488 (73.0402) 
Training Epoch: [46/1000] Step: [150 / 285] Batch Time: 0.1451 (0.1594) Data Time: 0.0106 (0.0251) Average Loss: 1.0231 (0.9882) Average CE Loss (Source):  1.0231 ( 0.9882) Learning Rate: 0.1000 (0.1000) Top1_base: 74.2188 (72.3281) Top1_base_per_class: 76.6667 (72.8624) 
Training Epoch: [46/1000] Step: [160 / 285] Batch Time: 0.1703 (0.1595) Data Time: 0.0379 (0.0253) Average Loss: 1.0515 (0.9878) Average CE Loss (Source):  1.0515 ( 0.9878) Learning Rate: 0.1000 (0.1000) Top1_base: 67.1875 (72.3730) Top1_base_per_class: 71.7514 (72.9738) 
Training Epoch: [46/1000] Step: [170 / 285] Batch Time: 0.1469 (0.1594) Data Time: 0.0103 (0.0252) Average Loss: 0.6787 (0.9869) Average CE Loss (Source):  0.6787 ( 0.9869) Learning Rate: 0.1000 (0.1000) Top1_base: 81.2500 (72.3529) Top1_base_per_class: 82.9722 (72.9990) 
Training Epoch: [46/1000] Step: [180 / 285] Batch Time: 0.1729 (0.1592) Data Time: 0.0397 (0.0250) Average Loss: 0.9263 (0.9873) Average CE Loss (Source):  0.9263 ( 0.9873) Learning Rate: 0.1000 (0.1000) Top1_base: 71.8750 (72.3047) Top1_base_per_class: 72.4383 (72.9882) 
Training Epoch: [46/1000] Step: [190 / 285] Batch Time: 0.1456 (0.1590) Data Time: 0.0126 (0.0250) Average Loss: 1.1173 (0.9914) Average CE Loss (Source):  1.1173 ( 0.9914) Learning Rate: 0.1000 (0.1000) Top1_base: 70.3125 (72.2738) Top1_base_per_class: 64.4969 (73.0038) 
Training Epoch: [46/1000] Step: [200 / 285] Batch Time: 0.1532 (0.1587) Data Time: 0.0226 (0.0248) Average Loss: 1.1827 (0.9929) Average CE Loss (Source):  1.1827 ( 0.9929) Learning Rate: 0.1000 (0.1000) Top1_base: 67.1875 (72.2266) Top1_base_per_class: 66.2893 (72.9093) 
Training Epoch: [46/1000] Step: [210 / 285] Batch Time: 0.1437 (0.1587) Data Time: 0.0113 (0.0248) Average Loss: 1.0197 (0.9982) Average CE Loss (Source):  1.0197 ( 0.9982) Learning Rate: 0.1000 (0.1000) Top1_base: 71.8750 (72.0610) Top1_base_per_class: 72.0238 (72.7204) 
Training Epoch: [46/1000] Step: [220 / 285] Batch Time: 0.2557 (0.1591) Data Time: 0.1235 (0.0252) Average Loss: 1.0111 (0.9981) Average CE Loss (Source):  1.0111 ( 0.9981) Learning Rate: 0.1000 (0.1000) Top1_base: 70.3125 (72.0987) Top1_base_per_class: 71.5517 (72.7854) 
Training Epoch: [46/1000] Step: [230 / 285] Batch Time: 0.1485 (0.1591) Data Time: 0.0119 (0.0252) Average Loss: 1.0803 (0.9997) Average CE Loss (Source):  1.0803 ( 0.9997) Learning Rate: 0.1000 (0.1000) Top1_base: 73.4375 (72.1365) Top1_base_per_class: 75.5017 (72.7952) 
Training Epoch: [46/1000] Step: [240 / 285] Batch Time: 0.1985 (0.1590) Data Time: 0.0651 (0.0251) Average Loss: 1.1336 (0.9991) Average CE Loss (Source):  1.1336 ( 0.9991) Learning Rate: 0.1000 (0.1000) Top1_base: 67.1875 (72.1517) Top1_base_per_class: 63.8139 (72.7717) 
Training Epoch: [46/1000] Step: [250 / 285] Batch Time: 0.1464 (0.1588) Data Time: 0.0109 (0.0249) Average Loss: 1.1323 (1.0008) Average CE Loss (Source):  1.1323 ( 1.0008) Learning Rate: 0.1000 (0.1000) Top1_base: 72.6562 (72.1000) Top1_base_per_class: 72.4702 (72.6873) 
Training Epoch: [46/1000] Step: [260 / 285] Batch Time: 0.1485 (0.1589) Data Time: 0.0152 (0.0251) Average Loss: 1.2239 (1.0012) Average CE Loss (Source):  1.2239 ( 1.0012) Learning Rate: 0.1000 (0.1000) Top1_base: 63.2812 (72.1124) Top1_base_per_class: 63.8218 (72.7090) 
Training Epoch: [46/1000] Step: [270 / 285] Batch Time: 0.1469 (0.1588) Data Time: 0.0118 (0.0250) Average Loss: 1.2851 (1.0043) Average CE Loss (Source):  1.2851 ( 1.0043) Learning Rate: 0.1000 (0.1000) Top1_base: 66.4062 (72.0197) Top1_base_per_class: 69.2262 (72.6344) 
Training Epoch: [46/1000] Step: [280 / 285] Batch Time: 0.1819 (0.1587) Data Time: 0.0477 (0.0248) Average Loss: 1.1865 (1.0040) Average CE Loss (Source):  1.1865 ( 1.0040) Learning Rate: 0.1000 (0.1000) Top1_base: 66.4062 (72.0089) Top1_base_per_class: 65.9821 (72.6179) 
Training Epoch: [47/1000] Step: [0] Batch Time: 0.1436 (0.1585) Data Time: 0.0114 (0.0247) Average Loss: 0.9905 (1.0044) Average CE Loss (Source):  0.9905 ( 1.0044) Learning Rate: 0.1000 (0.1000) Top1_base: 73.4375 (72.0011) Top1_base_per_class: 73.0736 (72.6101) 
Training Epoch: [47/1000] Step: [10 / 285] Batch Time: 0.1414 (0.2413) Data Time: 0.0118 (0.1087) Average Loss: 1.3338 (0.9882) Average CE Loss (Source):  1.3338 ( 0.9882) Learning Rate: 0.1000 (0.1000) Top1_base: 67.9688 (73.3594) Top1_base_per_class: 69.3567 (73.3718) 
Training Epoch: [47/1000] Step: [20 / 285] Batch Time: 0.1458 (0.2010) Data Time: 0.0134 (0.0687) Average Loss: 0.8615 (0.9320) Average CE Loss (Source):  0.8615 ( 0.9320) Learning Rate: 0.1000 (0.1000) Top1_base: 73.4375 (74.4141) Top1_base_per_class: 73.0000 (74.3804) 
Training Epoch: [47/1000] Step: [30 / 285] Batch Time: 0.1483 (0.1882) Data Time: 0.0160 (0.0556) Average Loss: 0.9719 (0.9486) Average CE Loss (Source):  0.9719 ( 0.9486) Learning Rate: 0.1000 (0.1000) Top1_base: 72.6562 (73.6979) Top1_base_per_class: 73.5454 (74.2074) 
Training Epoch: [47/1000] Step: [40 / 285] Batch Time: 0.1483 (0.1806) Data Time: 0.0155 (0.0478) Average Loss: 0.8234 (0.9488) Average CE Loss (Source):  0.8234 ( 0.9488) Learning Rate: 0.1000 (0.1000) Top1_base: 79.6875 (73.4961) Top1_base_per_class: 81.2798 (73.8908) 
Training Epoch: [47/1000] Step: [50 / 285] Batch Time: 0.1549 (0.1739) Data Time: 0.0218 (0.0411) Average Loss: 1.0279 (0.9613) Average CE Loss (Source):  1.0279 ( 0.9613) Learning Rate: 0.1000 (0.1000) Top1_base: 69.5312 (73.2188) Top1_base_per_class: 67.3977 (73.6459) 
Training Epoch: [47/1000] Step: [60 / 285] Batch Time: 0.1471 (0.1714) Data Time: 0.0157 (0.0385) Average Loss: 1.0188 (0.9597) Average CE Loss (Source):  1.0188 ( 0.9597) Learning Rate: 0.1000 (0.1000) Top1_base: 73.4375 (73.4505) Top1_base_per_class: 76.9828 (73.9607) 
Training Epoch: [47/1000] Step: [70 / 285] Batch Time: 0.1670 (0.1683) Data Time: 0.0341 (0.0355) Average Loss: 0.7810 (0.9627) Average CE Loss (Source):  0.7810 ( 0.9627) Learning Rate: 0.1000 (0.1000) Top1_base: 78.1250 (73.4040) Top1_base_per_class: 77.2917 (73.8411) 
Training Epoch: [47/1000] Step: [80 / 285] Batch Time: 0.1510 (0.1670) Data Time: 0.0173 (0.0341) Average Loss: 0.8124 (0.9668) Average CE Loss (Source):  0.8124 ( 0.9668) Learning Rate: 0.1000 (0.1000) Top1_base: 75.0000 (73.3105) Top1_base_per_class: 72.3684 (73.7502) 
Training Epoch: [47/1000] Step: [90 / 285] Batch Time: 0.1487 (0.1653) Data Time: 0.0167 (0.0324) Average Loss: 0.9866 (0.9662) Average CE Loss (Source):  0.9866 ( 0.9662) Learning Rate: 0.1000 (0.1000) Top1_base: 72.6562 (73.3941) Top1_base_per_class: 77.2278 (73.8439) 
Training Epoch: [47/1000] Step: [100 / 285] Batch Time: 0.1487 (0.1643) Data Time: 0.0162 (0.0312) Average Loss: 1.2074 (0.9789) Average CE Loss (Source):  1.2074 ( 0.9789) Learning Rate: 0.1000 (0.1000) Top1_base: 68.7500 (73.1797) Top1_base_per_class: 70.7778 (73.6510) 
Training Epoch: [47/1000] Step: [110 / 285] Batch Time: 0.1793 (0.1639) Data Time: 0.0481 (0.0309) Average Loss: 0.9653 (0.9737) Average CE Loss (Source):  0.9653 ( 0.9737) Learning Rate: 0.1000 (0.1000) Top1_base: 75.7812 (73.3594) Top1_base_per_class: 76.8868 (73.9056) 
Training Epoch: [47/1000] Step: [120 / 285] Batch Time: 0.1495 (0.1626) Data Time: 0.0166 (0.0296) Average Loss: 1.0319 (0.9728) Average CE Loss (Source):  1.0319 ( 0.9728) Learning Rate: 0.1000 (0.1000) Top1_base: 75.7812 (73.4049) Top1_base_per_class: 75.8438 (73.9396) 
Training Epoch: [47/1000] Step: [130 / 285] Batch Time: 0.1484 (0.1617) Data Time: 0.0168 (0.0287) Average Loss: 0.9503 (0.9743) Average CE Loss (Source):  0.9503 ( 0.9743) Learning Rate: 0.1000 (0.1000) Top1_base: 75.0000 (73.3714) Top1_base_per_class: 73.7179 (73.8589) 
Training Epoch: [47/1000] Step: [140 / 285] Batch Time: 0.1492 (0.1607) Data Time: 0.0170 (0.0277) Average Loss: 1.0031 (0.9764) Average CE Loss (Source):  1.0031 ( 0.9764) Learning Rate: 0.1000 (0.1000) Top1_base: 71.0938 (73.3203) Top1_base_per_class: 73.5088 (73.7639) 
Training Epoch: [47/1000] Step: [150 / 285] Batch Time: 0.1473 (0.1602) Data Time: 0.0139 (0.0272) Average Loss: 1.2849 (0.9851) Average CE Loss (Source):  1.2849 ( 0.9851) Learning Rate: 0.1000 (0.1000) Top1_base: 67.9688 (73.1719) Top1_base_per_class: 68.3041 (73.6260) 
Training Epoch: [47/1000] Step: [160 / 285] Batch Time: 0.2209 (0.1610) Data Time: 0.0884 (0.0279) Average Loss: 1.1400 (0.9857) Average CE Loss (Source):  1.1400 ( 0.9857) Learning Rate: 0.1000 (0.1000) Top1_base: 68.7500 (73.1396) Top1_base_per_class: 69.1243 (73.6249) 
Training Epoch: [47/1000] Step: [170 / 285] Batch Time: 0.1436 (0.1604) Data Time: 0.0109 (0.0273) Average Loss: 0.8796 (0.9897) Average CE Loss (Source):  0.8796 ( 0.9897) Learning Rate: 0.1000 (0.1000) Top1_base: 73.4375 (72.9963) Top1_base_per_class: 74.5283 (73.4527) 
Training Epoch: [47/1000] Step: [180 / 285] Batch Time: 0.1828 (0.1600) Data Time: 0.0511 (0.0269) Average Loss: 1.0962 (0.9914) Average CE Loss (Source):  1.0962 ( 0.9914) Learning Rate: 0.1000 (0.1000) Top1_base: 70.3125 (72.8993) Top1_base_per_class: 71.9507 (73.3368) 
Training Epoch: [47/1000] Step: [190 / 285] Batch Time: 0.1472 (0.1594) Data Time: 0.0151 (0.0263) Average Loss: 1.0088 (0.9934) Average CE Loss (Source):  1.0088 ( 0.9934) Learning Rate: 0.1000 (0.1000) Top1_base: 74.2188 (72.7714) Top1_base_per_class: 70.5152 (73.2493) 
Training Epoch: [47/1000] Step: [200 / 285] Batch Time: 0.2072 (0.1597) Data Time: 0.0751 (0.0266) Average Loss: 1.0103 (0.9963) Average CE Loss (Source):  1.0103 ( 0.9963) Learning Rate: 0.1000 (0.1000) Top1_base: 71.8750 (72.7383) Top1_base_per_class: 70.9119 (73.1337) 
Training Epoch: [47/1000] Step: [210 / 285] Batch Time: 0.1495 (0.1595) Data Time: 0.0174 (0.0265) Average Loss: 0.9950 (0.9993) Average CE Loss (Source):  0.9950 ( 0.9993) Learning Rate: 0.1000 (0.1000) Top1_base: 75.0000 (72.7158) Top1_base_per_class: 73.9881 (73.1315) 
Training Epoch: [47/1000] Step: [220 / 285] Batch Time: 0.1778 (0.1603) Data Time: 0.0465 (0.0273) Average Loss: 1.0114 (1.0002) Average CE Loss (Source):  1.0114 ( 1.0002) Learning Rate: 0.1000 (0.1000) Top1_base: 69.5312 (72.6634) Top1_base_per_class: 67.8931 (73.1165) 
Training Epoch: [47/1000] Step: [230 / 285] Batch Time: 0.1445 (0.1604) Data Time: 0.0131 (0.0274) Average Loss: 0.7552 (1.0026) Average CE Loss (Source):  0.7552 ( 1.0026) Learning Rate: 0.1000 (0.1000) Top1_base: 78.1250 (72.6495) Top1_base_per_class: 79.0880 (73.1347) 
Training Epoch: [47/1000] Step: [240 / 285] Batch Time: 0.1902 (0.1602) Data Time: 0.0578 (0.0273) Average Loss: 1.1100 (1.0033) Average CE Loss (Source):  1.1100 ( 1.0033) Learning Rate: 0.1000 (0.1000) Top1_base: 64.8438 (72.5260) Top1_base_per_class: 66.3580 (73.0308) 
Training Epoch: [47/1000] Step: [250 / 285] Batch Time: 0.1440 (0.1599) Data Time: 0.0126 (0.0269) Average Loss: 1.1011 (1.0039) Average CE Loss (Source):  1.1011 ( 1.0039) Learning Rate: 0.1000 (0.1000) Top1_base: 67.1875 (72.5281) Top1_base_per_class: 72.9167 (73.0635) 
Training Epoch: [47/1000] Step: [260 / 285] Batch Time: 0.1626 (0.1597) Data Time: 0.0309 (0.0268) Average Loss: 1.2484 (1.0042) Average CE Loss (Source):  1.2484 ( 1.0042) Learning Rate: 0.1000 (0.1000) Top1_base: 66.4062 (72.5270) Top1_base_per_class: 68.4249 (73.0515) 
Training Epoch: [47/1000] Step: [270 / 285] Batch Time: 0.1461 (0.1597) Data Time: 0.0152 (0.0267) Average Loss: 0.9701 (1.0042) Average CE Loss (Source):  0.9701 ( 1.0042) Learning Rate: 0.1000 (0.1000) Top1_base: 73.4375 (72.4769) Top1_base_per_class: 75.1148 (72.9922) 
Training Epoch: [47/1000] Step: [280 / 285] Batch Time: 0.1621 (0.1599) Data Time: 0.0311 (0.0269) Average Loss: 1.0440 (1.0041) Average CE Loss (Source):  1.0440 ( 1.0041) Learning Rate: 0.1000 (0.1000) Top1_base: 74.2188 (72.5140) Top1_base_per_class: 75.3333 (73.0322) 
Training Epoch: [48/1000] Step: [0] Batch Time: 0.1399 (0.1597) Data Time: 0.0115 (0.0268) Average Loss: 1.0494 (1.0067) Average CE Loss (Source):  1.0494 ( 1.0067) Learning Rate: 0.1000 (0.1000) Top1_base: 68.7500 (72.4644) Top1_base_per_class: 64.2308 (72.9764) 
  5%|▍         | 48/1000 [38:01<12:21:18, 46.72s/it]  5%|▍         | 49/1000 [38:46<12:11:58, 46.18s/it]Training Epoch: [48/1000] Step: [10 / 285] Batch Time: 0.1424 (0.2343) Data Time: 0.0113 (0.1025) Average Loss: 1.0766 (0.9032) Average CE Loss (Source):  1.0766 ( 0.9032) Learning Rate: 0.1000 (0.1000) Top1_base: 74.2188 (75.3906) Top1_base_per_class: 79.4253 (74.9901) 
Training Epoch: [48/1000] Step: [20 / 285] Batch Time: 0.1494 (0.2022) Data Time: 0.0112 (0.0692) Average Loss: 1.1463 (0.9326) Average CE Loss (Source):  1.1463 ( 0.9326) Learning Rate: 0.1000 (0.1000) Top1_base: 71.8750 (74.5703) Top1_base_per_class: 73.0117 (75.2116) 
Training Epoch: [48/1000] Step: [30 / 285] Batch Time: 0.1445 (0.1859) Data Time: 0.0113 (0.0530) Average Loss: 0.9603 (0.9523) Average CE Loss (Source):  0.9603 ( 0.9523) Learning Rate: 0.1000 (0.1000) Top1_base: 70.3125 (73.7760) Top1_base_per_class: 67.1296 (73.8734) 
Training Epoch: [48/1000] Step: [40 / 285] Batch Time: 0.1458 (0.1794) Data Time: 0.0144 (0.0464) Average Loss: 0.9630 (0.9575) Average CE Loss (Source):  0.9630 ( 0.9575) Learning Rate: 0.1000 (0.1000) Top1_base: 69.5312 (73.4570) Top1_base_per_class: 69.4952 (73.4589) 
Training Epoch: [48/1000] Step: [50 / 285] Batch Time: 0.1444 (0.1747) Data Time: 0.0129 (0.0414) Average Loss: 0.8994 (0.9705) Average CE Loss (Source):  0.8994 ( 0.9705) Learning Rate: 0.1000 (0.1000) Top1_base: 74.2188 (72.9531) Top1_base_per_class: 74.7953 (73.2129) 
Training Epoch: [48/1000] Step: [60 / 285] Batch Time: 0.1485 (0.1707) Data Time: 0.0115 (0.0374) Average Loss: 0.8993 (0.9692) Average CE Loss (Source):  0.8993 ( 0.9692) Learning Rate: 0.1000 (0.1000) Top1_base: 75.0000 (72.9557) Top1_base_per_class: 76.5741 (73.2510) 
Training Epoch: [48/1000] Step: [70 / 285] Batch Time: 0.1450 (0.1696) Data Time: 0.0130 (0.0362) Average Loss: 1.0464 (0.9722) Average CE Loss (Source):  1.0464 ( 0.9722) Learning Rate: 0.1000 (0.1000) Top1_base: 67.1875 (72.8571) Top1_base_per_class: 69.0278 (73.3139) 
Training Epoch: [48/1000] Step: [80 / 285] Batch Time: 0.1459 (0.1678) Data Time: 0.0104 (0.0344) Average Loss: 0.7585 (0.9659) Average CE Loss (Source):  0.7585 ( 0.9659) Learning Rate: 0.1000 (0.1000) Top1_base: 74.2188 (72.9688) Top1_base_per_class: 76.1607 (73.4428) 
Training Epoch: [48/1000] Step: [90 / 285] Batch Time: 0.1438 (0.1658) Data Time: 0.0114 (0.0325) Average Loss: 0.8090 (0.9688) Average CE Loss (Source):  0.8090 ( 0.9688) Learning Rate: 0.1000 (0.1000) Top1_base: 75.7812 (73.0903) Top1_base_per_class: 73.8580 (73.5546) 
Training Epoch: [48/1000] Step: [100 / 285] Batch Time: 0.1465 (0.1639) Data Time: 0.0111 (0.0306) Average Loss: 1.1098 (0.9743) Average CE Loss (Source):  1.1098 ( 0.9743) Learning Rate: 0.1000 (0.1000) Top1_base: 71.0938 (72.9375) Top1_base_per_class: 70.0617 (73.4364) 
Training Epoch: [48/1000] Step: [110 / 285] Batch Time: 0.1459 (0.1627) Data Time: 0.0116 (0.0294) Average Loss: 1.0622 (0.9727) Average CE Loss (Source):  1.0622 ( 0.9727) Learning Rate: 0.1000 (0.1000) Top1_base: 71.0938 (72.9545) Top1_base_per_class: 72.4242 (73.5011) 
Training Epoch: [48/1000] Step: [120 / 285] Batch Time: 0.1453 (0.1625) Data Time: 0.0137 (0.0291) Average Loss: 0.9783 (0.9728) Average CE Loss (Source):  0.9783 ( 0.9728) Learning Rate: 0.1000 (0.1000) Top1_base: 67.1875 (72.9232) Top1_base_per_class: 68.4259 (73.4938) 
Training Epoch: [48/1000] Step: [130 / 285] Batch Time: 0.1472 (0.1621) Data Time: 0.0119 (0.0287) Average Loss: 1.2184 (0.9740) Average CE Loss (Source):  1.2184 ( 0.9740) Learning Rate: 0.1000 (0.1000) Top1_base: 64.0625 (72.8486) Top1_base_per_class: 71.2641 (73.4219) 
Training Epoch: [48/1000] Step: [140 / 285] Batch Time: 0.1444 (0.1612) Data Time: 0.0108 (0.0280) Average Loss: 1.2191 (0.9717) Average CE Loss (Source):  1.2191 ( 0.9717) Learning Rate: 0.1000 (0.1000) Top1_base: 68.7500 (72.8181) Top1_base_per_class: 71.4620 (73.3939) 
Training Epoch: [48/1000] Step: [150 / 285] Batch Time: 0.1437 (0.1607) Data Time: 0.0137 (0.0275) Average Loss: 0.8386 (0.9703) Average CE Loss (Source):  0.8386 ( 0.9703) Learning Rate: 0.1000 (0.1000) Top1_base: 77.3438 (72.8854) Top1_base_per_class: 74.2128 (73.4194) 
Training Epoch: [48/1000] Step: [160 / 285] Batch Time: 0.1453 (0.1599) Data Time: 0.0140 (0.0267) Average Loss: 0.9146 (0.9686) Average CE Loss (Source):  0.9146 ( 0.9686) Learning Rate: 0.1000 (0.1000) Top1_base: 72.6562 (72.8223) Top1_base_per_class: 71.2893 (73.3303) 
Training Epoch: [48/1000] Step: [170 / 285] Batch Time: 0.1477 (0.1592) Data Time: 0.0154 (0.0260) Average Loss: 0.8693 (0.9703) Average CE Loss (Source):  0.8693 ( 0.9703) Learning Rate: 0.1000 (0.1000) Top1_base: 72.6562 (72.7114) Top1_base_per_class: 76.6236 (73.1905) 
Training Epoch: [48/1000] Step: [180 / 285] Batch Time: 0.1462 (0.1585) Data Time: 0.0109 (0.0253) Average Loss: 0.8349 (0.9734) Average CE Loss (Source):  0.8349 ( 0.9734) Learning Rate: 0.1000 (0.1000) Top1_base: 75.0000 (72.6432) Top1_base_per_class: 75.1190 (73.0594) 
Training Epoch: [48/1000] Step: [190 / 285] Batch Time: 0.1490 (0.1579) Data Time: 0.0153 (0.0247) Average Loss: 1.2515 (0.9756) Average CE Loss (Source):  1.2515 ( 0.9756) Learning Rate: 0.1000 (0.1000) Top1_base: 66.4062 (72.5863) Top1_base_per_class: 64.5614 (72.9786) 
Training Epoch: [48/1000] Step: [200 / 285] Batch Time: 0.1420 (0.1574) Data Time: 0.0126 (0.0242) Average Loss: 1.2533 (0.9804) Average CE Loss (Source):  1.2533 ( 0.9804) Learning Rate: 0.1000 (0.1000) Top1_base: 65.6250 (72.4922) Top1_base_per_class: 63.8050 (72.8756) 
Training Epoch: [48/1000] Step: [210 / 285] Batch Time: 0.2098 (0.1577) Data Time: 0.0766 (0.0245) Average Loss: 0.9692 (0.9792) Average CE Loss (Source):  0.9692 ( 0.9792) Learning Rate: 0.1000 (0.1000) Top1_base: 72.6562 (72.5856) Top1_base_per_class: 71.2424 (72.9653) 
Training Epoch: [48/1000] Step: [220 / 285] Batch Time: 0.1449 (0.1572) Data Time: 0.0137 (0.0240) Average Loss: 0.8979 (0.9811) Average CE Loss (Source):  0.8979 ( 0.9811) Learning Rate: 0.1000 (0.1000) Top1_base: 75.0000 (72.5639) Top1_base_per_class: 75.0926 (72.9484) 
Training Epoch: [48/1000] Step: [230 / 285] Batch Time: 0.1559 (0.1574) Data Time: 0.0244 (0.0243) Average Loss: 1.0126 (0.9815) Average CE Loss (Source):  1.0126 ( 0.9815) Learning Rate: 0.1000 (0.1000) Top1_base: 73.4375 (72.5136) Top1_base_per_class: 75.7184 (72.9258) 
Training Epoch: [48/1000] Step: [240 / 285] Batch Time: 0.1458 (0.1574) Data Time: 0.0108 (0.0243) Average Loss: 0.7692 (0.9806) Average CE Loss (Source):  0.7692 ( 0.9806) Learning Rate: 0.1000 (0.1000) Top1_base: 78.1250 (72.5358) Top1_base_per_class: 79.2560 (72.9605) 
Training Epoch: [48/1000] Step: [250 / 285] Batch Time: 0.2302 (0.1578) Data Time: 0.0987 (0.0247) Average Loss: 0.8363 (0.9852) Average CE Loss (Source):  0.8363 ( 0.9852) Learning Rate: 0.1000 (0.1000) Top1_base: 75.0000 (72.3844) Top1_base_per_class: 71.2865 (72.7818) 
Training Epoch: [48/1000] Step: [260 / 285] Batch Time: 0.1458 (0.1579) Data Time: 0.0116 (0.0247) Average Loss: 1.2668 (0.9883) Average CE Loss (Source):  1.2668 ( 0.9883) Learning Rate: 0.1000 (0.1000) Top1_base: 60.1562 (72.2686) Top1_base_per_class: 64.0303 (72.6877) 
Training Epoch: [48/1000] Step: [270 / 285] Batch Time: 0.1617 (0.1578) Data Time: 0.0293 (0.0246) Average Loss: 1.0761 (0.9907) Average CE Loss (Source):  1.0761 ( 0.9907) Learning Rate: 0.1000 (0.1000) Top1_base: 68.7500 (72.1962) Top1_base_per_class: 70.4386 (72.6463) 
Training Epoch: [48/1000] Step: [280 / 285] Batch Time: 0.1459 (0.1576) Data Time: 0.0107 (0.0244) Average Loss: 0.8991 (0.9914) Average CE Loss (Source):  0.8991 ( 0.9914) Learning Rate: 0.1000 (0.1000) Top1_base: 71.8750 (72.1903) Top1_base_per_class: 72.6786 (72.6093) 
Training Epoch: [49/1000] Step: [0] Batch Time: 0.1441 (0.1574) Data Time: 0.0122 (0.0242) Average Loss: 1.0866 (0.9924) Average CE Loss (Source):  1.0866 ( 0.9924) Learning Rate: 0.1000 (0.1000) Top1_base: 66.4062 (72.1628) Top1_base_per_class: 70.6215 (72.5856) 
Training Epoch: [49/1000] Step: [10 / 285] Batch Time: 0.1460 (0.2589) Data Time: 0.0113 (0.1255) Average Loss: 1.1576 (1.0523) Average CE Loss (Source):  1.1576 ( 1.0523) Learning Rate: 0.1000 (0.1000) Top1_base: 71.0938 (71.5625) Top1_base_per_class: 76.3117 (72.0697) 
Training Epoch: [49/1000] Step: [20 / 285] Batch Time: 0.1461 (0.2116) Data Time: 0.0129 (0.0785) Average Loss: 1.0680 (1.0202) Average CE Loss (Source):  1.0680 ( 1.0202) Learning Rate: 0.1000 (0.1000) Top1_base: 69.5312 (72.4609) Top1_base_per_class: 70.7627 (73.1247) 
Training Epoch: [49/1000] Step: [30 / 285] Batch Time: 0.1458 (0.1926) Data Time: 0.0112 (0.0593) Average Loss: 1.0027 (1.0073) Average CE Loss (Source):  1.0027 ( 1.0073) Learning Rate: 0.1000 (0.1000) Top1_base: 74.2188 (73.1771) Top1_base_per_class: 78.6163 (73.9019) 
Training Epoch: [49/1000] Step: [40 / 285] Batch Time: 0.1471 (0.1824) Data Time: 0.0115 (0.0492) Average Loss: 0.8113 (0.9939) Average CE Loss (Source):  0.8113 ( 0.9939) Learning Rate: 0.1000 (0.1000) Top1_base: 74.2188 (73.0859) Top1_base_per_class: 74.9038 (73.8582) 
Training Epoch: [49/1000] Step: [50 / 285] Batch Time: 0.1494 (0.1770) Data Time: 0.0135 (0.0438) Average Loss: 0.7694 (0.9805) Average CE Loss (Source):  0.7694 ( 0.9805) Learning Rate: 0.1000 (0.1000) Top1_base: 78.9062 (73.4375) Top1_base_per_class: 80.9784 (74.1618) 
Training Epoch: [49/1000] Step: [60 / 285] Batch Time: 0.1463 (0.1727) Data Time: 0.0105 (0.0395) Average Loss: 0.9523 (0.9769) Average CE Loss (Source):  0.9523 ( 0.9769) Learning Rate: 0.1000 (0.1000) Top1_base: 69.5312 (73.3594) Top1_base_per_class: 70.8046 (74.1285) 
Training Epoch: [49/1000] Step: [70 / 285] Batch Time: 0.1466 (0.1705) Data Time: 0.0110 (0.0374) Average Loss: 0.9479 (0.9739) Average CE Loss (Source):  0.9479 ( 0.9739) Learning Rate: 0.1000 (0.1000) Top1_base: 72.6562 (73.2254) Top1_base_per_class: 75.8621 (74.1076) 
Training Epoch: [49/1000] Step: [80 / 285] Batch Time: 0.1460 (0.1682) Data Time: 0.0113 (0.0349) Average Loss: 1.0258 (0.9775) Average CE Loss (Source):  1.0258 ( 0.9775) Learning Rate: 0.1000 (0.1000) Top1_base: 69.5312 (73.1055) Top1_base_per_class: 68.0747 (73.7900) 
Training Epoch: [49/1000] Step: [90 / 285] Batch Time: 0.1467 (0.1682) Data Time: 0.0134 (0.0349) Average Loss: 1.0383 (0.9806) Average CE Loss (Source):  1.0383 ( 0.9806) Learning Rate: 0.1000 (0.1000) Top1_base: 73.4375 (73.1510) Top1_base_per_class: 74.7126 (73.9746) 
Training Epoch: [49/1000] Step: [100 / 285] Batch Time: 0.1440 (0.1665) Data Time: 0.0126 (0.0332) Average Loss: 0.8545 (0.9869) Average CE Loss (Source):  0.8545 ( 0.9869) Learning Rate: 0.1000 (0.1000) Top1_base: 75.0000 (73.0703) Top1_base_per_class: 77.0000 (73.8366) 
Training Epoch: [49/1000] Step: [110 / 285] Batch Time: 0.1464 (0.1650) Data Time: 0.0109 (0.0318) Average Loss: 0.9012 (0.9860) Average CE Loss (Source):  0.9012 ( 0.9860) Learning Rate: 0.1000 (0.1000) Top1_base: 75.0000 (72.9474) Top1_base_per_class: 78.0357 (73.6792) 
Training Epoch: [49/1000] Step: [120 / 285] Batch Time: 0.1473 (0.1647) Data Time: 0.0116 (0.0315) Average Loss: 0.7594 (0.9845) Average CE Loss (Source):  0.7594 ( 0.9845) Learning Rate: 0.1000 (0.1000) Top1_base: 80.4688 (72.9232) Top1_base_per_class: 80.6874 (73.5880) 
Training Epoch: [49/1000] Step: [130 / 285] Batch Time: 0.1444 (0.1639) Data Time: 0.0111 (0.0307) Average Loss: 1.0506 (0.9825) Average CE Loss (Source):  1.0506 ( 0.9825) Learning Rate: 0.1000 (0.1000) Top1_base: 67.1875 (72.9627) Top1_base_per_class: 66.6667 (73.6367) 
Training Epoch: [49/1000] Step: [140 / 285] Batch Time: 0.1464 (0.1631) Data Time: 0.0137 (0.0299) Average Loss: 1.0003 (0.9835) Average CE Loss (Source):  1.0003 ( 0.9835) Learning Rate: 0.1000 (0.1000) Top1_base: 71.0938 (72.8795) Top1_base_per_class: 72.3183 (73.5157) 
Training Epoch: [49/1000] Step: [150 / 285] Batch Time: 0.1460 (0.1631) Data Time: 0.0134 (0.0299) Average Loss: 1.0512 (0.9794) Average CE Loss (Source):  1.0512 ( 0.9794) Learning Rate: 0.1000 (0.1000) Top1_base: 74.2188 (72.9688) Top1_base_per_class: 74.7953 (73.5809) 
Training Epoch: [49/1000] Step: [160 / 285] Batch Time: 0.1442 (0.1626) Data Time: 0.0122 (0.0295) Average Loss: 0.9855 (0.9774) Average CE Loss (Source):  0.9855 ( 0.9774) Learning Rate: 0.1000 (0.1000) Top1_base: 77.3438 (73.0566) Top1_base_per_class: 75.8772 (73.6394) 
Training Epoch: [49/1000] Step: [170 / 285] Batch Time: 0.1449 (0.1620) Data Time: 0.0127 (0.0289) Average Loss: 0.9655 (0.9749) Average CE Loss (Source):  0.9655 ( 0.9749) Learning Rate: 0.1000 (0.1000) Top1_base: 74.2188 (73.0882) Top1_base_per_class: 76.1212 (73.6362) 
Training Epoch: [49/1000] Step: [180 / 285] Batch Time: 0.1468 (0.1616) Data Time: 0.0116 (0.0285) Average Loss: 0.9589 (0.9750) Average CE Loss (Source):  0.9589 ( 0.9750) Learning Rate: 0.1000 (0.1000) Top1_base: 68.7500 (73.0642) Top1_base_per_class: 71.9091 (73.6073) 
Training Epoch: [49/1000] Step: [190 / 285] Batch Time: 0.1451 (0.1615) Data Time: 0.0111 (0.0285) Average Loss: 1.1928 (0.9763) Average CE Loss (Source):  1.1928 ( 0.9763) Learning Rate: 0.1000 (0.1000) Top1_base: 63.2812 (73.0181) Top1_base_per_class: 68.1609 (73.5969) 
Training Epoch: [49/1000] Step: [200 / 285] Batch Time: 0.1451 (0.1608) Data Time: 0.0126 (0.0277) Average Loss: 1.0042 (0.9789) Average CE Loss (Source):  1.0042 ( 0.9789) Learning Rate: 0.1000 (0.1000) Top1_base: 73.4375 (72.8828) Top1_base_per_class: 73.1481 (73.4210) 
Training Epoch: [49/1000] Step: [210 / 285] Batch Time: 0.1459 (0.1607) Data Time: 0.0108 (0.0276) Average Loss: 0.8886 (0.9802) Average CE Loss (Source):  0.8886 ( 0.9802) Learning Rate: 0.1000 (0.1000) Top1_base: 78.1250 (72.9055) Top1_base_per_class: 79.5455 (73.4406) 
Training Epoch: [49/1000] Step: [220 / 285] Batch Time: 0.1442 (0.1601) Data Time: 0.0126 (0.0270) Average Loss: 1.1091 (0.9812) Average CE Loss (Source):  1.1091 ( 0.9812) Learning Rate: 0.1000 (0.1000) Top1_base: 68.7500 (72.8267) Top1_base_per_class: 69.2262 (73.3408) 
Training Epoch: [49/1000] Step: [230 / 285] Batch Time: 0.1429 (0.1597) Data Time: 0.0127 (0.0267) Average Loss: 1.0229 (0.9864) Average CE Loss (Source):  1.0229 ( 0.9864) Learning Rate: 0.1000 (0.1000) Top1_base: 71.8750 (72.7004) Top1_base_per_class: 74.8485 (73.2066) 
Training Epoch: [49/1000] Step: [240 / 285] Batch Time: 0.1492 (0.1591) Data Time: 0.0115 (0.0261) Average Loss: 1.2519 (0.9902) Average CE Loss (Source):  1.2519 ( 0.9902) Learning Rate: 0.1000 (0.1000) Top1_base: 67.1875 (72.6204) Top1_base_per_class: 65.7407 (73.0983) 
Training Epoch: [49/1000] Step: [250 / 285] Batch Time: 0.1458 (0.1587) Data Time: 0.0124 (0.0256) Average Loss: 0.9556 (0.9897) Average CE Loss (Source):  0.9556 ( 0.9897) Learning Rate: 0.1000 (0.1000) Top1_base: 75.0000 (72.6813) Top1_base_per_class: 75.7716 (73.1590) 
Training Epoch: [49/1000] Step: [260 / 285] Batch Time: 0.1499 (0.1583) Data Time: 0.0126 (0.0251) Average Loss: 1.0831 (0.9910) Average CE Loss (Source):  1.0831 ( 0.9910) Learning Rate: 0.1000 (0.1000) Top1_base: 67.9688 (72.6262) Top1_base_per_class: 71.8182 (73.0757) 
Training Epoch: [49/1000] Step: [270 / 285] Batch Time: 0.1451 (0.1579) Data Time: 0.0130 (0.0247) Average Loss: 1.1131 (0.9915) Average CE Loss (Source):  1.1131 ( 0.9915) Learning Rate: 0.1000 (0.1000) Top1_base: 66.4062 (72.5926) Top1_base_per_class: 61.1515 (73.0196) 
Training Epoch: [49/1000] Step: [280 / 285] Batch Time: 0.1488 (0.1576) Data Time: 0.0117 (0.0244) Average Loss: 1.2702 (0.9942) Average CE Loss (Source):  1.2702 ( 0.9942) Learning Rate: 0.1000 (0.1000) Top1_base: 67.1875 (72.5279) Top1_base_per_class: 69.7953 (72.9948) 
Training Epoch: [50/1000] Step: [0] Batch Time: 0.1429 (0.1574) Data Time: 0.0123 (0.0242) Average Loss: 0.9441 (0.9958) Average CE Loss (Source):  0.9441 ( 0.9958) Learning Rate: 0.1000 (0.1000) Top1_base: 73.4375 (72.4753) Top1_base_per_class: 70.3509 (72.8989) 
  5%|▌         | 50/1000 [39:33<12:18:26, 46.64s/it]  5%|▌         | 51/1000 [40:18<12:05:55, 45.90s/it]Training Epoch: [50/1000] Step: [10 / 285] Batch Time: 0.1499 (0.2302) Data Time: 0.0156 (0.0969) Average Loss: 0.9467 (0.9708) Average CE Loss (Source):  0.9467 ( 0.9708) Learning Rate: 0.1000 (0.1000) Top1_base: 70.3125 (73.5156) Top1_base_per_class: 72.1264 (74.6379) 
Training Epoch: [50/1000] Step: [20 / 285] Batch Time: 0.1454 (0.1935) Data Time: 0.0111 (0.0605) Average Loss: 0.9231 (0.9897) Average CE Loss (Source):  0.9231 ( 0.9897) Learning Rate: 0.1000 (0.1000) Top1_base: 71.8750 (72.5781) Top1_base_per_class: 69.7701 (73.1800) 
Training Epoch: [50/1000] Step: [30 / 285] Batch Time: 0.1493 (0.1797) Data Time: 0.0154 (0.0463) Average Loss: 0.8305 (0.9823) Average CE Loss (Source):  0.8305 ( 0.9823) Learning Rate: 0.1000 (0.1000) Top1_base: 79.6875 (72.8906) Top1_base_per_class: 82.1131 (73.7182) 
Training Epoch: [50/1000] Step: [40 / 285] Batch Time: 0.1464 (0.1725) Data Time: 0.0111 (0.0390) Average Loss: 0.8805 (0.9577) Average CE Loss (Source):  0.8805 ( 0.9577) Learning Rate: 0.1000 (0.1000) Top1_base: 75.0000 (73.3008) Top1_base_per_class: 78.1921 (74.4033) 
Training Epoch: [50/1000] Step: [50 / 285] Batch Time: 0.2166 (0.1711) Data Time: 0.0834 (0.0375) Average Loss: 1.1239 (0.9622) Average CE Loss (Source):  1.1239 ( 0.9622) Learning Rate: 0.1000 (0.1000) Top1_base: 70.3125 (73.5000) Top1_base_per_class: 72.5575 (74.5381) 
Training Epoch: [50/1000] Step: [60 / 285] Batch Time: 0.1451 (0.1670) Data Time: 0.0116 (0.0336) Average Loss: 0.8178 (0.9687) Average CE Loss (Source):  0.8178 ( 0.9687) Learning Rate: 0.1000 (0.1000) Top1_base: 78.1250 (73.3203) Top1_base_per_class: 78.1761 (74.2728) 
Training Epoch: [50/1000] Step: [70 / 285] Batch Time: 0.1663 (0.1653) Data Time: 0.0353 (0.0318) Average Loss: 0.8511 (0.9571) Average CE Loss (Source):  0.8511 ( 0.9571) Learning Rate: 0.1000 (0.1000) Top1_base: 75.0000 (73.4821) Top1_base_per_class: 77.3718 (74.4678) 
Training Epoch: [50/1000] Step: [80 / 285] Batch Time: 0.1460 (0.1650) Data Time: 0.0110 (0.0316) Average Loss: 0.8539 (0.9597) Average CE Loss (Source):  0.8539 ( 0.9597) Learning Rate: 0.1000 (0.1000) Top1_base: 74.2188 (73.4473) Top1_base_per_class: 76.0063 (74.4399) 
Training Epoch: [50/1000] Step: [90 / 285] Batch Time: 0.1931 (0.1649) Data Time: 0.0631 (0.0315) Average Loss: 1.0136 (0.9603) Average CE Loss (Source):  1.0136 ( 0.9603) Learning Rate: 0.1000 (0.1000) Top1_base: 68.7500 (73.3681) Top1_base_per_class: 68.8272 (74.1544) 
Training Epoch: [50/1000] Step: [100 / 285] Batch Time: 0.1443 (0.1631) Data Time: 0.0110 (0.0297) Average Loss: 1.1427 (0.9630) Average CE Loss (Source):  1.1427 ( 0.9630) Learning Rate: 0.1000 (0.1000) Top1_base: 64.8438 (73.2188) Top1_base_per_class: 66.8071 (73.9768) 
Training Epoch: [50/1000] Step: [110 / 285] Batch Time: 0.1515 (0.1618) Data Time: 0.0173 (0.0283) Average Loss: 0.7679 (0.9626) Average CE Loss (Source):  0.7679 ( 0.9626) Learning Rate: 0.1000 (0.1000) Top1_base: 78.1250 (73.2528) Top1_base_per_class: 76.5476 (73.9916) 
Training Epoch: [50/1000] Step: [120 / 285] Batch Time: 0.1502 (0.1608) Data Time: 0.0120 (0.0272) Average Loss: 1.0237 (0.9591) Average CE Loss (Source):  1.0237 ( 0.9591) Learning Rate: 0.1000 (0.1000) Top1_base: 72.6562 (73.3008) Top1_base_per_class: 71.8129 (74.0890) 
Training Epoch: [50/1000] Step: [130 / 285] Batch Time: 0.1487 (0.1600) Data Time: 0.0149 (0.0262) Average Loss: 0.9770 (0.9560) Average CE Loss (Source):  0.9770 ( 0.9560) Learning Rate: 0.1000 (0.1000) Top1_base: 73.4375 (73.3474) Top1_base_per_class: 73.6065 (74.0265) 
Training Epoch: [50/1000] Step: [140 / 285] Batch Time: 0.1484 (0.1590) Data Time: 0.0140 (0.0253) Average Loss: 1.0855 (0.9553) Average CE Loss (Source):  1.0855 ( 0.9553) Learning Rate: 0.1000 (0.1000) Top1_base: 72.6562 (73.3315) Top1_base_per_class: 75.3736 (74.0179) 
Training Epoch: [50/1000] Step: [150 / 285] Batch Time: 0.1464 (0.1582) Data Time: 0.0132 (0.0245) Average Loss: 1.2505 (0.9549) Average CE Loss (Source):  1.2505 ( 0.9549) Learning Rate: 0.1000 (0.1000) Top1_base: 65.6250 (73.2812) Top1_base_per_class: 67.0175 (73.9558) 
Training Epoch: [50/1000] Step: [160 / 285] Batch Time: 0.1469 (0.1575) Data Time: 0.0106 (0.0239) Average Loss: 0.9426 (0.9562) Average CE Loss (Source):  0.9426 ( 0.9562) Learning Rate: 0.1000 (0.1000) Top1_base: 70.3125 (73.1885) Top1_base_per_class: 71.2654 (73.7911) 
Training Epoch: [50/1000] Step: [170 / 285] Batch Time: 0.1473 (0.1576) Data Time: 0.0162 (0.0239) Average Loss: 1.0460 (0.9576) Average CE Loss (Source):  1.0460 ( 0.9576) Learning Rate: 0.1000 (0.1000) Top1_base: 68.7500 (73.1985) Top1_base_per_class: 66.5603 (73.7999) 
Training Epoch: [50/1000] Step: [180 / 285] Batch Time: 0.1486 (0.1576) Data Time: 0.0103 (0.0239) Average Loss: 0.9509 (0.9589) Average CE Loss (Source):  0.9509 ( 0.9589) Learning Rate: 0.1000 (0.1000) Top1_base: 77.3438 (73.2465) Top1_base_per_class: 75.5085 (73.7875) 
Training Epoch: [50/1000] Step: [190 / 285] Batch Time: 0.1490 (0.1572) Data Time: 0.0149 (0.0236) Average Loss: 0.8369 (0.9614) Average CE Loss (Source):  0.8369 ( 0.9614) Learning Rate: 0.1000 (0.1000) Top1_base: 77.3438 (73.1867) Top1_base_per_class: 78.9881 (73.6819) 
Training Epoch: [50/1000] Step: [200 / 285] Batch Time: 0.1451 (0.1570) Data Time: 0.0119 (0.0233) Average Loss: 1.0003 (0.9621) Average CE Loss (Source):  1.0003 ( 0.9621) Learning Rate: 0.1000 (0.1000) Top1_base: 75.0000 (73.1914) Top1_base_per_class: 78.7798 (73.6190) 
Training Epoch: [50/1000] Step: [210 / 285] Batch Time: 0.1466 (0.1567) Data Time: 0.0133 (0.0231) Average Loss: 1.0397 (0.9661) Average CE Loss (Source):  1.0397 ( 0.9661) Learning Rate: 0.1000 (0.1000) Top1_base: 67.9688 (73.0320) Top1_base_per_class: 70.8333 (73.4403) 
Training Epoch: [50/1000] Step: [220 / 285] Batch Time: 0.1495 (0.1565) Data Time: 0.0106 (0.0229) Average Loss: 0.9754 (0.9704) Average CE Loss (Source):  0.9754 ( 0.9704) Learning Rate: 0.1000 (0.1000) Top1_base: 75.7812 (72.9297) Top1_base_per_class: 74.5322 (73.3627) 
Training Epoch: [50/1000] Step: [230 / 285] Batch Time: 0.1527 (0.1563) Data Time: 0.0178 (0.0225) Average Loss: 1.1127 (0.9715) Average CE Loss (Source):  1.1127 ( 0.9715) Learning Rate: 0.1000 (0.1000) Top1_base: 65.6250 (72.8635) Top1_base_per_class: 64.9713 (73.2157) 
Training Epoch: [50/1000] Step: [240 / 285] Batch Time: 0.1500 (0.1559) Data Time: 0.0106 (0.0222) Average Loss: 1.1829 (0.9740) Average CE Loss (Source):  1.1829 ( 0.9740) Learning Rate: 0.1000 (0.1000) Top1_base: 65.6250 (72.7572) Top1_base_per_class: 64.2460 (73.1114) 
Training Epoch: [50/1000] Step: [250 / 285] Batch Time: 0.1493 (0.1557) Data Time: 0.0173 (0.0219) Average Loss: 1.0303 (0.9739) Average CE Loss (Source):  1.0303 ( 0.9739) Learning Rate: 0.1000 (0.1000) Top1_base: 73.4375 (72.7687) Top1_base_per_class: 75.9524 (73.1332) 
Training Epoch: [50/1000] Step: [260 / 285] Batch Time: 0.1466 (0.1554) Data Time: 0.0122 (0.0216) Average Loss: 1.2544 (0.9779) Average CE Loss (Source):  1.2544 ( 0.9779) Learning Rate: 0.1000 (0.1000) Top1_base: 64.8438 (72.7043) Top1_base_per_class: 63.9394 (73.0996) 
Training Epoch: [50/1000] Step: [270 / 285] Batch Time: 0.1484 (0.1551) Data Time: 0.0145 (0.0213) Average Loss: 0.9637 (0.9780) Average CE Loss (Source):  0.9637 ( 0.9780) Learning Rate: 0.1000 (0.1000) Top1_base: 73.4375 (72.6881) Top1_base_per_class: 77.1930 (73.0600) 
Training Epoch: [50/1000] Step: [280 / 285] Batch Time: 0.1677 (0.1549) Data Time: 0.0356 (0.0212) Average Loss: 1.0021 (0.9788) Average CE Loss (Source):  1.0021 ( 0.9788) Learning Rate: 0.1000 (0.1000) Top1_base: 74.2188 (72.6786) Top1_base_per_class: 76.9048 (73.0638) 
Training Epoch: [51/1000] Step: [0] Batch Time: 0.1463 (0.1548) Data Time: 0.0115 (0.0210) Average Loss: 0.9679 (0.9797) Average CE Loss (Source):  0.9679 ( 0.9797) Learning Rate: 0.1000 (0.1000) Top1_base: 69.5312 (72.6425) Top1_base_per_class: 70.8333 (73.0256) 
Training Epoch: [51/1000] Step: [10 / 285] Batch Time: 0.1502 (0.2305) Data Time: 0.0163 (0.0983) Average Loss: 1.0211 (0.9096) Average CE Loss (Source):  1.0211 ( 0.9096) Learning Rate: 0.1000 (0.1000) Top1_base: 71.0938 (75.0000) Top1_base_per_class: 69.3910 (74.7512) 
Training Epoch: [51/1000] Step: [20 / 285] Batch Time: 0.1445 (0.1912) Data Time: 0.0123 (0.0587) Average Loss: 0.8505 (0.9275) Average CE Loss (Source):  0.8505 ( 0.9275) Learning Rate: 0.1000 (0.1000) Top1_base: 75.7812 (73.7109) Top1_base_per_class: 76.4881 (73.5946) 
Training Epoch: [51/1000] Step: [30 / 285] Batch Time: 0.2249 (0.1839) Data Time: 0.0927 (0.0516) Average Loss: 0.8479 (0.9267) Average CE Loss (Source):  0.8479 ( 0.9267) Learning Rate: 0.1000 (0.1000) Top1_base: 71.8750 (73.9062) Top1_base_per_class: 73.6310 (74.0059) 
Training Epoch: [51/1000] Step: [40 / 285] Batch Time: 0.1462 (0.1760) Data Time: 0.0115 (0.0435) Average Loss: 1.0390 (0.9359) Average CE Loss (Source):  1.0390 ( 0.9359) Learning Rate: 0.1000 (0.1000) Top1_base: 72.6562 (73.7695) Top1_base_per_class: 71.4943 (73.7568) 
Training Epoch: [51/1000] Step: [50 / 285] Batch Time: 0.1512 (0.1708) Data Time: 0.0169 (0.0375) Average Loss: 1.0242 (0.9352) Average CE Loss (Source):  1.0242 ( 0.9352) Learning Rate: 0.1000 (0.1000) Top1_base: 73.4375 (73.6719) Top1_base_per_class: 74.4069 (74.1515) 
Training Epoch: [51/1000] Step: [60 / 285] Batch Time: 0.1459 (0.1668) Data Time: 0.0111 (0.0335) Average Loss: 1.1864 (0.9454) Average CE Loss (Source):  1.1864 ( 0.9454) Learning Rate: 0.1000 (0.1000) Top1_base: 70.3125 (73.5417) Top1_base_per_class: 71.0345 (74.1126) 
Training Epoch: [51/1000] Step: [70 / 285] Batch Time: 0.1504 (0.1660) Data Time: 0.0149 (0.0323) Average Loss: 1.0097 (0.9584) Average CE Loss (Source):  1.0097 ( 0.9584) Learning Rate: 0.1000 (0.1000) Top1_base: 69.5312 (73.1027) Top1_base_per_class: 70.4849 (73.5293) 
Training Epoch: [51/1000] Step: [80 / 285] Batch Time: 0.1439 (0.1636) Data Time: 0.0116 (0.0301) Average Loss: 0.8272 (0.9538) Average CE Loss (Source):  0.8272 ( 0.9538) Learning Rate: 0.1000 (0.1000) Top1_base: 78.1250 (73.2812) Top1_base_per_class: 77.7359 (73.8783) 
Training Epoch: [51/1000] Step: [90 / 285] Batch Time: 0.2402 (0.1639) Data Time: 0.1050 (0.0305) Average Loss: 1.0103 (0.9505) Average CE Loss (Source):  1.0103 ( 0.9505) Learning Rate: 0.1000 (0.1000) Top1_base: 74.2188 (73.3941) Top1_base_per_class: 72.6730 (73.9143) 
Training Epoch: [51/1000] Step: [100 / 285] Batch Time: 0.1413 (0.1643) Data Time: 0.0103 (0.0310) Average Loss: 1.0794 (0.9531) Average CE Loss (Source):  1.0794 ( 0.9531) Learning Rate: 0.1000 (0.1000) Top1_base: 71.8750 (73.1797) Top1_base_per_class: 73.2527 (73.7320) 
Training Epoch: [51/1000] Step: [110 / 285] Batch Time: 0.1521 (0.1627) Data Time: 0.0173 (0.0294) Average Loss: 1.0049 (0.9545) Average CE Loss (Source):  1.0049 ( 0.9545) Learning Rate: 0.1000 (0.1000) Top1_base: 71.0938 (73.1747) Top1_base_per_class: 71.2500 (73.8134) 
Training Epoch: [51/1000] Step: [120 / 285] Batch Time: 0.1418 (0.1613) Data Time: 0.0107 (0.0281) Average Loss: 0.8432 (0.9505) Average CE Loss (Source):  0.8432 ( 0.9505) Learning Rate: 0.1000 (0.1000) Top1_base: 75.7812 (73.2812) Top1_base_per_class: 77.5439 (73.8888) 
Training Epoch: [51/1000] Step: [130 / 285] Batch Time: 0.2296 (0.1610) Data Time: 0.0947 (0.0278) Average Loss: 0.9083 (0.9536) Average CE Loss (Source):  0.9083 ( 0.9536) Learning Rate: 0.1000 (0.1000) Top1_base: 69.5312 (73.2091) Top1_base_per_class: 73.9951 (73.8320) 
Training Epoch: [51/1000] Step: [140 / 285] Batch Time: 0.1414 (0.1604) Data Time: 0.0105 (0.0273) Average Loss: 0.7931 (0.9518) Average CE Loss (Source):  0.7931 ( 0.9518) Learning Rate: 0.1000 (0.1000) Top1_base: 77.3438 (73.3092) Top1_base_per_class: 76.2919 (73.9771) 
Training Epoch: [51/1000] Step: [150 / 285] Batch Time: 0.2674 (0.1604) Data Time: 0.1322 (0.0272) Average Loss: 0.9906 (0.9509) Average CE Loss (Source):  0.9906 ( 0.9509) Learning Rate: 0.1000 (0.1000) Top1_base: 69.5312 (73.2969) Top1_base_per_class: 69.0476 (73.7806) 
Training Epoch: [51/1000] Step: [160 / 285] Batch Time: 0.1478 (0.1600) Data Time: 0.0129 (0.0268) Average Loss: 0.7868 (0.9504) Average CE Loss (Source):  0.7868 ( 0.9504) Learning Rate: 0.1000 (0.1000) Top1_base: 75.0000 (73.2666) Top1_base_per_class: 77.2424 (73.7070) 
Training Epoch: [51/1000] Step: [170 / 285] Batch Time: 0.1559 (0.1595) Data Time: 0.0191 (0.0261) Average Loss: 0.8109 (0.9519) Average CE Loss (Source):  0.8109 ( 0.9519) Learning Rate: 0.1000 (0.1000) Top1_base: 78.1250 (73.2491) Top1_base_per_class: 79.4196 (73.6743) 
Training Epoch: [51/1000] Step: [180 / 285] Batch Time: 0.1450 (0.1589) Data Time: 0.0110 (0.0254) Average Loss: 0.8349 (0.9533) Average CE Loss (Source):  0.8349 ( 0.9533) Learning Rate: 0.1000 (0.1000) Top1_base: 80.4688 (73.2509) Top1_base_per_class: 83.6728 (73.7065) 
Training Epoch: [51/1000] Step: [190 / 285] Batch Time: 0.1546 (0.1584) Data Time: 0.0185 (0.0248) Average Loss: 0.8578 (0.9578) Average CE Loss (Source):  0.8578 ( 0.9578) Learning Rate: 0.1000 (0.1000) Top1_base: 80.4688 (73.2031) Top1_base_per_class: 78.7069 (73.6192) 
Training Epoch: [51/1000] Step: [200 / 285] Batch Time: 0.1426 (0.1580) Data Time: 0.0109 (0.0244) Average Loss: 1.0358 (0.9602) Average CE Loss (Source):  1.0358 ( 0.9602) Learning Rate: 0.1000 (0.1000) Top1_base: 70.3125 (73.1289) Top1_base_per_class: 67.5000 (73.5946) 
Training Epoch: [51/1000] Step: [210 / 285] Batch Time: 0.1454 (0.1578) Data Time: 0.0143 (0.0243) Average Loss: 1.0420 (0.9612) Average CE Loss (Source):  1.0420 ( 0.9612) Learning Rate: 0.1000 (0.1000) Top1_base: 69.5312 (73.1176) Top1_base_per_class: 70.2168 (73.6239) 
Training Epoch: [51/1000] Step: [220 / 285] Batch Time: 0.1464 (0.1574) Data Time: 0.0107 (0.0238) Average Loss: 0.8836 (0.9616) Average CE Loss (Source):  0.8836 ( 0.9616) Learning Rate: 0.1000 (0.1000) Top1_base: 75.7812 (73.1179) Top1_base_per_class: 78.3898 (73.6638) 
Training Epoch: [51/1000] Step: [230 / 285] Batch Time: 0.1587 (0.1570) Data Time: 0.0233 (0.0234) Average Loss: 0.8432 (0.9620) Average CE Loss (Source):  0.8432 ( 0.9620) Learning Rate: 0.1000 (0.1000) Top1_base: 75.0000 (73.0842) Top1_base_per_class: 75.9167 (73.6643) 
Training Epoch: [51/1000] Step: [240 / 285] Batch Time: 0.1422 (0.1571) Data Time: 0.0103 (0.0235) Average Loss: 0.8105 (0.9609) Average CE Loss (Source):  0.8105 ( 0.9609) Learning Rate: 0.1000 (0.1000) Top1_base: 78.9062 (73.1738) Top1_base_per_class: 79.0207 (73.7280) 
Training Epoch: [51/1000] Step: [250 / 285] Batch Time: 0.1767 (0.1570) Data Time: 0.0422 (0.0235) Average Loss: 1.0960 (0.9627) Average CE Loss (Source):  1.0960 ( 0.9627) Learning Rate: 0.1000 (0.1000) Top1_base: 69.5312 (73.0656) Top1_base_per_class: 68.4795 (73.6241) 
Training Epoch: [51/1000] Step: [260 / 285] Batch Time: 0.1447 (0.1568) Data Time: 0.0125 (0.0233) Average Loss: 1.2586 (0.9645) Average CE Loss (Source):  1.2586 ( 0.9645) Learning Rate: 0.1000 (0.1000) Top1_base: 68.7500 (73.0649) Top1_base_per_class: 70.8788 (73.5780) 
Training Epoch: [51/1000] Step: [270 / 285] Batch Time: 0.2048 (0.1570) Data Time: 0.0707 (0.0235) Average Loss: 1.0838 (0.9645) Average CE Loss (Source):  1.0838 ( 0.9645) Learning Rate: 0.1000 (0.1000) Top1_base: 65.6250 (73.0671) Top1_base_per_class: 67.4496 (73.5510) 
Training Epoch: [51/1000] Step: [280 / 285] Batch Time: 0.1392 (0.1570) Data Time: 0.0104 (0.0236) Average Loss: 0.9474 (0.9636) Average CE Loss (Source):  0.9474 ( 0.9636) Learning Rate: 0.1000 (0.1000) Top1_base: 74.2188 (73.0748) Top1_base_per_class: 74.5062 (73.5593) 
Training Epoch: [52/1000] Step: [0] Batch Time: 0.1414 (0.1568) Data Time: 0.0122 (0.0234) Average Loss: 1.1043 (0.9655) Average CE Loss (Source):  1.1043 ( 0.9655) Learning Rate: 0.1000 (0.1000) Top1_base: 67.1875 (73.0592) Top1_base_per_class: 66.6667 (73.5325) 
  5%|▌         | 52/1000 [41:05<12:12:38, 46.37s/it]  5%|▌         | 53/1000 [41:50<12:06:03, 46.00s/it]Training Epoch: [52/1000] Step: [10 / 285] Batch Time: 0.1497 (0.2347) Data Time: 0.0152 (0.1008) Average Loss: 0.9939 (0.9653) Average CE Loss (Source):  0.9939 ( 0.9653) Learning Rate: 0.1000 (0.1000) Top1_base: 73.4375 (74.2969) Top1_base_per_class: 69.8113 (75.5931) 
Training Epoch: [52/1000] Step: [20 / 285] Batch Time: 0.1428 (0.1988) Data Time: 0.0109 (0.0653) Average Loss: 0.9396 (0.9715) Average CE Loss (Source):  0.9396 ( 0.9715) Learning Rate: 0.1000 (0.1000) Top1_base: 73.4375 (73.1250) Top1_base_per_class: 73.3929 (73.7717) 
Training Epoch: [52/1000] Step: [30 / 285] Batch Time: 0.1484 (0.1860) Data Time: 0.0137 (0.0524) Average Loss: 0.9168 (0.9639) Average CE Loss (Source):  0.9168 ( 0.9639) Learning Rate: 0.1000 (0.1000) Top1_base: 76.5625 (72.8385) Top1_base_per_class: 78.5758 (74.1561) 
Training Epoch: [52/1000] Step: [40 / 285] Batch Time: 0.1422 (0.1774) Data Time: 0.0109 (0.0441) Average Loss: 0.9382 (0.9574) Average CE Loss (Source):  0.9382 ( 0.9574) Learning Rate: 0.1000 (0.1000) Top1_base: 73.4375 (72.9492) Top1_base_per_class: 72.2327 (74.3573) 
Training Epoch: [52/1000] Step: [50 / 285] Batch Time: 0.1461 (0.1738) Data Time: 0.0111 (0.0405) Average Loss: 1.1265 (0.9606) Average CE Loss (Source):  1.1265 ( 0.9606) Learning Rate: 0.1000 (0.1000) Top1_base: 74.2188 (73.1562) Top1_base_per_class: 73.2407 (74.2858) 
Training Epoch: [52/1000] Step: [60 / 285] Batch Time: 0.1421 (0.1712) Data Time: 0.0108 (0.0379) Average Loss: 0.9961 (0.9588) Average CE Loss (Source):  0.9961 ( 0.9588) Learning Rate: 0.1000 (0.1000) Top1_base: 71.8750 (73.2943) Top1_base_per_class: 74.4865 (74.4487) 
Training Epoch: [52/1000] Step: [70 / 285] Batch Time: 0.1486 (0.1680) Data Time: 0.0136 (0.0348) Average Loss: 0.9120 (0.9513) Average CE Loss (Source):  0.9120 ( 0.9513) Learning Rate: 0.1000 (0.1000) Top1_base: 74.2188 (73.4040) Top1_base_per_class: 74.3391 (74.4608) 
Training Epoch: [52/1000] Step: [80 / 285] Batch Time: 0.1433 (0.1656) Data Time: 0.0109 (0.0324) Average Loss: 0.8678 (0.9474) Average CE Loss (Source):  0.8678 ( 0.9474) Learning Rate: 0.1000 (0.1000) Top1_base: 75.0000 (73.5059) Top1_base_per_class: 78.1761 (74.4163) 
Training Epoch: [52/1000] Step: [90 / 285] Batch Time: 0.1492 (0.1648) Data Time: 0.0144 (0.0316) Average Loss: 1.2181 (0.9499) Average CE Loss (Source):  1.2181 ( 0.9499) Learning Rate: 0.1000 (0.1000) Top1_base: 67.1875 (73.3681) Top1_base_per_class: 71.3030 (74.2567) 
Training Epoch: [52/1000] Step: [100 / 285] Batch Time: 0.1426 (0.1629) Data Time: 0.0102 (0.0298) Average Loss: 0.8601 (0.9517) Average CE Loss (Source):  0.8601 ( 0.9517) Learning Rate: 0.1000 (0.1000) Top1_base: 74.2188 (73.3672) Top1_base_per_class: 70.9195 (74.1478) 
Training Epoch: [52/1000] Step: [110 / 285] Batch Time: 0.1489 (0.1616) Data Time: 0.0137 (0.0285) Average Loss: 0.9302 (0.9528) Average CE Loss (Source):  0.9302 ( 0.9528) Learning Rate: 0.1000 (0.1000) Top1_base: 75.7812 (73.3949) Top1_base_per_class: 76.6071 (74.1368) 
Training Epoch: [52/1000] Step: [120 / 285] Batch Time: 0.1437 (0.1608) Data Time: 0.0112 (0.0276) Average Loss: 0.8705 (0.9542) Average CE Loss (Source):  0.8705 ( 0.9542) Learning Rate: 0.1000 (0.1000) Top1_base: 74.2188 (73.3659) Top1_base_per_class: 75.2381 (74.2010) 
Training Epoch: [52/1000] Step: [130 / 285] Batch Time: 0.1499 (0.1602) Data Time: 0.0142 (0.0269) Average Loss: 1.0494 (0.9562) Average CE Loss (Source):  1.0494 ( 0.9562) Learning Rate: 0.1000 (0.1000) Top1_base: 70.3125 (73.3233) Top1_base_per_class: 68.8218 (74.1089) 
Training Epoch: [52/1000] Step: [140 / 285] Batch Time: 0.1418 (0.1594) Data Time: 0.0113 (0.0262) Average Loss: 0.9257 (0.9490) Average CE Loss (Source):  0.9257 ( 0.9490) Learning Rate: 0.1000 (0.1000) Top1_base: 76.5625 (73.5268) Top1_base_per_class: 78.5577 (74.2302) 
Training Epoch: [52/1000] Step: [150 / 285] Batch Time: 0.1469 (0.1590) Data Time: 0.0137 (0.0258) Average Loss: 1.1257 (0.9535) Average CE Loss (Source):  1.1257 ( 0.9535) Learning Rate: 0.1000 (0.1000) Top1_base: 63.2812 (73.3854) Top1_base_per_class: 65.3939 (74.0596) 
Training Epoch: [52/1000] Step: [160 / 285] Batch Time: 0.1417 (0.1596) Data Time: 0.0112 (0.0264) Average Loss: 1.2295 (0.9593) Average CE Loss (Source):  1.2295 ( 0.9593) Learning Rate: 0.1000 (0.1000) Top1_base: 65.6250 (73.1982) Top1_base_per_class: 67.1914 (73.8331) 
Training Epoch: [52/1000] Step: [170 / 285] Batch Time: 0.1501 (0.1594) Data Time: 0.0151 (0.0262) Average Loss: 0.9068 (0.9622) Average CE Loss (Source):  0.9068 ( 0.9622) Learning Rate: 0.1000 (0.1000) Top1_base: 73.4375 (73.1664) Top1_base_per_class: 69.2816 (73.8021) 
Training Epoch: [52/1000] Step: [180 / 285] Batch Time: 0.1424 (0.1590) Data Time: 0.0112 (0.0258) Average Loss: 1.0254 (0.9605) Average CE Loss (Source):  1.0254 ( 0.9605) Learning Rate: 0.1000 (0.1000) Top1_base: 71.8750 (73.1510) Top1_base_per_class: 70.2161 (73.7520) 
Training Epoch: [52/1000] Step: [190 / 285] Batch Time: 0.1509 (0.1591) Data Time: 0.0156 (0.0259) Average Loss: 0.8373 (0.9585) Average CE Loss (Source):  0.8373 ( 0.9585) Learning Rate: 0.1000 (0.1000) Top1_base: 77.3438 (73.1702) Top1_base_per_class: 78.3908 (73.7269) 
Training Epoch: [52/1000] Step: [200 / 285] Batch Time: 0.1421 (0.1591) Data Time: 0.0109 (0.0259) Average Loss: 1.0429 (0.9612) Average CE Loss (Source):  1.0429 ( 0.9612) Learning Rate: 0.1000 (0.1000) Top1_base: 71.0938 (73.0586) Top1_base_per_class: 70.9821 (73.6149) 
Training Epoch: [52/1000] Step: [210 / 285] Batch Time: 0.1426 (0.1588) Data Time: 0.0123 (0.0256) Average Loss: 1.1072 (0.9648) Average CE Loss (Source):  1.1072 ( 0.9648) Learning Rate: 0.1000 (0.1000) Top1_base: 64.0625 (72.9725) Top1_base_per_class: 63.8365 (73.4666) 
Training Epoch: [52/1000] Step: [220 / 285] Batch Time: 0.1432 (0.1589) Data Time: 0.0108 (0.0256) Average Loss: 1.0569 (0.9643) Average CE Loss (Source):  1.0569 ( 0.9643) Learning Rate: 0.1000 (0.1000) Top1_base: 73.4375 (73.0327) Top1_base_per_class: 72.0728 (73.5550) 
Training Epoch: [52/1000] Step: [230 / 285] Batch Time: 0.1511 (0.1590) Data Time: 0.0159 (0.0257) Average Loss: 1.0662 (0.9649) Average CE Loss (Source):  1.0662 ( 0.9649) Learning Rate: 0.1000 (0.1000) Top1_base: 71.8750 (73.0639) Top1_base_per_class: 73.5317 (73.5679) 
Training Epoch: [52/1000] Step: [240 / 285] Batch Time: 0.1460 (0.1590) Data Time: 0.0135 (0.0257) Average Loss: 0.6063 (0.9616) Average CE Loss (Source):  0.6063 ( 0.9616) Learning Rate: 0.1000 (0.1000) Top1_base: 82.0312 (73.1510) Top1_base_per_class: 81.8750 (73.6701) 
Training Epoch: [52/1000] Step: [250 / 285] Batch Time: 0.1438 (0.1591) Data Time: 0.0122 (0.0258) Average Loss: 1.0541 (0.9648) Average CE Loss (Source):  1.0541 ( 0.9648) Learning Rate: 0.1000 (0.1000) Top1_base: 73.4375 (73.0812) Top1_base_per_class: 73.8988 (73.5720) 
Training Epoch: [52/1000] Step: [260 / 285] Batch Time: 0.1469 (0.1590) Data Time: 0.0127 (0.0257) Average Loss: 0.9448 (0.9639) Average CE Loss (Source):  0.9448 ( 0.9639) Learning Rate: 0.1000 (0.1000) Top1_base: 73.4375 (73.1220) Top1_base_per_class: 73.5494 (73.6102) 
Training Epoch: [52/1000] Step: [270 / 285] Batch Time: 0.1510 (0.1587) Data Time: 0.0149 (0.0254) Average Loss: 0.6518 (0.9633) Average CE Loss (Source):  0.6518 ( 0.9633) Learning Rate: 0.1000 (0.1000) Top1_base: 81.2500 (73.1279) Top1_base_per_class: 78.1212 (73.5850) 
Training Epoch: [52/1000] Step: [280 / 285] Batch Time: 0.1451 (0.1584) Data Time: 0.0117 (0.0251) Average Loss: 0.9360 (0.9640) Average CE Loss (Source):  0.9360 ( 0.9640) Learning Rate: 0.1000 (0.1000) Top1_base: 74.2188 (73.0943) Top1_base_per_class: 75.8642 (73.6148) 
Training Epoch: [53/1000] Step: [0] Batch Time: 0.1446 (0.1582) Data Time: 0.0113 (0.0249) Average Loss: 0.8676 (0.9647) Average CE Loss (Source):  0.8676 ( 0.9647) Learning Rate: 0.1000 (0.1000) Top1_base: 75.0000 (73.0921) Top1_base_per_class: 78.7125 (73.6109) 
Training Epoch: [53/1000] Step: [10 / 285] Batch Time: 0.1445 (0.2265) Data Time: 0.0129 (0.0941) Average Loss: 1.0662 (0.9742) Average CE Loss (Source):  1.0662 ( 0.9742) Learning Rate: 0.1000 (0.1000) Top1_base: 72.6562 (73.6719) Top1_base_per_class: 70.9941 (73.3809) 
Training Epoch: [53/1000] Step: [20 / 285] Batch Time: 0.1465 (0.1972) Data Time: 0.0129 (0.0646) Average Loss: 0.9166 (0.9521) Average CE Loss (Source):  0.9166 ( 0.9521) Learning Rate: 0.1000 (0.1000) Top1_base: 71.8750 (73.8281) Top1_base_per_class: 72.8736 (74.4076) 
Training Epoch: [53/1000] Step: [30 / 285] Batch Time: 0.1523 (0.1825) Data Time: 0.0177 (0.0498) Average Loss: 0.9652 (0.9617) Average CE Loss (Source):  0.9652 ( 0.9617) Learning Rate: 0.1000 (0.1000) Top1_base: 72.6562 (73.5417) Top1_base_per_class: 74.3275 (74.0118) 
Training Epoch: [53/1000] Step: [40 / 285] Batch Time: 0.1435 (0.1792) Data Time: 0.0108 (0.0464) Average Loss: 0.7562 (0.9577) Average CE Loss (Source):  0.7562 ( 0.9577) Learning Rate: 0.1000 (0.1000) Top1_base: 75.7812 (73.6328) Top1_base_per_class: 76.8079 (74.0122) 
Training Epoch: [53/1000] Step: [50 / 285] Batch Time: 0.1492 (0.1750) Data Time: 0.0137 (0.0419) Average Loss: 1.1958 (0.9579) Average CE Loss (Source):  1.1958 ( 0.9579) Learning Rate: 0.1000 (0.1000) Top1_base: 67.9688 (73.5781) Top1_base_per_class: 70.1149 (73.8156) 
Training Epoch: [53/1000] Step: [60 / 285] Batch Time: 0.1428 (0.1732) Data Time: 0.0106 (0.0401) Average Loss: 0.9550 (0.9628) Average CE Loss (Source):  0.9550 ( 0.9628) Learning Rate: 0.1000 (0.1000) Top1_base: 73.4375 (73.3724) Top1_base_per_class: 73.1609 (73.4725) 
Training Epoch: [53/1000] Step: [70 / 285] Batch Time: 0.1433 (0.1702) Data Time: 0.0121 (0.0371) Average Loss: 0.8815 (0.9646) Average CE Loss (Source):  0.8815 ( 0.9646) Learning Rate: 0.1000 (0.1000) Top1_base: 72.6562 (73.3705) Top1_base_per_class: 71.1905 (73.6692) 
Training Epoch: [53/1000] Step: [80 / 285] Batch Time: 0.1420 (0.1675) Data Time: 0.0106 (0.0344) Average Loss: 0.9041 (0.9562) Average CE Loss (Source):  0.9041 ( 0.9562) Learning Rate: 0.1000 (0.1000) Top1_base: 77.3438 (73.5645) Top1_base_per_class: 79.0178 (73.7812) 
Training Epoch: [53/1000] Step: [90 / 285] Batch Time: 0.1509 (0.1669) Data Time: 0.0146 (0.0339) Average Loss: 1.1151 (0.9706) Average CE Loss (Source):  1.1151 ( 0.9706) Learning Rate: 0.1000 (0.1000) Top1_base: 75.7812 (73.3073) Top1_base_per_class: 77.1726 (73.6887) 
Training Epoch: [53/1000] Step: [100 / 285] Batch Time: 0.1427 (0.1654) Data Time: 0.0110 (0.0323) Average Loss: 1.0331 (0.9699) Average CE Loss (Source):  1.0331 ( 0.9699) Learning Rate: 0.1000 (0.1000) Top1_base: 66.4062 (73.2734) Top1_base_per_class: 69.0351 (73.6587) 
Training Epoch: [53/1000] Step: [110 / 285] Batch Time: 0.1494 (0.1642) Data Time: 0.0147 (0.0311) Average Loss: 1.0843 (0.9697) Average CE Loss (Source):  1.0843 ( 0.9697) Learning Rate: 0.1000 (0.1000) Top1_base: 70.3125 (73.3097) Top1_base_per_class: 71.0494 (73.6915) 
Training Epoch: [53/1000] Step: [120 / 285] Batch Time: 0.1445 (0.1636) Data Time: 0.0124 (0.0305) Average Loss: 1.0657 (0.9670) Average CE Loss (Source):  1.0657 ( 0.9670) Learning Rate: 0.1000 (0.1000) Top1_base: 72.6562 (73.3268) Top1_base_per_class: 74.5119 (73.7127) 
Training Epoch: [53/1000] Step: [130 / 285] Batch Time: 0.1480 (0.1625) Data Time: 0.0144 (0.0295) Average Loss: 0.8063 (0.9688) Average CE Loss (Source):  0.8063 ( 0.9688) Learning Rate: 0.1000 (0.1000) Top1_base: 81.2500 (73.2873) Top1_base_per_class: 80.6034 (73.7796) 
Training Epoch: [53/1000] Step: [140 / 285] Batch Time: 0.1437 (0.1623) Data Time: 0.0115 (0.0292) Average Loss: 0.7468 (0.9645) Average CE Loss (Source):  0.7468 ( 0.9645) Learning Rate: 0.1000 (0.1000) Top1_base: 80.4688 (73.4152) Top1_base_per_class: 85.0303 (73.9396) 
Training Epoch: [53/1000] Step: [150 / 285] Batch Time: 0.1489 (0.1621) Data Time: 0.0139 (0.0291) Average Loss: 1.0361 (0.9633) Average CE Loss (Source):  1.0361 ( 0.9633) Learning Rate: 0.1000 (0.1000) Top1_base: 70.3125 (73.4583) Top1_base_per_class: 71.3158 (74.0125) 
Training Epoch: [53/1000] Step: [160 / 285] Batch Time: 0.1467 (0.1622) Data Time: 0.0135 (0.0292) Average Loss: 0.9223 (0.9622) Average CE Loss (Source):  0.9223 ( 0.9622) Learning Rate: 0.1000 (0.1000) Top1_base: 71.0938 (73.4473) Top1_base_per_class: 69.0252 (73.9878) 
Training Epoch: [53/1000] Step: [170 / 285] Batch Time: 0.1476 (0.1621) Data Time: 0.0132 (0.0291) Average Loss: 1.0261 (0.9632) Average CE Loss (Source):  1.0261 ( 0.9632) Learning Rate: 0.1000 (0.1000) Top1_base: 64.8438 (73.3732) Top1_base_per_class: 64.0909 (73.8344) 
Training Epoch: [53/1000] Step: [180 / 285] Batch Time: 0.1417 (0.1624) Data Time: 0.0107 (0.0294) Average Loss: 0.9833 (0.9590) Average CE Loss (Source):  0.9833 ( 0.9590) Learning Rate: 0.1000 (0.1000) Top1_base: 71.8750 (73.4332) Top1_base_per_class: 68.7879 (73.8997) 
Training Epoch: [53/1000] Step: [190 / 285] Batch Time: 0.1489 (0.1623) Data Time: 0.0143 (0.0292) Average Loss: 0.8654 (0.9584) Average CE Loss (Source):  0.8654 ( 0.9584) Learning Rate: 0.1000 (0.1000) Top1_base: 72.6562 (73.3676) Top1_base_per_class: 73.5919 (73.8275) 
Training Epoch: [53/1000] Step: [200 / 285] Batch Time: 0.1441 (0.1619) Data Time: 0.0109 (0.0289) Average Loss: 0.9079 (0.9573) Average CE Loss (Source):  0.9079 ( 0.9573) Learning Rate: 0.1000 (0.1000) Top1_base: 74.2188 (73.4102) Top1_base_per_class: 71.3272 (73.8650) 
Training Epoch: [53/1000] Step: [210 / 285] Batch Time: 0.1465 (0.1619) Data Time: 0.0121 (0.0288) Average Loss: 0.7597 (0.9577) Average CE Loss (Source):  0.7597 ( 0.9577) Learning Rate: 0.1000 (0.1000) Top1_base: 78.1250 (73.4226) Top1_base_per_class: 74.8044 (73.8321) 
Training Epoch: [53/1000] Step: [220 / 285] Batch Time: 0.1420 (0.1615) Data Time: 0.0106 (0.0285) Average Loss: 1.3800 (0.9599) Average CE Loss (Source):  1.3800 ( 0.9599) Learning Rate: 0.1000 (0.1000) Top1_base: 64.8438 (73.3736) Top1_base_per_class: 63.2407 (73.8152) 
Training Epoch: [53/1000] Step: [230 / 285] Batch Time: 0.1433 (0.1610) Data Time: 0.0120 (0.0281) Average Loss: 1.0425 (0.9616) Average CE Loss (Source):  1.0425 ( 0.9616) Learning Rate: 0.1000 (0.1000) Top1_base: 71.8750 (73.2982) Top1_base_per_class: 72.3851 (73.7387) 
Training Epoch: [53/1000] Step: [240 / 285] Batch Time: 0.1448 (0.1604) Data Time: 0.0110 (0.0274) Average Loss: 1.0819 (0.9659) Average CE Loss (Source):  1.0819 ( 0.9659) Learning Rate: 0.1000 (0.1000) Top1_base: 70.3125 (73.1641) Top1_base_per_class: 69.0432 (73.5415) 
Training Epoch: [53/1000] Step: [250 / 285] Batch Time: 0.1521 (0.1602) Data Time: 0.0143 (0.0271) Average Loss: 1.1478 (0.9679) Average CE Loss (Source):  1.1478 ( 0.9679) Learning Rate: 0.1000 (0.1000) Top1_base: 68.7500 (73.1156) Top1_base_per_class: 66.3940 (73.4711) 
Training Epoch: [53/1000] Step: [260 / 285] Batch Time: 0.1461 (0.1603) Data Time: 0.0105 (0.0271) Average Loss: 1.0477 (0.9664) Average CE Loss (Source):  1.0477 ( 0.9664) Learning Rate: 0.1000 (0.1000) Top1_base: 67.9688 (73.1550) Top1_base_per_class: 70.8176 (73.5428) 
Training Epoch: [53/1000] Step: [270 / 285] Batch Time: 0.1466 (0.1599) Data Time: 0.0120 (0.0268) Average Loss: 0.9945 (0.9653) Average CE Loss (Source):  0.9945 ( 0.9653) Learning Rate: 0.1000 (0.1000) Top1_base: 69.5312 (73.1366) Top1_base_per_class: 70.2244 (73.5169) 
Training Epoch: [53/1000] Step: [280 / 285] Batch Time: 0.1419 (0.1597) Data Time: 0.0105 (0.0265) Average Loss: 0.8789 (0.9667) Average CE Loss (Source):  0.8789 ( 0.9667) Learning Rate: 0.1000 (0.1000) Top1_base: 71.8750 (73.1334) Top1_base_per_class: 72.2599 (73.5229) 
Training Epoch: [54/1000] Step: [0] Batch Time: 0.1417 (0.1593) Data Time: 0.0096 (0.0263) Average Loss: 1.2951 (0.9674) Average CE Loss (Source):  1.2951 ( 0.9674) Learning Rate: 0.1000 (0.1000) Top1_base: 67.9688 (73.1195) Top1_base_per_class: 70.0943 (73.5128) 
  5%|▌         | 54/1000 [42:38<12:15:46, 46.67s/it]  6%|▌         | 55/1000 [43:23<12:06:01, 46.10s/it]Training Epoch: [54/1000] Step: [10 / 285] Batch Time: 0.1469 (0.2286) Data Time: 0.0155 (0.0963) Average Loss: 1.0829 (0.8972) Average CE Loss (Source):  1.0829 ( 0.8972) Learning Rate: 0.1000 (0.1000) Top1_base: 75.7812 (75.7812) Top1_base_per_class: 78.7719 (76.2490) 
Training Epoch: [54/1000] Step: [20 / 285] Batch Time: 0.1495 (0.1928) Data Time: 0.0142 (0.0606) Average Loss: 0.7750 (0.8827) Average CE Loss (Source):  0.7750 ( 0.8827) Learning Rate: 0.1000 (0.1000) Top1_base: 77.3438 (76.3281) Top1_base_per_class: 76.7576 (76.8007) 
Training Epoch: [54/1000] Step: [30 / 285] Batch Time: 0.1434 (0.1857) Data Time: 0.0106 (0.0533) Average Loss: 0.8434 (0.8944) Average CE Loss (Source):  0.8434 ( 0.8944) Learning Rate: 0.1000 (0.1000) Top1_base: 78.1250 (75.7812) Top1_base_per_class: 78.9128 (76.1785) 
Training Epoch: [54/1000] Step: [40 / 285] Batch Time: 0.1469 (0.1778) Data Time: 0.0110 (0.0453) Average Loss: 0.8652 (0.9098) Average CE Loss (Source):  0.8652 ( 0.9098) Learning Rate: 0.1000 (0.1000) Top1_base: 74.2188 (75.0195) Top1_base_per_class: 74.0066 (75.7995) 
Training Epoch: [54/1000] Step: [50 / 285] Batch Time: 0.1465 (0.1727) Data Time: 0.0107 (0.0396) Average Loss: 0.8714 (0.9107) Average CE Loss (Source):  0.8714 ( 0.9107) Learning Rate: 0.1000 (0.1000) Top1_base: 78.1250 (74.9531) Top1_base_per_class: 79.1465 (75.6619) 
Training Epoch: [54/1000] Step: [60 / 285] Batch Time: 0.1503 (0.1688) Data Time: 0.0128 (0.0353) Average Loss: 0.8280 (0.9076) Average CE Loss (Source):  0.8280 ( 0.9076) Learning Rate: 0.1000 (0.1000) Top1_base: 79.6875 (74.9219) Top1_base_per_class: 79.7531 (75.5398) 
Training Epoch: [54/1000] Step: [70 / 285] Batch Time: 0.1495 (0.1662) Data Time: 0.0108 (0.0323) Average Loss: 0.8737 (0.9037) Average CE Loss (Source):  0.8737 ( 0.9037) Learning Rate: 0.1000 (0.1000) Top1_base: 75.7812 (74.9330) Top1_base_per_class: 76.1212 (75.4964) 
Training Epoch: [54/1000] Step: [80 / 285] Batch Time: 0.1451 (0.1640) Data Time: 0.0137 (0.0301) Average Loss: 1.2235 (0.9066) Average CE Loss (Source):  1.2235 ( 0.9066) Learning Rate: 0.1000 (0.1000) Top1_base: 67.9688 (74.9219) Top1_base_per_class: 68.3636 (75.5353) 
Training Epoch: [54/1000] Step: [90 / 285] Batch Time: 0.1483 (0.1630) Data Time: 0.0107 (0.0291) Average Loss: 0.9955 (0.9086) Average CE Loss (Source):  0.9955 ( 0.9086) Learning Rate: 0.1000 (0.1000) Top1_base: 70.3125 (74.9826) Top1_base_per_class: 68.0272 (75.5570) 
Training Epoch: [54/1000] Step: [100 / 285] Batch Time: 0.1477 (0.1617) Data Time: 0.0127 (0.0277) Average Loss: 0.8202 (0.9121) Average CE Loss (Source):  0.8202 ( 0.9121) Learning Rate: 0.1000 (0.1000) Top1_base: 74.2188 (74.9219) Top1_base_per_class: 76.4744 (75.5776) 
Training Epoch: [54/1000] Step: [110 / 285] Batch Time: 0.1455 (0.1608) Data Time: 0.0120 (0.0268) Average Loss: 0.9720 (0.9137) Average CE Loss (Source):  0.9720 ( 0.9137) Learning Rate: 0.1000 (0.1000) Top1_base: 74.2188 (74.8509) Top1_base_per_class: 72.5000 (75.3262) 
Training Epoch: [54/1000] Step: [120 / 285] Batch Time: 0.1466 (0.1598) Data Time: 0.0146 (0.0258) Average Loss: 0.8378 (0.9090) Average CE Loss (Source):  0.8378 ( 0.9090) Learning Rate: 0.1000 (0.1000) Top1_base: 77.3438 (74.9609) Top1_base_per_class: 80.7051 (75.4421) 
Training Epoch: [54/1000] Step: [130 / 285] Batch Time: 0.1459 (0.1603) Data Time: 0.0111 (0.0264) Average Loss: 0.9244 (0.9063) Average CE Loss (Source):  0.9244 ( 0.9063) Learning Rate: 0.1000 (0.1000) Top1_base: 74.2188 (74.9519) Top1_base_per_class: 72.1429 (75.4530) 
Training Epoch: [54/1000] Step: [140 / 285] Batch Time: 0.1462 (0.1604) Data Time: 0.0114 (0.0266) Average Loss: 1.0391 (0.9139) Average CE Loss (Source):  1.0391 ( 0.9139) Learning Rate: 0.1000 (0.1000) Top1_base: 71.8750 (74.7656) Top1_base_per_class: 71.1012 (75.2545) 
Training Epoch: [54/1000] Step: [150 / 285] Batch Time: 0.1459 (0.1608) Data Time: 0.0107 (0.0270) Average Loss: 0.9385 (0.9159) Average CE Loss (Source):  0.9385 ( 0.9159) Learning Rate: 0.1000 (0.1000) Top1_base: 76.5625 (74.7240) Top1_base_per_class: 78.8983 (75.2616) 
Training Epoch: [54/1000] Step: [160 / 285] Batch Time: 0.1449 (0.1607) Data Time: 0.0110 (0.0269) Average Loss: 0.9055 (0.9217) Average CE Loss (Source):  0.9055 ( 0.9217) Learning Rate: 0.1000 (0.1000) Top1_base: 74.2188 (74.5215) Top1_base_per_class: 74.5058 (75.1776) 
Training Epoch: [54/1000] Step: [170 / 285] Batch Time: 0.1463 (0.1604) Data Time: 0.0110 (0.0267) Average Loss: 0.7002 (0.9180) Average CE Loss (Source):  0.7002 ( 0.9180) Learning Rate: 0.1000 (0.1000) Top1_base: 77.3438 (74.5588) Top1_base_per_class: 76.8553 (75.3127) 
Training Epoch: [54/1000] Step: [180 / 285] Batch Time: 0.1470 (0.1597) Data Time: 0.0107 (0.0261) Average Loss: 1.0744 (0.9206) Average CE Loss (Source):  1.0744 ( 0.9206) Learning Rate: 0.1000 (0.1000) Top1_base: 65.6250 (74.5356) Top1_base_per_class: 65.5152 (75.2623) 
Training Epoch: [54/1000] Step: [190 / 285] Batch Time: 0.1451 (0.1590) Data Time: 0.0110 (0.0254) Average Loss: 0.8122 (0.9220) Average CE Loss (Source):  0.8122 ( 0.9220) Learning Rate: 0.1000 (0.1000) Top1_base: 78.1250 (74.4819) Top1_base_per_class: 80.4720 (75.2032) 
Training Epoch: [54/1000] Step: [200 / 285] Batch Time: 0.1466 (0.1584) Data Time: 0.0118 (0.0248) Average Loss: 1.1432 (0.9238) Average CE Loss (Source):  1.1432 ( 0.9238) Learning Rate: 0.1000 (0.1000) Top1_base: 71.0938 (74.4258) Top1_base_per_class: 76.0802 (75.1629) 
Training Epoch: [54/1000] Step: [210 / 285] Batch Time: 0.1472 (0.1582) Data Time: 0.0106 (0.0246) Average Loss: 0.9249 (0.9237) Average CE Loss (Source):  0.9249 ( 0.9237) Learning Rate: 0.1000 (0.1000) Top1_base: 72.6562 (74.4420) Top1_base_per_class: 70.8929 (75.1554) 
Training Epoch: [54/1000] Step: [220 / 285] Batch Time: 0.1445 (0.1583) Data Time: 0.0106 (0.0247) Average Loss: 0.8942 (0.9263) Average CE Loss (Source):  0.8942 ( 0.9263) Learning Rate: 0.1000 (0.1000) Top1_base: 79.6875 (74.3857) Top1_base_per_class: 78.6257 (75.0945) 
Training Epoch: [54/1000] Step: [230 / 285] Batch Time: 0.1439 (0.1587) Data Time: 0.0105 (0.0251) Average Loss: 0.8177 (0.9259) Average CE Loss (Source):  0.8177 ( 0.9259) Learning Rate: 0.1000 (0.1000) Top1_base: 73.4375 (74.3342) Top1_base_per_class: 74.8611 (75.0466) 
Training Epoch: [54/1000] Step: [240 / 285] Batch Time: 0.1453 (0.1582) Data Time: 0.0122 (0.0247) Average Loss: 0.8643 (0.9291) Average CE Loss (Source):  0.8643 ( 0.9291) Learning Rate: 0.1000 (0.1000) Top1_base: 75.7812 (74.2546) Top1_base_per_class: 76.2684 (74.9531) 
Training Epoch: [54/1000] Step: [250 / 285] Batch Time: 0.1445 (0.1578) Data Time: 0.0118 (0.0242) Average Loss: 1.1814 (0.9317) Average CE Loss (Source):  1.1814 ( 0.9317) Learning Rate: 0.1000 (0.1000) Top1_base: 64.8438 (74.1750) Top1_base_per_class: 69.6364 (74.9054) 
Training Epoch: [54/1000] Step: [260 / 285] Batch Time: 0.1540 (0.1576) Data Time: 0.0152 (0.0240) Average Loss: 0.9679 (0.9344) Average CE Loss (Source):  0.9679 ( 0.9344) Learning Rate: 0.1000 (0.1000) Top1_base: 76.5625 (74.1256) Top1_base_per_class: 80.4464 (74.8708) 
Training Epoch: [54/1000] Step: [270 / 285] Batch Time: 0.1490 (0.1574) Data Time: 0.0113 (0.0237) Average Loss: 0.7985 (0.9355) Average CE Loss (Source):  0.7985 ( 0.9355) Learning Rate: 0.1000 (0.1000) Top1_base: 79.6875 (74.1030) Top1_base_per_class: 76.1364 (74.8605) 
Training Epoch: [54/1000] Step: [280 / 285] Batch Time: 0.1445 (0.1571) Data Time: 0.0135 (0.0233) Average Loss: 0.8979 (0.9361) Average CE Loss (Source):  0.8979 ( 0.9361) Learning Rate: 0.1000 (0.1000) Top1_base: 75.0000 (74.1127) Top1_base_per_class: 73.8461 (74.8222) 
Training Epoch: [55/1000] Step: [0] Batch Time: 0.1459 (0.1569) Data Time: 0.0152 (0.0232) Average Loss: 1.0783 (0.9374) Average CE Loss (Source):  1.0783 ( 0.9374) Learning Rate: 0.1000 (0.1000) Top1_base: 67.1875 (74.0625) Top1_base_per_class: 65.3939 (74.7648) 
Training Epoch: [55/1000] Step: [10 / 285] Batch Time: 0.1457 (0.2318) Data Time: 0.0110 (0.0983) Average Loss: 0.8023 (0.8539) Average CE Loss (Source):  0.8023 ( 0.8539) Learning Rate: 0.1000 (0.1000) Top1_base: 83.5938 (77.3438) Top1_base_per_class: 79.6199 (76.8379) 
Training Epoch: [55/1000] Step: [20 / 285] Batch Time: 0.1467 (0.1958) Data Time: 0.0112 (0.0619) Average Loss: 0.9103 (0.8701) Average CE Loss (Source):  0.9103 ( 0.8701) Learning Rate: 0.1000 (0.1000) Top1_base: 69.5312 (76.0938) Top1_base_per_class: 71.5774 (76.0587) 
Training Epoch: [55/1000] Step: [30 / 285] Batch Time: 0.1429 (0.1810) Data Time: 0.0106 (0.0471) Average Loss: 0.7442 (0.8588) Average CE Loss (Source):  0.7442 ( 0.8588) Learning Rate: 0.1000 (0.1000) Top1_base: 78.1250 (76.4062) Top1_base_per_class: 78.1818 (76.4321) 
Training Epoch: [55/1000] Step: [40 / 285] Batch Time: 0.1495 (0.1728) Data Time: 0.0120 (0.0388) Average Loss: 0.8045 (0.8593) Average CE Loss (Source):  0.8045 ( 0.8593) Learning Rate: 0.1000 (0.1000) Top1_base: 78.1250 (76.0938) Top1_base_per_class: 76.9883 (76.5036) 
Training Epoch: [55/1000] Step: [50 / 285] Batch Time: 0.1474 (0.1682) Data Time: 0.0152 (0.0344) Average Loss: 0.7329 (0.8532) Average CE Loss (Source):  0.7329 ( 0.8532) Learning Rate: 0.1000 (0.1000) Top1_base: 81.2500 (76.2656) Top1_base_per_class: 84.0909 (76.7813) 
Training Epoch: [55/1000] Step: [60 / 285] Batch Time: 0.1474 (0.1654) Data Time: 0.0139 (0.0317) Average Loss: 0.9681 (0.8650) Average CE Loss (Source):  0.9681 ( 0.8650) Learning Rate: 0.1000 (0.1000) Top1_base: 70.3125 (75.9766) Top1_base_per_class: 71.7560 (76.5307) 
Training Epoch: [55/1000] Step: [70 / 285] Batch Time: 0.2149 (0.1650) Data Time: 0.0811 (0.0313) Average Loss: 0.9708 (0.8757) Average CE Loss (Source):  0.9708 ( 0.8757) Learning Rate: 0.1000 (0.1000) Top1_base: 69.5312 (75.5580) Top1_base_per_class: 67.8869 (76.1035) 
Training Epoch: [55/1000] Step: [80 / 285] Batch Time: 0.1466 (0.1643) Data Time: 0.0110 (0.0307) Average Loss: 0.9699 (0.8822) Average CE Loss (Source):  0.9699 ( 0.8822) Learning Rate: 0.1000 (0.1000) Top1_base: 73.4375 (75.4785) Top1_base_per_class: 74.4940 (76.0250) 
Training Epoch: [55/1000] Step: [90 / 285] Batch Time: 0.1490 (0.1642) Data Time: 0.0133 (0.0306) Average Loss: 0.8231 (0.8874) Average CE Loss (Source):  0.8231 ( 0.8874) Learning Rate: 0.1000 (0.1000) Top1_base: 74.2188 (75.3472) Top1_base_per_class: 75.1667 (75.8854) 
Training Epoch: [55/1000] Step: [100 / 285] Batch Time: 0.1455 (0.1636) Data Time: 0.0105 (0.0300) Average Loss: 1.0937 (0.8923) Average CE Loss (Source):  1.0937 ( 0.8923) Learning Rate: 0.1000 (0.1000) Top1_base: 65.6250 (75.1641) Top1_base_per_class: 68.4545 (75.7822) 
Training Epoch: [55/1000] Step: [110 / 285] Batch Time: 0.1466 (0.1636) Data Time: 0.0109 (0.0300) Average Loss: 0.9287 (0.9002) Average CE Loss (Source):  0.9287 ( 0.9002) Learning Rate: 0.1000 (0.1000) Top1_base: 75.0000 (74.9219) Top1_base_per_class: 74.7799 (75.6447) 
Training Epoch: [55/1000] Step: [120 / 285] Batch Time: 0.1470 (0.1630) Data Time: 0.0116 (0.0295) Average Loss: 1.0438 (0.9057) Average CE Loss (Source):  1.0438 ( 0.9057) Learning Rate: 0.1000 (0.1000) Top1_base: 70.3125 (74.7266) Top1_base_per_class: 68.9474 (75.4120) 
Training Epoch: [55/1000] Step: [130 / 285] Batch Time: 0.1452 (0.1630) Data Time: 0.0135 (0.0296) Average Loss: 0.9889 (0.9076) Average CE Loss (Source):  0.9889 ( 0.9076) Learning Rate: 0.1000 (0.1000) Top1_base: 71.8750 (74.5853) Top1_base_per_class: 73.2164 (75.2489) 
Training Epoch: [55/1000] Step: [140 / 285] Batch Time: 0.1469 (0.1622) Data Time: 0.0120 (0.0288) Average Loss: 1.0029 (0.9085) Average CE Loss (Source):  1.0029 ( 0.9085) Learning Rate: 0.1000 (0.1000) Top1_base: 72.6562 (74.6150) Top1_base_per_class: 71.4423 (75.2273) 
Training Epoch: [55/1000] Step: [150 / 285] Batch Time: 0.1446 (0.1619) Data Time: 0.0125 (0.0285) Average Loss: 0.8968 (0.9081) Average CE Loss (Source):  0.8968 ( 0.9081) Learning Rate: 0.1000 (0.1000) Top1_base: 76.5625 (74.6510) Top1_base_per_class: 76.2893 (75.2906) 
Training Epoch: [55/1000] Step: [160 / 285] Batch Time: 0.1473 (0.1614) Data Time: 0.0152 (0.0281) Average Loss: 1.0330 (0.9133) Average CE Loss (Source):  1.0330 ( 0.9133) Learning Rate: 0.1000 (0.1000) Top1_base: 73.4375 (74.4971) Top1_base_per_class: 74.5902 (75.1957) 
Training Epoch: [55/1000] Step: [170 / 285] Batch Time: 0.1475 (0.1610) Data Time: 0.0117 (0.0276) Average Loss: 0.9402 (0.9171) Average CE Loss (Source):  0.9402 ( 0.9171) Learning Rate: 0.1000 (0.1000) Top1_base: 73.4375 (74.4531) Top1_base_per_class: 74.5155 (75.1500) 
Training Epoch: [55/1000] Step: [180 / 285] Batch Time: 0.1457 (0.1605) Data Time: 0.0107 (0.0271) Average Loss: 1.0504 (0.9200) Average CE Loss (Source):  1.0504 ( 0.9200) Learning Rate: 0.1000 (0.1000) Top1_base: 70.3125 (74.4184) Top1_base_per_class: 71.7576 (75.1545) 
Training Epoch: [55/1000] Step: [190 / 285] Batch Time: 0.1447 (0.1602) Data Time: 0.0108 (0.0269) Average Loss: 0.9566 (0.9223) Average CE Loss (Source):  0.9566 ( 0.9223) Learning Rate: 0.1000 (0.1000) Top1_base: 71.0938 (74.3092) Top1_base_per_class: 72.9532 (75.0668) 
Training Epoch: [55/1000] Step: [200 / 285] Batch Time: 0.1475 (0.1604) Data Time: 0.0139 (0.0271) Average Loss: 0.9727 (0.9227) Average CE Loss (Source):  0.9727 ( 0.9227) Learning Rate: 0.1000 (0.1000) Top1_base: 67.9688 (74.2148) Top1_base_per_class: 70.4237 (74.9990) 
Training Epoch: [55/1000] Step: [210 / 285] Batch Time: 0.1462 (0.1603) Data Time: 0.0144 (0.0270) Average Loss: 0.8297 (0.9223) Average CE Loss (Source):  0.8297 ( 0.9223) Learning Rate: 0.1000 (0.1000) Top1_base: 79.6875 (74.2299) Top1_base_per_class: 81.2429 (75.0219) 
Training Epoch: [55/1000] Step: [220 / 285] Batch Time: 0.1447 (0.1602) Data Time: 0.0106 (0.0269) Average Loss: 0.8954 (0.9224) Average CE Loss (Source):  0.8954 ( 0.9224) Learning Rate: 0.1000 (0.1000) Top1_base: 76.5625 (74.2188) Top1_base_per_class: 76.2654 (75.0313) 
Training Epoch: [55/1000] Step: [230 / 285] Batch Time: 0.1471 (0.1600) Data Time: 0.0106 (0.0267) Average Loss: 0.9921 (0.9250) Average CE Loss (Source):  0.9921 ( 0.9250) Learning Rate: 0.1000 (0.1000) Top1_base: 76.5625 (74.1916) Top1_base_per_class: 77.8363 (74.9675) 
Training Epoch: [55/1000] Step: [240 / 285] Batch Time: 0.1478 (0.1595) Data Time: 0.0122 (0.0262) Average Loss: 1.0257 (0.9273) Average CE Loss (Source):  1.0257 ( 0.9273) Learning Rate: 0.1000 (0.1000) Top1_base: 68.7500 (74.0918) Top1_base_per_class: 69.6429 (74.8832) 
Training Epoch: [55/1000] Step: [250 / 285] Batch Time: 0.1452 (0.1596) Data Time: 0.0118 (0.0262) Average Loss: 1.0471 (0.9285) Average CE Loss (Source):  1.0471 ( 0.9285) Learning Rate: 0.1000 (0.1000) Top1_base: 66.4062 (74.0156) Top1_base_per_class: 65.7471 (74.7992) 
Training Epoch: [55/1000] Step: [260 / 285] Batch Time: 0.1461 (0.1592) Data Time: 0.0103 (0.0259) Average Loss: 0.9928 (0.9308) Average CE Loss (Source):  0.9928 ( 0.9308) Learning Rate: 0.1000 (0.1000) Top1_base: 71.0938 (73.9483) Top1_base_per_class: 70.5556 (74.7083) 
Training Epoch: [55/1000] Step: [270 / 285] Batch Time: 0.1437 (0.1590) Data Time: 0.0120 (0.0257) Average Loss: 1.1249 (0.9312) Average CE Loss (Source):  1.1249 ( 0.9312) Learning Rate: 0.1000 (0.1000) Top1_base: 73.4375 (73.9525) Top1_base_per_class: 74.2727 (74.6929) 
Training Epoch: [55/1000] Step: [280 / 285] Batch Time: 0.1448 (0.1586) Data Time: 0.0114 (0.0253) Average Loss: 0.8380 (0.9318) Average CE Loss (Source):  0.8380 ( 0.9318) Learning Rate: 0.1000 (0.1000) Top1_base: 78.1250 (73.9342) Top1_base_per_class: 75.8621 (74.7033) 
Training Epoch: [56/1000] Step: [0] Batch Time: 0.1469 (0.1584) Data Time: 0.0153 (0.0251) Average Loss: 0.9729 (0.9341) Average CE Loss (Source):  0.9729 ( 0.9341) Learning Rate: 0.1000 (0.1000) Top1_base: 75.7812 (73.8569) Top1_base_per_class: 78.5152 (74.6368) 
  6%|▌         | 56/1000 [44:11<12:14:21, 46.67s/it]  6%|▌         | 57/1000 [44:57<12:07:58, 46.32s/it]Training Epoch: [56/1000] Step: [10 / 285] Batch Time: 0.1479 (0.2475) Data Time: 0.0141 (0.1145) Average Loss: 0.9799 (0.9579) Average CE Loss (Source):  0.9799 ( 0.9579) Learning Rate: 0.1000 (0.1000) Top1_base: 71.8750 (73.4375) Top1_base_per_class: 75.2778 (74.6739) 
Training Epoch: [56/1000] Step: [20 / 285] Batch Time: 0.1487 (0.1994) Data Time: 0.0127 (0.0656) Average Loss: 0.5733 (0.9191) Average CE Loss (Source):  0.5733 ( 0.9191) Learning Rate: 0.1000 (0.1000) Top1_base: 83.5938 (74.7266) Top1_base_per_class: 84.4633 (75.8174) 
Training Epoch: [56/1000] Step: [30 / 285] Batch Time: 0.1494 (0.1851) Data Time: 0.0145 (0.0514) Average Loss: 0.9308 (0.9268) Average CE Loss (Source):  0.9308 ( 0.9268) Learning Rate: 0.1000 (0.1000) Top1_base: 72.6562 (74.4271) Top1_base_per_class: 69.4048 (75.2481) 
Training Epoch: [56/1000] Step: [40 / 285] Batch Time: 0.1414 (0.1766) Data Time: 0.0106 (0.0431) Average Loss: 1.1158 (0.9189) Average CE Loss (Source):  1.1158 ( 0.9189) Learning Rate: 0.1000 (0.1000) Top1_base: 66.4062 (74.4141) Top1_base_per_class: 62.3030 (75.1221) 
Training Epoch: [56/1000] Step: [50 / 285] Batch Time: 0.1491 (0.1727) Data Time: 0.0140 (0.0393) Average Loss: 0.9756 (0.9207) Average CE Loss (Source):  0.9756 ( 0.9207) Learning Rate: 0.1000 (0.1000) Top1_base: 71.8750 (74.2969) Top1_base_per_class: 73.6364 (75.1543) 
Training Epoch: [56/1000] Step: [60 / 285] Batch Time: 0.1416 (0.1714) Data Time: 0.0103 (0.0380) Average Loss: 0.8664 (0.9122) Average CE Loss (Source):  0.8664 ( 0.9122) Learning Rate: 0.1000 (0.1000) Top1_base: 73.4375 (74.4661) Top1_base_per_class: 73.0818 (75.4119) 
Training Epoch: [56/1000] Step: [70 / 285] Batch Time: 0.1433 (0.1685) Data Time: 0.0117 (0.0353) Average Loss: 1.0101 (0.9060) Average CE Loss (Source):  1.0101 ( 0.9060) Learning Rate: 0.1000 (0.1000) Top1_base: 71.8750 (74.7433) Top1_base_per_class: 73.5714 (75.5745) 
Training Epoch: [56/1000] Step: [80 / 285] Batch Time: 0.1453 (0.1679) Data Time: 0.0117 (0.0347) Average Loss: 0.7512 (0.9018) Average CE Loss (Source):  0.7512 ( 0.9018) Learning Rate: 0.1000 (0.1000) Top1_base: 79.6875 (74.9707) Top1_base_per_class: 76.7901 (75.7496) 
Training Epoch: [56/1000] Step: [90 / 285] Batch Time: 0.1488 (0.1675) Data Time: 0.0144 (0.0344) Average Loss: 0.9792 (0.9084) Average CE Loss (Source):  0.9792 ( 0.9084) Learning Rate: 0.1000 (0.1000) Top1_base: 71.0938 (74.7049) Top1_base_per_class: 69.9697 (75.4969) 
Training Epoch: [56/1000] Step: [100 / 285] Batch Time: 0.1460 (0.1663) Data Time: 0.0147 (0.0332) Average Loss: 1.0396 (0.9164) Average CE Loss (Source):  1.0396 ( 0.9164) Learning Rate: 0.1000 (0.1000) Top1_base: 72.6562 (74.5312) Top1_base_per_class: 73.5494 (75.3180) 
Training Epoch: [56/1000] Step: [110 / 285] Batch Time: 0.1415 (0.1657) Data Time: 0.0120 (0.0328) Average Loss: 0.8683 (0.9199) Average CE Loss (Source):  0.8683 ( 0.9199) Learning Rate: 0.1000 (0.1000) Top1_base: 75.0000 (74.4602) Top1_base_per_class: 77.7264 (75.2291) 
Training Epoch: [56/1000] Step: [120 / 285] Batch Time: 0.1424 (0.1650) Data Time: 0.0106 (0.0320) Average Loss: 1.0904 (0.9195) Average CE Loss (Source):  1.0904 ( 0.9195) Learning Rate: 0.1000 (0.1000) Top1_base: 68.7500 (74.4596) Top1_base_per_class: 69.7988 (75.2781) 
Training Epoch: [56/1000] Step: [130 / 285] Batch Time: 0.1490 (0.1638) Data Time: 0.0139 (0.0308) Average Loss: 0.8438 (0.9167) Average CE Loss (Source):  0.8438 ( 0.9167) Learning Rate: 0.1000 (0.1000) Top1_base: 75.7812 (74.5433) Top1_base_per_class: 72.8788 (75.3627) 
Training Epoch: [56/1000] Step: [140 / 285] Batch Time: 0.1416 (0.1636) Data Time: 0.0110 (0.0305) Average Loss: 0.9423 (0.9190) Average CE Loss (Source):  0.9423 ( 0.9190) Learning Rate: 0.1000 (0.1000) Top1_base: 77.3438 (74.4922) Top1_base_per_class: 75.2830 (75.3053) 
Training Epoch: [56/1000] Step: [150 / 285] Batch Time: 0.1493 (0.1626) Data Time: 0.0138 (0.0295) Average Loss: 0.8620 (0.9147) Average CE Loss (Source):  0.8620 ( 0.9147) Learning Rate: 0.1000 (0.1000) Top1_base: 78.1250 (74.7083) Top1_base_per_class: 76.3290 (75.4886) 
Training Epoch: [56/1000] Step: [160 / 285] Batch Time: 0.1440 (0.1620) Data Time: 0.0114 (0.0290) Average Loss: 0.8431 (0.9088) Average CE Loss (Source):  0.8431 ( 0.9088) Learning Rate: 0.1000 (0.1000) Top1_base: 77.3438 (74.8828) Top1_base_per_class: 71.2135 (75.5750) 
Training Epoch: [56/1000] Step: [170 / 285] Batch Time: 0.1492 (0.1615) Data Time: 0.0130 (0.0283) Average Loss: 0.9109 (0.9078) Average CE Loss (Source):  0.9109 ( 0.9078) Learning Rate: 0.1000 (0.1000) Top1_base: 75.0000 (74.8897) Top1_base_per_class: 74.2105 (75.5301) 
Training Epoch: [56/1000] Step: [180 / 285] Batch Time: 0.1478 (0.1612) Data Time: 0.0136 (0.0280) Average Loss: 0.7392 (0.9121) Average CE Loss (Source):  0.7392 ( 0.9121) Learning Rate: 0.1000 (0.1000) Top1_base: 84.3750 (74.7917) Top1_base_per_class: 80.8654 (75.4883) 
Training Epoch: [56/1000] Step: [190 / 285] Batch Time: 0.1498 (0.1611) Data Time: 0.0149 (0.0280) Average Loss: 0.8122 (0.9121) Average CE Loss (Source):  0.8122 ( 0.9121) Learning Rate: 0.1000 (0.1000) Top1_base: 74.2188 (74.7697) Top1_base_per_class: 75.1543 (75.4792) 
Training Epoch: [56/1000] Step: [200 / 285] Batch Time: 0.1474 (0.1612) Data Time: 0.0119 (0.0281) Average Loss: 0.9959 (0.9145) Average CE Loss (Source):  0.9959 ( 0.9145) Learning Rate: 0.1000 (0.1000) Top1_base: 72.6562 (74.6719) Top1_base_per_class: 71.5758 (75.3461) 
Training Epoch: [56/1000] Step: [210 / 285] Batch Time: 0.1437 (0.1609) Data Time: 0.0109 (0.0277) Average Loss: 0.9887 (0.9178) Average CE Loss (Source):  0.9887 ( 0.9178) Learning Rate: 0.1000 (0.1000) Top1_base: 71.0938 (74.5647) Top1_base_per_class: 68.3626 (75.1879) 
Training Epoch: [56/1000] Step: [220 / 285] Batch Time: 0.1458 (0.1603) Data Time: 0.0118 (0.0271) Average Loss: 0.8719 (0.9205) Average CE Loss (Source):  0.8719 ( 0.9205) Learning Rate: 0.1000 (0.1000) Top1_base: 75.0000 (74.4531) Top1_base_per_class: 77.7485 (75.1293) 
Training Epoch: [56/1000] Step: [230 / 285] Batch Time: 0.1500 (0.1597) Data Time: 0.0156 (0.0265) Average Loss: 1.0050 (0.9234) Average CE Loss (Source):  1.0050 ( 0.9234) Learning Rate: 0.1000 (0.1000) Top1_base: 72.6562 (74.3207) Top1_base_per_class: 71.6667 (75.0362) 
Training Epoch: [56/1000] Step: [240 / 285] Batch Time: 0.1428 (0.1602) Data Time: 0.0104 (0.0270) Average Loss: 1.1315 (0.9270) Average CE Loss (Source):  1.1315 ( 0.9270) Learning Rate: 0.1000 (0.1000) Top1_base: 67.1875 (74.2611) Top1_base_per_class: 65.6284 (74.9635) 
Training Epoch: [56/1000] Step: [250 / 285] Batch Time: 0.1491 (0.1600) Data Time: 0.0138 (0.0268) Average Loss: 0.9330 (0.9283) Average CE Loss (Source):  0.9330 ( 0.9283) Learning Rate: 0.1000 (0.1000) Top1_base: 73.4375 (74.1906) Top1_base_per_class: 71.7879 (74.8547) 
Training Epoch: [56/1000] Step: [260 / 285] Batch Time: 0.1454 (0.1599) Data Time: 0.0133 (0.0268) Average Loss: 0.9066 (0.9283) Average CE Loss (Source):  0.9066 ( 0.9283) Learning Rate: 0.1000 (0.1000) Top1_base: 76.5625 (74.1617) Top1_base_per_class: 76.4506 (74.8451) 
Training Epoch: [56/1000] Step: [270 / 285] Batch Time: 0.1495 (0.1594) Data Time: 0.0155 (0.0263) Average Loss: 0.8806 (0.9295) Average CE Loss (Source):  0.8806 ( 0.9295) Learning Rate: 0.1000 (0.1000) Top1_base: 75.0000 (74.1030) Top1_base_per_class: 74.7115 (74.7384) 
Training Epoch: [56/1000] Step: [280 / 285] Batch Time: 0.1471 (0.1593) Data Time: 0.0129 (0.0262) Average Loss: 1.0328 (0.9344) Average CE Loss (Source):  1.0328 ( 0.9344) Learning Rate: 0.1000 (0.1000) Top1_base: 75.7812 (73.9760) Top1_base_per_class: 78.1579 (74.6446) 
Training Epoch: [57/1000] Step: [0] Batch Time: 0.1451 (0.1594) Data Time: 0.0096 (0.0263) Average Loss: 0.8815 (0.9358) Average CE Loss (Source):  0.8815 ( 0.9358) Learning Rate: 0.1000 (0.1000) Top1_base: 75.0000 (73.9501) Top1_base_per_class: 77.5595 (74.6127) 
Training Epoch: [57/1000] Step: [10 / 285] Batch Time: 0.1478 (0.2413) Data Time: 0.0103 (0.1058) Average Loss: 0.9160 (0.9504) Average CE Loss (Source):  0.9160 ( 0.9504) Learning Rate: 0.1000 (0.1000) Top1_base: 76.5625 (72.9688) Top1_base_per_class: 78.3621 (73.6023) 
Training Epoch: [57/1000] Step: [20 / 285] Batch Time: 0.1516 (0.2015) Data Time: 0.0115 (0.0659) Average Loss: 0.7794 (0.9554) Average CE Loss (Source):  0.7794 ( 0.9554) Learning Rate: 0.1000 (0.1000) Top1_base: 81.2500 (73.4375) Top1_base_per_class: 83.4545 (74.4334) 
Training Epoch: [57/1000] Step: [30 / 285] Batch Time: 0.1475 (0.1902) Data Time: 0.0137 (0.0553) Average Loss: 1.3466 (0.9579) Average CE Loss (Source):  1.3466 ( 0.9579) Learning Rate: 0.1000 (0.1000) Top1_base: 66.4062 (73.6458) Top1_base_per_class: 65.9307 (74.1032) 
Training Epoch: [57/1000] Step: [40 / 285] Batch Time: 0.1481 (0.1812) Data Time: 0.0109 (0.0459) Average Loss: 0.8622 (0.9491) Average CE Loss (Source):  0.8622 ( 0.9491) Learning Rate: 0.1000 (0.1000) Top1_base: 78.9062 (73.8086) Top1_base_per_class: 79.0909 (74.4078) 
Training Epoch: [57/1000] Step: [50 / 285] Batch Time: 0.1491 (0.1791) Data Time: 0.0133 (0.0437) Average Loss: 1.1926 (0.9418) Average CE Loss (Source):  1.1926 ( 0.9418) Learning Rate: 0.1000 (0.1000) Top1_base: 71.0938 (73.8594) Top1_base_per_class: 70.3086 (74.2367) 
Training Epoch: [57/1000] Step: [60 / 285] Batch Time: 0.1506 (0.1748) Data Time: 0.0107 (0.0392) Average Loss: 0.8765 (0.9376) Average CE Loss (Source):  0.8765 ( 0.9376) Learning Rate: 0.1000 (0.1000) Top1_base: 78.1250 (73.9844) Top1_base_per_class: 76.6384 (74.5085) 
Training Epoch: [57/1000] Step: [70 / 285] Batch Time: 0.1480 (0.1713) Data Time: 0.0127 (0.0357) Average Loss: 0.8065 (0.9275) Average CE Loss (Source):  0.8065 ( 0.9275) Learning Rate: 0.1000 (0.1000) Top1_base: 79.6875 (74.2857) Top1_base_per_class: 79.9394 (74.6879) 
Training Epoch: [57/1000] Step: [80 / 285] Batch Time: 0.1464 (0.1684) Data Time: 0.0141 (0.0331) Average Loss: 0.8075 (0.9276) Average CE Loss (Source):  0.8075 ( 0.9276) Learning Rate: 0.1000 (0.1000) Top1_base: 76.5625 (74.1699) Top1_base_per_class: 75.5315 (74.5644) 
Training Epoch: [57/1000] Step: [90 / 285] Batch Time: 0.1454 (0.1663) Data Time: 0.0111 (0.0313) Average Loss: 1.0592 (0.9306) Average CE Loss (Source):  1.0592 ( 0.9306) Learning Rate: 0.1000 (0.1000) Top1_base: 71.0938 (74.1233) Top1_base_per_class: 68.7654 (74.4336) 
Training Epoch: [57/1000] Step: [100 / 285] Batch Time: 0.1523 (0.1648) Data Time: 0.0121 (0.0295) Average Loss: 0.9716 (0.9288) Average CE Loss (Source):  0.9716 ( 0.9288) Learning Rate: 0.1000 (0.1000) Top1_base: 72.6562 (74.3125) Top1_base_per_class: 71.4583 (74.6393) 
Training Epoch: [57/1000] Step: [110 / 285] Batch Time: 0.1475 (0.1635) Data Time: 0.0146 (0.0282) Average Loss: 0.8055 (0.9238) Average CE Loss (Source):  0.8055 ( 0.9238) Learning Rate: 0.1000 (0.1000) Top1_base: 81.2500 (74.4105) Top1_base_per_class: 79.3636 (74.8037) 
Training Epoch: [57/1000] Step: [120 / 285] Batch Time: 0.1504 (0.1623) Data Time: 0.0128 (0.0271) Average Loss: 0.9398 (0.9240) Average CE Loss (Source):  0.9398 ( 0.9240) Learning Rate: 0.1000 (0.1000) Top1_base: 73.4375 (74.4727) Top1_base_per_class: 66.3462 (74.7676) 
Training Epoch: [57/1000] Step: [130 / 285] Batch Time: 0.1507 (0.1619) Data Time: 0.0145 (0.0265) Average Loss: 0.9695 (0.9270) Average CE Loss (Source):  0.9695 ( 0.9270) Learning Rate: 0.1000 (0.1000) Top1_base: 75.0000 (74.3870) Top1_base_per_class: 75.3869 (74.7045) 
Training Epoch: [57/1000] Step: [140 / 285] Batch Time: 0.1504 (0.1611) Data Time: 0.0123 (0.0259) Average Loss: 0.9341 (0.9263) Average CE Loss (Source):  0.9341 ( 0.9263) Learning Rate: 0.1000 (0.1000) Top1_base: 74.2188 (74.4029) Top1_base_per_class: 68.6550 (74.7289) 
Training Epoch: [57/1000] Step: [150 / 285] Batch Time: 0.1434 (0.1606) Data Time: 0.0112 (0.0254) Average Loss: 0.8823 (0.9255) Average CE Loss (Source):  0.8823 ( 0.9255) Learning Rate: 0.1000 (0.1000) Top1_base: 74.2188 (74.4323) Top1_base_per_class: 75.4717 (74.7821) 
Training Epoch: [57/1000] Step: [160 / 285] Batch Time: 0.1475 (0.1606) Data Time: 0.0107 (0.0254) Average Loss: 0.7762 (0.9258) Average CE Loss (Source):  0.7762 ( 0.9258) Learning Rate: 0.1000 (0.1000) Top1_base: 75.7812 (74.4434) Top1_base_per_class: 78.6164 (74.8064) 
Training Epoch: [57/1000] Step: [170 / 285] Batch Time: 0.1478 (0.1600) Data Time: 0.0130 (0.0247) Average Loss: 0.9360 (0.9293) Average CE Loss (Source):  0.9360 ( 0.9293) Learning Rate: 0.1000 (0.1000) Top1_base: 75.0000 (74.4256) Top1_base_per_class: 77.8526 (74.8209) 
Training Epoch: [57/1000] Step: [180 / 285] Batch Time: 0.1447 (0.1594) Data Time: 0.0137 (0.0241) Average Loss: 1.1284 (0.9292) Average CE Loss (Source):  1.1284 ( 0.9292) Learning Rate: 0.1000 (0.1000) Top1_base: 64.8438 (74.3707) Top1_base_per_class: 67.2282 (74.7867) 
Training Epoch: [57/1000] Step: [190 / 285] Batch Time: 0.1471 (0.1587) Data Time: 0.0140 (0.0236) Average Loss: 0.9499 (0.9322) Average CE Loss (Source):  0.9499 ( 0.9322) Learning Rate: 0.1000 (0.1000) Top1_base: 72.6562 (74.2105) Top1_base_per_class: 75.6970 (74.6874) 
Training Epoch: [57/1000] Step: [200 / 285] Batch Time: 0.1476 (0.1583) Data Time: 0.0171 (0.0232) Average Loss: 0.9039 (0.9336) Average CE Loss (Source):  0.9039 ( 0.9336) Learning Rate: 0.1000 (0.1000) Top1_base: 71.8750 (74.1719) Top1_base_per_class: 67.5617 (74.6239) 
Training Epoch: [57/1000] Step: [210 / 285] Batch Time: 0.1472 (0.1581) Data Time: 0.0133 (0.0231) Average Loss: 1.0176 (0.9340) Average CE Loss (Source):  1.0176 ( 0.9340) Learning Rate: 0.1000 (0.1000) Top1_base: 74.2188 (74.1778) Top1_base_per_class: 78.1818 (74.6949) 
Training Epoch: [57/1000] Step: [220 / 285] Batch Time: 0.1515 (0.1579) Data Time: 0.0120 (0.0228) Average Loss: 0.7807 (0.9359) Average CE Loss (Source):  0.7807 ( 0.9359) Learning Rate: 0.1000 (0.1000) Top1_base: 75.7812 (74.1229) Top1_base_per_class: 75.7440 (74.6088) 
Training Epoch: [57/1000] Step: [230 / 285] Batch Time: 0.1467 (0.1576) Data Time: 0.0136 (0.0226) Average Loss: 1.0809 (0.9377) Average CE Loss (Source):  1.0809 ( 0.9377) Learning Rate: 0.1000 (0.1000) Top1_base: 67.9688 (74.0659) Top1_base_per_class: 66.2202 (74.5716) 
Training Epoch: [57/1000] Step: [240 / 285] Batch Time: 0.1442 (0.1573) Data Time: 0.0121 (0.0223) Average Loss: 1.1461 (0.9387) Average CE Loss (Source):  1.1461 ( 0.9387) Learning Rate: 0.1000 (0.1000) Top1_base: 69.5312 (74.0918) Top1_base_per_class: 70.3161 (74.6185) 
Training Epoch: [57/1000] Step: [250 / 285] Batch Time: 0.1555 (0.1572) Data Time: 0.0197 (0.0221) Average Loss: 0.9269 (0.9367) Average CE Loss (Source):  0.9269 ( 0.9367) Learning Rate: 0.1000 (0.1000) Top1_base: 75.0000 (74.1437) Top1_base_per_class: 76.6667 (74.6651) 
Training Epoch: [57/1000] Step: [260 / 285] Batch Time: 0.1462 (0.1569) Data Time: 0.0127 (0.0218) Average Loss: 1.0315 (0.9393) Average CE Loss (Source):  1.0315 ( 0.9393) Learning Rate: 0.1000 (0.1000) Top1_base: 68.7500 (74.1106) Top1_base_per_class: 69.7373 (74.6149) 
Training Epoch: [57/1000] Step: [270 / 285] Batch Time: 0.1530 (0.1566) Data Time: 0.0169 (0.0216) Average Loss: 1.0403 (0.9426) Average CE Loss (Source):  1.0403 ( 0.9426) Learning Rate: 0.1000 (0.1000) Top1_base: 74.2188 (74.0712) Top1_base_per_class: 73.3333 (74.5734) 
Training Epoch: [57/1000] Step: [280 / 285] Batch Time: 0.1507 (0.1564) Data Time: 0.0127 (0.0213) Average Loss: 0.9464 (0.9447) Average CE Loss (Source):  0.9464 ( 0.9447) Learning Rate: 0.1000 (0.1000) Top1_base: 75.0000 (74.0151) Top1_base_per_class: 74.7917 (74.5075) 
Training Epoch: [58/1000] Step: [0] Batch Time: 0.1522 (0.1563) Data Time: 0.0174 (0.0212) Average Loss: 0.8532 (0.9462) Average CE Loss (Source):  0.8532 ( 0.9462) Learning Rate: 0.1000 (0.1000) Top1_base: 77.3438 (73.9885) Top1_base_per_class: 77.7976 (74.4787) 
  6%|▌         | 58/1000 [45:44<12:12:04, 46.63s/it]  6%|▌         | 59/1000 [46:30<12:07:41, 46.40s/it]Training Epoch: [58/1000] Step: [10 / 285] Batch Time: 0.1424 (0.2447) Data Time: 0.0103 (0.1115) Average Loss: 1.0541 (0.9444) Average CE Loss (Source):  1.0541 ( 0.9444) Learning Rate: 0.1000 (0.1000) Top1_base: 67.9688 (73.9844) Top1_base_per_class: 68.0189 (74.6967) 
Training Epoch: [58/1000] Step: [20 / 285] Batch Time: 0.1510 (0.2024) Data Time: 0.0122 (0.0684) Average Loss: 1.0393 (0.9623) Average CE Loss (Source):  1.0393 ( 0.9623) Learning Rate: 0.1000 (0.1000) Top1_base: 74.2188 (73.7109) Top1_base_per_class: 74.5278 (74.4396) 
Training Epoch: [58/1000] Step: [30 / 285] Batch Time: 0.1434 (0.1920) Data Time: 0.0109 (0.0575) Average Loss: 0.8361 (0.9377) Average CE Loss (Source):  0.8361 ( 0.9377) Learning Rate: 0.1000 (0.1000) Top1_base: 79.6875 (74.5052) Top1_base_per_class: 79.0179 (75.3168) 
Training Epoch: [58/1000] Step: [40 / 285] Batch Time: 0.1504 (0.1850) Data Time: 0.0143 (0.0505) Average Loss: 0.9984 (0.9366) Average CE Loss (Source):  0.9984 ( 0.9366) Learning Rate: 0.1000 (0.1000) Top1_base: 67.9688 (74.4141) Top1_base_per_class: 70.6897 (75.2352) 
Training Epoch: [58/1000] Step: [50 / 285] Batch Time: 0.1483 (0.1785) Data Time: 0.0131 (0.0440) Average Loss: 0.9781 (0.9319) Average CE Loss (Source):  0.9781 ( 0.9319) Learning Rate: 0.1000 (0.1000) Top1_base: 72.6562 (74.2656) Top1_base_per_class: 73.3333 (75.1025) 
Training Epoch: [58/1000] Step: [60 / 285] Batch Time: 0.1480 (0.1752) Data Time: 0.0163 (0.0408) Average Loss: 1.0086 (0.9208) Average CE Loss (Source):  1.0086 ( 0.9208) Learning Rate: 0.1000 (0.1000) Top1_base: 70.3125 (74.4141) Top1_base_per_class: 72.9487 (75.4094) 
Training Epoch: [58/1000] Step: [70 / 285] Batch Time: 0.1480 (0.1720) Data Time: 0.0106 (0.0376) Average Loss: 0.7917 (0.9272) Average CE Loss (Source):  0.7917 ( 0.9272) Learning Rate: 0.1000 (0.1000) Top1_base: 76.5625 (74.2746) Top1_base_per_class: 77.9967 (75.2516) 
Training Epoch: [58/1000] Step: [80 / 285] Batch Time: 0.1500 (0.1708) Data Time: 0.0184 (0.0365) Average Loss: 0.8755 (0.9229) Average CE Loss (Source):  0.8755 ( 0.9229) Learning Rate: 0.1000 (0.1000) Top1_base: 74.2188 (74.3555) Top1_base_per_class: 74.4848 (75.3355) 
Training Epoch: [58/1000] Step: [90 / 285] Batch Time: 0.1441 (0.1693) Data Time: 0.0121 (0.0351) Average Loss: 0.8865 (0.9161) Average CE Loss (Source):  0.8865 ( 0.9161) Learning Rate: 0.1000 (0.1000) Top1_base: 75.0000 (74.4271) Top1_base_per_class: 76.3074 (75.3215) 
Training Epoch: [58/1000] Step: [100 / 285] Batch Time: 0.1538 (0.1673) Data Time: 0.0218 (0.0333) Average Loss: 1.0762 (0.9168) Average CE Loss (Source):  1.0762 ( 0.9168) Learning Rate: 0.1000 (0.1000) Top1_base: 67.1875 (74.5078) Top1_base_per_class: 67.6061 (75.3480) 
Training Epoch: [58/1000] Step: [110 / 285] Batch Time: 0.1464 (0.1664) Data Time: 0.0140 (0.0325) Average Loss: 0.8854 (0.9107) Average CE Loss (Source):  0.8854 ( 0.9107) Learning Rate: 0.1000 (0.1000) Top1_base: 73.4375 (74.7230) Top1_base_per_class: 75.4762 (75.4407) 
Training Epoch: [58/1000] Step: [120 / 285] Batch Time: 0.1568 (0.1652) Data Time: 0.0221 (0.0313) Average Loss: 0.9052 (0.9106) Average CE Loss (Source):  0.9052 ( 0.9106) Learning Rate: 0.1000 (0.1000) Top1_base: 73.4375 (74.6810) Top1_base_per_class: 73.1806 (75.4386) 
Training Epoch: [58/1000] Step: [130 / 285] Batch Time: 0.1475 (0.1638) Data Time: 0.0120 (0.0300) Average Loss: 0.9314 (0.9143) Average CE Loss (Source):  0.9314 ( 0.9143) Learning Rate: 0.1000 (0.1000) Top1_base: 71.0938 (74.5613) Top1_base_per_class: 73.5673 (75.3468) 
Training Epoch: [58/1000] Step: [140 / 285] Batch Time: 0.1954 (0.1639) Data Time: 0.0650 (0.0302) Average Loss: 1.1018 (0.9161) Average CE Loss (Source):  1.1018 ( 0.9161) Learning Rate: 0.1000 (0.1000) Top1_base: 67.9688 (74.4308) Top1_base_per_class: 69.3567 (75.2275) 
Training Epoch: [58/1000] Step: [150 / 285] Batch Time: 0.1477 (0.1632) Data Time: 0.0119 (0.0295) Average Loss: 1.1393 (0.9197) Average CE Loss (Source):  1.1393 ( 0.9197) Learning Rate: 0.1000 (0.1000) Top1_base: 71.0938 (74.3698) Top1_base_per_class: 75.0000 (75.1022) 
Training Epoch: [58/1000] Step: [160 / 285] Batch Time: 0.1740 (0.1626) Data Time: 0.0396 (0.0289) Average Loss: 0.8721 (0.9187) Average CE Loss (Source):  0.8721 ( 0.9187) Learning Rate: 0.1000 (0.1000) Top1_base: 72.6562 (74.3555) Top1_base_per_class: 71.3636 (75.0504) 
Training Epoch: [58/1000] Step: [170 / 285] Batch Time: 0.1447 (0.1620) Data Time: 0.0110 (0.0283) Average Loss: 0.9779 (0.9212) Average CE Loss (Source):  0.9779 ( 0.9212) Learning Rate: 0.1000 (0.1000) Top1_base: 71.0938 (74.3107) Top1_base_per_class: 75.1212 (75.0448) 
Training Epoch: [58/1000] Step: [180 / 285] Batch Time: 0.1659 (0.1617) Data Time: 0.0334 (0.0280) Average Loss: 0.8849 (0.9234) Average CE Loss (Source):  0.8849 ( 0.9234) Learning Rate: 0.1000 (0.1000) Top1_base: 74.2188 (74.2665) Top1_base_per_class: 75.3117 (75.0131) 
Training Epoch: [58/1000] Step: [190 / 285] Batch Time: 0.1427 (0.1617) Data Time: 0.0106 (0.0280) Average Loss: 0.8441 (0.9275) Average CE Loss (Source):  0.8441 ( 0.9275) Learning Rate: 0.1000 (0.1000) Top1_base: 77.3438 (74.2023) Top1_base_per_class: 77.0062 (74.9083) 
Training Epoch: [58/1000] Step: [200 / 285] Batch Time: 0.2907 (0.1621) Data Time: 0.1586 (0.0285) Average Loss: 0.8557 (0.9268) Average CE Loss (Source):  0.8557 ( 0.9268) Learning Rate: 0.1000 (0.1000) Top1_base: 75.0000 (74.1875) Top1_base_per_class: 76.5790 (74.9139) 
Training Epoch: [58/1000] Step: [210 / 285] Batch Time: 0.1470 (0.1618) Data Time: 0.0115 (0.0282) Average Loss: 0.9965 (0.9289) Average CE Loss (Source):  0.9965 ( 0.9289) Learning Rate: 0.1000 (0.1000) Top1_base: 71.8750 (74.0662) Top1_base_per_class: 73.2526 (74.7808) 
Training Epoch: [58/1000] Step: [220 / 285] Batch Time: 0.1847 (0.1615) Data Time: 0.0524 (0.0278) Average Loss: 0.9465 (0.9277) Average CE Loss (Source):  0.9465 ( 0.9277) Learning Rate: 0.1000 (0.1000) Top1_base: 75.0000 (74.0803) Top1_base_per_class: 74.6726 (74.7657) 
Training Epoch: [58/1000] Step: [230 / 285] Batch Time: 0.1442 (0.1610) Data Time: 0.0103 (0.0274) Average Loss: 0.8726 (0.9272) Average CE Loss (Source):  0.8726 ( 0.9272) Learning Rate: 0.1000 (0.1000) Top1_base: 78.1250 (74.1746) Top1_base_per_class: 76.8103 (74.8764) 
Training Epoch: [58/1000] Step: [240 / 285] Batch Time: 0.1838 (0.1612) Data Time: 0.0512 (0.0276) Average Loss: 0.8779 (0.9277) Average CE Loss (Source):  0.8779 ( 0.9277) Learning Rate: 0.1000 (0.1000) Top1_base: 73.4375 (74.1309) Top1_base_per_class: 67.6367 (74.8049) 
Training Epoch: [58/1000] Step: [250 / 285] Batch Time: 0.1445 (0.1613) Data Time: 0.0105 (0.0277) Average Loss: 0.7429 (0.9275) Average CE Loss (Source):  0.7429 ( 0.9275) Learning Rate: 0.1000 (0.1000) Top1_base: 78.9062 (74.1562) Top1_base_per_class: 81.4594 (74.8454) 
Training Epoch: [58/1000] Step: [260 / 285] Batch Time: 0.1647 (0.1613) Data Time: 0.0301 (0.0278) Average Loss: 1.1326 (0.9271) Average CE Loss (Source):  1.1326 ( 0.9271) Learning Rate: 0.1000 (0.1000) Top1_base: 71.8750 (74.1737) Top1_base_per_class: 74.7344 (74.8840) 
Training Epoch: [58/1000] Step: [270 / 285] Batch Time: 0.1447 (0.1610) Data Time: 0.0103 (0.0275) Average Loss: 0.9014 (0.9283) Average CE Loss (Source):  0.9014 ( 0.9283) Learning Rate: 0.1000 (0.1000) Top1_base: 71.0938 (74.1667) Top1_base_per_class: 77.8070 (74.9238) 
Training Epoch: [58/1000] Step: [280 / 285] Batch Time: 0.2000 (0.1609) Data Time: 0.0663 (0.0273) Average Loss: 0.9728 (0.9312) Average CE Loss (Source):  0.9728 ( 0.9312) Learning Rate: 0.1000 (0.1000) Top1_base: 71.8750 (74.1211) Top1_base_per_class: 72.8070 (74.8790) 
Training Epoch: [59/1000] Step: [0] Batch Time: 0.1448 (0.1607) Data Time: 0.0110 (0.0272) Average Loss: 1.1970 (0.9306) Average CE Loss (Source):  1.1970 ( 0.9306) Learning Rate: 0.1000 (0.1000) Top1_base: 68.7500 (74.1776) Top1_base_per_class: 73.3333 (74.9599) 
Training Epoch: [59/1000] Step: [10 / 285] Batch Time: 0.1430 (0.2362) Data Time: 0.0110 (0.1009) Average Loss: 0.9540 (1.0237) Average CE Loss (Source):  0.9540 ( 1.0237) Learning Rate: 0.1000 (0.1000) Top1_base: 70.3125 (71.4062) Top1_base_per_class: 74.1314 (72.6107) 
Training Epoch: [59/1000] Step: [20 / 285] Batch Time: 0.1488 (0.1982) Data Time: 0.0163 (0.0639) Average Loss: 0.7307 (0.9486) Average CE Loss (Source):  0.7307 ( 0.9486) Learning Rate: 0.1000 (0.1000) Top1_base: 79.6875 (73.4766) Top1_base_per_class: 81.0000 (74.5166) 
Training Epoch: [59/1000] Step: [30 / 285] Batch Time: 0.1473 (0.1878) Data Time: 0.0159 (0.0538) Average Loss: 0.9216 (0.9097) Average CE Loss (Source):  0.9216 ( 0.9097) Learning Rate: 0.1000 (0.1000) Top1_base: 78.1250 (74.4010) Top1_base_per_class: 79.6069 (75.1576) 
Training Epoch: [59/1000] Step: [40 / 285] Batch Time: 0.1502 (0.1776) Data Time: 0.0143 (0.0438) Average Loss: 1.0040 (0.9055) Average CE Loss (Source):  1.0040 ( 0.9055) Learning Rate: 0.1000 (0.1000) Top1_base: 71.8750 (74.6289) Top1_base_per_class: 71.7084 (75.0617) 
Training Epoch: [59/1000] Step: [50 / 285] Batch Time: 0.1477 (0.1716) Data Time: 0.0132 (0.0379) Average Loss: 0.8322 (0.8968) Average CE Loss (Source):  0.8322 ( 0.8968) Learning Rate: 0.1000 (0.1000) Top1_base: 77.3438 (74.6719) Top1_base_per_class: 78.6158 (75.2347) 
Training Epoch: [59/1000] Step: [60 / 285] Batch Time: 0.1489 (0.1680) Data Time: 0.0141 (0.0344) Average Loss: 1.0105 (0.9020) Average CE Loss (Source):  1.0105 ( 0.9020) Learning Rate: 0.1000 (0.1000) Top1_base: 71.8750 (74.5703) Top1_base_per_class: 74.1667 (75.0197) 
Training Epoch: [59/1000] Step: [70 / 285] Batch Time: 0.1747 (0.1667) Data Time: 0.0383 (0.0329) Average Loss: 1.1107 (0.9074) Average CE Loss (Source):  1.1107 ( 0.9074) Learning Rate: 0.1000 (0.1000) Top1_base: 67.9688 (74.5759) Top1_base_per_class: 71.5136 (75.1025) 
Training Epoch: [59/1000] Step: [80 / 285] Batch Time: 0.1484 (0.1644) Data Time: 0.0148 (0.0306) Average Loss: 0.9493 (0.9051) Average CE Loss (Source):  0.9493 ( 0.9051) Learning Rate: 0.1000 (0.1000) Top1_base: 69.5312 (74.5312) Top1_base_per_class: 70.0563 (75.0665) 
Training Epoch: [59/1000] Step: [90 / 285] Batch Time: 0.1478 (0.1628) Data Time: 0.0142 (0.0290) Average Loss: 0.8022 (0.9026) Average CE Loss (Source):  0.8022 ( 0.9026) Learning Rate: 0.1000 (0.1000) Top1_base: 77.3438 (74.5920) Top1_base_per_class: 77.5564 (75.1072) 
Training Epoch: [59/1000] Step: [100 / 285] Batch Time: 0.1491 (0.1622) Data Time: 0.0159 (0.0284) Average Loss: 0.9223 (0.9010) Average CE Loss (Source):  0.9223 ( 0.9010) Learning Rate: 0.1000 (0.1000) Top1_base: 75.7812 (74.7422) Top1_base_per_class: 78.3036 (75.2603) 
Training Epoch: [59/1000] Step: [110 / 285] Batch Time: 0.1471 (0.1620) Data Time: 0.0109 (0.0282) Average Loss: 0.7590 (0.9048) Average CE Loss (Source):  0.7590 ( 0.9048) Learning Rate: 0.1000 (0.1000) Top1_base: 76.5625 (74.6804) Top1_base_per_class: 77.2807 (75.2185) 
Training Epoch: [59/1000] Step: [120 / 285] Batch Time: 0.1485 (0.1612) Data Time: 0.0147 (0.0274) Average Loss: 0.9492 (0.9102) Average CE Loss (Source):  0.9492 ( 0.9102) Learning Rate: 0.1000 (0.1000) Top1_base: 75.7812 (74.5573) Top1_base_per_class: 74.3750 (75.1308) 
Training Epoch: [59/1000] Step: [130 / 285] Batch Time: 0.1459 (0.1614) Data Time: 0.0111 (0.0275) Average Loss: 0.8789 (0.9144) Average CE Loss (Source):  0.8789 ( 0.9144) Learning Rate: 0.1000 (0.1000) Top1_base: 75.0000 (74.4291) Top1_base_per_class: 75.1543 (74.9874) 
Training Epoch: [59/1000] Step: [140 / 285] Batch Time: 0.1488 (0.1604) Data Time: 0.0172 (0.0265) Average Loss: 0.9996 (0.9145) Average CE Loss (Source):  0.9996 ( 0.9145) Learning Rate: 0.1000 (0.1000) Top1_base: 70.3125 (74.4810) Top1_base_per_class: 70.7310 (75.0058) 
Training Epoch: [59/1000] Step: [150 / 285] Batch Time: 0.1455 (0.1600) Data Time: 0.0102 (0.0262) Average Loss: 0.8999 (0.9143) Average CE Loss (Source):  0.8999 ( 0.9143) Learning Rate: 0.1000 (0.1000) Top1_base: 74.2188 (74.5052) Top1_base_per_class: 76.3218 (74.8781) 
Training Epoch: [59/1000] Step: [160 / 285] Batch Time: 0.1485 (0.1595) Data Time: 0.0160 (0.0256) Average Loss: 0.8791 (0.9091) Average CE Loss (Source):  0.8791 ( 0.9091) Learning Rate: 0.1000 (0.1000) Top1_base: 74.2188 (74.6289) Top1_base_per_class: 73.1548 (74.9883) 
Training Epoch: [59/1000] Step: [170 / 285] Batch Time: 0.1439 (0.1595) Data Time: 0.0119 (0.0258) Average Loss: 1.0543 (0.9090) Average CE Loss (Source):  1.0543 ( 0.9090) Learning Rate: 0.1000 (0.1000) Top1_base: 71.8750 (74.6461) Top1_base_per_class: 73.6218 (74.9544) 
Training Epoch: [59/1000] Step: [180 / 285] Batch Time: 0.1478 (0.1592) Data Time: 0.0139 (0.0255) Average Loss: 1.0459 (0.9087) Average CE Loss (Source):  1.0459 ( 0.9087) Learning Rate: 0.1000 (0.1000) Top1_base: 73.4375 (74.7352) Top1_base_per_class: 72.6415 (75.0278) 
Training Epoch: [59/1000] Step: [190 / 285] Batch Time: 0.1470 (0.1599) Data Time: 0.0108 (0.0262) Average Loss: 0.9724 (0.9087) Average CE Loss (Source):  0.9724 ( 0.9087) Learning Rate: 0.1000 (0.1000) Top1_base: 72.6562 (74.6793) Top1_base_per_class: 73.4394 (74.9892) 
Training Epoch: [59/1000] Step: [200 / 285] Batch Time: 0.1502 (0.1597) Data Time: 0.0157 (0.0260) Average Loss: 0.7981 (0.9092) Average CE Loss (Source):  0.7981 ( 0.9092) Learning Rate: 0.1000 (0.1000) Top1_base: 77.3438 (74.6289) Top1_base_per_class: 82.6543 (74.9488) 
Training Epoch: [59/1000] Step: [210 / 285] Batch Time: 0.1474 (0.1593) Data Time: 0.0107 (0.0255) Average Loss: 0.9762 (0.9090) Average CE Loss (Source):  0.9762 ( 0.9090) Learning Rate: 0.1000 (0.1000) Top1_base: 67.9688 (74.5982) Top1_base_per_class: 68.3929 (74.8863) 
Training Epoch: [59/1000] Step: [220 / 285] Batch Time: 0.1495 (0.1588) Data Time: 0.0149 (0.0250) Average Loss: 1.0075 (0.9106) Average CE Loss (Source):  1.0075 ( 0.9106) Learning Rate: 0.1000 (0.1000) Top1_base: 69.5312 (74.5561) Top1_base_per_class: 72.0833 (74.8869) 
Training Epoch: [59/1000] Step: [230 / 285] Batch Time: 0.1459 (0.1584) Data Time: 0.0119 (0.0245) Average Loss: 1.1537 (0.9138) Average CE Loss (Source):  1.1537 ( 0.9138) Learning Rate: 0.1000 (0.1000) Top1_base: 71.0938 (74.4803) Top1_base_per_class: 72.3585 (74.8817) 
Training Epoch: [59/1000] Step: [240 / 285] Batch Time: 0.1523 (0.1580) Data Time: 0.0162 (0.0241) Average Loss: 0.9775 (0.9141) Average CE Loss (Source):  0.9775 ( 0.9141) Learning Rate: 0.1000 (0.1000) Top1_base: 66.4062 (74.4466) Top1_base_per_class: 68.3046 (74.8191) 
Training Epoch: [59/1000] Step: [250 / 285] Batch Time: 0.1454 (0.1577) Data Time: 0.0120 (0.0237) Average Loss: 0.8276 (0.9167) Average CE Loss (Source):  0.8276 ( 0.9167) Learning Rate: 0.1000 (0.1000) Top1_base: 76.5625 (74.3906) Top1_base_per_class: 74.8851 (74.7459) 
Training Epoch: [59/1000] Step: [260 / 285] Batch Time: 0.1487 (0.1574) Data Time: 0.0167 (0.0234) Average Loss: 1.1438 (0.9235) Average CE Loss (Source):  1.1438 ( 0.9235) Learning Rate: 0.1000 (0.1000) Top1_base: 68.7500 (74.2668) Top1_base_per_class: 65.1543 (74.5810) 
Training Epoch: [59/1000] Step: [270 / 285] Batch Time: 0.1469 (0.1573) Data Time: 0.0106 (0.0234) Average Loss: 0.8818 (0.9242) Average CE Loss (Source):  0.8818 ( 0.9242) Learning Rate: 0.1000 (0.1000) Top1_base: 75.7812 (74.2477) Top1_base_per_class: 75.5000 (74.5630) 
Training Epoch: [59/1000] Step: [280 / 285] Batch Time: 0.1480 (0.1572) Data Time: 0.0129 (0.0233) Average Loss: 0.9420 (0.9276) Average CE Loss (Source):  0.9420 ( 0.9276) Learning Rate: 0.1000 (0.1000) Top1_base: 72.6562 (74.1323) Top1_base_per_class: 72.3056 (74.4544) 
Training Epoch: [60/1000] Step: [0] Batch Time: 0.1508 (0.1572) Data Time: 0.0194 (0.0234) Average Loss: 1.0975 (0.9297) Average CE Loss (Source):  1.0975 ( 0.9297) Learning Rate: 0.1000 (0.1000) Top1_base: 71.8750 (74.1283) Top1_base_per_class: 72.9310 (74.4601) 
  6%|▌         | 60/1000 [47:17<12:12:27, 46.75s/it]  6%|▌         | 61/1000 [48:02<12:02:10, 46.15s/it]Training Epoch: [60/1000] Step: [10 / 285] Batch Time: 0.1483 (0.2321) Data Time: 0.0129 (0.0981) Average Loss: 0.8808 (0.8601) Average CE Loss (Source):  0.8808 ( 0.8601) Learning Rate: 0.1000 (0.1000) Top1_base: 68.7500 (73.7500) Top1_base_per_class: 69.8588 (74.9493) 
Training Epoch: [60/1000] Step: [20 / 285] Batch Time: 0.1477 (0.2041) Data Time: 0.0164 (0.0703) Average Loss: 0.8145 (0.8695) Average CE Loss (Source):  0.8145 ( 0.8695) Learning Rate: 0.1000 (0.1000) Top1_base: 76.5625 (74.6484) Top1_base_per_class: 81.8750 (75.3765) 
Training Epoch: [60/1000] Step: [30 / 285] Batch Time: 0.2003 (0.1880) Data Time: 0.0655 (0.0546) Average Loss: 0.8726 (0.8643) Average CE Loss (Source):  0.8726 ( 0.8643) Learning Rate: 0.1000 (0.1000) Top1_base: 78.1250 (75.4688) Top1_base_per_class: 77.9464 (75.9246) 
Training Epoch: [60/1000] Step: [40 / 285] Batch Time: 0.1462 (0.1795) Data Time: 0.0144 (0.0458) Average Loss: 1.0398 (0.8826) Average CE Loss (Source):  1.0398 ( 0.8826) Learning Rate: 0.1000 (0.1000) Top1_base: 69.5312 (75.2148) Top1_base_per_class: 72.2727 (75.8274) 
Training Epoch: [60/1000] Step: [50 / 285] Batch Time: 0.1535 (0.1739) Data Time: 0.0198 (0.0403) Average Loss: 0.8931 (0.8865) Average CE Loss (Source):  0.8931 ( 0.8865) Learning Rate: 0.1000 (0.1000) Top1_base: 78.1250 (75.1094) Top1_base_per_class: 80.8291 (75.6279) 
Training Epoch: [60/1000] Step: [60 / 285] Batch Time: 0.1447 (0.1699) Data Time: 0.0129 (0.0363) Average Loss: 0.7591 (0.8841) Average CE Loss (Source):  0.7591 ( 0.8841) Learning Rate: 0.1000 (0.1000) Top1_base: 80.4688 (75.3125) Top1_base_per_class: 82.3420 (75.7198) 
Training Epoch: [60/1000] Step: [70 / 285] Batch Time: 0.1858 (0.1673) Data Time: 0.0503 (0.0337) Average Loss: 0.9845 (0.8852) Average CE Loss (Source):  0.9845 ( 0.8852) Learning Rate: 0.1000 (0.1000) Top1_base: 71.0938 (75.1674) Top1_base_per_class: 72.5575 (75.7044) 
Training Epoch: [60/1000] Step: [80 / 285] Batch Time: 0.1500 (0.1650) Data Time: 0.0187 (0.0314) Average Loss: 0.9075 (0.8801) Average CE Loss (Source):  0.9075 ( 0.8801) Learning Rate: 0.1000 (0.1000) Top1_base: 71.8750 (75.2930) Top1_base_per_class: 68.9937 (75.8119) 
Training Epoch: [60/1000] Step: [90 / 285] Batch Time: 0.1485 (0.1631) Data Time: 0.0156 (0.0295) Average Loss: 0.8824 (0.8779) Average CE Loss (Source):  0.8824 ( 0.8779) Learning Rate: 0.1000 (0.1000) Top1_base: 71.0938 (75.3299) Top1_base_per_class: 71.8421 (75.8923) 
Training Epoch: [60/1000] Step: [100 / 285] Batch Time: 0.1510 (0.1617) Data Time: 0.0188 (0.0280) Average Loss: 1.1004 (0.8836) Average CE Loss (Source):  1.1004 ( 0.8836) Learning Rate: 0.1000 (0.1000) Top1_base: 67.9688 (75.2109) Top1_base_per_class: 68.6926 (75.8267) 
Training Epoch: [60/1000] Step: [110 / 285] Batch Time: 0.2155 (0.1614) Data Time: 0.0811 (0.0278) Average Loss: 0.9922 (0.8870) Average CE Loss (Source):  0.9922 ( 0.8870) Learning Rate: 0.1000 (0.1000) Top1_base: 68.7500 (75.1847) Top1_base_per_class: 70.5247 (75.9594) 
Training Epoch: [60/1000] Step: [120 / 285] Batch Time: 0.1498 (0.1605) Data Time: 0.0189 (0.0268) Average Loss: 1.0870 (0.8892) Average CE Loss (Source):  1.0870 ( 0.8892) Learning Rate: 0.1000 (0.1000) Top1_base: 67.1875 (75.0586) Top1_base_per_class: 70.0758 (75.7152) 
Training Epoch: [60/1000] Step: [130 / 285] Batch Time: 0.1473 (0.1603) Data Time: 0.0128 (0.0267) Average Loss: 0.6552 (0.8898) Average CE Loss (Source):  0.6552 ( 0.8898) Learning Rate: 0.1000 (0.1000) Top1_base: 81.2500 (74.9940) Top1_base_per_class: 81.3636 (75.5891) 
Training Epoch: [60/1000] Step: [140 / 285] Batch Time: 0.1516 (0.1599) Data Time: 0.0183 (0.0263) Average Loss: 1.1377 (0.8941) Average CE Loss (Source):  1.1377 ( 0.8941) Learning Rate: 0.1000 (0.1000) Top1_base: 67.9688 (74.9051) Top1_base_per_class: 68.1437 (75.4352) 
Training Epoch: [60/1000] Step: [150 / 285] Batch Time: 0.1833 (0.1598) Data Time: 0.0507 (0.0262) Average Loss: 0.7745 (0.8973) Average CE Loss (Source):  0.7745 ( 0.8973) Learning Rate: 0.1000 (0.1000) Top1_base: 80.4688 (74.7604) Top1_base_per_class: 81.2500 (75.2816) 
Training Epoch: [60/1000] Step: [160 / 285] Batch Time: 0.1465 (0.1593) Data Time: 0.0139 (0.0258) Average Loss: 1.0662 (0.9058) Average CE Loss (Source):  1.0662 ( 0.9058) Learning Rate: 0.1000 (0.1000) Top1_base: 69.5312 (74.6143) Top1_base_per_class: 73.2390 (75.1404) 
Training Epoch: [60/1000] Step: [170 / 285] Batch Time: 0.1499 (0.1592) Data Time: 0.0140 (0.0257) Average Loss: 0.8741 (0.9051) Average CE Loss (Source):  0.8741 ( 0.9051) Learning Rate: 0.1000 (0.1000) Top1_base: 71.8750 (74.5634) Top1_base_per_class: 70.5655 (75.0803) 
Training Epoch: [60/1000] Step: [180 / 285] Batch Time: 0.1535 (0.1588) Data Time: 0.0199 (0.0252) Average Loss: 0.8736 (0.9098) Average CE Loss (Source):  0.8736 ( 0.9098) Learning Rate: 0.1000 (0.1000) Top1_base: 75.0000 (74.4705) Top1_base_per_class: 74.3082 (74.9444) 
Training Epoch: [60/1000] Step: [190 / 285] Batch Time: 0.1528 (0.1584) Data Time: 0.0130 (0.0247) Average Loss: 1.0844 (0.9110) Average CE Loss (Source):  1.0844 ( 0.9110) Learning Rate: 0.1000 (0.1000) Top1_base: 73.4375 (74.4696) Top1_base_per_class: 74.0606 (75.0303) 
Training Epoch: [60/1000] Step: [200 / 285] Batch Time: 0.1524 (0.1581) Data Time: 0.0180 (0.0242) Average Loss: 0.7978 (0.9144) Average CE Loss (Source):  0.7978 ( 0.9144) Learning Rate: 0.1000 (0.1000) Top1_base: 77.3438 (74.4023) Top1_base_per_class: 78.8304 (74.9840) 
Training Epoch: [60/1000] Step: [210 / 285] Batch Time: 0.1504 (0.1577) Data Time: 0.0122 (0.0238) Average Loss: 0.9040 (0.9151) Average CE Loss (Source):  0.9040 ( 0.9151) Learning Rate: 0.1000 (0.1000) Top1_base: 75.7812 (74.3527) Top1_base_per_class: 70.9477 (74.8958) 
Training Epoch: [60/1000] Step: [220 / 285] Batch Time: 0.1494 (0.1573) Data Time: 0.0184 (0.0234) Average Loss: 0.9747 (0.9162) Average CE Loss (Source):  0.9747 ( 0.9162) Learning Rate: 0.1000 (0.1000) Top1_base: 74.2188 (74.3750) Top1_base_per_class: 80.0309 (74.9771) 
Training Epoch: [60/1000] Step: [230 / 285] Batch Time: 0.1996 (0.1575) Data Time: 0.0640 (0.0236) Average Loss: 1.0173 (0.9173) Average CE Loss (Source):  1.0173 ( 0.9173) Learning Rate: 0.1000 (0.1000) Top1_base: 76.5625 (74.3784) Top1_base_per_class: 81.5022 (75.0333) 
Training Epoch: [60/1000] Step: [240 / 285] Batch Time: 0.1917 (0.1574) Data Time: 0.0590 (0.0234) Average Loss: 0.8623 (0.9197) Average CE Loss (Source):  0.8623 ( 0.9197) Learning Rate: 0.1000 (0.1000) Top1_base: 75.0000 (74.3262) Top1_base_per_class: 74.5679 (74.9291) 
Training Epoch: [60/1000] Step: [250 / 285] Batch Time: 0.1734 (0.1575) Data Time: 0.0406 (0.0236) Average Loss: 1.0377 (0.9200) Average CE Loss (Source):  1.0377 ( 0.9200) Learning Rate: 0.1000 (0.1000) Top1_base: 67.9688 (74.3219) Top1_base_per_class: 70.3133 (74.9427) 
Training Epoch: [60/1000] Step: [260 / 285] Batch Time: 0.1500 (0.1572) Data Time: 0.0163 (0.0233) Average Loss: 0.8458 (0.9209) Average CE Loss (Source):  0.8458 ( 0.9209) Learning Rate: 0.1000 (0.1000) Top1_base: 74.2188 (74.3269) Top1_base_per_class: 77.5926 (74.9861) 
Training Epoch: [60/1000] Step: [270 / 285] Batch Time: 0.1529 (0.1569) Data Time: 0.0149 (0.0229) Average Loss: 0.9441 (0.9224) Average CE Loss (Source):  0.9441 ( 0.9224) Learning Rate: 0.1000 (0.1000) Top1_base: 70.3125 (74.2969) Top1_base_per_class: 70.1462 (74.9430) 
Training Epoch: [60/1000] Step: [280 / 285] Batch Time: 0.1447 (0.1569) Data Time: 0.0133 (0.0230) Average Loss: 0.9170 (0.9239) Average CE Loss (Source):  0.9170 ( 0.9239) Learning Rate: 0.1000 (0.1000) Top1_base: 71.0938 (74.2494) Top1_base_per_class: 71.2078 (74.9035) 
Training Epoch: [61/1000] Step: [0] Batch Time: 0.1385 (0.1567) Data Time: 0.0097 (0.0229) Average Loss: 0.9268 (0.9241) Average CE Loss (Source):  0.9268 ( 0.9241) Learning Rate: 0.1000 (0.1000) Top1_base: 75.0000 (74.2379) Top1_base_per_class: 74.9020 (74.9037) 
Training Epoch: [61/1000] Step: [10 / 285] Batch Time: 0.1476 (0.2473) Data Time: 0.0136 (0.1135) Average Loss: 0.8145 (0.8441) Average CE Loss (Source):  0.8145 ( 0.8441) Learning Rate: 0.1000 (0.1000) Top1_base: 73.4375 (75.8594) Top1_base_per_class: 75.9568 (76.8084) 
Training Epoch: [61/1000] Step: [20 / 285] Batch Time: 0.1454 (0.2079) Data Time: 0.0123 (0.0741) Average Loss: 0.9249 (0.8565) Average CE Loss (Source):  0.9249 ( 0.8565) Learning Rate: 0.1000 (0.1000) Top1_base: 75.0000 (75.5859) Top1_base_per_class: 73.5310 (75.9969) 
Training Epoch: [61/1000] Step: [30 / 285] Batch Time: 0.1445 (0.1929) Data Time: 0.0125 (0.0591) Average Loss: 1.2070 (0.8626) Average CE Loss (Source):  1.2070 ( 0.8626) Learning Rate: 0.1000 (0.1000) Top1_base: 65.6250 (75.9635) Top1_base_per_class: 65.4632 (76.2418) 
Training Epoch: [61/1000] Step: [40 / 285] Batch Time: 0.1473 (0.1850) Data Time: 0.0132 (0.0513) Average Loss: 0.7289 (0.8471) Average CE Loss (Source):  0.7289 ( 0.8471) Learning Rate: 0.1000 (0.1000) Top1_base: 82.0312 (76.4062) Top1_base_per_class: 80.1852 (76.4403) 
Training Epoch: [61/1000] Step: [50 / 285] Batch Time: 0.1495 (0.1811) Data Time: 0.0150 (0.0475) Average Loss: 0.9218 (0.8564) Average CE Loss (Source):  0.9218 ( 0.8564) Learning Rate: 0.1000 (0.1000) Top1_base: 70.3125 (75.9844) Top1_base_per_class: 73.9548 (76.0553) 
Training Epoch: [61/1000] Step: [60 / 285] Batch Time: 0.1487 (0.1781) Data Time: 0.0124 (0.0444) Average Loss: 0.7600 (0.8568) Average CE Loss (Source):  0.7600 ( 0.8568) Learning Rate: 0.1000 (0.1000) Top1_base: 80.4688 (76.1068) Top1_base_per_class: 80.4167 (76.2004) 
Training Epoch: [61/1000] Step: [70 / 285] Batch Time: 0.1473 (0.1750) Data Time: 0.0129 (0.0412) Average Loss: 0.9296 (0.8600) Average CE Loss (Source):  0.9296 ( 0.8600) Learning Rate: 0.1000 (0.1000) Top1_base: 71.8750 (75.9152) Top1_base_per_class: 73.0702 (76.1766) 
Training Epoch: [61/1000] Step: [80 / 285] Batch Time: 0.1495 (0.1739) Data Time: 0.0137 (0.0401) Average Loss: 0.9439 (0.8669) Average CE Loss (Source):  0.9439 ( 0.8669) Learning Rate: 0.1000 (0.1000) Top1_base: 74.2188 (75.7324) Top1_base_per_class: 70.3459 (75.9327) 
Training Epoch: [61/1000] Step: [90 / 285] Batch Time: 0.1444 (0.1724) Data Time: 0.0118 (0.0387) Average Loss: 0.6546 (0.8622) Average CE Loss (Source):  0.6546 ( 0.8622) Learning Rate: 0.1000 (0.1000) Top1_base: 78.1250 (75.9115) Top1_base_per_class: 80.4464 (76.1370) 
Training Epoch: [61/1000] Step: [100 / 285] Batch Time: 0.1419 (0.1699) Data Time: 0.0112 (0.0364) Average Loss: 0.8438 (0.8626) Average CE Loss (Source):  0.8438 ( 0.8626) Learning Rate: 0.1000 (0.1000) Top1_base: 78.9062 (75.8828) Top1_base_per_class: 79.7619 (76.1584) 
Training Epoch: [61/1000] Step: [110 / 285] Batch Time: 0.1441 (0.1689) Data Time: 0.0111 (0.0355) Average Loss: 0.7877 (0.8641) Average CE Loss (Source):  0.7877 ( 0.8641) Learning Rate: 0.1000 (0.1000) Top1_base: 79.6875 (75.7741) Top1_base_per_class: 77.2807 (76.0631) 
Training Epoch: [61/1000] Step: [120 / 285] Batch Time: 0.1454 (0.1679) Data Time: 0.0130 (0.0345) Average Loss: 1.1655 (0.8749) Average CE Loss (Source):  1.1655 ( 0.8749) Learning Rate: 0.1000 (0.1000) Top1_base: 71.0938 (75.4492) Top1_base_per_class: 67.7273 (75.6639) 
Training Epoch: [61/1000] Step: [130 / 285] Batch Time: 0.1451 (0.1669) Data Time: 0.0133 (0.0337) Average Loss: 1.0421 (0.8852) Average CE Loss (Source):  1.0421 ( 0.8852) Learning Rate: 0.1000 (0.1000) Top1_base: 72.6562 (75.2344) Top1_base_per_class: 72.6836 (75.4998) 
Training Epoch: [61/1000] Step: [140 / 285] Batch Time: 0.1439 (0.1658) Data Time: 0.0119 (0.0326) Average Loss: 0.9463 (0.8867) Average CE Loss (Source):  0.9463 ( 0.8867) Learning Rate: 0.1000 (0.1000) Top1_base: 71.0938 (75.1395) Top1_base_per_class: 72.7576 (75.3746) 
Training Epoch: [61/1000] Step: [150 / 285] Batch Time: 0.1453 (0.1658) Data Time: 0.0110 (0.0326) Average Loss: 0.8399 (0.8917) Average CE Loss (Source):  0.8399 ( 0.8917) Learning Rate: 0.1000 (0.1000) Top1_base: 78.1250 (75.0990) Top1_base_per_class: 79.6517 (75.3608) 
Training Epoch: [61/1000] Step: [160 / 285] Batch Time: 0.1458 (0.1660) Data Time: 0.0129 (0.0328) Average Loss: 0.8953 (0.8936) Average CE Loss (Source):  0.8953 ( 0.8936) Learning Rate: 0.1000 (0.1000) Top1_base: 71.0938 (75.0098) Top1_base_per_class: 71.5774 (75.2585) 
Training Epoch: [61/1000] Step: [170 / 285] Batch Time: 0.1476 (0.1665) Data Time: 0.0129 (0.0334) Average Loss: 0.8001 (0.8971) Average CE Loss (Source):  0.8001 ( 0.8971) Learning Rate: 0.1000 (0.1000) Top1_base: 80.4688 (74.9908) Top1_base_per_class: 78.3019 (75.2364) 
Training Epoch: [61/1000] Step: [180 / 285] Batch Time: 0.1445 (0.1667) Data Time: 0.0137 (0.0335) Average Loss: 0.8256 (0.8968) Average CE Loss (Source):  0.8256 ( 0.8968) Learning Rate: 0.1000 (0.1000) Top1_base: 76.5625 (75.0477) Top1_base_per_class: 76.2877 (75.2394) 
Training Epoch: [61/1000] Step: [190 / 285] Batch Time: 0.1463 (0.1660) Data Time: 0.0140 (0.0328) Average Loss: 1.0269 (0.9003) Average CE Loss (Source):  1.0269 ( 0.9003) Learning Rate: 0.1000 (0.1000) Top1_base: 70.3125 (74.9836) Top1_base_per_class: 72.9938 (75.2191) 
Training Epoch: [61/1000] Step: [200 / 285] Batch Time: 0.1482 (0.1653) Data Time: 0.0154 (0.0320) Average Loss: 0.8983 (0.9004) Average CE Loss (Source):  0.8983 ( 0.9004) Learning Rate: 0.1000 (0.1000) Top1_base: 73.4375 (74.9805) Top1_base_per_class: 76.3272 (75.2114) 
Training Epoch: [61/1000] Step: [210 / 285] Batch Time: 0.1482 (0.1650) Data Time: 0.0157 (0.0316) Average Loss: 0.8728 (0.9061) Average CE Loss (Source):  0.8728 ( 0.9061) Learning Rate: 0.1000 (0.1000) Top1_base: 74.2188 (74.8214) Top1_base_per_class: 76.2994 (75.0902) 
Training Epoch: [61/1000] Step: [220 / 285] Batch Time: 0.1460 (0.1642) Data Time: 0.0119 (0.0308) Average Loss: 0.9010 (0.9076) Average CE Loss (Source):  0.9010 ( 0.9076) Learning Rate: 0.1000 (0.1000) Top1_base: 77.3438 (74.7337) Top1_base_per_class: 76.4881 (75.0567) 
Training Epoch: [61/1000] Step: [230 / 285] Batch Time: 0.1513 (0.1638) Data Time: 0.0146 (0.0304) Average Loss: 0.8458 (0.9087) Average CE Loss (Source):  0.8458 ( 0.9087) Learning Rate: 0.1000 (0.1000) Top1_base: 72.6562 (74.6535) Top1_base_per_class: 74.7222 (74.9709) 
Training Epoch: [61/1000] Step: [240 / 285] Batch Time: 0.1486 (0.1634) Data Time: 0.0159 (0.0299) Average Loss: 0.9640 (0.9135) Average CE Loss (Source):  0.9640 ( 0.9135) Learning Rate: 0.1000 (0.1000) Top1_base: 76.5625 (74.5443) Top1_base_per_class: 80.8480 (74.9223) 
Training Epoch: [61/1000] Step: [250 / 285] Batch Time: 0.1440 (0.1628) Data Time: 0.0104 (0.0294) Average Loss: 1.0452 (0.9157) Average CE Loss (Source):  1.0452 ( 0.9157) Learning Rate: 0.1000 (0.1000) Top1_base: 72.6562 (74.5187) Top1_base_per_class: 71.5238 (74.8670) 
Training Epoch: [61/1000] Step: [260 / 285] Batch Time: 0.1469 (0.1625) Data Time: 0.0126 (0.0290) Average Loss: 1.0034 (0.9184) Average CE Loss (Source):  1.0034 ( 0.9184) Learning Rate: 0.1000 (0.1000) Top1_base: 73.4375 (74.4441) Top1_base_per_class: 78.2080 (74.8319) 
Training Epoch: [61/1000] Step: [270 / 285] Batch Time: 0.1463 (0.1623) Data Time: 0.0121 (0.0289) Average Loss: 1.0203 (0.9227) Average CE Loss (Source):  1.0203 ( 0.9227) Learning Rate: 0.1000 (0.1000) Top1_base: 70.3125 (74.3605) Top1_base_per_class: 71.7593 (74.7281) 
Training Epoch: [61/1000] Step: [280 / 285] Batch Time: 0.1465 (0.1619) Data Time: 0.0133 (0.0284) Average Loss: 0.7851 (0.9217) Average CE Loss (Source):  0.7851 ( 0.9217) Learning Rate: 0.1000 (0.1000) Top1_base: 78.1250 (74.3610) Top1_base_per_class: 78.4226 (74.7240) 
Training Epoch: [62/1000] Step: [0] Batch Time: 0.1506 (0.1616) Data Time: 0.0120 (0.0281) Average Loss: 0.7526 (0.9205) Average CE Loss (Source):  0.7526 ( 0.9205) Learning Rate: 0.1000 (0.1000) Top1_base: 77.3438 (74.3777) Top1_base_per_class: 76.1111 (74.7339) 
  6%|▌         | 62/1000 [48:51<12:14:58, 47.01s/it]  6%|▋         | 63/1000 [49:37<12:08:40, 46.66s/it]Training Epoch: [62/1000] Step: [10 / 285] Batch Time: 0.1502 (0.2443) Data Time: 0.0138 (0.1101) Average Loss: 0.7957 (0.8732) Average CE Loss (Source):  0.7957 ( 0.8732) Learning Rate: 0.1000 (0.1000) Top1_base: 76.5625 (75.0781) Top1_base_per_class: 76.2421 (74.6020) 
Training Epoch: [62/1000] Step: [20 / 285] Batch Time: 0.1440 (0.2045) Data Time: 0.0123 (0.0712) Average Loss: 0.5948 (0.8940) Average CE Loss (Source):  0.5948 ( 0.8940) Learning Rate: 0.1000 (0.1000) Top1_base: 83.5938 (75.3125) Top1_base_per_class: 82.4545 (75.4250) 
Training Epoch: [62/1000] Step: [30 / 285] Batch Time: 0.1467 (0.1963) Data Time: 0.0107 (0.0631) Average Loss: 0.9173 (0.8644) Average CE Loss (Source):  0.9173 ( 0.8644) Learning Rate: 0.1000 (0.1000) Top1_base: 72.6562 (75.7292) Top1_base_per_class: 76.5033 (75.9507) 
Training Epoch: [62/1000] Step: [40 / 285] Batch Time: 0.1431 (0.1879) Data Time: 0.0122 (0.0553) Average Loss: 1.0213 (0.8671) Average CE Loss (Source):  1.0213 ( 0.8671) Learning Rate: 0.1000 (0.1000) Top1_base: 71.8750 (75.8594) Top1_base_per_class: 71.5741 (76.1895) 
Training Epoch: [62/1000] Step: [50 / 285] Batch Time: 0.1448 (0.1830) Data Time: 0.0132 (0.0506) Average Loss: 0.9962 (0.8567) Average CE Loss (Source):  0.9962 ( 0.8567) Learning Rate: 0.1000 (0.1000) Top1_base: 72.6562 (76.3906) Top1_base_per_class: 69.9091 (76.7103) 
Training Epoch: [62/1000] Step: [60 / 285] Batch Time: 0.1427 (0.1794) Data Time: 0.0115 (0.0470) Average Loss: 0.8919 (0.8715) Average CE Loss (Source):  0.8919 ( 0.8715) Learning Rate: 0.1000 (0.1000) Top1_base: 73.4375 (75.9115) Top1_base_per_class: 74.1818 (76.2499) 
Training Epoch: [62/1000] Step: [70 / 285] Batch Time: 0.1425 (0.1760) Data Time: 0.0115 (0.0435) Average Loss: 0.9572 (0.8773) Average CE Loss (Source):  0.9572 ( 0.8773) Learning Rate: 0.1000 (0.1000) Top1_base: 75.7812 (75.9040) Top1_base_per_class: 75.6725 (76.2898) 
Training Epoch: [62/1000] Step: [80 / 285] Batch Time: 0.1528 (0.1729) Data Time: 0.0158 (0.0404) Average Loss: 1.0825 (0.8825) Average CE Loss (Source):  1.0825 ( 0.8825) Learning Rate: 0.1000 (0.1000) Top1_base: 72.6562 (75.8398) Top1_base_per_class: 72.4561 (76.2412) 
Training Epoch: [62/1000] Step: [90 / 285] Batch Time: 0.1535 (0.1725) Data Time: 0.0169 (0.0398) Average Loss: 1.0695 (0.8823) Average CE Loss (Source):  1.0695 ( 0.8823) Learning Rate: 0.1000 (0.1000) Top1_base: 67.1875 (75.6510) Top1_base_per_class: 69.8305 (76.1701) 
Training Epoch: [62/1000] Step: [100 / 285] Batch Time: 0.1427 (0.1721) Data Time: 0.0122 (0.0394) Average Loss: 0.9567 (0.8851) Average CE Loss (Source):  0.9567 ( 0.8851) Learning Rate: 0.1000 (0.1000) Top1_base: 76.5625 (75.5938) Top1_base_per_class: 76.5064 (76.0790) 
Training Epoch: [62/1000] Step: [110 / 285] Batch Time: 0.1522 (0.1709) Data Time: 0.0160 (0.0380) Average Loss: 0.8252 (0.8830) Average CE Loss (Source):  0.8252 ( 0.8830) Learning Rate: 0.1000 (0.1000) Top1_base: 79.6875 (75.6108) Top1_base_per_class: 78.7500 (76.1815) 
Training Epoch: [62/1000] Step: [120 / 285] Batch Time: 0.1492 (0.1693) Data Time: 0.0164 (0.0365) Average Loss: 1.0905 (0.8826) Average CE Loss (Source):  1.0905 ( 0.8826) Learning Rate: 0.1000 (0.1000) Top1_base: 69.5312 (75.4948) Top1_base_per_class: 69.5238 (76.0387) 
Training Epoch: [62/1000] Step: [130 / 285] Batch Time: 0.1496 (0.1686) Data Time: 0.0167 (0.0357) Average Loss: 0.9491 (0.8852) Average CE Loss (Source):  0.9491 ( 0.8852) Learning Rate: 0.1000 (0.1000) Top1_base: 78.1250 (75.4087) Top1_base_per_class: 79.9685 (75.9763) 
Training Epoch: [62/1000] Step: [140 / 285] Batch Time: 0.1460 (0.1680) Data Time: 0.0118 (0.0352) Average Loss: 0.9453 (0.8867) Average CE Loss (Source):  0.9453 ( 0.8867) Learning Rate: 0.1000 (0.1000) Top1_base: 71.8750 (75.3460) Top1_base_per_class: 73.8690 (75.9193) 
Training Epoch: [62/1000] Step: [150 / 285] Batch Time: 0.1505 (0.1674) Data Time: 0.0150 (0.0345) Average Loss: 0.7719 (0.8881) Average CE Loss (Source):  0.7719 ( 0.8881) Learning Rate: 0.1000 (0.1000) Top1_base: 75.7812 (75.3385) Top1_base_per_class: 73.6299 (75.8379) 
Training Epoch: [62/1000] Step: [160 / 285] Batch Time: 0.1453 (0.1662) Data Time: 0.0115 (0.0332) Average Loss: 0.7641 (0.8848) Average CE Loss (Source):  0.7641 ( 0.8848) Learning Rate: 0.1000 (0.1000) Top1_base: 82.0312 (75.4150) Top1_base_per_class: 84.5758 (75.8665) 
Training Epoch: [62/1000] Step: [170 / 285] Batch Time: 0.1503 (0.1653) Data Time: 0.0163 (0.0323) Average Loss: 1.0231 (0.8842) Average CE Loss (Source):  1.0231 ( 0.8842) Learning Rate: 0.1000 (0.1000) Top1_base: 70.3125 (75.4550) Top1_base_per_class: 73.0000 (75.9311) 
Training Epoch: [62/1000] Step: [180 / 285] Batch Time: 0.1447 (0.1651) Data Time: 0.0125 (0.0321) Average Loss: 0.8924 (0.8832) Average CE Loss (Source):  0.8924 ( 0.8832) Learning Rate: 0.1000 (0.1000) Top1_base: 75.0000 (75.5208) Top1_base_per_class: 77.3214 (75.9943) 
Training Epoch: [62/1000] Step: [190 / 285] Batch Time: 0.1521 (0.1642) Data Time: 0.0178 (0.0312) Average Loss: 0.9946 (0.8843) Average CE Loss (Source):  0.9946 ( 0.8843) Learning Rate: 0.1000 (0.1000) Top1_base: 69.5312 (75.4030) Top1_base_per_class: 66.0920 (75.8526) 
Training Epoch: [62/1000] Step: [200 / 285] Batch Time: 0.1497 (0.1635) Data Time: 0.0134 (0.0305) Average Loss: 1.0772 (0.8893) Average CE Loss (Source):  1.0772 ( 0.8893) Learning Rate: 0.1000 (0.1000) Top1_base: 71.8750 (75.2578) Top1_base_per_class: 68.1090 (75.6390) 
Training Epoch: [62/1000] Step: [210 / 285] Batch Time: 0.1453 (0.1628) Data Time: 0.0119 (0.0297) Average Loss: 0.9317 (0.8968) Average CE Loss (Source):  0.9317 ( 0.8968) Learning Rate: 0.1000 (0.1000) Top1_base: 74.2188 (75.0856) Top1_base_per_class: 78.5000 (75.5317) 
Training Epoch: [62/1000] Step: [220 / 285] Batch Time: 0.1447 (0.1622) Data Time: 0.0108 (0.0290) Average Loss: 0.8476 (0.8994) Average CE Loss (Source):  0.8476 ( 0.8994) Learning Rate: 0.1000 (0.1000) Top1_base: 74.2188 (75.0639) Top1_base_per_class: 76.4600 (75.4988) 
Training Epoch: [62/1000] Step: [230 / 285] Batch Time: 0.1535 (0.1621) Data Time: 0.0136 (0.0288) Average Loss: 1.1285 (0.9032) Average CE Loss (Source):  1.1285 ( 0.9032) Learning Rate: 0.1000 (0.1000) Top1_base: 68.7500 (75.0000) Top1_base_per_class: 66.6970 (75.3858) 
Training Epoch: [62/1000] Step: [240 / 285] Batch Time: 0.1466 (0.1618) Data Time: 0.0128 (0.0284) Average Loss: 0.9382 (0.9049) Average CE Loss (Source):  0.9382 ( 0.9049) Learning Rate: 0.1000 (0.1000) Top1_base: 68.7500 (74.9316) Top1_base_per_class: 70.0847 (75.3703) 
Training Epoch: [62/1000] Step: [250 / 285] Batch Time: 0.1538 (0.1619) Data Time: 0.0138 (0.0283) Average Loss: 0.7466 (0.9039) Average CE Loss (Source):  0.7466 ( 0.9039) Learning Rate: 0.1000 (0.1000) Top1_base: 78.9062 (74.9437) Top1_base_per_class: 78.9181 (75.3567) 
Training Epoch: [62/1000] Step: [260 / 285] Batch Time: 0.1433 (0.1615) Data Time: 0.0119 (0.0279) Average Loss: 0.9580 (0.9049) Average CE Loss (Source):  0.9580 ( 0.9049) Learning Rate: 0.1000 (0.1000) Top1_base: 72.6562 (74.9309) Top1_base_per_class: 76.0606 (75.3323) 
Training Epoch: [62/1000] Step: [270 / 285] Batch Time: 0.1542 (0.1611) Data Time: 0.0176 (0.0275) Average Loss: 0.8762 (0.9041) Average CE Loss (Source):  0.8762 ( 0.9041) Learning Rate: 0.1000 (0.1000) Top1_base: 77.3438 (74.9479) Top1_base_per_class: 78.6207 (75.3707) 
Training Epoch: [62/1000] Step: [280 / 285] Batch Time: 0.1412 (0.1608) Data Time: 0.0103 (0.0272) Average Loss: 1.0103 (0.9079) Average CE Loss (Source):  1.0103 ( 0.9079) Learning Rate: 0.1000 (0.1000) Top1_base: 70.3125 (74.8633) Top1_base_per_class: 69.9371 (75.3173) 
Training Epoch: [63/1000] Step: [0] Batch Time: 0.1470 (0.1606) Data Time: 0.0107 (0.0269) Average Loss: 0.7756 (0.9086) Average CE Loss (Source):  0.7756 ( 0.9086) Learning Rate: 0.1000 (0.1000) Top1_base: 79.6875 (74.8081) Top1_base_per_class: 81.6964 (75.2777) 
Training Epoch: [63/1000] Step: [10 / 285] Batch Time: 0.1481 (0.2242) Data Time: 0.0159 (0.0919) Average Loss: 0.8706 (0.8527) Average CE Loss (Source):  0.8706 ( 0.8527) Learning Rate: 0.1000 (0.1000) Top1_base: 74.2188 (75.6250) Top1_base_per_class: 75.4938 (75.4383) 
Training Epoch: [63/1000] Step: [20 / 285] Batch Time: 0.1446 (0.1909) Data Time: 0.0121 (0.0587) Average Loss: 0.8876 (0.8763) Average CE Loss (Source):  0.8876 ( 0.8763) Learning Rate: 0.1000 (0.1000) Top1_base: 73.4375 (75.0391) Top1_base_per_class: 74.5906 (75.3627) 
Training Epoch: [63/1000] Step: [30 / 285] Batch Time: 0.1462 (0.1802) Data Time: 0.0142 (0.0480) Average Loss: 0.7912 (0.8963) Average CE Loss (Source):  0.7912 ( 0.8963) Learning Rate: 0.1000 (0.1000) Top1_base: 81.2500 (74.6875) Top1_base_per_class: 84.9730 (75.1397) 
Training Epoch: [63/1000] Step: [40 / 285] Batch Time: 0.1460 (0.1738) Data Time: 0.0145 (0.0413) Average Loss: 0.8227 (0.8967) Average CE Loss (Source):  0.8227 ( 0.8967) Learning Rate: 0.1000 (0.1000) Top1_base: 75.0000 (74.8828) Top1_base_per_class: 73.2680 (75.2388) 
Training Epoch: [63/1000] Step: [50 / 285] Batch Time: 0.2023 (0.1730) Data Time: 0.0715 (0.0403) Average Loss: 0.9001 (0.9049) Average CE Loss (Source):  0.9001 ( 0.9049) Learning Rate: 0.1000 (0.1000) Top1_base: 77.3438 (74.7344) Top1_base_per_class: 82.3899 (75.1629) 
Training Epoch: [63/1000] Step: [60 / 285] Batch Time: 0.1469 (0.1696) Data Time: 0.0147 (0.0368) Average Loss: 1.0039 (0.8980) Average CE Loss (Source):  1.0039 ( 0.8980) Learning Rate: 0.1000 (0.1000) Top1_base: 70.3125 (74.7786) Top1_base_per_class: 74.7126 (75.4971) 
Training Epoch: [63/1000] Step: [70 / 285] Batch Time: 0.2343 (0.1679) Data Time: 0.1039 (0.0351) Average Loss: 0.8512 (0.8951) Average CE Loss (Source):  0.8512 ( 0.8951) Learning Rate: 0.1000 (0.1000) Top1_base: 73.4375 (74.8438) Top1_base_per_class: 70.4762 (75.4611) 
Training Epoch: [63/1000] Step: [80 / 285] Batch Time: 0.1477 (0.1663) Data Time: 0.0147 (0.0334) Average Loss: 0.8768 (0.8905) Average CE Loss (Source):  0.8768 ( 0.8905) Learning Rate: 0.1000 (0.1000) Top1_base: 78.1250 (74.9707) Top1_base_per_class: 79.2373 (75.5325) 
Training Epoch: [63/1000] Step: [90 / 285] Batch Time: 0.1505 (0.1659) Data Time: 0.0189 (0.0329) Average Loss: 0.8745 (0.8881) Average CE Loss (Source):  0.8745 ( 0.8881) Learning Rate: 0.1000 (0.1000) Top1_base: 78.9062 (75.1389) Top1_base_per_class: 76.5476 (75.7876) 
Training Epoch: [63/1000] Step: [100 / 285] Batch Time: 0.1464 (0.1652) Data Time: 0.0138 (0.0322) Average Loss: 0.8545 (0.8925) Average CE Loss (Source):  0.8545 ( 0.8925) Learning Rate: 0.1000 (0.1000) Top1_base: 79.6875 (75.0859) Top1_base_per_class: 80.6250 (75.6202) 
Training Epoch: [63/1000] Step: [110 / 285] Batch Time: 0.1513 (0.1642) Data Time: 0.0196 (0.0312) Average Loss: 0.8500 (0.8905) Average CE Loss (Source):  0.8500 ( 0.8905) Learning Rate: 0.1000 (0.1000) Top1_base: 77.3438 (75.2202) Top1_base_per_class: 83.9286 (75.6757) 
Training Epoch: [63/1000] Step: [120 / 285] Batch Time: 0.1457 (0.1629) Data Time: 0.0124 (0.0299) Average Loss: 1.0004 (0.8879) Average CE Loss (Source):  1.0004 ( 0.8879) Learning Rate: 0.1000 (0.1000) Top1_base: 68.7500 (75.1693) Top1_base_per_class: 67.3545 (75.6752) 
Training Epoch: [63/1000] Step: [130 / 285] Batch Time: 0.1820 (0.1629) Data Time: 0.0494 (0.0299) Average Loss: 0.8697 (0.8830) Average CE Loss (Source):  0.8697 ( 0.8830) Learning Rate: 0.1000 (0.1000) Top1_base: 73.4375 (75.2224) Top1_base_per_class: 76.6082 (75.7869) 
Training Epoch: [63/1000] Step: [140 / 285] Batch Time: 0.1456 (0.1618) Data Time: 0.0137 (0.0287) Average Loss: 0.8845 (0.8806) Average CE Loss (Source):  0.8845 ( 0.8806) Learning Rate: 0.1000 (0.1000) Top1_base: 78.9062 (75.3460) Top1_base_per_class: 78.5802 (75.9247) 
Training Epoch: [63/1000] Step: [150 / 285] Batch Time: 0.2253 (0.1617) Data Time: 0.0924 (0.0286) Average Loss: 0.5720 (0.8813) Average CE Loss (Source):  0.5720 ( 0.8813) Learning Rate: 0.1000 (0.1000) Top1_base: 86.7188 (75.3698) Top1_base_per_class: 85.9295 (75.9167) 
Training Epoch: [63/1000] Step: [160 / 285] Batch Time: 0.1486 (0.1615) Data Time: 0.0153 (0.0284) Average Loss: 0.8328 (0.8846) Average CE Loss (Source):  0.8328 ( 0.8846) Learning Rate: 0.1000 (0.1000) Top1_base: 79.6875 (75.2246) Top1_base_per_class: 83.1151 (75.7352) 
Training Epoch: [63/1000] Step: [170 / 285] Batch Time: 0.1504 (0.1609) Data Time: 0.0178 (0.0278) Average Loss: 0.9002 (0.8894) Average CE Loss (Source):  0.9002 ( 0.8894) Learning Rate: 0.1000 (0.1000) Top1_base: 71.8750 (75.0735) Top1_base_per_class: 71.3256 (75.5856) 
Training Epoch: [63/1000] Step: [180 / 285] Batch Time: 0.1471 (0.1606) Data Time: 0.0146 (0.0274) Average Loss: 0.8328 (0.8932) Average CE Loss (Source):  0.8328 ( 0.8932) Learning Rate: 0.1000 (0.1000) Top1_base: 76.5625 (74.9479) Top1_base_per_class: 74.3750 (75.4363) 
Training Epoch: [63/1000] Step: [190 / 285] Batch Time: 0.1491 (0.1609) Data Time: 0.0164 (0.0278) Average Loss: 0.9261 (0.8978) Average CE Loss (Source):  0.9261 ( 0.8978) Learning Rate: 0.1000 (0.1000) Top1_base: 72.6562 (74.7656) Top1_base_per_class: 73.5802 (75.2899) 
Training Epoch: [63/1000] Step: [200 / 285] Batch Time: 0.1460 (0.1603) Data Time: 0.0122 (0.0272) Average Loss: 1.0207 (0.9019) Average CE Loss (Source):  1.0207 ( 0.9019) Learning Rate: 0.1000 (0.1000) Top1_base: 71.8750 (74.6602) Top1_base_per_class: 71.4368 (75.1522) 
Training Epoch: [63/1000] Step: [210 / 285] Batch Time: 0.1497 (0.1601) Data Time: 0.0180 (0.0270) Average Loss: 1.0633 (0.9018) Average CE Loss (Source):  1.0633 ( 0.9018) Learning Rate: 0.1000 (0.1000) Top1_base: 66.4062 (74.6094) Top1_base_per_class: 67.5321 (75.0176) 
Training Epoch: [63/1000] Step: [220 / 285] Batch Time: 0.1413 (0.1596) Data Time: 0.0110 (0.0266) Average Loss: 0.9823 (0.9036) Average CE Loss (Source):  0.9823 ( 0.9036) Learning Rate: 0.1000 (0.1000) Top1_base: 71.8750 (74.5632) Top1_base_per_class: 70.8490 (74.9645) 
Training Epoch: [63/1000] Step: [230 / 285] Batch Time: 0.1482 (0.1590) Data Time: 0.0148 (0.0260) Average Loss: 0.8285 (0.9019) Average CE Loss (Source):  0.8285 ( 0.9019) Learning Rate: 0.1000 (0.1000) Top1_base: 79.6875 (74.6773) Top1_base_per_class: 81.5278 (75.1123) 
Training Epoch: [63/1000] Step: [240 / 285] Batch Time: 0.1494 (0.1584) Data Time: 0.0166 (0.0255) Average Loss: 0.9472 (0.9038) Average CE Loss (Source):  0.9472 ( 0.9038) Learning Rate: 0.1000 (0.1000) Top1_base: 75.0000 (74.6582) Top1_base_per_class: 78.4242 (75.1914) 
Training Epoch: [63/1000] Step: [250 / 285] Batch Time: 0.1482 (0.1580) Data Time: 0.0153 (0.0251) Average Loss: 0.9188 (0.9039) Average CE Loss (Source):  0.9188 ( 0.9039) Learning Rate: 0.1000 (0.1000) Top1_base: 74.2188 (74.6344) Top1_base_per_class: 73.8272 (75.1591) 
Training Epoch: [63/1000] Step: [260 / 285] Batch Time: 0.1484 (0.1578) Data Time: 0.0145 (0.0248) Average Loss: 1.0672 (0.9083) Average CE Loss (Source):  1.0672 ( 0.9083) Learning Rate: 0.1000 (0.1000) Top1_base: 70.3125 (74.5162) Top1_base_per_class: 73.4503 (75.0568) 
Training Epoch: [63/1000] Step: [270 / 285] Batch Time: 0.1480 (0.1575) Data Time: 0.0166 (0.0246) Average Loss: 1.0170 (0.9124) Average CE Loss (Source):  1.0170 ( 0.9124) Learning Rate: 0.1000 (0.1000) Top1_base: 71.8750 (74.4358) Top1_base_per_class: 74.6667 (74.9869) 
Training Epoch: [63/1000] Step: [280 / 285] Batch Time: 0.2027 (0.1577) Data Time: 0.0707 (0.0248) Average Loss: 1.1289 (0.9123) Average CE Loss (Source):  1.1289 ( 0.9123) Learning Rate: 0.1000 (0.1000) Top1_base: 74.2188 (74.4615) Top1_base_per_class: 74.0303 (74.9581) 
Training Epoch: [64/1000] Step: [0] Batch Time: 0.1427 (0.1575) Data Time: 0.0103 (0.0245) Average Loss: 0.6768 (0.9116) Average CE Loss (Source):  0.6768 ( 0.9116) Learning Rate: 0.1000 (0.1000) Top1_base: 79.6875 (74.5011) Top1_base_per_class: 81.1782 (75.0316) 
  6%|▋         | 64/1000 [50:25<12:13:08, 47.00s/it]  6%|▋         | 65/1000 [51:10<12:02:42, 46.38s/it]Training Epoch: [64/1000] Step: [10 / 285] Batch Time: 0.1551 (0.2405) Data Time: 0.0167 (0.1056) Average Loss: 0.8402 (0.8555) Average CE Loss (Source):  0.8402 ( 0.8555) Learning Rate: 0.1000 (0.1000) Top1_base: 73.4375 (75.7812) Top1_base_per_class: 74.1342 (75.3718) 
Training Epoch: [64/1000] Step: [20 / 285] Batch Time: 0.1484 (0.1985) Data Time: 0.0142 (0.0625) Average Loss: 0.8837 (0.8460) Average CE Loss (Source):  0.8837 ( 0.8460) Learning Rate: 0.1000 (0.1000) Top1_base: 74.2188 (75.8984) Top1_base_per_class: 76.6061 (76.1093) 
Training Epoch: [64/1000] Step: [30 / 285] Batch Time: 0.1545 (0.1846) Data Time: 0.0140 (0.0482) Average Loss: 0.6751 (0.8460) Average CE Loss (Source):  0.6751 ( 0.8460) Learning Rate: 0.1000 (0.1000) Top1_base: 81.2500 (76.4583) Top1_base_per_class: 79.0303 (76.9041) 
Training Epoch: [64/1000] Step: [40 / 285] Batch Time: 0.1499 (0.1778) Data Time: 0.0158 (0.0413) Average Loss: 0.8401 (0.8579) Average CE Loss (Source):  0.8401 ( 0.8579) Learning Rate: 0.1000 (0.1000) Top1_base: 75.0000 (75.8789) Top1_base_per_class: 74.3217 (76.4006) 
Training Epoch: [64/1000] Step: [50 / 285] Batch Time: 0.1539 (0.1730) Data Time: 0.0140 (0.0364) Average Loss: 1.1917 (0.8698) Average CE Loss (Source):  1.1917 ( 0.8698) Learning Rate: 0.1000 (0.1000) Top1_base: 67.9688 (75.6250) Top1_base_per_class: 69.7126 (76.1549) 
Training Epoch: [64/1000] Step: [60 / 285] Batch Time: 0.1472 (0.1695) Data Time: 0.0133 (0.0329) Average Loss: 0.8511 (0.8728) Average CE Loss (Source):  0.8511 ( 0.8728) Learning Rate: 0.1000 (0.1000) Top1_base: 71.8750 (75.5469) Top1_base_per_class: 70.1743 (76.0915) 
Training Epoch: [64/1000] Step: [70 / 285] Batch Time: 0.1523 (0.1669) Data Time: 0.0174 (0.0303) Average Loss: 1.2201 (0.8757) Average CE Loss (Source):  1.2201 ( 0.8757) Learning Rate: 0.1000 (0.1000) Top1_base: 63.2812 (75.4911) Top1_base_per_class: 63.9667 (76.3636) 
Training Epoch: [64/1000] Step: [80 / 285] Batch Time: 0.1507 (0.1648) Data Time: 0.0174 (0.0285) Average Loss: 0.8898 (0.8867) Average CE Loss (Source):  0.8898 ( 0.8867) Learning Rate: 0.1000 (0.1000) Top1_base: 76.5625 (75.2734) Top1_base_per_class: 79.9383 (76.2086) 
Training Epoch: [64/1000] Step: [90 / 285] Batch Time: 0.1538 (0.1631) Data Time: 0.0185 (0.0270) Average Loss: 0.8595 (0.8890) Average CE Loss (Source):  0.8595 ( 0.8890) Learning Rate: 0.1000 (0.1000) Top1_base: 78.9062 (75.2604) Top1_base_per_class: 80.4630 (76.2048) 
Training Epoch: [64/1000] Step: [100 / 285] Batch Time: 0.1468 (0.1620) Data Time: 0.0140 (0.0259) Average Loss: 0.8603 (0.8897) Average CE Loss (Source):  0.8603 ( 0.8897) Learning Rate: 0.1000 (0.1000) Top1_base: 72.6562 (75.3203) Top1_base_per_class: 67.5000 (76.1985) 
Training Epoch: [64/1000] Step: [110 / 285] Batch Time: 0.1566 (0.1609) Data Time: 0.0202 (0.0249) Average Loss: 0.8121 (0.8946) Average CE Loss (Source):  0.8121 ( 0.8946) Learning Rate: 0.1000 (0.1000) Top1_base: 78.1250 (75.3267) Top1_base_per_class: 81.3691 (76.1895) 
Training Epoch: [64/1000] Step: [120 / 285] Batch Time: 0.1472 (0.1599) Data Time: 0.0154 (0.0240) Average Loss: 1.0193 (0.9011) Average CE Loss (Source):  1.0193 ( 0.9011) Learning Rate: 0.1000 (0.1000) Top1_base: 69.5312 (75.0846) Top1_base_per_class: 68.8182 (75.8336) 
Training Epoch: [64/1000] Step: [130 / 285] Batch Time: 0.1566 (0.1593) Data Time: 0.0194 (0.0234) Average Loss: 0.8473 (0.9070) Average CE Loss (Source):  0.8473 ( 0.9070) Learning Rate: 0.1000 (0.1000) Top1_base: 73.4375 (74.8978) Top1_base_per_class: 73.7202 (75.6205) 
Training Epoch: [64/1000] Step: [140 / 285] Batch Time: 0.1434 (0.1589) Data Time: 0.0129 (0.0230) Average Loss: 0.8006 (0.9066) Average CE Loss (Source):  0.8006 ( 0.9066) Learning Rate: 0.1000 (0.1000) Top1_base: 78.1250 (74.8717) Top1_base_per_class: 77.5758 (75.5488) 
Training Epoch: [64/1000] Step: [150 / 285] Batch Time: 0.1525 (0.1583) Data Time: 0.0173 (0.0224) Average Loss: 1.0359 (0.9042) Average CE Loss (Source):  1.0359 ( 0.9042) Learning Rate: 0.1000 (0.1000) Top1_base: 75.0000 (74.8542) Top1_base_per_class: 71.9811 (75.5681) 
Training Epoch: [64/1000] Step: [160 / 285] Batch Time: 0.1454 (0.1588) Data Time: 0.0117 (0.0232) Average Loss: 0.8718 (0.9036) Average CE Loss (Source):  0.8718 ( 0.9036) Learning Rate: 0.1000 (0.1000) Top1_base: 72.6562 (74.8584) Top1_base_per_class: 74.3910 (75.5689) 
Training Epoch: [64/1000] Step: [170 / 285] Batch Time: 0.1515 (0.1591) Data Time: 0.0172 (0.0235) Average Loss: 1.0213 (0.9052) Average CE Loss (Source):  1.0213 ( 0.9052) Learning Rate: 0.1000 (0.1000) Top1_base: 74.2188 (74.8667) Top1_base_per_class: 72.8363 (75.5496) 
Training Epoch: [64/1000] Step: [180 / 285] Batch Time: 0.1430 (0.1590) Data Time: 0.0104 (0.0235) Average Loss: 1.0891 (0.9093) Average CE Loss (Source):  1.0891 ( 0.9093) Learning Rate: 0.1000 (0.1000) Top1_base: 71.8750 (74.7613) Top1_base_per_class: 71.3522 (75.4445) 
Training Epoch: [64/1000] Step: [190 / 285] Batch Time: 0.1656 (0.1594) Data Time: 0.0282 (0.0240) Average Loss: 0.6929 (0.9084) Average CE Loss (Source):  0.6929 ( 0.9084) Learning Rate: 0.1000 (0.1000) Top1_base: 78.9062 (74.7492) Top1_base_per_class: 78.3908 (75.3949) 
Training Epoch: [64/1000] Step: [200 / 285] Batch Time: 0.1429 (0.1589) Data Time: 0.0108 (0.0236) Average Loss: 0.8232 (0.9063) Average CE Loss (Source):  0.8232 ( 0.9063) Learning Rate: 0.1000 (0.1000) Top1_base: 75.0000 (74.7617) Top1_base_per_class: 68.5494 (75.3916) 
Training Epoch: [64/1000] Step: [210 / 285] Batch Time: 0.2206 (0.1590) Data Time: 0.0840 (0.0236) Average Loss: 0.8520 (0.9044) Average CE Loss (Source):  0.8520 ( 0.9044) Learning Rate: 0.1000 (0.1000) Top1_base: 72.6562 (74.8103) Top1_base_per_class: 72.9938 (75.4137) 
Training Epoch: [64/1000] Step: [220 / 285] Batch Time: 0.1488 (0.1586) Data Time: 0.0145 (0.0232) Average Loss: 0.7806 (0.9025) Average CE Loss (Source):  0.7806 ( 0.9025) Learning Rate: 0.1000 (0.1000) Top1_base: 78.9062 (74.9041) Top1_base_per_class: 80.9483 (75.4671) 
Training Epoch: [64/1000] Step: [230 / 285] Batch Time: 0.1936 (0.1586) Data Time: 0.0634 (0.0234) Average Loss: 0.9987 (0.9010) Average CE Loss (Source):  0.9987 ( 0.9010) Learning Rate: 0.1000 (0.1000) Top1_base: 75.0000 (74.8981) Top1_base_per_class: 78.0303 (75.4684) 
Training Epoch: [64/1000] Step: [240 / 285] Batch Time: 0.1472 (0.1583) Data Time: 0.0110 (0.0231) Average Loss: 0.9694 (0.9011) Average CE Loss (Source):  0.9694 ( 0.9011) Learning Rate: 0.1000 (0.1000) Top1_base: 73.4375 (74.9121) Top1_base_per_class: 71.6667 (75.4553) 
Training Epoch: [64/1000] Step: [250 / 285] Batch Time: 0.1516 (0.1579) Data Time: 0.0209 (0.0227) Average Loss: 0.7232 (0.9011) Average CE Loss (Source):  0.7232 ( 0.9011) Learning Rate: 0.1000 (0.1000) Top1_base: 75.7812 (74.8906) Top1_base_per_class: 76.2925 (75.4140) 
Training Epoch: [64/1000] Step: [260 / 285] Batch Time: 0.1465 (0.1579) Data Time: 0.0140 (0.0228) Average Loss: 0.8396 (0.9005) Average CE Loss (Source):  0.8396 ( 0.9005) Learning Rate: 0.1000 (0.1000) Top1_base: 76.5625 (74.9129) Top1_base_per_class: 75.5655 (75.3900) 
Training Epoch: [64/1000] Step: [270 / 285] Batch Time: 0.1759 (0.1580) Data Time: 0.0422 (0.0230) Average Loss: 0.8340 (0.9010) Average CE Loss (Source):  0.8340 ( 0.9010) Learning Rate: 0.1000 (0.1000) Top1_base: 74.2188 (74.8987) Top1_base_per_class: 73.7356 (75.3532) 
Training Epoch: [64/1000] Step: [280 / 285] Batch Time: 0.1467 (0.1576) Data Time: 0.0145 (0.0227) Average Loss: 1.1888 (0.9006) Average CE Loss (Source):  1.1888 ( 0.9006) Learning Rate: 0.1000 (0.1000) Top1_base: 70.3125 (74.9442) Top1_base_per_class: 70.6897 (75.4018) 
Training Epoch: [65/1000] Step: [0] Batch Time: 0.1423 (0.1574) Data Time: 0.0097 (0.0226) Average Loss: 0.7700 (0.8992) Average CE Loss (Source):  0.7700 ( 0.8992) Learning Rate: 0.1000 (0.1000) Top1_base: 77.3438 (74.9616) Top1_base_per_class: 74.5513 (75.4162) 
Training Epoch: [65/1000] Step: [10 / 285] Batch Time: 0.1449 (0.2583) Data Time: 0.0106 (0.1256) Average Loss: 0.8911 (0.8138) Average CE Loss (Source):  0.8911 ( 0.8138) Learning Rate: 0.1000 (0.1000) Top1_base: 75.7812 (77.5000) Top1_base_per_class: 76.4328 (78.0255) 
Training Epoch: [65/1000] Step: [20 / 285] Batch Time: 0.1471 (0.2106) Data Time: 0.0122 (0.0778) Average Loss: 0.6925 (0.8028) Average CE Loss (Source):  0.6925 ( 0.8028) Learning Rate: 0.1000 (0.1000) Top1_base: 79.6875 (77.1484) Top1_base_per_class: 80.7018 (77.5896) 
Training Epoch: [65/1000] Step: [30 / 285] Batch Time: 0.1468 (0.1949) Data Time: 0.0141 (0.0621) Average Loss: 0.8589 (0.8156) Average CE Loss (Source):  0.8589 ( 0.8156) Learning Rate: 0.1000 (0.1000) Top1_base: 69.5312 (77.1094) Top1_base_per_class: 70.4630 (77.0485) 
Training Epoch: [65/1000] Step: [40 / 285] Batch Time: 0.1489 (0.1844) Data Time: 0.0128 (0.0515) Average Loss: 0.6614 (0.8290) Average CE Loss (Source):  0.6614 ( 0.8290) Learning Rate: 0.1000 (0.1000) Top1_base: 82.0312 (77.4023) Top1_base_per_class: 83.0409 (77.4940) 
Training Epoch: [65/1000] Step: [50 / 285] Batch Time: 0.1457 (0.1789) Data Time: 0.0126 (0.0459) Average Loss: 0.8669 (0.8465) Average CE Loss (Source):  0.8669 ( 0.8465) Learning Rate: 0.1000 (0.1000) Top1_base: 75.7812 (77.1094) Top1_base_per_class: 76.4848 (77.4842) 
Training Epoch: [65/1000] Step: [60 / 285] Batch Time: 0.1498 (0.1752) Data Time: 0.0126 (0.0421) Average Loss: 0.9125 (0.8463) Average CE Loss (Source):  0.9125 ( 0.8463) Learning Rate: 0.1000 (0.1000) Top1_base: 70.3125 (76.9531) Top1_base_per_class: 70.2874 (77.2611) 
Training Epoch: [65/1000] Step: [70 / 285] Batch Time: 0.1468 (0.1723) Data Time: 0.0111 (0.0391) Average Loss: 0.8200 (0.8486) Average CE Loss (Source):  0.8200 ( 0.8486) Learning Rate: 0.1000 (0.1000) Top1_base: 75.0000 (76.8638) Top1_base_per_class: 74.6810 (77.2895) 
Training Epoch: [65/1000] Step: [80 / 285] Batch Time: 0.1446 (0.1703) Data Time: 0.0105 (0.0371) Average Loss: 0.8390 (0.8509) Average CE Loss (Source):  0.8390 ( 0.8509) Learning Rate: 0.1000 (0.1000) Top1_base: 74.2188 (76.6992) Top1_base_per_class: 78.8141 (77.1825) 
Training Epoch: [65/1000] Step: [90 / 285] Batch Time: 0.1463 (0.1683) Data Time: 0.0111 (0.0350) Average Loss: 0.9880 (0.8503) Average CE Loss (Source):  0.9880 ( 0.8503) Learning Rate: 0.1000 (0.1000) Top1_base: 74.2188 (76.7535) Top1_base_per_class: 76.7879 (77.3541) 
Training Epoch: [65/1000] Step: [100 / 285] Batch Time: 0.1499 (0.1668) Data Time: 0.0128 (0.0335) Average Loss: 0.9717 (0.8493) Average CE Loss (Source):  0.9717 ( 0.8493) Learning Rate: 0.1000 (0.1000) Top1_base: 69.5312 (76.8203) Top1_base_per_class: 68.8580 (77.3953) 
Training Epoch: [65/1000] Step: [110 / 285] Batch Time: 0.1449 (0.1665) Data Time: 0.0135 (0.0332) Average Loss: 1.0770 (0.8537) Average CE Loss (Source):  1.0770 ( 0.8537) Learning Rate: 0.1000 (0.1000) Top1_base: 70.3125 (76.6690) Top1_base_per_class: 74.5758 (77.1482) 
Training Epoch: [65/1000] Step: [120 / 285] Batch Time: 0.1466 (0.1652) Data Time: 0.0107 (0.0318) Average Loss: 0.8641 (0.8617) Average CE Loss (Source):  0.8641 ( 0.8617) Learning Rate: 0.1000 (0.1000) Top1_base: 70.3125 (76.3542) Top1_base_per_class: 72.5989 (76.8271) 
Training Epoch: [65/1000] Step: [130 / 285] Batch Time: 0.1470 (0.1641) Data Time: 0.0122 (0.0308) Average Loss: 0.7011 (0.8604) Average CE Loss (Source):  0.7011 ( 0.8604) Learning Rate: 0.1000 (0.1000) Top1_base: 78.1250 (76.3762) Top1_base_per_class: 77.4405 (76.8312) 
Training Epoch: [65/1000] Step: [140 / 285] Batch Time: 0.1439 (0.1629) Data Time: 0.0135 (0.0296) Average Loss: 0.8036 (0.8646) Average CE Loss (Source):  0.8036 ( 0.8646) Learning Rate: 0.1000 (0.1000) Top1_base: 78.1250 (76.2835) Top1_base_per_class: 82.6543 (76.7949) 
Training Epoch: [65/1000] Step: [150 / 285] Batch Time: 0.1468 (0.1621) Data Time: 0.0135 (0.0287) Average Loss: 0.8534 (0.8656) Average CE Loss (Source):  0.8534 ( 0.8656) Learning Rate: 0.1000 (0.1000) Top1_base: 74.2188 (76.1719) Top1_base_per_class: 68.1609 (76.6680) 
Training Epoch: [65/1000] Step: [160 / 285] Batch Time: 0.1457 (0.1616) Data Time: 0.0146 (0.0282) Average Loss: 0.8112 (0.8670) Average CE Loss (Source):  0.8112 ( 0.8670) Learning Rate: 0.1000 (0.1000) Top1_base: 82.0312 (76.1572) Top1_base_per_class: 80.7310 (76.5725) 
Training Epoch: [65/1000] Step: [170 / 285] Batch Time: 0.1476 (0.1610) Data Time: 0.0105 (0.0276) Average Loss: 0.8568 (0.8665) Average CE Loss (Source):  0.8568 ( 0.8665) Learning Rate: 0.1000 (0.1000) Top1_base: 78.1250 (76.1811) Top1_base_per_class: 77.8086 (76.5635) 
Training Epoch: [65/1000] Step: [180 / 285] Batch Time: 0.1461 (0.1605) Data Time: 0.0113 (0.0270) Average Loss: 1.0657 (0.8697) Average CE Loss (Source):  1.0657 ( 0.8697) Learning Rate: 0.1000 (0.1000) Top1_base: 67.9688 (76.0417) Top1_base_per_class: 68.3908 (76.3885) 
Training Epoch: [65/1000] Step: [190 / 285] Batch Time: 0.1466 (0.1611) Data Time: 0.0142 (0.0276) Average Loss: 1.0259 (0.8723) Average CE Loss (Source):  1.0259 ( 0.8723) Learning Rate: 0.1000 (0.1000) Top1_base: 73.4375 (75.9786) Top1_base_per_class: 70.0260 (76.3086) 
Training Epoch: [65/1000] Step: [200 / 285] Batch Time: 0.1470 (0.1609) Data Time: 0.0106 (0.0274) Average Loss: 0.9411 (0.8721) Average CE Loss (Source):  0.9411 ( 0.8721) Learning Rate: 0.1000 (0.1000) Top1_base: 73.4375 (75.9102) Top1_base_per_class: 74.6045 (76.2520) 
Training Epoch: [65/1000] Step: [210 / 285] Batch Time: 0.1458 (0.1606) Data Time: 0.0105 (0.0271) Average Loss: 0.9999 (0.8742) Average CE Loss (Source):  0.9999 ( 0.8742) Learning Rate: 0.1000 (0.1000) Top1_base: 71.8750 (75.8073) Top1_base_per_class: 76.2657 (76.1491) 
Training Epoch: [65/1000] Step: [220 / 285] Batch Time: 0.1465 (0.1601) Data Time: 0.0121 (0.0266) Average Loss: 0.7442 (0.8780) Average CE Loss (Source):  0.7442 ( 0.8780) Learning Rate: 0.1000 (0.1000) Top1_base: 81.2500 (75.7102) Top1_base_per_class: 84.3931 (76.0999) 
Training Epoch: [65/1000] Step: [230 / 285] Batch Time: 0.1486 (0.1600) Data Time: 0.0153 (0.0266) Average Loss: 0.8513 (0.8827) Average CE Loss (Source):  0.8513 ( 0.8827) Learning Rate: 0.1000 (0.1000) Top1_base: 75.7812 (75.5944) Top1_base_per_class: 75.6140 (76.0301) 
Training Epoch: [65/1000] Step: [240 / 285] Batch Time: 0.1429 (0.1595) Data Time: 0.0121 (0.0261) Average Loss: 0.8711 (0.8834) Average CE Loss (Source):  0.8711 ( 0.8834) Learning Rate: 0.1000 (0.1000) Top1_base: 73.4375 (75.5762) Top1_base_per_class: 77.3203 (76.0096) 
Training Epoch: [65/1000] Step: [250 / 285] Batch Time: 0.1449 (0.1596) Data Time: 0.0124 (0.0262) Average Loss: 0.8763 (0.8852) Average CE Loss (Source):  0.8763 ( 0.8852) Learning Rate: 0.1000 (0.1000) Top1_base: 70.3125 (75.5219) Top1_base_per_class: 74.2655 (75.9722) 
Training Epoch: [65/1000] Step: [260 / 285] Batch Time: 0.1482 (0.1600) Data Time: 0.0120 (0.0266) Average Loss: 0.9206 (0.8888) Average CE Loss (Source):  0.9206 ( 0.8888) Learning Rate: 0.1000 (0.1000) Top1_base: 75.0000 (75.4117) Top1_base_per_class: 78.5220 (75.8356) 
Training Epoch: [65/1000] Step: [270 / 285] Batch Time: 0.1464 (0.1597) Data Time: 0.0150 (0.0263) Average Loss: 1.0969 (0.8919) Average CE Loss (Source):  1.0969 ( 0.8919) Learning Rate: 0.1000 (0.1000) Top1_base: 70.3125 (75.3125) Top1_base_per_class: 71.4465 (75.7536) 
Training Epoch: [65/1000] Step: [280 / 285] Batch Time: 0.1411 (0.1598) Data Time: 0.0117 (0.0264) Average Loss: 0.8613 (0.8937) Average CE Loss (Source):  0.8613 ( 0.8937) Learning Rate: 0.1000 (0.1000) Top1_base: 75.7812 (75.2874) Top1_base_per_class: 80.0265 (75.7505) 
Training Epoch: [66/1000] Step: [0] Batch Time: 0.1433 (0.1596) Data Time: 0.0115 (0.0263) Average Loss: 0.8559 (0.8957) Average CE Loss (Source):  0.8559 ( 0.8957) Learning Rate: 0.1000 (0.1000) Top1_base: 75.7812 (75.2275) Top1_base_per_class: 79.7848 (75.7291) 
  7%|▋         | 66/1000 [51:58<12:11:01, 46.96s/it]  7%|▋         | 67/1000 [52:44<12:06:15, 46.70s/it]Training Epoch: [66/1000] Step: [10 / 285] Batch Time: 0.1448 (0.2438) Data Time: 0.0103 (0.1103) Average Loss: 0.9478 (0.8445) Average CE Loss (Source):  0.9478 ( 0.8445) Learning Rate: 0.1000 (0.1000) Top1_base: 71.8750 (76.4062) Top1_base_per_class: 76.9737 (77.0026) 
Training Epoch: [66/1000] Step: [20 / 285] Batch Time: 0.1429 (0.2001) Data Time: 0.0117 (0.0671) Average Loss: 0.8319 (0.8756) Average CE Loss (Source):  0.8319 ( 0.8756) Learning Rate: 0.1000 (0.1000) Top1_base: 77.3438 (75.3516) Top1_base_per_class: 75.9749 (75.8734) 
Training Epoch: [66/1000] Step: [30 / 285] Batch Time: 0.1431 (0.1903) Data Time: 0.0106 (0.0571) Average Loss: 0.6256 (0.8623) Average CE Loss (Source):  0.6256 ( 0.8623) Learning Rate: 0.1000 (0.1000) Top1_base: 85.1562 (75.6510) Top1_base_per_class: 86.3793 (76.5162) 
Training Epoch: [66/1000] Step: [40 / 285] Batch Time: 0.1461 (0.1854) Data Time: 0.0116 (0.0520) Average Loss: 0.9803 (0.8669) Average CE Loss (Source):  0.9803 ( 0.8669) Learning Rate: 0.1000 (0.1000) Top1_base: 74.2188 (75.5664) Top1_base_per_class: 73.6257 (76.3344) 
Training Epoch: [66/1000] Step: [50 / 285] Batch Time: 0.1477 (0.1802) Data Time: 0.0109 (0.0467) Average Loss: 0.7049 (0.8462) Average CE Loss (Source):  0.7049 ( 0.8462) Learning Rate: 0.1000 (0.1000) Top1_base: 78.9062 (76.2969) Top1_base_per_class: 81.4969 (76.9542) 
Training Epoch: [66/1000] Step: [60 / 285] Batch Time: 0.1467 (0.1769) Data Time: 0.0137 (0.0433) Average Loss: 0.8263 (0.8450) Average CE Loss (Source):  0.8263 ( 0.8450) Learning Rate: 0.1000 (0.1000) Top1_base: 75.7812 (76.3411) Top1_base_per_class: 79.2949 (77.1098) 
Training Epoch: [66/1000] Step: [70 / 285] Batch Time: 0.1450 (0.1759) Data Time: 0.0127 (0.0423) Average Loss: 0.8590 (0.8387) Average CE Loss (Source):  0.8590 ( 0.8387) Learning Rate: 0.1000 (0.1000) Top1_base: 75.7812 (76.3058) Top1_base_per_class: 77.8086 (77.0088) 
Training Epoch: [66/1000] Step: [80 / 285] Batch Time: 0.1470 (0.1738) Data Time: 0.0128 (0.0403) Average Loss: 0.8892 (0.8509) Average CE Loss (Source):  0.8892 ( 0.8509) Learning Rate: 0.1000 (0.1000) Top1_base: 77.3438 (76.0547) Top1_base_per_class: 78.7592 (76.8983) 
Training Epoch: [66/1000] Step: [90 / 285] Batch Time: 0.1463 (0.1723) Data Time: 0.0134 (0.0387) Average Loss: 0.9309 (0.8537) Average CE Loss (Source):  0.9309 ( 0.8537) Learning Rate: 0.1000 (0.1000) Top1_base: 75.0000 (76.0330) Top1_base_per_class: 75.7440 (76.8289) 
Training Epoch: [66/1000] Step: [100 / 285] Batch Time: 0.1471 (0.1703) Data Time: 0.0143 (0.0367) Average Loss: 0.9799 (0.8523) Average CE Loss (Source):  0.9799 ( 0.8523) Learning Rate: 0.1000 (0.1000) Top1_base: 71.0938 (75.9922) Top1_base_per_class: 71.2931 (76.6864) 
Training Epoch: [66/1000] Step: [110 / 285] Batch Time: 0.1448 (0.1710) Data Time: 0.0107 (0.0374) Average Loss: 1.0025 (0.8517) Average CE Loss (Source):  1.0025 ( 0.8517) Learning Rate: 0.1000 (0.1000) Top1_base: 75.0000 (76.1009) Top1_base_per_class: 79.9415 (76.8441) 
Training Epoch: [66/1000] Step: [120 / 285] Batch Time: 0.1481 (0.1703) Data Time: 0.0145 (0.0366) Average Loss: 1.1619 (0.8522) Average CE Loss (Source):  1.1619 ( 0.8522) Learning Rate: 0.1000 (0.1000) Top1_base: 69.5312 (76.1393) Top1_base_per_class: 69.7701 (76.8353) 
Training Epoch: [66/1000] Step: [130 / 285] Batch Time: 0.1462 (0.1703) Data Time: 0.0103 (0.0367) Average Loss: 0.9478 (0.8635) Average CE Loss (Source):  0.9478 ( 0.8635) Learning Rate: 0.1000 (0.1000) Top1_base: 74.2188 (75.8594) Top1_base_per_class: 74.2857 (76.4180) 
Training Epoch: [66/1000] Step: [140 / 285] Batch Time: 0.1453 (0.1687) Data Time: 0.0135 (0.0351) Average Loss: 0.9245 (0.8620) Average CE Loss (Source):  0.9245 ( 0.8620) Learning Rate: 0.1000 (0.1000) Top1_base: 70.3125 (75.8929) Top1_base_per_class: 68.4877 (76.4060) 
Training Epoch: [66/1000] Step: [150 / 285] Batch Time: 0.1430 (0.1679) Data Time: 0.0116 (0.0343) Average Loss: 0.8654 (0.8625) Average CE Loss (Source):  0.8654 ( 0.8625) Learning Rate: 0.1000 (0.1000) Top1_base: 78.9062 (75.9583) Top1_base_per_class: 78.2727 (76.4427) 
Training Epoch: [66/1000] Step: [160 / 285] Batch Time: 0.1494 (0.1673) Data Time: 0.0149 (0.0338) Average Loss: 1.0473 (0.8668) Average CE Loss (Source):  1.0473 ( 0.8668) Learning Rate: 0.1000 (0.1000) Top1_base: 67.9688 (75.8154) Top1_base_per_class: 68.2372 (76.3048) 
Training Epoch: [66/1000] Step: [170 / 285] Batch Time: 0.1498 (0.1667) Data Time: 0.0109 (0.0331) Average Loss: 0.7468 (0.8667) Average CE Loss (Source):  0.7468 ( 0.8667) Learning Rate: 0.1000 (0.1000) Top1_base: 82.8125 (75.8594) Top1_base_per_class: 84.5402 (76.3840) 
Training Epoch: [66/1000] Step: [180 / 285] Batch Time: 0.1462 (0.1661) Data Time: 0.0131 (0.0325) Average Loss: 0.8417 (0.8660) Average CE Loss (Source):  0.8417 ( 0.8660) Learning Rate: 0.1000 (0.1000) Top1_base: 73.4375 (75.8594) Top1_base_per_class: 75.0000 (76.3745) 
Training Epoch: [66/1000] Step: [190 / 285] Batch Time: 0.1462 (0.1656) Data Time: 0.0103 (0.0320) Average Loss: 0.8124 (0.8664) Average CE Loss (Source):  0.8124 ( 0.8664) Learning Rate: 0.1000 (0.1000) Top1_base: 79.6875 (75.8388) Top1_base_per_class: 81.9209 (76.3112) 
Training Epoch: [66/1000] Step: [200 / 285] Batch Time: 0.1468 (0.1648) Data Time: 0.0146 (0.0312) Average Loss: 0.8381 (0.8659) Average CE Loss (Source):  0.8381 ( 0.8659) Learning Rate: 0.1000 (0.1000) Top1_base: 73.4375 (75.8711) Top1_base_per_class: 72.1133 (76.3300) 
Training Epoch: [66/1000] Step: [210 / 285] Batch Time: 0.1464 (0.1647) Data Time: 0.0105 (0.0311) Average Loss: 0.7941 (0.8677) Average CE Loss (Source):  0.7941 ( 0.8677) Learning Rate: 0.1000 (0.1000) Top1_base: 73.4375 (75.7924) Top1_base_per_class: 74.5614 (76.2066) 
Training Epoch: [66/1000] Step: [220 / 285] Batch Time: 0.1464 (0.1639) Data Time: 0.0133 (0.0303) Average Loss: 0.9243 (0.8701) Average CE Loss (Source):  0.9243 ( 0.8701) Learning Rate: 0.1000 (0.1000) Top1_base: 73.4375 (75.7564) Top1_base_per_class: 71.0819 (76.1461) 
Training Epoch: [66/1000] Step: [230 / 285] Batch Time: 0.1472 (0.1635) Data Time: 0.0122 (0.0300) Average Loss: 1.1466 (0.8755) Average CE Loss (Source):  1.1466 ( 0.8755) Learning Rate: 0.1000 (0.1000) Top1_base: 61.7188 (75.5740) Top1_base_per_class: 61.2579 (75.9774) 
Training Epoch: [66/1000] Step: [240 / 285] Batch Time: 0.1482 (0.1632) Data Time: 0.0141 (0.0296) Average Loss: 0.6905 (0.8768) Average CE Loss (Source):  0.6905 ( 0.8768) Learning Rate: 0.1000 (0.1000) Top1_base: 82.8125 (75.5566) Top1_base_per_class: 80.5357 (75.9510) 
Training Epoch: [66/1000] Step: [250 / 285] Batch Time: 0.1507 (0.1627) Data Time: 0.0130 (0.0292) Average Loss: 0.9849 (0.8775) Average CE Loss (Source):  0.9849 ( 0.8775) Learning Rate: 0.1000 (0.1000) Top1_base: 75.0000 (75.5438) Top1_base_per_class: 75.9877 (75.9204) 
Training Epoch: [66/1000] Step: [260 / 285] Batch Time: 0.1530 (0.1623) Data Time: 0.0168 (0.0286) Average Loss: 0.7785 (0.8810) Average CE Loss (Source):  0.7785 ( 0.8810) Learning Rate: 0.1000 (0.1000) Top1_base: 78.1250 (75.4357) Top1_base_per_class: 77.3977 (75.8337) 
Training Epoch: [66/1000] Step: [270 / 285] Batch Time: 0.1487 (0.1619) Data Time: 0.0107 (0.0281) Average Loss: 0.9256 (0.8817) Average CE Loss (Source):  0.9256 ( 0.8817) Learning Rate: 0.1000 (0.1000) Top1_base: 71.0938 (75.3443) Top1_base_per_class: 74.8765 (75.7859) 
Training Epoch: [66/1000] Step: [280 / 285] Batch Time: 0.1506 (0.1615) Data Time: 0.0155 (0.0276) Average Loss: 0.9874 (0.8816) Average CE Loss (Source):  0.9874 ( 0.8816) Learning Rate: 0.1000 (0.1000) Top1_base: 77.3438 (75.3571) Top1_base_per_class: 77.0115 (75.7926) 
Training Epoch: [67/1000] Step: [0] Batch Time: 0.1652 (0.1616) Data Time: 0.0347 (0.0277) Average Loss: 0.8043 (0.8819) Average CE Loss (Source):  0.8043 ( 0.8819) Learning Rate: 0.1000 (0.1000) Top1_base: 75.0000 (75.3317) Top1_base_per_class: 74.3644 (75.7831) 
Training Epoch: [67/1000] Step: [10 / 285] Batch Time: 0.1494 (0.2487) Data Time: 0.0143 (0.1146) Average Loss: 0.8320 (0.8240) Average CE Loss (Source):  0.8320 ( 0.8240) Learning Rate: 0.1000 (0.1000) Top1_base: 76.5625 (77.3438) Top1_base_per_class: 78.5556 (79.0952) 
Training Epoch: [67/1000] Step: [20 / 285] Batch Time: 0.1472 (0.2041) Data Time: 0.0132 (0.0704) Average Loss: 1.0397 (0.8502) Average CE Loss (Source):  1.0397 ( 0.8502) Learning Rate: 0.1000 (0.1000) Top1_base: 70.3125 (76.5625) Top1_base_per_class: 66.9643 (77.4485) 
Training Epoch: [67/1000] Step: [30 / 285] Batch Time: 0.1494 (0.1871) Data Time: 0.0148 (0.0533) Average Loss: 1.0489 (0.8493) Average CE Loss (Source):  1.0489 ( 0.8493) Learning Rate: 0.1000 (0.1000) Top1_base: 73.4375 (76.5625) Top1_base_per_class: 75.2381 (77.6726) 
Training Epoch: [67/1000] Step: [40 / 285] Batch Time: 0.1430 (0.1804) Data Time: 0.0107 (0.0466) Average Loss: 0.9426 (0.8547) Average CE Loss (Source):  0.9426 ( 0.8547) Learning Rate: 0.1000 (0.1000) Top1_base: 74.2188 (76.4258) Top1_base_per_class: 75.8772 (77.5622) 
Training Epoch: [67/1000] Step: [50 / 285] Batch Time: 0.1533 (0.1753) Data Time: 0.0157 (0.0412) Average Loss: 0.8754 (0.8607) Average CE Loss (Source):  0.8754 ( 0.8607) Learning Rate: 0.1000 (0.1000) Top1_base: 78.1250 (76.3594) Top1_base_per_class: 78.2716 (77.1899) 
Training Epoch: [67/1000] Step: [60 / 285] Batch Time: 0.1490 (0.1714) Data Time: 0.0150 (0.0369) Average Loss: 0.9270 (0.8645) Average CE Loss (Source):  0.9270 ( 0.8645) Learning Rate: 0.1000 (0.1000) Top1_base: 77.3438 (76.2500) Top1_base_per_class: 78.3616 (77.0948) 
Training Epoch: [67/1000] Step: [70 / 285] Batch Time: 0.1514 (0.1696) Data Time: 0.0146 (0.0351) Average Loss: 1.0552 (0.8693) Average CE Loss (Source):  1.0552 ( 0.8693) Learning Rate: 0.1000 (0.1000) Top1_base: 71.0938 (76.1719) Top1_base_per_class: 74.0260 (77.0256) 
Training Epoch: [67/1000] Step: [80 / 285] Batch Time: 0.2406 (0.1689) Data Time: 0.1095 (0.0344) Average Loss: 1.0856 (0.8761) Average CE Loss (Source):  1.0856 ( 0.8761) Learning Rate: 0.1000 (0.1000) Top1_base: 69.5312 (76.0742) Top1_base_per_class: 68.4906 (76.7320) 
Training Epoch: [67/1000] Step: [90 / 285] Batch Time: 0.1460 (0.1667) Data Time: 0.0127 (0.0322) Average Loss: 0.8911 (0.8735) Average CE Loss (Source):  0.8911 ( 0.8735) Learning Rate: 0.1000 (0.1000) Top1_base: 72.6562 (76.0503) Top1_base_per_class: 74.0385 (76.7346) 
Training Epoch: [67/1000] Step: [100 / 285] Batch Time: 0.1795 (0.1661) Data Time: 0.0457 (0.0315) Average Loss: 0.6575 (0.8644) Average CE Loss (Source):  0.6575 ( 0.8644) Learning Rate: 0.1000 (0.1000) Top1_base: 79.6875 (76.3750) Top1_base_per_class: 82.2727 (77.0338) 
Training Epoch: [67/1000] Step: [110 / 285] Batch Time: 0.1446 (0.1654) Data Time: 0.0111 (0.0308) Average Loss: 0.7232 (0.8624) Average CE Loss (Source):  0.7232 ( 0.8624) Learning Rate: 0.1000 (0.1000) Top1_base: 79.6875 (76.3565) Top1_base_per_class: 79.7175 (76.9275) 
Training Epoch: [67/1000] Step: [120 / 285] Batch Time: 0.1939 (0.1647) Data Time: 0.0610 (0.0302) Average Loss: 0.8368 (0.8673) Average CE Loss (Source):  0.8368 ( 0.8673) Learning Rate: 0.1000 (0.1000) Top1_base: 75.7812 (76.2826) Top1_base_per_class: 76.5000 (76.8968) 
Training Epoch: [67/1000] Step: [130 / 285] Batch Time: 0.1444 (0.1639) Data Time: 0.0130 (0.0295) Average Loss: 0.7681 (0.8656) Average CE Loss (Source):  0.7681 ( 0.8656) Learning Rate: 0.1000 (0.1000) Top1_base: 78.9062 (76.2740) Top1_base_per_class: 79.2767 (76.8959) 
Training Epoch: [67/1000] Step: [140 / 285] Batch Time: 0.2429 (0.1639) Data Time: 0.1113 (0.0296) Average Loss: 1.0562 (0.8694) Average CE Loss (Source):  1.0562 ( 0.8694) Learning Rate: 0.1000 (0.1000) Top1_base: 73.4375 (76.1775) Top1_base_per_class: 69.2076 (76.7306) 
Training Epoch: [67/1000] Step: [150 / 285] Batch Time: 0.1444 (0.1628) Data Time: 0.0130 (0.0286) Average Loss: 1.0828 (0.8719) Average CE Loss (Source):  1.0828 ( 0.8719) Learning Rate: 0.1000 (0.1000) Top1_base: 67.1875 (76.1458) Top1_base_per_class: 71.1988 (76.6656) 
Training Epoch: [67/1000] Step: [160 / 285] Batch Time: 0.2507 (0.1630) Data Time: 0.1187 (0.0287) Average Loss: 1.0320 (0.8724) Average CE Loss (Source):  1.0320 ( 0.8724) Learning Rate: 0.1000 (0.1000) Top1_base: 73.4375 (76.1670) Top1_base_per_class: 75.5059 (76.7076) 
Training Epoch: [67/1000] Step: [170 / 285] Batch Time: 0.1488 (0.1630) Data Time: 0.0152 (0.0287) Average Loss: 0.8844 (0.8713) Average CE Loss (Source):  0.8844 ( 0.8713) Learning Rate: 0.1000 (0.1000) Top1_base: 77.3438 (76.1903) Top1_base_per_class: 77.0909 (76.7475) 
Training Epoch: [67/1000] Step: [180 / 285] Batch Time: 0.3729 (0.1635) Data Time: 0.2421 (0.0293) Average Loss: 0.8679 (0.8730) Average CE Loss (Source):  0.8679 ( 0.8730) Learning Rate: 0.1000 (0.1000) Top1_base: 71.8750 (76.1024) Top1_base_per_class: 74.7321 (76.6087) 
Training Epoch: [67/1000] Step: [190 / 285] Batch Time: 0.1504 (0.1631) Data Time: 0.0158 (0.0290) Average Loss: 1.1950 (0.8748) Average CE Loss (Source):  1.1950 ( 0.8748) Learning Rate: 0.1000 (0.1000) Top1_base: 67.1875 (76.0814) Top1_base_per_class: 69.1521 (76.6318) 
Training Epoch: [67/1000] Step: [200 / 285] Batch Time: 0.2229 (0.1638) Data Time: 0.0919 (0.0297) Average Loss: 0.8336 (0.8769) Average CE Loss (Source):  0.8336 ( 0.8769) Learning Rate: 0.1000 (0.1000) Top1_base: 73.4375 (75.9688) Top1_base_per_class: 74.0606 (76.4916) 
Training Epoch: [67/1000] Step: [210 / 285] Batch Time: 0.1486 (0.1632) Data Time: 0.0153 (0.0291) Average Loss: 1.0547 (0.8786) Average CE Loss (Source):  1.0547 ( 0.8786) Learning Rate: 0.1000 (0.1000) Top1_base: 71.0938 (75.8631) Top1_base_per_class: 74.3544 (76.3958) 
Training Epoch: [67/1000] Step: [220 / 285] Batch Time: 0.1854 (0.1628) Data Time: 0.0525 (0.0286) Average Loss: 0.7390 (0.8794) Average CE Loss (Source):  0.7390 ( 0.8794) Learning Rate: 0.1000 (0.1000) Top1_base: 75.7812 (75.7812) Top1_base_per_class: 79.0643 (76.2779) 
Training Epoch: [67/1000] Step: [230 / 285] Batch Time: 0.1425 (0.1622) Data Time: 0.0127 (0.0281) Average Loss: 0.7886 (0.8801) Average CE Loss (Source):  0.7886 ( 0.8801) Learning Rate: 0.1000 (0.1000) Top1_base: 76.5625 (75.7914) Top1_base_per_class: 75.9877 (76.3079) 
Training Epoch: [67/1000] Step: [240 / 285] Batch Time: 0.2703 (0.1623) Data Time: 0.1387 (0.0282) Average Loss: 0.9018 (0.8818) Average CE Loss (Source):  0.9018 ( 0.8818) Learning Rate: 0.1000 (0.1000) Top1_base: 78.1250 (75.7910) Top1_base_per_class: 79.5062 (76.2438) 
Training Epoch: [67/1000] Step: [250 / 285] Batch Time: 0.1524 (0.1618) Data Time: 0.0166 (0.0277) Average Loss: 1.2868 (0.8826) Average CE Loss (Source):  1.2868 ( 0.8826) Learning Rate: 0.1000 (0.1000) Top1_base: 63.2812 (75.7812) Top1_base_per_class: 64.4828 (76.2080) 
Training Epoch: [67/1000] Step: [260 / 285] Batch Time: 0.1470 (0.1613) Data Time: 0.0167 (0.0272) Average Loss: 0.9289 (0.8843) Average CE Loss (Source):  0.9289 ( 0.8843) Learning Rate: 0.1000 (0.1000) Top1_base: 78.1250 (75.7452) Top1_base_per_class: 77.9100 (76.1788) 
Training Epoch: [67/1000] Step: [270 / 285] Batch Time: 0.1440 (0.1608) Data Time: 0.0129 (0.0267) Average Loss: 0.7800 (0.8851) Average CE Loss (Source):  0.7800 ( 0.8851) Learning Rate: 0.1000 (0.1000) Top1_base: 75.7812 (75.7031) Top1_base_per_class: 76.6667 (76.1544) 
Training Epoch: [67/1000] Step: [280 / 285] Batch Time: 0.1499 (0.1604) Data Time: 0.0179 (0.0263) Average Loss: 0.8069 (0.8820) Average CE Loss (Source):  0.8069 ( 0.8820) Learning Rate: 0.1000 (0.1000) Top1_base: 79.6875 (75.7533) Top1_base_per_class: 77.1212 (76.2015) 
Training Epoch: [68/1000] Step: [0] Batch Time: 0.1464 (0.1601) Data Time: 0.0105 (0.0260) Average Loss: 0.9435 (0.8836) Average CE Loss (Source):  0.9435 ( 0.8836) Learning Rate: 0.1000 (0.1000) Top1_base: 75.7812 (75.7045) Top1_base_per_class: 73.0702 (76.1504) 
  7%|▋         | 68/1000 [53:33<12:13:30, 47.22s/it]  7%|▋         | 69/1000 [54:18<12:02:31, 46.56s/it]Training Epoch: [68/1000] Step: [10 / 285] Batch Time: 0.1438 (0.2418) Data Time: 0.0109 (0.1089) Average Loss: 0.6989 (0.8292) Average CE Loss (Source):  0.6989 ( 0.8292) Learning Rate: 0.1000 (0.1000) Top1_base: 78.1250 (76.4062) Top1_base_per_class: 79.4182 (76.2022) 
Training Epoch: [68/1000] Step: [20 / 285] Batch Time: 0.1531 (0.2071) Data Time: 0.0185 (0.0735) Average Loss: 0.7655 (0.8449) Average CE Loss (Source):  0.7655 ( 0.8449) Learning Rate: 0.1000 (0.1000) Top1_base: 82.8125 (76.7969) Top1_base_per_class: 83.2184 (76.6464) 
Training Epoch: [68/1000] Step: [30 / 285] Batch Time: 0.1426 (0.1894) Data Time: 0.0106 (0.0559) Average Loss: 0.8546 (0.8533) Average CE Loss (Source):  0.8546 ( 0.8533) Learning Rate: 0.1000 (0.1000) Top1_base: 78.1250 (76.4583) Top1_base_per_class: 76.8210 (76.7098) 
Training Epoch: [68/1000] Step: [40 / 285] Batch Time: 0.1532 (0.1802) Data Time: 0.0160 (0.0465) Average Loss: 0.9245 (0.8468) Average CE Loss (Source):  0.9245 ( 0.8468) Learning Rate: 0.1000 (0.1000) Top1_base: 72.6562 (76.2109) Top1_base_per_class: 75.2554 (76.5954) 
Training Epoch: [68/1000] Step: [50 / 285] Batch Time: 0.1470 (0.1741) Data Time: 0.0123 (0.0403) Average Loss: 0.7985 (0.8449) Average CE Loss (Source):  0.7985 ( 0.8449) Learning Rate: 0.1000 (0.1000) Top1_base: 78.1250 (76.2812) Top1_base_per_class: 78.2738 (76.5562) 
Training Epoch: [68/1000] Step: [60 / 285] Batch Time: 0.1487 (0.1712) Data Time: 0.0161 (0.0376) Average Loss: 1.1334 (0.8472) Average CE Loss (Source):  1.1334 ( 0.8472) Learning Rate: 0.1000 (0.1000) Top1_base: 69.5312 (76.1198) Top1_base_per_class: 72.2727 (76.3824) 
Training Epoch: [68/1000] Step: [70 / 285] Batch Time: 0.1442 (0.1681) Data Time: 0.0105 (0.0345) Average Loss: 1.1030 (0.8515) Average CE Loss (Source):  1.1030 ( 0.8515) Learning Rate: 0.1000 (0.1000) Top1_base: 75.0000 (76.1496) Top1_base_per_class: 77.0057 (76.4614) 
Training Epoch: [68/1000] Step: [80 / 285] Batch Time: 0.1481 (0.1662) Data Time: 0.0147 (0.0326) Average Loss: 0.7775 (0.8567) Average CE Loss (Source):  0.7775 ( 0.8567) Learning Rate: 0.1000 (0.1000) Top1_base: 83.5938 (76.0156) Top1_base_per_class: 84.3750 (76.1727) 
Training Epoch: [68/1000] Step: [90 / 285] Batch Time: 0.1434 (0.1652) Data Time: 0.0107 (0.0316) Average Loss: 0.9375 (0.8560) Average CE Loss (Source):  0.9375 ( 0.8560) Learning Rate: 0.1000 (0.1000) Top1_base: 70.3125 (76.0851) Top1_base_per_class: 70.8485 (76.2989) 
Training Epoch: [68/1000] Step: [100 / 285] Batch Time: 0.1447 (0.1649) Data Time: 0.0115 (0.0312) Average Loss: 0.7866 (0.8605) Average CE Loss (Source):  0.7866 ( 0.8605) Learning Rate: 0.1000 (0.1000) Top1_base: 74.2188 (75.9219) Top1_base_per_class: 69.6045 (76.1259) 
Training Epoch: [68/1000] Step: [110 / 285] Batch Time: 0.1459 (0.1636) Data Time: 0.0118 (0.0298) Average Loss: 0.7033 (0.8606) Average CE Loss (Source):  0.7033 ( 0.8606) Learning Rate: 0.1000 (0.1000) Top1_base: 79.6875 (76.0227) Top1_base_per_class: 81.5094 (76.2780) 
Training Epoch: [68/1000] Step: [120 / 285] Batch Time: 0.1516 (0.1623) Data Time: 0.0151 (0.0286) Average Loss: 0.7697 (0.8599) Average CE Loss (Source):  0.7697 ( 0.8599) Learning Rate: 0.1000 (0.1000) Top1_base: 82.8125 (75.9701) Top1_base_per_class: 85.2047 (76.2201) 
Training Epoch: [68/1000] Step: [130 / 285] Batch Time: 0.1457 (0.1624) Data Time: 0.0119 (0.0288) Average Loss: 0.8088 (0.8594) Average CE Loss (Source):  0.8088 ( 0.8594) Learning Rate: 0.1000 (0.1000) Top1_base: 78.1250 (76.0276) Top1_base_per_class: 80.1852 (76.3626) 
Training Epoch: [68/1000] Step: [140 / 285] Batch Time: 0.1449 (0.1614) Data Time: 0.0115 (0.0278) Average Loss: 0.8250 (0.8589) Average CE Loss (Source):  0.8250 ( 0.8589) Learning Rate: 0.1000 (0.1000) Top1_base: 78.1250 (76.0379) Top1_base_per_class: 75.6061 (76.4361) 
Training Epoch: [68/1000] Step: [150 / 285] Batch Time: 0.1462 (0.1618) Data Time: 0.0119 (0.0282) Average Loss: 0.7160 (0.8611) Average CE Loss (Source):  0.7160 ( 0.8611) Learning Rate: 0.1000 (0.1000) Top1_base: 80.4688 (75.9896) Top1_base_per_class: 80.9649 (76.4131) 
Training Epoch: [68/1000] Step: [160 / 285] Batch Time: 0.1490 (0.1609) Data Time: 0.0152 (0.0274) Average Loss: 1.0279 (0.8632) Average CE Loss (Source):  1.0279 ( 0.8632) Learning Rate: 0.1000 (0.1000) Top1_base: 70.3125 (75.8789) Top1_base_per_class: 69.5238 (76.2839) 
Training Epoch: [68/1000] Step: [170 / 285] Batch Time: 0.1425 (0.1601) Data Time: 0.0104 (0.0266) Average Loss: 0.9063 (0.8634) Average CE Loss (Source):  0.9063 ( 0.8634) Learning Rate: 0.1000 (0.1000) Top1_base: 69.5312 (75.8824) Top1_base_per_class: 72.6840 (76.3532) 
Training Epoch: [68/1000] Step: [180 / 285] Batch Time: 0.1530 (0.1599) Data Time: 0.0165 (0.0263) Average Loss: 0.8421 (0.8664) Average CE Loss (Source):  0.8421 ( 0.8664) Learning Rate: 0.1000 (0.1000) Top1_base: 76.5625 (75.7899) Top1_base_per_class: 73.7719 (76.2540) 
Training Epoch: [68/1000] Step: [190 / 285] Batch Time: 0.1468 (0.1597) Data Time: 0.0141 (0.0262) Average Loss: 0.9491 (0.8662) Average CE Loss (Source):  0.9491 ( 0.8662) Learning Rate: 0.1000 (0.1000) Top1_base: 68.7500 (75.7895) Top1_base_per_class: 68.2184 (76.2379) 
Training Epoch: [68/1000] Step: [200 / 285] Batch Time: 0.1474 (0.1591) Data Time: 0.0144 (0.0255) Average Loss: 0.8540 (0.8672) Average CE Loss (Source):  0.8540 ( 0.8672) Learning Rate: 0.1000 (0.1000) Top1_base: 75.0000 (75.7305) Top1_base_per_class: 77.3589 (76.1740) 
Training Epoch: [68/1000] Step: [210 / 285] Batch Time: 0.1436 (0.1586) Data Time: 0.0102 (0.0250) Average Loss: 0.8032 (0.8695) Average CE Loss (Source):  0.8032 ( 0.8695) Learning Rate: 0.1000 (0.1000) Top1_base: 72.6562 (75.6101) Top1_base_per_class: 71.7229 (76.0601) 
Training Epoch: [68/1000] Step: [220 / 285] Batch Time: 0.1482 (0.1583) Data Time: 0.0153 (0.0246) Average Loss: 0.8100 (0.8699) Average CE Loss (Source):  0.8100 ( 0.8699) Learning Rate: 0.1000 (0.1000) Top1_base: 78.1250 (75.6179) Top1_base_per_class: 76.9674 (76.0779) 
Training Epoch: [68/1000] Step: [230 / 285] Batch Time: 0.1467 (0.1580) Data Time: 0.0120 (0.0243) Average Loss: 0.9878 (0.8712) Average CE Loss (Source):  0.9878 ( 0.8712) Learning Rate: 0.1000 (0.1000) Top1_base: 72.6562 (75.5367) Top1_base_per_class: 72.5000 (75.9523) 
Training Epoch: [68/1000] Step: [240 / 285] Batch Time: 0.1484 (0.1576) Data Time: 0.0137 (0.0240) Average Loss: 0.8947 (0.8732) Average CE Loss (Source):  0.8947 ( 0.8732) Learning Rate: 0.1000 (0.1000) Top1_base: 74.2188 (75.5208) Top1_base_per_class: 71.7797 (75.9183) 
Training Epoch: [68/1000] Step: [250 / 285] Batch Time: 0.1459 (0.1576) Data Time: 0.0122 (0.0239) Average Loss: 0.9375 (0.8751) Average CE Loss (Source):  0.9375 ( 0.8751) Learning Rate: 0.1000 (0.1000) Top1_base: 74.2188 (75.4531) Top1_base_per_class: 72.9167 (75.8680) 
Training Epoch: [68/1000] Step: [260 / 285] Batch Time: 0.1531 (0.1578) Data Time: 0.0160 (0.0242) Average Loss: 0.8510 (0.8777) Average CE Loss (Source):  0.8510 ( 0.8777) Learning Rate: 0.1000 (0.1000) Top1_base: 79.6875 (75.3816) Top1_base_per_class: 78.0609 (75.7533) 
Training Epoch: [68/1000] Step: [270 / 285] Batch Time: 0.1460 (0.1580) Data Time: 0.0141 (0.0243) Average Loss: 0.6874 (0.8793) Average CE Loss (Source):  0.6874 ( 0.8793) Learning Rate: 0.1000 (0.1000) Top1_base: 82.0312 (75.3617) Top1_base_per_class: 81.8954 (75.7387) 
Training Epoch: [68/1000] Step: [280 / 285] Batch Time: 0.1496 (0.1577) Data Time: 0.0134 (0.0241) Average Loss: 0.9944 (0.8813) Average CE Loss (Source):  0.9944 ( 0.8813) Learning Rate: 0.1000 (0.1000) Top1_base: 75.0000 (75.3516) Top1_base_per_class: 75.0575 (75.7074) 
Training Epoch: [69/1000] Step: [0] Batch Time: 0.2147 (0.1578) Data Time: 0.0826 (0.0242) Average Loss: 0.9318 (0.8822) Average CE Loss (Source):  0.9318 ( 0.8822) Learning Rate: 0.1000 (0.1000) Top1_base: 76.5625 (75.3509) Top1_base_per_class: 72.0402 (75.7041) 
Training Epoch: [69/1000] Step: [10 / 285] Batch Time: 0.1440 (0.2287) Data Time: 0.0122 (0.0962) Average Loss: 0.8761 (0.7822) Average CE Loss (Source):  0.8761 ( 0.7822) Learning Rate: 0.1000 (0.1000) Top1_base: 79.6875 (78.6719) Top1_base_per_class: 83.3036 (79.5781) 
Training Epoch: [69/1000] Step: [20 / 285] Batch Time: 0.1478 (0.1890) Data Time: 0.0122 (0.0559) Average Loss: 0.7937 (0.8056) Average CE Loss (Source):  0.7937 ( 0.8056) Learning Rate: 0.1000 (0.1000) Top1_base: 79.6875 (78.2422) Top1_base_per_class: 84.5238 (79.4452) 
Training Epoch: [69/1000] Step: [30 / 285] Batch Time: 0.1834 (0.1770) Data Time: 0.0516 (0.0442) Average Loss: 0.6868 (0.8028) Average CE Loss (Source):  0.6868 ( 0.8028) Learning Rate: 0.1000 (0.1000) Top1_base: 78.1250 (77.7344) Top1_base_per_class: 77.4545 (78.3410) 
Training Epoch: [69/1000] Step: [40 / 285] Batch Time: 0.1518 (0.1710) Data Time: 0.0135 (0.0380) Average Loss: 0.9074 (0.8183) Average CE Loss (Source):  0.9074 ( 0.8183) Learning Rate: 0.1000 (0.1000) Top1_base: 78.1250 (77.2266) Top1_base_per_class: 75.0862 (77.6428) 
Training Epoch: [69/1000] Step: [50 / 285] Batch Time: 0.1479 (0.1687) Data Time: 0.0148 (0.0358) Average Loss: 0.9176 (0.8357) Average CE Loss (Source):  0.9176 ( 0.8357) Learning Rate: 0.1000 (0.1000) Top1_base: 75.0000 (76.4531) Top1_base_per_class: 75.4762 (76.9313) 
Training Epoch: [69/1000] Step: [60 / 285] Batch Time: 0.1476 (0.1657) Data Time: 0.0141 (0.0326) Average Loss: 1.0398 (0.8368) Average CE Loss (Source):  1.0398 ( 0.8368) Learning Rate: 0.1000 (0.1000) Top1_base: 73.4375 (76.5755) Top1_base_per_class: 77.0370 (77.2222) 
Training Epoch: [69/1000] Step: [70 / 285] Batch Time: 0.1467 (0.1643) Data Time: 0.0148 (0.0311) Average Loss: 0.7326 (0.8394) Average CE Loss (Source):  0.7326 ( 0.8394) Learning Rate: 0.1000 (0.1000) Top1_base: 78.1250 (76.7076) Top1_base_per_class: 77.6235 (77.2776) 
Training Epoch: [69/1000] Step: [80 / 285] Batch Time: 0.1475 (0.1636) Data Time: 0.0120 (0.0302) Average Loss: 0.8986 (0.8442) Average CE Loss (Source):  0.8986 ( 0.8442) Learning Rate: 0.1000 (0.1000) Top1_base: 75.0000 (76.5137) Top1_base_per_class: 76.0494 (76.9395) 
Training Epoch: [69/1000] Step: [90 / 285] Batch Time: 0.1593 (0.1628) Data Time: 0.0251 (0.0294) Average Loss: 0.7085 (0.8397) Average CE Loss (Source):  0.7085 ( 0.8397) Learning Rate: 0.1000 (0.1000) Top1_base: 79.6875 (76.5799) Top1_base_per_class: 74.0454 (76.8754) 
Training Epoch: [69/1000] Step: [100 / 285] Batch Time: 0.1465 (0.1618) Data Time: 0.0136 (0.0284) Average Loss: 1.0509 (0.8327) Average CE Loss (Source):  1.0509 ( 0.8327) Learning Rate: 0.1000 (0.1000) Top1_base: 72.6562 (76.8203) Top1_base_per_class: 71.4931 (77.0479) 
Training Epoch: [69/1000] Step: [110 / 285] Batch Time: 0.2753 (0.1623) Data Time: 0.1429 (0.0289) Average Loss: 1.0536 (0.8398) Average CE Loss (Source):  1.0536 ( 0.8398) Learning Rate: 0.1000 (0.1000) Top1_base: 71.8750 (76.5980) Top1_base_per_class: 73.4821 (76.8243) 
Training Epoch: [69/1000] Step: [120 / 285] Batch Time: 0.1466 (0.1613) Data Time: 0.0112 (0.0279) Average Loss: 0.6637 (0.8472) Average CE Loss (Source):  0.6637 ( 0.8472) Learning Rate: 0.1000 (0.1000) Top1_base: 78.9062 (76.3867) Top1_base_per_class: 78.3036 (76.6474) 
Training Epoch: [69/1000] Step: [130 / 285] Batch Time: 0.1691 (0.1614) Data Time: 0.0375 (0.0280) Average Loss: 0.7868 (0.8470) Average CE Loss (Source):  0.7868 ( 0.8470) Learning Rate: 0.1000 (0.1000) Top1_base: 78.9062 (76.3341) Top1_base_per_class: 77.7778 (76.5887) 
Training Epoch: [69/1000] Step: [140 / 285] Batch Time: 0.1454 (0.1606) Data Time: 0.0133 (0.0273) Average Loss: 0.6439 (0.8449) Average CE Loss (Source):  0.6439 ( 0.8449) Learning Rate: 0.1000 (0.1000) Top1_base: 80.4688 (76.3393) Top1_base_per_class: 79.7879 (76.5627) 
Training Epoch: [69/1000] Step: [150 / 285] Batch Time: 0.1527 (0.1606) Data Time: 0.0191 (0.0271) Average Loss: 1.1230 (0.8451) Average CE Loss (Source):  1.1230 ( 0.8451) Learning Rate: 0.1000 (0.1000) Top1_base: 67.1875 (76.2865) Top1_base_per_class: 68.8580 (76.5118) 
Training Epoch: [69/1000] Step: [160 / 285] Batch Time: 0.1512 (0.1599) Data Time: 0.0124 (0.0263) Average Loss: 1.0196 (0.8504) Average CE Loss (Source):  1.0196 ( 0.8504) Learning Rate: 0.1000 (0.1000) Top1_base: 64.8438 (76.0938) Top1_base_per_class: 62.8968 (76.2554) 
Training Epoch: [69/1000] Step: [170 / 285] Batch Time: 0.1478 (0.1591) Data Time: 0.0159 (0.0255) Average Loss: 0.9971 (0.8535) Average CE Loss (Source):  0.9971 ( 0.8535) Learning Rate: 0.1000 (0.1000) Top1_base: 69.5312 (75.9007) Top1_base_per_class: 71.2424 (76.1183) 
Training Epoch: [69/1000] Step: [180 / 285] Batch Time: 0.1504 (0.1587) Data Time: 0.0130 (0.0251) Average Loss: 0.8359 (0.8546) Average CE Loss (Source):  0.8359 ( 0.8546) Learning Rate: 0.1000 (0.1000) Top1_base: 75.7812 (75.8637) Top1_base_per_class: 75.2083 (76.1011) 
Training Epoch: [69/1000] Step: [190 / 285] Batch Time: 0.1590 (0.1587) Data Time: 0.0243 (0.0250) Average Loss: 1.1890 (0.8595) Average CE Loss (Source):  1.1890 ( 0.8595) Learning Rate: 0.1000 (0.1000) Top1_base: 67.9688 (75.7319) Top1_base_per_class: 64.2815 (75.9413) 
Training Epoch: [69/1000] Step: [200 / 285] Batch Time: 0.1453 (0.1581) Data Time: 0.0104 (0.0244) Average Loss: 0.8239 (0.8620) Average CE Loss (Source):  0.8239 ( 0.8620) Learning Rate: 0.1000 (0.1000) Top1_base: 77.3438 (75.7188) Top1_base_per_class: 76.8379 (75.9290) 
Training Epoch: [69/1000] Step: [210 / 285] Batch Time: 0.2737 (0.1582) Data Time: 0.1420 (0.0245) Average Loss: 1.0022 (0.8636) Average CE Loss (Source):  1.0022 ( 0.8636) Learning Rate: 0.1000 (0.1000) Top1_base: 74.2188 (75.7292) Top1_base_per_class: 74.2593 (75.9758) 
Training Epoch: [69/1000] Step: [220 / 285] Batch Time: 0.1457 (0.1580) Data Time: 0.0111 (0.0243) Average Loss: 0.9055 (0.8681) Average CE Loss (Source):  0.9055 ( 0.8681) Learning Rate: 0.1000 (0.1000) Top1_base: 72.6562 (75.6001) Top1_base_per_class: 72.6730 (75.7763) 
Training Epoch: [69/1000] Step: [230 / 285] Batch Time: 0.2522 (0.1583) Data Time: 0.1211 (0.0246) Average Loss: 0.9631 (0.8690) Average CE Loss (Source):  0.9631 ( 0.8690) Learning Rate: 0.1000 (0.1000) Top1_base: 71.8750 (75.5537) Top1_base_per_class: 69.9074 (75.6796) 
Training Epoch: [69/1000] Step: [240 / 285] Batch Time: 0.1429 (0.1579) Data Time: 0.0124 (0.0243) Average Loss: 0.8977 (0.8686) Average CE Loss (Source):  0.8977 ( 0.8686) Learning Rate: 0.1000 (0.1000) Top1_base: 78.1250 (75.5469) Top1_base_per_class: 76.6970 (75.6705) 
Training Epoch: [69/1000] Step: [250 / 285] Batch Time: 0.1857 (0.1581) Data Time: 0.0524 (0.0246) Average Loss: 0.8178 (0.8692) Average CE Loss (Source):  0.8178 ( 0.8692) Learning Rate: 0.1000 (0.1000) Top1_base: 81.2500 (75.5906) Top1_base_per_class: 82.6515 (75.7068) 
Training Epoch: [69/1000] Step: [260 / 285] Batch Time: 0.1424 (0.1581) Data Time: 0.0113 (0.0246) Average Loss: 0.8463 (0.8717) Average CE Loss (Source):  0.8463 ( 0.8717) Learning Rate: 0.1000 (0.1000) Top1_base: 77.3438 (75.5078) Top1_base_per_class: 74.6384 (75.6407) 
Training Epoch: [69/1000] Step: [270 / 285] Batch Time: 0.1645 (0.1581) Data Time: 0.0315 (0.0247) Average Loss: 0.9764 (0.8734) Average CE Loss (Source):  0.9764 ( 0.8734) Learning Rate: 0.1000 (0.1000) Top1_base: 69.5312 (75.4774) Top1_base_per_class: 70.6790 (75.6223) 
Training Epoch: [69/1000] Step: [280 / 285] Batch Time: 0.1423 (0.1578) Data Time: 0.0113 (0.0244) Average Loss: 0.8186 (0.8731) Average CE Loss (Source):  0.8186 ( 0.8731) Learning Rate: 0.1000 (0.1000) Top1_base: 75.0000 (75.4799) Top1_base_per_class: 73.3631 (75.5890) 
Training Epoch: [70/1000] Step: [0] Batch Time: 0.1433 (0.1575) Data Time: 0.0118 (0.0242) Average Loss: 1.2050 (0.8743) Average CE Loss (Source):  1.2050 ( 0.8743) Learning Rate: 0.1000 (0.1000) Top1_base: 67.9688 (75.4441) Top1_base_per_class: 71.4626 (75.5314) 
  7%|▋         | 70/1000 [55:05<12:07:29, 46.93s/it]  7%|▋         | 71/1000 [55:51<12:02:41, 46.68s/it]Training Epoch: [70/1000] Step: [10 / 285] Batch Time: 0.1434 (0.2419) Data Time: 0.0114 (0.1093) Average Loss: 0.8914 (0.8497) Average CE Loss (Source):  0.8914 ( 0.8497) Learning Rate: 0.1000 (0.1000) Top1_base: 75.0000 (76.2500) Top1_base_per_class: 75.2874 (75.7956) 
Training Epoch: [70/1000] Step: [20 / 285] Batch Time: 0.1469 (0.2030) Data Time: 0.0114 (0.0701) Average Loss: 0.9478 (0.8473) Average CE Loss (Source):  0.9478 ( 0.8473) Learning Rate: 0.1000 (0.1000) Top1_base: 71.8750 (75.8984) Top1_base_per_class: 76.9856 (76.0254) 
Training Epoch: [70/1000] Step: [30 / 285] Batch Time: 0.1443 (0.1945) Data Time: 0.0119 (0.0616) Average Loss: 0.8876 (0.8532) Average CE Loss (Source):  0.8876 ( 0.8532) Learning Rate: 0.1000 (0.1000) Top1_base: 78.1250 (75.9635) Top1_base_per_class: 77.1605 (75.8555) 
Training Epoch: [70/1000] Step: [40 / 285] Batch Time: 0.1435 (0.1844) Data Time: 0.0122 (0.0518) Average Loss: 0.7253 (0.8492) Average CE Loss (Source):  0.7253 ( 0.8492) Learning Rate: 0.1000 (0.1000) Top1_base: 79.6875 (76.2109) Top1_base_per_class: 81.2037 (76.3580) 
Training Epoch: [70/1000] Step: [50 / 285] Batch Time: 0.1441 (0.1793) Data Time: 0.0116 (0.0470) Average Loss: 0.7504 (0.8585) Average CE Loss (Source):  0.7504 ( 0.8585) Learning Rate: 0.1000 (0.1000) Top1_base: 81.2500 (76.0000) Top1_base_per_class: 81.6667 (76.2587) 
Training Epoch: [70/1000] Step: [60 / 285] Batch Time: 0.1537 (0.1748) Data Time: 0.0136 (0.0422) Average Loss: 0.7464 (0.8506) Average CE Loss (Source):  0.7464 ( 0.8506) Learning Rate: 0.1000 (0.1000) Top1_base: 82.8125 (76.3672) Top1_base_per_class: 83.6782 (76.7137) 
Training Epoch: [70/1000] Step: [70 / 285] Batch Time: 0.1431 (0.1741) Data Time: 0.0106 (0.0412) Average Loss: 0.8536 (0.8526) Average CE Loss (Source):  0.8536 ( 0.8526) Learning Rate: 0.1000 (0.1000) Top1_base: 74.2188 (76.3281) Top1_base_per_class: 73.5119 (76.7348) 
Training Epoch: [70/1000] Step: [80 / 285] Batch Time: 0.1416 (0.1714) Data Time: 0.0119 (0.0387) Average Loss: 0.7207 (0.8603) Average CE Loss (Source):  0.7207 ( 0.8603) Learning Rate: 0.1000 (0.1000) Top1_base: 78.9062 (76.1426) Top1_base_per_class: 84.0018 (76.4336) 
Training Epoch: [70/1000] Step: [90 / 285] Batch Time: 0.1437 (0.1702) Data Time: 0.0115 (0.0376) Average Loss: 1.0322 (0.8663) Average CE Loss (Source):  1.0322 ( 0.8663) Learning Rate: 0.1000 (0.1000) Top1_base: 72.6562 (75.9288) Top1_base_per_class: 75.7848 (76.2173) 
Training Epoch: [70/1000] Step: [100 / 285] Batch Time: 0.1415 (0.1689) Data Time: 0.0121 (0.0363) Average Loss: 0.7942 (0.8674) Average CE Loss (Source):  0.7942 ( 0.8674) Learning Rate: 0.1000 (0.1000) Top1_base: 78.9062 (75.8750) Top1_base_per_class: 78.9233 (76.2491) 
Training Epoch: [70/1000] Step: [110 / 285] Batch Time: 0.1421 (0.1688) Data Time: 0.0111 (0.0362) Average Loss: 0.8971 (0.8672) Average CE Loss (Source):  0.8971 ( 0.8672) Learning Rate: 0.1000 (0.1000) Top1_base: 76.5625 (75.8310) Top1_base_per_class: 77.4074 (76.2293) 
Training Epoch: [70/1000] Step: [120 / 285] Batch Time: 0.1500 (0.1677) Data Time: 0.0136 (0.0349) Average Loss: 1.1370 (0.8665) Average CE Loss (Source):  1.1370 ( 0.8665) Learning Rate: 0.1000 (0.1000) Top1_base: 71.8750 (75.8529) Top1_base_per_class: 74.8870 (76.3044) 
Training Epoch: [70/1000] Step: [130 / 285] Batch Time: 0.1438 (0.1671) Data Time: 0.0109 (0.0342) Average Loss: 0.9492 (0.8669) Average CE Loss (Source):  0.9492 ( 0.8669) Learning Rate: 0.1000 (0.1000) Top1_base: 71.8750 (75.8534) Top1_base_per_class: 75.6364 (76.3688) 
Training Epoch: [70/1000] Step: [140 / 285] Batch Time: 0.1514 (0.1662) Data Time: 0.0156 (0.0331) Average Loss: 1.0339 (0.8669) Average CE Loss (Source):  1.0339 ( 0.8669) Learning Rate: 0.1000 (0.1000) Top1_base: 72.6562 (75.9542) Top1_base_per_class: 75.3390 (76.4794) 
Training Epoch: [70/1000] Step: [150 / 285] Batch Time: 0.1434 (0.1662) Data Time: 0.0107 (0.0331) Average Loss: 0.7886 (0.8699) Average CE Loss (Source):  0.7886 ( 0.8699) Learning Rate: 0.1000 (0.1000) Top1_base: 78.1250 (75.9167) Top1_base_per_class: 80.2168 (76.4588) 
Training Epoch: [70/1000] Step: [160 / 285] Batch Time: 0.1434 (0.1656) Data Time: 0.0128 (0.0324) Average Loss: 0.8670 (0.8709) Average CE Loss (Source):  0.8670 ( 0.8709) Learning Rate: 0.1000 (0.1000) Top1_base: 75.7812 (75.8984) Top1_base_per_class: 74.9394 (76.4115) 
Training Epoch: [70/1000] Step: [170 / 285] Batch Time: 0.1466 (0.1657) Data Time: 0.0128 (0.0326) Average Loss: 0.7296 (0.8700) Average CE Loss (Source):  0.7296 ( 0.8700) Learning Rate: 0.1000 (0.1000) Top1_base: 77.3438 (75.9329) Top1_base_per_class: 78.6550 (76.5272) 
Training Epoch: [70/1000] Step: [180 / 285] Batch Time: 0.1500 (0.1649) Data Time: 0.0152 (0.0318) Average Loss: 1.0096 (0.8707) Average CE Loss (Source):  1.0096 ( 0.8707) Learning Rate: 0.1000 (0.1000) Top1_base: 68.7500 (75.9332) Top1_base_per_class: 71.5900 (76.6063) 
Training Epoch: [70/1000] Step: [190 / 285] Batch Time: 0.1424 (0.1648) Data Time: 0.0111 (0.0318) Average Loss: 0.8550 (0.8737) Average CE Loss (Source):  0.8550 ( 0.8737) Learning Rate: 0.1000 (0.1000) Top1_base: 76.5625 (75.8553) Top1_base_per_class: 76.9253 (76.5302) 
Training Epoch: [70/1000] Step: [200 / 285] Batch Time: 0.1500 (0.1639) Data Time: 0.0142 (0.0309) Average Loss: 0.9808 (0.8765) Average CE Loss (Source):  0.9808 ( 0.8765) Learning Rate: 0.1000 (0.1000) Top1_base: 71.0938 (75.7617) Top1_base_per_class: 72.7238 (76.4568) 
Training Epoch: [70/1000] Step: [210 / 285] Batch Time: 0.1419 (0.1633) Data Time: 0.0102 (0.0302) Average Loss: 1.0955 (0.8755) Average CE Loss (Source):  1.0955 ( 0.8755) Learning Rate: 0.1000 (0.1000) Top1_base: 73.4375 (75.7738) Top1_base_per_class: 74.8538 (76.4292) 
Training Epoch: [70/1000] Step: [220 / 285] Batch Time: 0.1495 (0.1629) Data Time: 0.0150 (0.0298) Average Loss: 0.8920 (0.8749) Average CE Loss (Source):  0.8920 ( 0.8749) Learning Rate: 0.1000 (0.1000) Top1_base: 74.2188 (75.8345) Top1_base_per_class: 71.6358 (76.4833) 
Training Epoch: [70/1000] Step: [230 / 285] Batch Time: 0.1422 (0.1631) Data Time: 0.0110 (0.0300) Average Loss: 0.8663 (0.8733) Average CE Loss (Source):  0.8663 ( 0.8733) Learning Rate: 0.1000 (0.1000) Top1_base: 73.4375 (75.9001) Top1_base_per_class: 73.1482 (76.5605) 
Training Epoch: [70/1000] Step: [240 / 285] Batch Time: 0.1477 (0.1627) Data Time: 0.0134 (0.0296) Average Loss: 1.0197 (0.8764) Average CE Loss (Source):  1.0197 ( 0.8764) Learning Rate: 0.1000 (0.1000) Top1_base: 67.9688 (75.8171) Top1_base_per_class: 66.3580 (76.4421) 
Training Epoch: [70/1000] Step: [250 / 285] Batch Time: 0.1425 (0.1625) Data Time: 0.0111 (0.0294) Average Loss: 0.8915 (0.8769) Average CE Loss (Source):  0.8915 ( 0.8769) Learning Rate: 0.1000 (0.1000) Top1_base: 75.7812 (75.8000) Top1_base_per_class: 73.8002 (76.4322) 
Training Epoch: [70/1000] Step: [260 / 285] Batch Time: 0.1487 (0.1621) Data Time: 0.0148 (0.0290) Average Loss: 0.6969 (0.8768) Average CE Loss (Source):  0.6969 ( 0.8768) Learning Rate: 0.1000 (0.1000) Top1_base: 80.4688 (75.7692) Top1_base_per_class: 79.1667 (76.3992) 
Training Epoch: [70/1000] Step: [270 / 285] Batch Time: 0.1436 (0.1616) Data Time: 0.0107 (0.0285) Average Loss: 0.9070 (0.8775) Average CE Loss (Source):  0.9070 ( 0.8775) Learning Rate: 0.1000 (0.1000) Top1_base: 78.1250 (75.7639) Top1_base_per_class: 79.3590 (76.4135) 
Training Epoch: [70/1000] Step: [280 / 285] Batch Time: 0.1468 (0.1615) Data Time: 0.0118 (0.0284) Average Loss: 1.1670 (0.8772) Average CE Loss (Source):  1.1670 ( 0.8772) Learning Rate: 0.1000 (0.1000) Top1_base: 68.7500 (75.7617) Top1_base_per_class: 71.4240 (76.3843) 
Training Epoch: [71/1000] Step: [0] Batch Time: 0.2000 (0.1614) Data Time: 0.0692 (0.0284) Average Loss: 0.9670 (0.8780) Average CE Loss (Source):  0.9670 ( 0.8780) Learning Rate: 0.1000 (0.1000) Top1_base: 71.0938 (75.7319) Top1_base_per_class: 69.7151 (76.3144) 
Training Epoch: [71/1000] Step: [10 / 285] Batch Time: 0.1476 (0.2419) Data Time: 0.0128 (0.1077) Average Loss: 0.7654 (0.8329) Average CE Loss (Source):  0.7654 ( 0.8329) Learning Rate: 0.1000 (0.1000) Top1_base: 78.1250 (77.8906) Top1_base_per_class: 76.4151 (78.1399) 
Training Epoch: [71/1000] Step: [20 / 285] Batch Time: 0.1479 (0.1979) Data Time: 0.0123 (0.0639) Average Loss: 0.6001 (0.8408) Average CE Loss (Source):  0.6001 ( 0.8408) Learning Rate: 0.1000 (0.1000) Top1_base: 84.3750 (77.3828) Top1_base_per_class: 83.6364 (77.7599) 
Training Epoch: [71/1000] Step: [30 / 285] Batch Time: 0.2341 (0.1915) Data Time: 0.0979 (0.0569) Average Loss: 0.8622 (0.8488) Average CE Loss (Source):  0.8622 ( 0.8488) Learning Rate: 0.1000 (0.1000) Top1_base: 74.2188 (76.3542) Top1_base_per_class: 71.1988 (77.0547) 
Training Epoch: [71/1000] Step: [40 / 285] Batch Time: 0.1511 (0.1857) Data Time: 0.0155 (0.0511) Average Loss: 0.7694 (0.8551) Average CE Loss (Source):  0.7694 ( 0.8551) Learning Rate: 0.1000 (0.1000) Top1_base: 76.5625 (76.2891) Top1_base_per_class: 76.1818 (77.1862) 
Training Epoch: [71/1000] Step: [50 / 285] Batch Time: 0.1513 (0.1803) Data Time: 0.0178 (0.0455) Average Loss: 1.0153 (0.8533) Average CE Loss (Source):  1.0153 ( 0.8533) Learning Rate: 0.1000 (0.1000) Top1_base: 68.7500 (76.2500) Top1_base_per_class: 71.5758 (77.2658) 
Training Epoch: [71/1000] Step: [60 / 285] Batch Time: 0.1488 (0.1764) Data Time: 0.0158 (0.0418) Average Loss: 0.8344 (0.8387) Average CE Loss (Source):  0.8344 ( 0.8387) Learning Rate: 0.1000 (0.1000) Top1_base: 74.2188 (76.5365) Top1_base_per_class: 79.1228 (77.5396) 
Training Epoch: [71/1000] Step: [70 / 285] Batch Time: 0.1550 (0.1727) Data Time: 0.0176 (0.0380) Average Loss: 0.8730 (0.8340) Average CE Loss (Source):  0.8730 ( 0.8340) Learning Rate: 0.1000 (0.1000) Top1_base: 76.5625 (76.6295) Top1_base_per_class: 74.8870 (77.6489) 
Training Epoch: [71/1000] Step: [80 / 285] Batch Time: 0.1477 (0.1697) Data Time: 0.0132 (0.0351) Average Loss: 0.8172 (0.8412) Average CE Loss (Source):  0.8172 ( 0.8412) Learning Rate: 0.1000 (0.1000) Top1_base: 76.5625 (76.2988) Top1_base_per_class: 73.4211 (77.1053) 
Training Epoch: [71/1000] Step: [90 / 285] Batch Time: 0.1547 (0.1676) Data Time: 0.0195 (0.0331) Average Loss: 0.7087 (0.8465) Average CE Loss (Source):  0.7087 ( 0.8465) Learning Rate: 0.1000 (0.1000) Top1_base: 82.8125 (76.1024) Top1_base_per_class: 85.3333 (76.8531) 
Training Epoch: [71/1000] Step: [100 / 285] Batch Time: 0.1463 (0.1660) Data Time: 0.0143 (0.0316) Average Loss: 0.8309 (0.8446) Average CE Loss (Source):  0.8309 ( 0.8446) Learning Rate: 0.1000 (0.1000) Top1_base: 75.7812 (76.1953) Top1_base_per_class: 72.4545 (76.8943) 
Training Epoch: [71/1000] Step: [110 / 285] Batch Time: 0.1754 (0.1655) Data Time: 0.0448 (0.0312) Average Loss: 1.0632 (0.8492) Average CE Loss (Source):  1.0632 ( 0.8492) Learning Rate: 0.1000 (0.1000) Top1_base: 71.0938 (76.0866) Top1_base_per_class: 79.3405 (76.8437) 
Training Epoch: [71/1000] Step: [120 / 285] Batch Time: 0.1512 (0.1641) Data Time: 0.0166 (0.0298) Average Loss: 0.8500 (0.8590) Average CE Loss (Source):  0.8500 ( 0.8590) Learning Rate: 0.1000 (0.1000) Top1_base: 78.1250 (75.8789) Top1_base_per_class: 73.1818 (76.5931) 
Training Epoch: [71/1000] Step: [130 / 285] Batch Time: 0.1532 (0.1631) Data Time: 0.0187 (0.0290) Average Loss: 0.9212 (0.8595) Average CE Loss (Source):  0.9212 ( 0.8595) Learning Rate: 0.1000 (0.1000) Top1_base: 71.8750 (75.9615) Top1_base_per_class: 72.7731 (76.7278) 
Training Epoch: [71/1000] Step: [140 / 285] Batch Time: 0.1817 (0.1628) Data Time: 0.0489 (0.0286) Average Loss: 0.9429 (0.8633) Average CE Loss (Source):  0.9429 ( 0.8633) Learning Rate: 0.1000 (0.1000) Top1_base: 73.4375 (75.8315) Top1_base_per_class: 74.5029 (76.5934) 
Training Epoch: [71/1000] Step: [150 / 285] Batch Time: 0.2548 (0.1630) Data Time: 0.1233 (0.0289) Average Loss: 1.0494 (0.8665) Average CE Loss (Source):  1.0494 ( 0.8665) Learning Rate: 0.1000 (0.1000) Top1_base: 74.2188 (75.8438) Top1_base_per_class: 75.5848 (76.5701) 
Training Epoch: [71/1000] Step: [160 / 285] Batch Time: 0.1641 (0.1623) Data Time: 0.0304 (0.0283) Average Loss: 0.8177 (0.8635) Average CE Loss (Source):  0.8177 ( 0.8635) Learning Rate: 0.1000 (0.1000) Top1_base: 78.9062 (75.8691) Top1_base_per_class: 80.4082 (76.5742) 
Training Epoch: [71/1000] Step: [170 / 285] Batch Time: 0.1527 (0.1620) Data Time: 0.0188 (0.0280) Average Loss: 0.9933 (0.8634) Average CE Loss (Source):  0.9933 ( 0.8634) Learning Rate: 0.1000 (0.1000) Top1_base: 73.4375 (75.9375) Top1_base_per_class: 75.0654 (76.6193) 
Training Epoch: [71/1000] Step: [180 / 285] Batch Time: 0.1759 (0.1620) Data Time: 0.0443 (0.0280) Average Loss: 0.9262 (0.8655) Average CE Loss (Source):  0.9262 ( 0.8655) Learning Rate: 0.1000 (0.1000) Top1_base: 72.6562 (75.8941) Top1_base_per_class: 72.2662 (76.5045) 
Training Epoch: [71/1000] Step: [190 / 285] Batch Time: 0.1532 (0.1615) Data Time: 0.0172 (0.0275) Average Loss: 0.7945 (0.8685) Average CE Loss (Source):  0.7945 ( 0.8685) Learning Rate: 0.1000 (0.1000) Top1_base: 71.8750 (75.7607) Top1_base_per_class: 75.3448 (76.4194) 
Training Epoch: [71/1000] Step: [200 / 285] Batch Time: 0.1646 (0.1611) Data Time: 0.0313 (0.0271) Average Loss: 0.9328 (0.8683) Average CE Loss (Source):  0.9328 ( 0.8683) Learning Rate: 0.1000 (0.1000) Top1_base: 78.9062 (75.7773) Top1_base_per_class: 82.8655 (76.4044) 
Training Epoch: [71/1000] Step: [210 / 285] Batch Time: 0.1554 (0.1606) Data Time: 0.0169 (0.0266) Average Loss: 0.8354 (0.8698) Average CE Loss (Source):  0.8354 ( 0.8698) Learning Rate: 0.1000 (0.1000) Top1_base: 75.7812 (75.7850) Top1_base_per_class: 74.7839 (76.4174) 
Training Epoch: [71/1000] Step: [220 / 285] Batch Time: 0.2061 (0.1604) Data Time: 0.0751 (0.0264) Average Loss: 0.9770 (0.8728) Average CE Loss (Source):  0.9770 ( 0.8728) Learning Rate: 0.1000 (0.1000) Top1_base: 71.0938 (75.6925) Top1_base_per_class: 71.3945 (76.3192) 
Training Epoch: [71/1000] Step: [230 / 285] Batch Time: 0.1519 (0.1605) Data Time: 0.0141 (0.0265) Average Loss: 1.1686 (0.8737) Average CE Loss (Source):  1.1686 ( 0.8737) Learning Rate: 0.1000 (0.1000) Top1_base: 67.1875 (75.6793) Top1_base_per_class: 71.1017 (76.2842) 
Training Epoch: [71/1000] Step: [240 / 285] Batch Time: 0.1521 (0.1601) Data Time: 0.0208 (0.0261) Average Loss: 0.8175 (0.8739) Average CE Loss (Source):  0.8175 ( 0.8739) Learning Rate: 0.1000 (0.1000) Top1_base: 78.9062 (75.6543) Top1_base_per_class: 84.3580 (76.2665) 
Training Epoch: [71/1000] Step: [250 / 285] Batch Time: 0.1512 (0.1598) Data Time: 0.0152 (0.0257) Average Loss: 0.7329 (0.8722) Average CE Loss (Source):  0.7329 ( 0.8722) Learning Rate: 0.1000 (0.1000) Top1_base: 79.6875 (75.7281) Top1_base_per_class: 80.9119 (76.3276) 
Training Epoch: [71/1000] Step: [260 / 285] Batch Time: 0.1666 (0.1596) Data Time: 0.0345 (0.0256) Average Loss: 0.8699 (0.8741) Average CE Loss (Source):  0.8699 ( 0.8741) Learning Rate: 0.1000 (0.1000) Top1_base: 77.3438 (75.6911) Top1_base_per_class: 78.9623 (76.2415) 
Training Epoch: [71/1000] Step: [270 / 285] Batch Time: 0.1529 (0.1592) Data Time: 0.0154 (0.0251) Average Loss: 0.8767 (0.8746) Average CE Loss (Source):  0.8767 ( 0.8746) Learning Rate: 0.1000 (0.1000) Top1_base: 75.0000 (75.7031) Top1_base_per_class: 77.9464 (76.2634) 
Training Epoch: [71/1000] Step: [280 / 285] Batch Time: 0.1478 (0.1592) Data Time: 0.0173 (0.0252) Average Loss: 0.8718 (0.8779) Average CE Loss (Source):  0.8718 ( 0.8779) Learning Rate: 0.1000 (0.1000) Top1_base: 75.7812 (75.5971) Top1_base_per_class: 76.8086 (76.1675) 
Training Epoch: [72/1000] Step: [0] Batch Time: 0.1441 (0.1589) Data Time: 0.0104 (0.0249) Average Loss: 0.9555 (0.8789) Average CE Loss (Source):  0.9555 ( 0.8789) Learning Rate: 0.1000 (0.1000) Top1_base: 71.8750 (75.5811) Top1_base_per_class: 75.7372 (76.1778) 
  7%|▋         | 72/1000 [56:40<12:08:21, 47.09s/it]  7%|▋         | 73/1000 [57:24<11:57:16, 46.43s/it]Training Epoch: [72/1000] Step: [10 / 285] Batch Time: 0.1456 (0.2313) Data Time: 0.0147 (0.0990) Average Loss: 0.9770 (0.8132) Average CE Loss (Source):  0.9770 ( 0.8132) Learning Rate: 0.1000 (0.1000) Top1_base: 71.0938 (76.8750) Top1_base_per_class: 71.9182 (78.5509) 
Training Epoch: [72/1000] Step: [20 / 285] Batch Time: 0.1526 (0.1956) Data Time: 0.0138 (0.0627) Average Loss: 0.9381 (0.8418) Average CE Loss (Source):  0.9381 ( 0.8418) Learning Rate: 0.1000 (0.1000) Top1_base: 73.4375 (76.3672) Top1_base_per_class: 69.9702 (77.3388) 
Training Epoch: [72/1000] Step: [30 / 285] Batch Time: 0.1473 (0.1804) Data Time: 0.0154 (0.0468) Average Loss: 0.8270 (0.8454) Average CE Loss (Source):  0.8270 ( 0.8454) Learning Rate: 0.1000 (0.1000) Top1_base: 78.9062 (76.3021) Top1_base_per_class: 76.7794 (76.5521) 
Training Epoch: [72/1000] Step: [40 / 285] Batch Time: 0.1484 (0.1726) Data Time: 0.0150 (0.0391) Average Loss: 0.7200 (0.8376) Average CE Loss (Source):  0.7200 ( 0.8376) Learning Rate: 0.1000 (0.1000) Top1_base: 79.6875 (76.5430) Top1_base_per_class: 75.1923 (76.6151) 
Training Epoch: [72/1000] Step: [50 / 285] Batch Time: 0.1488 (0.1684) Data Time: 0.0147 (0.0348) Average Loss: 0.8010 (0.8334) Average CE Loss (Source):  0.8010 ( 0.8334) Learning Rate: 0.1000 (0.1000) Top1_base: 79.6875 (76.7969) Top1_base_per_class: 77.8395 (77.0213) 
Training Epoch: [72/1000] Step: [60 / 285] Batch Time: 0.1516 (0.1655) Data Time: 0.0122 (0.0315) Average Loss: 0.8303 (0.8291) Average CE Loss (Source):  0.8303 ( 0.8291) Learning Rate: 0.1000 (0.1000) Top1_base: 75.7812 (76.9531) Top1_base_per_class: 79.2157 (77.3161) 
Training Epoch: [72/1000] Step: [70 / 285] Batch Time: 0.1487 (0.1633) Data Time: 0.0161 (0.0292) Average Loss: 0.8212 (0.8361) Average CE Loss (Source):  0.8212 ( 0.8361) Learning Rate: 0.1000 (0.1000) Top1_base: 76.5625 (76.7746) Top1_base_per_class: 77.2381 (77.2488) 
Training Epoch: [72/1000] Step: [80 / 285] Batch Time: 0.1487 (0.1616) Data Time: 0.0122 (0.0276) Average Loss: 0.9061 (0.8393) Average CE Loss (Source):  0.9061 ( 0.8393) Learning Rate: 0.1000 (0.1000) Top1_base: 74.2188 (76.6992) Top1_base_per_class: 72.9091 (77.2424) 
Training Epoch: [72/1000] Step: [90 / 285] Batch Time: 0.1474 (0.1605) Data Time: 0.0150 (0.0265) Average Loss: 0.8718 (0.8462) Average CE Loss (Source):  0.8718 ( 0.8462) Learning Rate: 0.1000 (0.1000) Top1_base: 74.2188 (76.4670) Top1_base_per_class: 73.6364 (76.9366) 
Training Epoch: [72/1000] Step: [100 / 285] Batch Time: 0.1491 (0.1601) Data Time: 0.0136 (0.0262) Average Loss: 0.6339 (0.8472) Average CE Loss (Source):  0.6339 ( 0.8472) Learning Rate: 0.1000 (0.1000) Top1_base: 80.4688 (76.4453) Top1_base_per_class: 74.5029 (76.8749) 
Training Epoch: [72/1000] Step: [110 / 285] Batch Time: 0.1505 (0.1597) Data Time: 0.0176 (0.0258) Average Loss: 0.8453 (0.8467) Average CE Loss (Source):  0.8453 ( 0.8467) Learning Rate: 0.1000 (0.1000) Top1_base: 75.7812 (76.3352) Top1_base_per_class: 80.2041 (76.8963) 
Training Epoch: [72/1000] Step: [120 / 285] Batch Time: 0.1518 (0.1599) Data Time: 0.0203 (0.0260) Average Loss: 0.9167 (0.8416) Average CE Loss (Source):  0.9167 ( 0.8416) Learning Rate: 0.1000 (0.1000) Top1_base: 75.7812 (76.4388) Top1_base_per_class: 74.8214 (76.9471) 
Training Epoch: [72/1000] Step: [130 / 285] Batch Time: 0.1524 (0.1596) Data Time: 0.0194 (0.0256) Average Loss: 0.8611 (0.8406) Average CE Loss (Source):  0.8611 ( 0.8406) Learning Rate: 0.1000 (0.1000) Top1_base: 78.9062 (76.5024) Top1_base_per_class: 78.6859 (77.0176) 
Training Epoch: [72/1000] Step: [140 / 285] Batch Time: 0.1484 (0.1596) Data Time: 0.0118 (0.0256) Average Loss: 0.9944 (0.8467) Average CE Loss (Source):  0.9944 ( 0.8467) Learning Rate: 0.1000 (0.1000) Top1_base: 77.3438 (76.4230) Top1_base_per_class: 79.3210 (76.9921) 
Training Epoch: [72/1000] Step: [150 / 285] Batch Time: 0.1510 (0.1595) Data Time: 0.0174 (0.0254) Average Loss: 0.7587 (0.8472) Average CE Loss (Source):  0.7587 ( 0.8472) Learning Rate: 0.1000 (0.1000) Top1_base: 77.3438 (76.4115) Top1_base_per_class: 78.2164 (76.9478) 
Training Epoch: [72/1000] Step: [160 / 285] Batch Time: 0.1463 (0.1592) Data Time: 0.0116 (0.0251) Average Loss: 0.9395 (0.8466) Average CE Loss (Source):  0.9395 ( 0.8466) Learning Rate: 0.1000 (0.1000) Top1_base: 74.2188 (76.4404) Top1_base_per_class: 73.8769 (76.9992) 
Training Epoch: [72/1000] Step: [170 / 285] Batch Time: 0.1883 (0.1592) Data Time: 0.0562 (0.0251) Average Loss: 0.6716 (0.8496) Average CE Loss (Source):  0.6716 ( 0.8496) Learning Rate: 0.1000 (0.1000) Top1_base: 82.0312 (76.3879) Top1_base_per_class: 81.2281 (77.0092) 
Training Epoch: [72/1000] Step: [180 / 285] Batch Time: 0.1473 (0.1591) Data Time: 0.0120 (0.0250) Average Loss: 0.6859 (0.8508) Average CE Loss (Source):  0.6859 ( 0.8508) Learning Rate: 0.1000 (0.1000) Top1_base: 78.9062 (76.3715) Top1_base_per_class: 79.5455 (77.0123) 
Training Epoch: [72/1000] Step: [190 / 285] Batch Time: 0.1504 (0.1592) Data Time: 0.0160 (0.0251) Average Loss: 0.8631 (0.8508) Average CE Loss (Source):  0.8631 ( 0.8508) Learning Rate: 0.1000 (0.1000) Top1_base: 77.3438 (76.3199) Top1_base_per_class: 78.2407 (76.9863) 
Training Epoch: [72/1000] Step: [200 / 285] Batch Time: 0.1483 (0.1587) Data Time: 0.0145 (0.0246) Average Loss: 1.0004 (0.8503) Average CE Loss (Source):  1.0004 ( 0.8503) Learning Rate: 0.1000 (0.1000) Top1_base: 72.6562 (76.2930) Top1_base_per_class: 73.8177 (76.9445) 
Training Epoch: [72/1000] Step: [210 / 285] Batch Time: 0.2441 (0.1587) Data Time: 0.1100 (0.0247) Average Loss: 0.8661 (0.8505) Average CE Loss (Source):  0.8661 ( 0.8505) Learning Rate: 0.1000 (0.1000) Top1_base: 75.0000 (76.2760) Top1_base_per_class: 76.2500 (76.9196) 
Training Epoch: [72/1000] Step: [220 / 285] Batch Time: 0.1505 (0.1584) Data Time: 0.0119 (0.0243) Average Loss: 0.8675 (0.8549) Average CE Loss (Source):  0.8675 ( 0.8549) Learning Rate: 0.1000 (0.1000) Top1_base: 78.1250 (76.1435) Top1_base_per_class: 78.5531 (76.7788) 
Training Epoch: [72/1000] Step: [230 / 285] Batch Time: 0.2568 (0.1586) Data Time: 0.1241 (0.0246) Average Loss: 0.9818 (0.8569) Average CE Loss (Source):  0.9818 ( 0.8569) Learning Rate: 0.1000 (0.1000) Top1_base: 77.3438 (76.0836) Top1_base_per_class: 79.1758 (76.7815) 
Training Epoch: [72/1000] Step: [240 / 285] Batch Time: 0.1485 (0.1583) Data Time: 0.0153 (0.0242) Average Loss: 0.7059 (0.8581) Average CE Loss (Source):  0.7059 ( 0.8581) Learning Rate: 0.1000 (0.1000) Top1_base: 78.9062 (76.0352) Top1_base_per_class: 81.3506 (76.7115) 
Training Epoch: [72/1000] Step: [250 / 285] Batch Time: 0.1772 (0.1579) Data Time: 0.0451 (0.0239) Average Loss: 1.1205 (0.8601) Average CE Loss (Source):  1.1205 ( 0.8601) Learning Rate: 0.1000 (0.1000) Top1_base: 67.1875 (75.9156) Top1_base_per_class: 73.3951 (76.6372) 
Training Epoch: [72/1000] Step: [260 / 285] Batch Time: 0.1499 (0.1579) Data Time: 0.0157 (0.0240) Average Loss: 1.0632 (0.8635) Average CE Loss (Source):  1.0632 ( 0.8635) Learning Rate: 0.1000 (0.1000) Top1_base: 75.7812 (75.8383) Top1_base_per_class: 78.1845 (76.5081) 
Training Epoch: [72/1000] Step: [270 / 285] Batch Time: 0.1533 (0.1576) Data Time: 0.0185 (0.0236) Average Loss: 1.0318 (0.8668) Average CE Loss (Source):  1.0318 ( 0.8668) Learning Rate: 0.1000 (0.1000) Top1_base: 75.7812 (75.7610) Top1_base_per_class: 72.6852 (76.4313) 
Training Epoch: [72/1000] Step: [280 / 285] Batch Time: 0.1478 (0.1574) Data Time: 0.0109 (0.0233) Average Loss: 0.8010 (0.8688) Average CE Loss (Source):  0.8010 ( 0.8688) Learning Rate: 0.1000 (0.1000) Top1_base: 78.9062 (75.6641) Top1_base_per_class: 77.8219 (76.3494) 
Training Epoch: [73/1000] Step: [0] Batch Time: 0.1470 (0.1572) Data Time: 0.0131 (0.0231) Average Loss: 0.8702 (0.8693) Average CE Loss (Source):  0.8702 ( 0.8693) Learning Rate: 0.1000 (0.1000) Top1_base: 76.5625 (75.6661) Top1_base_per_class: 75.1603 (76.3427) 
Training Epoch: [73/1000] Step: [10 / 285] Batch Time: 0.1526 (0.2316) Data Time: 0.0154 (0.0957) Average Loss: 0.9892 (0.8994) Average CE Loss (Source):  0.9892 ( 0.8994) Learning Rate: 0.1000 (0.1000) Top1_base: 71.8750 (74.7656) Top1_base_per_class: 72.5989 (76.6329) 
Training Epoch: [73/1000] Step: [20 / 285] Batch Time: 0.1438 (0.1961) Data Time: 0.0111 (0.0610) Average Loss: 0.7603 (0.8471) Average CE Loss (Source):  0.7603 ( 0.8471) Learning Rate: 0.1000 (0.1000) Top1_base: 80.4688 (76.2891) Top1_base_per_class: 87.8346 (78.2591) 
Training Epoch: [73/1000] Step: [30 / 285] Batch Time: 0.1510 (0.1843) Data Time: 0.0167 (0.0494) Average Loss: 0.6233 (0.8470) Average CE Loss (Source):  0.6233 ( 0.8470) Learning Rate: 0.1000 (0.1000) Top1_base: 85.1562 (76.0156) Top1_base_per_class: 86.3782 (77.5458) 
Training Epoch: [73/1000] Step: [40 / 285] Batch Time: 0.1457 (0.1801) Data Time: 0.0132 (0.0454) Average Loss: 0.8574 (0.8465) Average CE Loss (Source):  0.8574 ( 0.8465) Learning Rate: 0.1000 (0.1000) Top1_base: 78.1250 (76.0547) Top1_base_per_class: 77.8070 (77.1953) 
Training Epoch: [73/1000] Step: [50 / 285] Batch Time: 0.1460 (0.1737) Data Time: 0.0123 (0.0392) Average Loss: 0.7089 (0.8345) Average CE Loss (Source):  0.7089 ( 0.8345) Learning Rate: 0.1000 (0.1000) Top1_base: 79.6875 (76.4062) Top1_base_per_class: 81.0714 (77.3083) 
Training Epoch: [73/1000] Step: [60 / 285] Batch Time: 0.1420 (0.1707) Data Time: 0.0109 (0.0363) Average Loss: 0.7277 (0.8284) Average CE Loss (Source):  0.7277 ( 0.8284) Learning Rate: 0.1000 (0.1000) Top1_base: 81.2500 (76.4583) Top1_base_per_class: 78.0655 (77.2203) 
Training Epoch: [73/1000] Step: [70 / 285] Batch Time: 0.1494 (0.1691) Data Time: 0.0134 (0.0348) Average Loss: 0.7500 (0.8263) Average CE Loss (Source):  0.7500 ( 0.8263) Learning Rate: 0.1000 (0.1000) Top1_base: 75.7812 (76.5848) Top1_base_per_class: 77.7976 (77.3806) 
Training Epoch: [73/1000] Step: [80 / 285] Batch Time: 0.1422 (0.1682) Data Time: 0.0111 (0.0341) Average Loss: 0.9149 (0.8348) Average CE Loss (Source):  0.9149 ( 0.8348) Learning Rate: 0.1000 (0.1000) Top1_base: 76.5625 (76.4746) Top1_base_per_class: 75.4733 (77.2901) 
Training Epoch: [73/1000] Step: [90 / 285] Batch Time: 0.1422 (0.1666) Data Time: 0.0122 (0.0326) Average Loss: 0.7968 (0.8385) Average CE Loss (Source):  0.7968 ( 0.8385) Learning Rate: 0.1000 (0.1000) Top1_base: 80.4688 (76.4931) Top1_base_per_class: 83.5758 (77.3127) 
Training Epoch: [73/1000] Step: [100 / 285] Batch Time: 0.1461 (0.1657) Data Time: 0.0142 (0.0320) Average Loss: 0.8808 (0.8464) Average CE Loss (Source):  0.8808 ( 0.8464) Learning Rate: 0.1000 (0.1000) Top1_base: 74.2188 (76.1562) Top1_base_per_class: 75.5436 (77.0017) 
Training Epoch: [73/1000] Step: [110 / 285] Batch Time: 0.1453 (0.1644) Data Time: 0.0116 (0.0308) Average Loss: 0.7996 (0.8486) Average CE Loss (Source):  0.7996 ( 0.8486) Learning Rate: 0.1000 (0.1000) Top1_base: 76.5625 (76.0653) Top1_base_per_class: 79.3750 (76.7947) 
Training Epoch: [73/1000] Step: [120 / 285] Batch Time: 0.1466 (0.1637) Data Time: 0.0135 (0.0301) Average Loss: 1.1615 (0.8500) Average CE Loss (Source):  1.1615 ( 0.8500) Learning Rate: 0.1000 (0.1000) Top1_base: 68.7500 (76.1198) Top1_base_per_class: 68.2390 (76.7973) 
Training Epoch: [73/1000] Step: [130 / 285] Batch Time: 0.1441 (0.1633) Data Time: 0.0118 (0.0298) Average Loss: 0.7642 (0.8474) Average CE Loss (Source):  0.7642 ( 0.8474) Learning Rate: 0.1000 (0.1000) Top1_base: 77.3438 (76.1659) Top1_base_per_class: 76.3272 (76.8424) 
Training Epoch: [73/1000] Step: [140 / 285] Batch Time: 0.1417 (0.1638) Data Time: 0.0109 (0.0303) Average Loss: 0.9148 (0.8493) Average CE Loss (Source):  0.9148 ( 0.8493) Learning Rate: 0.1000 (0.1000) Top1_base: 77.3438 (76.1663) Top1_base_per_class: 78.1129 (76.7745) 
Training Epoch: [73/1000] Step: [150 / 285] Batch Time: 0.1506 (0.1631) Data Time: 0.0149 (0.0296) Average Loss: 0.9001 (0.8560) Average CE Loss (Source):  0.9001 ( 0.8560) Learning Rate: 0.1000 (0.1000) Top1_base: 78.1250 (76.1302) Top1_base_per_class: 82.4405 (76.7788) 
Training Epoch: [73/1000] Step: [160 / 285] Batch Time: 0.1432 (0.1624) Data Time: 0.0112 (0.0290) Average Loss: 0.9220 (0.8577) Average CE Loss (Source):  0.9220 ( 0.8577) Learning Rate: 0.1000 (0.1000) Top1_base: 69.5312 (76.0986) Top1_base_per_class: 73.4833 (76.7618) 
Training Epoch: [73/1000] Step: [170 / 285] Batch Time: 0.1504 (0.1622) Data Time: 0.0146 (0.0286) Average Loss: 0.6959 (0.8560) Average CE Loss (Source):  0.6959 ( 0.8560) Learning Rate: 0.1000 (0.1000) Top1_base: 84.3750 (76.1627) Top1_base_per_class: 85.0278 (76.8566) 
Training Epoch: [73/1000] Step: [180 / 285] Batch Time: 0.1464 (0.1621) Data Time: 0.0128 (0.0286) Average Loss: 0.9091 (0.8588) Average CE Loss (Source):  0.9091 ( 0.8588) Learning Rate: 0.1000 (0.1000) Top1_base: 76.5625 (76.1415) Top1_base_per_class: 73.8218 (76.8055) 
Training Epoch: [73/1000] Step: [190 / 285] Batch Time: 0.1471 (0.1615) Data Time: 0.0141 (0.0279) Average Loss: 0.7976 (0.8564) Average CE Loss (Source):  0.7976 ( 0.8564) Learning Rate: 0.1000 (0.1000) Top1_base: 75.7812 (76.2130) Top1_base_per_class: 74.3155 (76.8243) 
Training Epoch: [73/1000] Step: [200 / 285] Batch Time: 0.1444 (0.1615) Data Time: 0.0132 (0.0279) Average Loss: 0.8055 (0.8542) Average CE Loss (Source):  0.8055 ( 0.8542) Learning Rate: 0.1000 (0.1000) Top1_base: 79.6875 (76.2539) Top1_base_per_class: 80.1572 (76.8603) 
Training Epoch: [73/1000] Step: [210 / 285] Batch Time: 0.1445 (0.1609) Data Time: 0.0129 (0.0275) Average Loss: 0.7670 (0.8546) Average CE Loss (Source):  0.7670 ( 0.8546) Learning Rate: 0.1000 (0.1000) Top1_base: 79.6875 (76.2537) Top1_base_per_class: 83.9198 (76.8973) 
Training Epoch: [73/1000] Step: [220 / 285] Batch Time: 0.1428 (0.1610) Data Time: 0.0111 (0.0276) Average Loss: 0.7640 (0.8555) Average CE Loss (Source):  0.7640 ( 0.8555) Learning Rate: 0.1000 (0.1000) Top1_base: 80.4688 (76.2180) Top1_base_per_class: 77.3392 (76.8269) 
Training Epoch: [73/1000] Step: [230 / 285] Batch Time: 0.1505 (0.1606) Data Time: 0.0128 (0.0271) Average Loss: 0.8361 (0.8558) Average CE Loss (Source):  0.8361 ( 0.8558) Learning Rate: 0.1000 (0.1000) Top1_base: 71.8750 (76.1617) Top1_base_per_class: 67.7966 (76.7654) 
Training Epoch: [73/1000] Step: [240 / 285] Batch Time: 0.1445 (0.1605) Data Time: 0.0115 (0.0270) Average Loss: 1.0016 (0.8565) Average CE Loss (Source):  1.0016 ( 0.8565) Learning Rate: 0.1000 (0.1000) Top1_base: 70.3125 (76.1458) Top1_base_per_class: 71.5434 (76.7943) 
Training Epoch: [73/1000] Step: [250 / 285] Batch Time: 0.1445 (0.1600) Data Time: 0.0126 (0.0264) Average Loss: 1.0392 (0.8583) Average CE Loss (Source):  1.0392 ( 0.8583) Learning Rate: 0.1000 (0.1000) Top1_base: 69.5312 (76.0812) Top1_base_per_class: 68.4211 (76.7349) 
Training Epoch: [73/1000] Step: [260 / 285] Batch Time: 0.1460 (0.1595) Data Time: 0.0125 (0.0259) Average Loss: 0.9248 (0.8607) Average CE Loss (Source):  0.9248 ( 0.8607) Learning Rate: 0.1000 (0.1000) Top1_base: 75.7812 (76.0066) Top1_base_per_class: 76.2981 (76.7300) 
Training Epoch: [73/1000] Step: [270 / 285] Batch Time: 0.1514 (0.1594) Data Time: 0.0145 (0.0257) Average Loss: 0.8688 (0.8613) Average CE Loss (Source):  0.8688 ( 0.8613) Learning Rate: 0.1000 (0.1000) Top1_base: 75.7812 (75.9462) Top1_base_per_class: 79.1212 (76.6694) 
Training Epoch: [73/1000] Step: [280 / 285] Batch Time: 0.1430 (0.1591) Data Time: 0.0111 (0.0254) Average Loss: 0.9836 (0.8632) Average CE Loss (Source):  0.9836 ( 0.8632) Learning Rate: 0.1000 (0.1000) Top1_base: 73.4375 (75.9096) Top1_base_per_class: 74.2121 (76.6097) 
Training Epoch: [74/1000] Step: [0] Batch Time: 0.1397 (0.1592) Data Time: 0.0111 (0.0256) Average Loss: 0.8915 (0.8632) Average CE Loss (Source):  0.8915 ( 0.8632) Learning Rate: 0.1000 (0.1000) Top1_base: 74.2188 (75.9265) Top1_base_per_class: 75.3395 (76.5994) 
  7%|▋         | 74/1000 [58:13<12:05:09, 46.99s/it]  8%|▊         | 75/1000 [58:58<11:55:03, 46.38s/it]Training Epoch: [74/1000] Step: [10 / 285] Batch Time: 0.1470 (0.2366) Data Time: 0.0156 (0.1034) Average Loss: 0.6921 (0.8622) Average CE Loss (Source):  0.6921 ( 0.8622) Learning Rate: 0.1000 (0.1000) Top1_base: 79.6875 (75.4688) Top1_base_per_class: 77.8143 (76.1102) 
Training Epoch: [74/1000] Step: [20 / 285] Batch Time: 0.1425 (0.1981) Data Time: 0.0133 (0.0649) Average Loss: 0.7623 (0.8196) Average CE Loss (Source):  0.7623 ( 0.8196) Learning Rate: 0.1000 (0.1000) Top1_base: 75.7812 (76.5234) Top1_base_per_class: 74.7170 (77.0429) 
Training Epoch: [74/1000] Step: [30 / 285] Batch Time: 0.1450 (0.1880) Data Time: 0.0102 (0.0548) Average Loss: 0.9499 (0.8248) Average CE Loss (Source):  0.9499 ( 0.8248) Learning Rate: 0.1000 (0.1000) Top1_base: 73.4375 (76.4583) Top1_base_per_class: 75.7862 (77.2347) 
Training Epoch: [74/1000] Step: [40 / 285] Batch Time: 0.1455 (0.1803) Data Time: 0.0139 (0.0471) Average Loss: 0.9353 (0.8280) Average CE Loss (Source):  0.9353 ( 0.8280) Learning Rate: 0.1000 (0.1000) Top1_base: 71.0938 (76.5039) Top1_base_per_class: 72.0621 (77.1076) 
Training Epoch: [74/1000] Step: [50 / 285] Batch Time: 0.1451 (0.1751) Data Time: 0.0102 (0.0419) Average Loss: 0.6757 (0.8268) Average CE Loss (Source):  0.6757 ( 0.8268) Learning Rate: 0.1000 (0.1000) Top1_base: 78.9062 (76.6875) Top1_base_per_class: 79.5758 (77.1899) 
Training Epoch: [74/1000] Step: [60 / 285] Batch Time: 0.1482 (0.1707) Data Time: 0.0157 (0.0375) Average Loss: 0.7690 (0.8273) Average CE Loss (Source):  0.7690 ( 0.8273) Learning Rate: 0.1000 (0.1000) Top1_base: 80.4688 (76.6927) Top1_base_per_class: 81.7130 (76.9279) 
Training Epoch: [74/1000] Step: [70 / 285] Batch Time: 0.1450 (0.1688) Data Time: 0.0126 (0.0354) Average Loss: 0.8021 (0.8248) Average CE Loss (Source):  0.8021 ( 0.8248) Learning Rate: 0.1000 (0.1000) Top1_base: 75.0000 (76.8304) Top1_base_per_class: 73.7500 (77.1717) 
Training Epoch: [74/1000] Step: [80 / 285] Batch Time: 0.1465 (0.1674) Data Time: 0.0139 (0.0341) Average Loss: 0.8192 (0.8215) Average CE Loss (Source):  0.8192 ( 0.8215) Learning Rate: 0.1000 (0.1000) Top1_base: 77.3438 (77.0117) Top1_base_per_class: 76.3782 (77.3252) 
Training Epoch: [74/1000] Step: [90 / 285] Batch Time: 0.1467 (0.1653) Data Time: 0.0108 (0.0319) Average Loss: 0.8723 (0.8227) Average CE Loss (Source):  0.8723 ( 0.8227) Learning Rate: 0.1000 (0.1000) Top1_base: 78.9062 (77.0139) Top1_base_per_class: 82.7966 (77.3730) 
Training Epoch: [74/1000] Step: [100 / 285] Batch Time: 0.1461 (0.1636) Data Time: 0.0135 (0.0301) Average Loss: 0.7421 (0.8272) Average CE Loss (Source):  0.7421 ( 0.8272) Learning Rate: 0.1000 (0.1000) Top1_base: 80.4688 (76.8984) Top1_base_per_class: 83.1212 (77.2256) 
Training Epoch: [74/1000] Step: [110 / 285] Batch Time: 0.1467 (0.1639) Data Time: 0.0110 (0.0304) Average Loss: 0.8006 (0.8247) Average CE Loss (Source):  0.8006 ( 0.8247) Learning Rate: 0.1000 (0.1000) Top1_base: 73.4375 (76.8963) Top1_base_per_class: 74.1358 (77.2451) 
Training Epoch: [74/1000] Step: [120 / 285] Batch Time: 0.1476 (0.1631) Data Time: 0.0154 (0.0296) Average Loss: 0.8653 (0.8297) Average CE Loss (Source):  0.8653 ( 0.8297) Learning Rate: 0.1000 (0.1000) Top1_base: 74.2188 (76.7383) Top1_base_per_class: 75.8621 (77.0172) 
Training Epoch: [74/1000] Step: [130 / 285] Batch Time: 0.1469 (0.1622) Data Time: 0.0140 (0.0287) Average Loss: 0.8337 (0.8308) Average CE Loss (Source):  0.8337 ( 0.8308) Learning Rate: 0.1000 (0.1000) Top1_base: 78.1250 (76.7488) Top1_base_per_class: 78.9506 (76.9743) 
Training Epoch: [74/1000] Step: [140 / 285] Batch Time: 0.1463 (0.1616) Data Time: 0.0133 (0.0281) Average Loss: 0.9141 (0.8340) Average CE Loss (Source):  0.9141 ( 0.8340) Learning Rate: 0.1000 (0.1000) Top1_base: 74.2188 (76.6183) Top1_base_per_class: 71.1111 (76.8002) 
Training Epoch: [74/1000] Step: [150 / 285] Batch Time: 0.1463 (0.1610) Data Time: 0.0123 (0.0276) Average Loss: 0.9522 (0.8363) Average CE Loss (Source):  0.9522 ( 0.8363) Learning Rate: 0.1000 (0.1000) Top1_base: 72.6562 (76.5208) Top1_base_per_class: 68.5057 (76.6732) 
Training Epoch: [74/1000] Step: [160 / 285] Batch Time: 0.1464 (0.1601) Data Time: 0.0158 (0.0267) Average Loss: 1.0168 (0.8380) Average CE Loss (Source):  1.0168 ( 0.8380) Learning Rate: 0.1000 (0.1000) Top1_base: 67.9688 (76.5332) Top1_base_per_class: 68.9169 (76.6727) 
Training Epoch: [74/1000] Step: [170 / 285] Batch Time: 0.1443 (0.1596) Data Time: 0.0124 (0.0262) Average Loss: 1.0848 (0.8451) Average CE Loss (Source):  1.0848 ( 0.8451) Learning Rate: 0.1000 (0.1000) Top1_base: 69.5312 (76.3373) Top1_base_per_class: 66.3889 (76.4776) 
Training Epoch: [74/1000] Step: [180 / 285] Batch Time: 0.1473 (0.1589) Data Time: 0.0147 (0.0256) Average Loss: 0.8473 (0.8474) Average CE Loss (Source):  0.8473 ( 0.8474) Learning Rate: 0.1000 (0.1000) Top1_base: 75.0000 (76.2196) Top1_base_per_class: 72.8363 (76.3580) 
Training Epoch: [74/1000] Step: [190 / 285] Batch Time: 0.1445 (0.1585) Data Time: 0.0109 (0.0252) Average Loss: 0.9693 (0.8504) Average CE Loss (Source):  0.9693 ( 0.8504) Learning Rate: 0.1000 (0.1000) Top1_base: 75.7812 (76.2048) Top1_base_per_class: 79.1369 (76.4240) 
Training Epoch: [74/1000] Step: [200 / 285] Batch Time: 0.1485 (0.1579) Data Time: 0.0170 (0.0246) Average Loss: 0.8707 (0.8533) Average CE Loss (Source):  0.8707 ( 0.8533) Learning Rate: 0.1000 (0.1000) Top1_base: 74.2188 (76.1133) Top1_base_per_class: 72.1818 (76.3392) 
Training Epoch: [74/1000] Step: [210 / 285] Batch Time: 0.1455 (0.1579) Data Time: 0.0108 (0.0245) Average Loss: 1.0710 (0.8529) Average CE Loss (Source):  1.0710 ( 0.8529) Learning Rate: 0.1000 (0.1000) Top1_base: 66.4062 (76.1421) Top1_base_per_class: 69.8563 (76.3637) 
Training Epoch: [74/1000] Step: [220 / 285] Batch Time: 0.1513 (0.1575) Data Time: 0.0179 (0.0242) Average Loss: 0.7658 (0.8527) Average CE Loss (Source):  0.7658 ( 0.8527) Learning Rate: 0.1000 (0.1000) Top1_base: 78.9062 (76.1506) Top1_base_per_class: 79.7840 (76.3425) 
Training Epoch: [74/1000] Step: [230 / 285] Batch Time: 0.1455 (0.1579) Data Time: 0.0109 (0.0245) Average Loss: 0.7925 (0.8508) Average CE Loss (Source):  0.7925 ( 0.8508) Learning Rate: 0.1000 (0.1000) Top1_base: 78.9062 (76.2058) Top1_base_per_class: 79.9667 (76.4201) 
Training Epoch: [74/1000] Step: [240 / 285] Batch Time: 0.1485 (0.1578) Data Time: 0.0155 (0.0243) Average Loss: 0.9512 (0.8535) Average CE Loss (Source):  0.9512 ( 0.8535) Learning Rate: 0.1000 (0.1000) Top1_base: 75.7812 (76.1426) Top1_base_per_class: 79.8538 (76.3378) 
Training Epoch: [74/1000] Step: [250 / 285] Batch Time: 0.1468 (0.1577) Data Time: 0.0111 (0.0242) Average Loss: 0.8292 (0.8545) Average CE Loss (Source):  0.8292 ( 0.8545) Learning Rate: 0.1000 (0.1000) Top1_base: 75.7812 (76.1250) Top1_base_per_class: 77.6608 (76.3071) 
Training Epoch: [74/1000] Step: [260 / 285] Batch Time: 0.1460 (0.1574) Data Time: 0.0119 (0.0240) Average Loss: 0.8492 (0.8561) Average CE Loss (Source):  0.8492 ( 0.8561) Learning Rate: 0.1000 (0.1000) Top1_base: 76.5625 (76.0998) Top1_base_per_class: 72.9938 (76.2487) 
Training Epoch: [74/1000] Step: [270 / 285] Batch Time: 0.1427 (0.1572) Data Time: 0.0115 (0.0237) Average Loss: 0.8676 (0.8570) Average CE Loss (Source):  0.8676 ( 0.8570) Learning Rate: 0.1000 (0.1000) Top1_base: 78.9062 (76.0475) Top1_base_per_class: 79.0179 (76.2140) 
Training Epoch: [74/1000] Step: [280 / 285] Batch Time: 0.1442 (0.1573) Data Time: 0.0116 (0.0239) Average Loss: 0.8887 (0.8579) Average CE Loss (Source):  0.8887 ( 0.8579) Learning Rate: 0.1000 (0.1000) Top1_base: 75.7812 (76.0352) Top1_base_per_class: 72.2876 (76.1897) 
Training Epoch: [75/1000] Step: [0] Batch Time: 0.2385 (0.1576) Data Time: 0.1100 (0.0242) Average Loss: 1.0321 (0.8592) Average CE Loss (Source):  1.0321 ( 0.8592) Learning Rate: 0.1000 (0.1000) Top1_base: 71.8750 (76.0143) Top1_base_per_class: 76.6667 (76.1845) 
Training Epoch: [75/1000] Step: [10 / 285] Batch Time: 0.1461 (0.2419) Data Time: 0.0114 (0.1072) Average Loss: 0.8424 (0.7987) Average CE Loss (Source):  0.8424 ( 0.7987) Learning Rate: 0.1000 (0.1000) Top1_base: 76.5625 (77.7344) Top1_base_per_class: 77.6023 (78.5737) 
Training Epoch: [75/1000] Step: [20 / 285] Batch Time: 0.1444 (0.2002) Data Time: 0.0135 (0.0657) Average Loss: 0.8603 (0.8074) Average CE Loss (Source):  0.8603 ( 0.8074) Learning Rate: 0.1000 (0.1000) Top1_base: 75.7812 (78.1250) Top1_base_per_class: 77.2327 (78.8226) 
Training Epoch: [75/1000] Step: [30 / 285] Batch Time: 0.1462 (0.1872) Data Time: 0.0117 (0.0529) Average Loss: 0.8254 (0.8148) Average CE Loss (Source):  0.8254 ( 0.8148) Learning Rate: 0.1000 (0.1000) Top1_base: 79.6875 (77.6562) Top1_base_per_class: 76.5406 (78.1818) 
Training Epoch: [75/1000] Step: [40 / 285] Batch Time: 0.1465 (0.1800) Data Time: 0.0148 (0.0457) Average Loss: 0.8753 (0.8194) Average CE Loss (Source):  0.8753 ( 0.8194) Learning Rate: 0.1000 (0.1000) Top1_base: 78.1250 (77.2656) Top1_base_per_class: 79.1358 (77.7304) 
Training Epoch: [75/1000] Step: [50 / 285] Batch Time: 0.1483 (0.1789) Data Time: 0.0123 (0.0448) Average Loss: 0.8919 (0.8161) Average CE Loss (Source):  0.8919 ( 0.8161) Learning Rate: 0.1000 (0.1000) Top1_base: 74.2188 (77.2344) Top1_base_per_class: 71.7529 (77.8167) 
Training Epoch: [75/1000] Step: [60 / 285] Batch Time: 0.1471 (0.1740) Data Time: 0.0137 (0.0399) Average Loss: 0.9125 (0.8175) Average CE Loss (Source):  0.9125 ( 0.8175) Learning Rate: 0.1000 (0.1000) Top1_base: 72.6562 (77.1354) Top1_base_per_class: 73.5802 (77.5571) 
Training Epoch: [75/1000] Step: [70 / 285] Batch Time: 0.1460 (0.1719) Data Time: 0.0104 (0.0379) Average Loss: 0.6440 (0.8180) Average CE Loss (Source):  0.6440 ( 0.8180) Learning Rate: 0.1000 (0.1000) Top1_base: 82.0312 (77.1540) Top1_base_per_class: 85.9226 (77.5160) 
Training Epoch: [75/1000] Step: [80 / 285] Batch Time: 0.1495 (0.1701) Data Time: 0.0142 (0.0359) Average Loss: 0.9518 (0.8184) Average CE Loss (Source):  0.9518 ( 0.8184) Learning Rate: 0.1000 (0.1000) Top1_base: 70.3125 (77.1484) Top1_base_per_class: 73.2424 (77.5269) 
Training Epoch: [75/1000] Step: [90 / 285] Batch Time: 0.1492 (0.1679) Data Time: 0.0105 (0.0334) Average Loss: 0.6565 (0.8139) Average CE Loss (Source):  0.6565 ( 0.8139) Learning Rate: 0.1000 (0.1000) Top1_base: 82.8125 (77.3003) Top1_base_per_class: 77.7576 (77.7024) 
Training Epoch: [75/1000] Step: [100 / 285] Batch Time: 0.1490 (0.1668) Data Time: 0.0142 (0.0321) Average Loss: 1.1044 (0.8201) Average CE Loss (Source):  1.1044 ( 0.8201) Learning Rate: 0.1000 (0.1000) Top1_base: 74.2188 (77.1875) Top1_base_per_class: 76.5179 (77.6440) 
Training Epoch: [75/1000] Step: [110 / 285] Batch Time: 0.1482 (0.1658) Data Time: 0.0107 (0.0310) Average Loss: 0.8138 (0.8265) Average CE Loss (Source):  0.8138 ( 0.8265) Learning Rate: 0.1000 (0.1000) Top1_base: 73.4375 (77.1023) Top1_base_per_class: 72.0707 (77.5366) 
Training Epoch: [75/1000] Step: [120 / 285] Batch Time: 0.1467 (0.1645) Data Time: 0.0128 (0.0297) Average Loss: 0.8320 (0.8282) Average CE Loss (Source):  0.8320 ( 0.8282) Learning Rate: 0.1000 (0.1000) Top1_base: 77.3438 (76.9661) Top1_base_per_class: 79.1379 (77.4135) 
Training Epoch: [75/1000] Step: [130 / 285] Batch Time: 0.1480 (0.1639) Data Time: 0.0129 (0.0292) Average Loss: 0.9685 (0.8276) Average CE Loss (Source):  0.9685 ( 0.8276) Learning Rate: 0.1000 (0.1000) Top1_base: 76.5625 (77.0613) Top1_base_per_class: 80.4632 (77.4866) 
Training Epoch: [75/1000] Step: [140 / 285] Batch Time: 0.1473 (0.1635) Data Time: 0.0150 (0.0289) Average Loss: 0.9049 (0.8291) Average CE Loss (Source):  0.9049 ( 0.8291) Learning Rate: 0.1000 (0.1000) Top1_base: 77.3438 (77.0424) Top1_base_per_class: 76.9883 (77.4520) 
Training Epoch: [75/1000] Step: [150 / 285] Batch Time: 0.1465 (0.1634) Data Time: 0.0104 (0.0288) Average Loss: 0.8151 (0.8289) Average CE Loss (Source):  0.8151 ( 0.8289) Learning Rate: 0.1000 (0.1000) Top1_base: 75.7812 (76.9479) Top1_base_per_class: 77.2640 (77.4108) 
Training Epoch: [75/1000] Step: [160 / 285] Batch Time: 0.1458 (0.1628) Data Time: 0.0136 (0.0283) Average Loss: 1.0407 (0.8363) Average CE Loss (Source):  1.0407 ( 0.8363) Learning Rate: 0.1000 (0.1000) Top1_base: 68.7500 (76.6602) Top1_base_per_class: 70.3736 (77.0783) 
Training Epoch: [75/1000] Step: [170 / 285] Batch Time: 0.1470 (0.1626) Data Time: 0.0105 (0.0281) Average Loss: 0.8351 (0.8373) Average CE Loss (Source):  0.8351 ( 0.8373) Learning Rate: 0.1000 (0.1000) Top1_base: 77.3438 (76.5579) Top1_base_per_class: 75.4237 (77.0039) 
Training Epoch: [75/1000] Step: [180 / 285] Batch Time: 0.1459 (0.1618) Data Time: 0.0142 (0.0274) Average Loss: 0.8404 (0.8395) Average CE Loss (Source):  0.8404 ( 0.8395) Learning Rate: 0.1000 (0.1000) Top1_base: 75.0000 (76.4670) Top1_base_per_class: 74.5974 (76.9595) 
Training Epoch: [75/1000] Step: [190 / 285] Batch Time: 0.1454 (0.1622) Data Time: 0.0108 (0.0278) Average Loss: 0.9241 (0.8395) Average CE Loss (Source):  0.9241 ( 0.8395) Learning Rate: 0.1000 (0.1000) Top1_base: 75.7812 (76.5173) Top1_base_per_class: 79.6784 (77.0451) 
Training Epoch: [75/1000] Step: [200 / 285] Batch Time: 0.1488 (0.1615) Data Time: 0.0122 (0.0271) Average Loss: 0.9360 (0.8396) Average CE Loss (Source):  0.9360 ( 0.8396) Learning Rate: 0.1000 (0.1000) Top1_base: 76.5625 (76.5586) Top1_base_per_class: 78.2430 (77.1005) 
Training Epoch: [75/1000] Step: [210 / 285] Batch Time: 0.1468 (0.1612) Data Time: 0.0109 (0.0268) Average Loss: 0.8244 (0.8410) Average CE Loss (Source):  0.8244 ( 0.8410) Learning Rate: 0.1000 (0.1000) Top1_base: 75.7812 (76.4360) Top1_base_per_class: 79.5139 (76.9722) 
Training Epoch: [75/1000] Step: [220 / 285] Batch Time: 0.1459 (0.1607) Data Time: 0.0143 (0.0264) Average Loss: 0.8674 (0.8447) Average CE Loss (Source):  0.8674 ( 0.8447) Learning Rate: 0.1000 (0.1000) Top1_base: 71.8750 (76.2678) Top1_base_per_class: 76.1238 (76.8146) 
Training Epoch: [75/1000] Step: [230 / 285] Batch Time: 0.1479 (0.1609) Data Time: 0.0106 (0.0266) Average Loss: 1.0090 (0.8446) Average CE Loss (Source):  1.0090 ( 0.8446) Learning Rate: 0.1000 (0.1000) Top1_base: 73.4375 (76.1923) Top1_base_per_class: 75.4598 (76.7474) 
Training Epoch: [75/1000] Step: [240 / 285] Batch Time: 0.1475 (0.1606) Data Time: 0.0121 (0.0263) Average Loss: 0.6338 (0.8455) Average CE Loss (Source):  0.6338 ( 0.8455) Learning Rate: 0.1000 (0.1000) Top1_base: 80.4688 (76.1165) Top1_base_per_class: 83.3030 (76.6956) 
Training Epoch: [75/1000] Step: [250 / 285] Batch Time: 0.1459 (0.1605) Data Time: 0.0105 (0.0262) Average Loss: 0.9223 (0.8459) Average CE Loss (Source):  0.9223 ( 0.8459) Learning Rate: 0.1000 (0.1000) Top1_base: 76.5625 (76.1437) Top1_base_per_class: 76.4035 (76.7273) 
Training Epoch: [75/1000] Step: [260 / 285] Batch Time: 0.1467 (0.1605) Data Time: 0.0131 (0.0262) Average Loss: 0.6271 (0.8472) Average CE Loss (Source):  0.6271 ( 0.8472) Learning Rate: 0.1000 (0.1000) Top1_base: 81.2500 (76.0847) Top1_base_per_class: 79.1228 (76.6682) 
Training Epoch: [75/1000] Step: [270 / 285] Batch Time: 0.1455 (0.1603) Data Time: 0.0106 (0.0260) Average Loss: 0.7412 (0.8469) Average CE Loss (Source):  0.7412 ( 0.8469) Learning Rate: 0.1000 (0.1000) Top1_base: 80.4688 (76.0735) Top1_base_per_class: 81.1765 (76.6134) 
Training Epoch: [75/1000] Step: [280 / 285] Batch Time: 0.1424 (0.1601) Data Time: 0.0111 (0.0258) Average Loss: 0.7960 (0.8488) Average CE Loss (Source):  0.7960 ( 0.8488) Learning Rate: 0.1000 (0.1000) Top1_base: 75.7812 (76.0379) Top1_base_per_class: 75.5449 (76.5323) 
Training Epoch: [76/1000] Step: [0] Batch Time: 0.1498 (0.1598) Data Time: 0.0201 (0.0256) Average Loss: 0.7506 (0.8481) Average CE Loss (Source):  0.7506 ( 0.8481) Learning Rate: 0.1000 (0.1000) Top1_base: 81.2500 (76.0691) Top1_base_per_class: 81.5278 (76.5518) 
  8%|▊         | 76/1000 [59:46<12:03:16, 46.97s/it]  8%|▊         | 77/1000 [1:00:31<11:55:04, 46.48s/it]Training Epoch: [76/1000] Step: [10 / 285] Batch Time: 0.1498 (0.2270) Data Time: 0.0127 (0.0910) Average Loss: 0.6204 (0.7492) Average CE Loss (Source):  0.6204 ( 0.7492) Learning Rate: 0.1000 (0.1000) Top1_base: 82.8125 (77.9688) Top1_base_per_class: 84.2560 (78.6075) 
Training Epoch: [76/1000] Step: [20 / 285] Batch Time: 0.1468 (0.1879) Data Time: 0.0126 (0.0525) Average Loss: 0.8543 (0.7781) Average CE Loss (Source):  0.8543 ( 0.7781) Learning Rate: 0.1000 (0.1000) Top1_base: 74.2188 (77.7734) Top1_base_per_class: 74.3333 (78.6354) 
Training Epoch: [76/1000] Step: [30 / 285] Batch Time: 0.1534 (0.1760) Data Time: 0.0169 (0.0410) Average Loss: 0.7412 (0.7922) Average CE Loss (Source):  0.7412 ( 0.7922) Learning Rate: 0.1000 (0.1000) Top1_base: 78.1250 (78.0729) Top1_base_per_class: 79.8663 (78.5855) 
Training Epoch: [76/1000] Step: [40 / 285] Batch Time: 0.1442 (0.1712) Data Time: 0.0125 (0.0364) Average Loss: 0.8150 (0.7891) Average CE Loss (Source):  0.8150 ( 0.7891) Learning Rate: 0.1000 (0.1000) Top1_base: 74.2188 (77.9883) Top1_base_per_class: 77.5287 (78.5263) 
Training Epoch: [76/1000] Step: [50 / 285] Batch Time: 0.1512 (0.1666) Data Time: 0.0174 (0.0320) Average Loss: 0.8444 (0.7849) Average CE Loss (Source):  0.8444 ( 0.7849) Learning Rate: 0.1000 (0.1000) Top1_base: 75.7812 (78.0312) Top1_base_per_class: 75.0000 (78.4965) 
Training Epoch: [76/1000] Step: [60 / 285] Batch Time: 0.1465 (0.1670) Data Time: 0.0147 (0.0325) Average Loss: 0.8159 (0.8007) Average CE Loss (Source):  0.8159 ( 0.8007) Learning Rate: 0.1000 (0.1000) Top1_base: 75.7812 (77.5260) Top1_base_per_class: 75.1543 (78.1322) 
Training Epoch: [76/1000] Step: [70 / 285] Batch Time: 0.1500 (0.1654) Data Time: 0.0139 (0.0310) Average Loss: 0.9705 (0.8130) Average CE Loss (Source):  0.9705 ( 0.8130) Learning Rate: 0.1000 (0.1000) Top1_base: 73.4375 (77.1987) Top1_base_per_class: 71.5789 (77.7926) 
Training Epoch: [76/1000] Step: [80 / 285] Batch Time: 0.1439 (0.1641) Data Time: 0.0109 (0.0298) Average Loss: 0.7932 (0.8143) Average CE Loss (Source):  0.7932 ( 0.8143) Learning Rate: 0.1000 (0.1000) Top1_base: 82.8125 (77.2656) Top1_base_per_class: 85.4762 (77.9190) 
Training Epoch: [76/1000] Step: [90 / 285] Batch Time: 0.1519 (0.1641) Data Time: 0.0161 (0.0299) Average Loss: 0.9858 (0.8180) Average CE Loss (Source):  0.9858 ( 0.8180) Learning Rate: 0.1000 (0.1000) Top1_base: 72.6562 (77.1007) Top1_base_per_class: 76.7836 (77.7807) 
Training Epoch: [76/1000] Step: [100 / 285] Batch Time: 0.1478 (0.1631) Data Time: 0.0145 (0.0289) Average Loss: 0.9979 (0.8200) Average CE Loss (Source):  0.9979 ( 0.8200) Learning Rate: 0.1000 (0.1000) Top1_base: 71.8750 (76.9766) Top1_base_per_class: 70.7273 (77.6222) 
Training Epoch: [76/1000] Step: [110 / 285] Batch Time: 0.1509 (0.1624) Data Time: 0.0159 (0.0281) Average Loss: 1.0853 (0.8231) Average CE Loss (Source):  1.0853 ( 0.8231) Learning Rate: 0.1000 (0.1000) Top1_base: 71.0938 (76.9602) Top1_base_per_class: 70.1543 (77.6698) 
Training Epoch: [76/1000] Step: [120 / 285] Batch Time: 0.1435 (0.1624) Data Time: 0.0117 (0.0282) Average Loss: 0.8654 (0.8219) Average CE Loss (Source):  0.8654 ( 0.8219) Learning Rate: 0.1000 (0.1000) Top1_base: 76.5625 (77.0964) Top1_base_per_class: 77.2436 (77.7551) 
Training Epoch: [76/1000] Step: [130 / 285] Batch Time: 0.1510 (0.1620) Data Time: 0.0166 (0.0278) Average Loss: 0.7430 (0.8220) Average CE Loss (Source):  0.7430 ( 0.8220) Learning Rate: 0.1000 (0.1000) Top1_base: 77.3438 (77.1274) Top1_base_per_class: 80.3107 (77.8010) 
Training Epoch: [76/1000] Step: [140 / 285] Batch Time: 0.1453 (0.1614) Data Time: 0.0108 (0.0273) Average Loss: 1.0766 (0.8249) Average CE Loss (Source):  1.0766 ( 0.8249) Learning Rate: 0.1000 (0.1000) Top1_base: 70.3125 (77.0424) Top1_base_per_class: 76.4407 (77.8225) 
Training Epoch: [76/1000] Step: [150 / 285] Batch Time: 0.1493 (0.1610) Data Time: 0.0146 (0.0269) Average Loss: 1.1007 (0.8265) Average CE Loss (Source):  1.1007 ( 0.8265) Learning Rate: 0.1000 (0.1000) Top1_base: 72.6562 (76.9740) Top1_base_per_class: 72.8814 (77.8193) 
Training Epoch: [76/1000] Step: [160 / 285] Batch Time: 0.1429 (0.1608) Data Time: 0.0106 (0.0268) Average Loss: 0.7546 (0.8268) Average CE Loss (Source):  0.7546 ( 0.8268) Learning Rate: 0.1000 (0.1000) Top1_base: 78.9062 (76.9482) Top1_base_per_class: 81.5805 (77.8175) 
Training Epoch: [76/1000] Step: [170 / 285] Batch Time: 0.1487 (0.1601) Data Time: 0.0135 (0.0261) Average Loss: 0.7496 (0.8286) Average CE Loss (Source):  0.7496 ( 0.8286) Learning Rate: 0.1000 (0.1000) Top1_base: 78.1250 (76.8888) Top1_base_per_class: 78.9198 (77.7335) 
Training Epoch: [76/1000] Step: [180 / 285] Batch Time: 0.1413 (0.1597) Data Time: 0.0101 (0.0258) Average Loss: 0.7872 (0.8306) Average CE Loss (Source):  0.7872 ( 0.8306) Learning Rate: 0.1000 (0.1000) Top1_base: 76.5625 (76.8056) Top1_base_per_class: 75.7310 (77.5865) 
Training Epoch: [76/1000] Step: [190 / 285] Batch Time: 0.1517 (0.1594) Data Time: 0.0152 (0.0256) Average Loss: 0.7656 (0.8290) Average CE Loss (Source):  0.7656 ( 0.8290) Learning Rate: 0.1000 (0.1000) Top1_base: 75.7812 (76.7887) Top1_base_per_class: 76.1590 (77.5833) 
Training Epoch: [76/1000] Step: [200 / 285] Batch Time: 0.1447 (0.1600) Data Time: 0.0128 (0.0262) Average Loss: 0.9385 (0.8290) Average CE Loss (Source):  0.9385 ( 0.8290) Learning Rate: 0.1000 (0.1000) Top1_base: 75.7812 (76.7070) Top1_base_per_class: 78.8972 (77.4876) 
Training Epoch: [76/1000] Step: [210 / 285] Batch Time: 0.1490 (0.1599) Data Time: 0.0142 (0.0260) Average Loss: 0.8775 (0.8324) Average CE Loss (Source):  0.8775 ( 0.8324) Learning Rate: 0.1000 (0.1000) Top1_base: 75.7812 (76.6332) Top1_base_per_class: 75.9028 (77.4170) 
Training Epoch: [76/1000] Step: [220 / 285] Batch Time: 0.1442 (0.1596) Data Time: 0.0116 (0.0258) Average Loss: 1.0918 (0.8359) Average CE Loss (Source):  1.0918 ( 0.8359) Learning Rate: 0.1000 (0.1000) Top1_base: 67.9688 (76.5128) Top1_base_per_class: 65.5060 (77.2301) 
Training Epoch: [76/1000] Step: [230 / 285] Batch Time: 0.1494 (0.1591) Data Time: 0.0158 (0.0253) Average Loss: 0.9090 (0.8386) Average CE Loss (Source):  0.9090 ( 0.8386) Learning Rate: 0.1000 (0.1000) Top1_base: 72.6562 (76.3995) Top1_base_per_class: 70.9141 (77.1359) 
Training Epoch: [76/1000] Step: [240 / 285] Batch Time: 0.1489 (0.1596) Data Time: 0.0150 (0.0258) Average Loss: 0.8599 (0.8387) Average CE Loss (Source):  0.8599 ( 0.8387) Learning Rate: 0.1000 (0.1000) Top1_base: 78.9062 (76.4453) Top1_base_per_class: 79.9107 (77.1753) 
Training Epoch: [76/1000] Step: [250 / 285] Batch Time: 0.1507 (0.1594) Data Time: 0.0146 (0.0257) Average Loss: 1.1673 (0.8434) Average CE Loss (Source):  1.1673 ( 0.8434) Learning Rate: 0.1000 (0.1000) Top1_base: 68.7500 (76.3219) Top1_base_per_class: 68.0747 (77.0284) 
Training Epoch: [76/1000] Step: [260 / 285] Batch Time: 0.1434 (0.1595) Data Time: 0.0121 (0.0258) Average Loss: 0.9159 (0.8459) Average CE Loss (Source):  0.9159 ( 0.8459) Learning Rate: 0.1000 (0.1000) Top1_base: 77.3438 (76.2470) Top1_base_per_class: 75.8772 (76.9442) 
Training Epoch: [76/1000] Step: [270 / 285] Batch Time: 0.1421 (0.1591) Data Time: 0.0123 (0.0254) Average Loss: 1.1302 (0.8482) Average CE Loss (Source):  1.1302 ( 0.8482) Learning Rate: 0.1000 (0.1000) Top1_base: 64.0625 (76.1487) Top1_base_per_class: 65.0292 (76.8107) 
Training Epoch: [76/1000] Step: [280 / 285] Batch Time: 0.1433 (0.1590) Data Time: 0.0123 (0.0253) Average Loss: 0.8558 (0.8487) Average CE Loss (Source):  0.8558 ( 0.8487) Learning Rate: 0.1000 (0.1000) Top1_base: 72.6562 (76.1328) Top1_base_per_class: 73.8304 (76.8018) 
Training Epoch: [77/1000] Step: [0] Batch Time: 0.1430 (0.1590) Data Time: 0.0099 (0.0253) Average Loss: 0.9046 (0.8492) Average CE Loss (Source):  0.9046 ( 0.8492) Learning Rate: 0.1000 (0.1000) Top1_base: 74.2188 (76.1102) Top1_base_per_class: 77.2222 (76.7775) 
Training Epoch: [77/1000] Step: [10 / 285] Batch Time: 0.1469 (0.2284) Data Time: 0.0135 (0.0954) Average Loss: 0.9687 (0.8300) Average CE Loss (Source):  0.9687 ( 0.8300) Learning Rate: 0.1000 (0.1000) Top1_base: 70.3125 (75.3125) Top1_base_per_class: 78.0460 (76.4906) 
Training Epoch: [77/1000] Step: [20 / 285] Batch Time: 0.1431 (0.1937) Data Time: 0.0103 (0.0606) Average Loss: 0.7814 (0.8166) Average CE Loss (Source):  0.7814 ( 0.8166) Learning Rate: 0.1000 (0.1000) Top1_base: 78.9062 (76.8359) Top1_base_per_class: 77.8274 (78.1769) 
Training Epoch: [77/1000] Step: [30 / 285] Batch Time: 0.1454 (0.1813) Data Time: 0.0126 (0.0480) Average Loss: 0.8538 (0.7983) Average CE Loss (Source):  0.8538 ( 0.7983) Learning Rate: 0.1000 (0.1000) Top1_base: 74.2188 (77.2656) Top1_base_per_class: 74.7103 (77.9283) 
Training Epoch: [77/1000] Step: [40 / 285] Batch Time: 0.1468 (0.1751) Data Time: 0.0124 (0.0415) Average Loss: 0.9672 (0.8149) Average CE Loss (Source):  0.9672 ( 0.8149) Learning Rate: 0.1000 (0.1000) Top1_base: 69.5312 (77.0508) Top1_base_per_class: 71.2424 (77.4948) 
Training Epoch: [77/1000] Step: [50 / 285] Batch Time: 0.1523 (0.1727) Data Time: 0.0137 (0.0386) Average Loss: 0.7264 (0.8237) Average CE Loss (Source):  0.7264 ( 0.8237) Learning Rate: 0.1000 (0.1000) Top1_base: 77.3438 (76.8281) Top1_base_per_class: 78.5920 (77.2792) 
Training Epoch: [77/1000] Step: [60 / 285] Batch Time: 0.1449 (0.1693) Data Time: 0.0117 (0.0350) Average Loss: 0.9283 (0.8254) Average CE Loss (Source):  0.9283 ( 0.8254) Learning Rate: 0.1000 (0.1000) Top1_base: 74.2188 (76.8880) Top1_base_per_class: 73.1250 (77.3705) 
Training Epoch: [77/1000] Step: [70 / 285] Batch Time: 0.1482 (0.1668) Data Time: 0.0137 (0.0324) Average Loss: 0.7211 (0.8276) Average CE Loss (Source):  0.7211 ( 0.8276) Learning Rate: 0.1000 (0.1000) Top1_base: 79.6875 (76.8973) Top1_base_per_class: 80.3463 (77.4194) 
Training Epoch: [77/1000] Step: [80 / 285] Batch Time: 0.1417 (0.1642) Data Time: 0.0106 (0.0301) Average Loss: 0.9796 (0.8337) Average CE Loss (Source):  0.9796 ( 0.8337) Learning Rate: 0.1000 (0.1000) Top1_base: 75.0000 (76.7871) Top1_base_per_class: 76.4035 (77.2443) 
Training Epoch: [77/1000] Step: [90 / 285] Batch Time: 0.1511 (0.1654) Data Time: 0.0161 (0.0314) Average Loss: 0.6061 (0.8285) Average CE Loss (Source):  0.6061 ( 0.8285) Learning Rate: 0.1000 (0.1000) Top1_base: 78.9062 (76.9010) Top1_base_per_class: 80.1483 (77.3334) 
Training Epoch: [77/1000] Step: [100 / 285] Batch Time: 0.1403 (0.1639) Data Time: 0.0106 (0.0300) Average Loss: 0.7167 (0.8347) Average CE Loss (Source):  0.7167 ( 0.8347) Learning Rate: 0.1000 (0.1000) Top1_base: 75.7812 (76.7266) Top1_base_per_class: 74.5238 (77.1827) 
Training Epoch: [77/1000] Step: [110 / 285] Batch Time: 0.1483 (0.1633) Data Time: 0.0139 (0.0295) Average Loss: 1.0116 (0.8405) Average CE Loss (Source):  1.0116 ( 0.8405) Learning Rate: 0.1000 (0.1000) Top1_base: 69.5312 (76.6690) Top1_base_per_class: 71.0512 (77.1942) 
Training Epoch: [77/1000] Step: [120 / 285] Batch Time: 0.1419 (0.1620) Data Time: 0.0106 (0.0284) Average Loss: 0.6542 (0.8399) Average CE Loss (Source):  0.6542 ( 0.8399) Learning Rate: 0.1000 (0.1000) Top1_base: 82.0312 (76.7318) Top1_base_per_class: 84.2500 (77.1513) 
Training Epoch: [77/1000] Step: [130 / 285] Batch Time: 0.1476 (0.1615) Data Time: 0.0137 (0.0279) Average Loss: 0.8931 (0.8413) Average CE Loss (Source):  0.8931 ( 0.8413) Learning Rate: 0.1000 (0.1000) Top1_base: 77.3438 (76.7668) Top1_base_per_class: 79.4883 (77.1475) 
Training Epoch: [77/1000] Step: [140 / 285] Batch Time: 0.1492 (0.1604) Data Time: 0.0133 (0.0269) Average Loss: 0.9688 (0.8440) Average CE Loss (Source):  0.9688 ( 0.8440) Learning Rate: 0.1000 (0.1000) Top1_base: 71.0938 (76.6462) Top1_base_per_class: 76.4751 (77.1405) 
Training Epoch: [77/1000] Step: [150 / 285] Batch Time: 0.1503 (0.1610) Data Time: 0.0150 (0.0274) Average Loss: 0.6003 (0.8437) Average CE Loss (Source):  0.6003 ( 0.8437) Learning Rate: 0.1000 (0.1000) Top1_base: 78.9062 (76.6250) Top1_base_per_class: 78.3929 (77.0836) 
Training Epoch: [77/1000] Step: [160 / 285] Batch Time: 0.1480 (0.1601) Data Time: 0.0130 (0.0265) Average Loss: 0.9112 (0.8459) Average CE Loss (Source):  0.9112 ( 0.8459) Learning Rate: 0.1000 (0.1000) Top1_base: 76.5625 (76.6211) Top1_base_per_class: 77.5320 (77.0650) 
Training Epoch: [77/1000] Step: [170 / 285] Batch Time: 0.1501 (0.1594) Data Time: 0.0140 (0.0258) Average Loss: 0.6786 (0.8473) Average CE Loss (Source):  0.6786 ( 0.8473) Learning Rate: 0.1000 (0.1000) Top1_base: 83.5938 (76.6085) Top1_base_per_class: 85.2083 (77.0384) 
Training Epoch: [77/1000] Step: [180 / 285] Batch Time: 0.1437 (0.1590) Data Time: 0.0105 (0.0253) Average Loss: 1.0063 (0.8462) Average CE Loss (Source):  1.0063 ( 0.8462) Learning Rate: 0.1000 (0.1000) Top1_base: 72.6562 (76.6146) Top1_base_per_class: 76.2521 (77.0310) 
Training Epoch: [77/1000] Step: [190 / 285] Batch Time: 0.1483 (0.1584) Data Time: 0.0141 (0.0247) Average Loss: 0.9892 (0.8485) Average CE Loss (Source):  0.9892 ( 0.8485) Learning Rate: 0.1000 (0.1000) Top1_base: 78.1250 (76.5913) Top1_base_per_class: 77.0262 (77.0622) 
Training Epoch: [77/1000] Step: [200 / 285] Batch Time: 0.1430 (0.1579) Data Time: 0.0124 (0.0242) Average Loss: 0.8808 (0.8526) Average CE Loss (Source):  0.8808 ( 0.8526) Learning Rate: 0.1000 (0.1000) Top1_base: 75.0000 (76.4297) Top1_base_per_class: 79.5331 (76.9366) 
Training Epoch: [77/1000] Step: [210 / 285] Batch Time: 0.1489 (0.1582) Data Time: 0.0139 (0.0245) Average Loss: 0.7663 (0.8517) Average CE Loss (Source):  0.7663 ( 0.8517) Learning Rate: 0.1000 (0.1000) Top1_base: 77.3438 (76.4509) Top1_base_per_class: 76.9298 (76.9212) 
Training Epoch: [77/1000] Step: [220 / 285] Batch Time: 0.1421 (0.1580) Data Time: 0.0104 (0.0243) Average Loss: 0.8643 (0.8517) Average CE Loss (Source):  0.8643 ( 0.8517) Learning Rate: 0.1000 (0.1000) Top1_base: 76.5625 (76.4311) Top1_base_per_class: 80.9277 (76.9284) 
Training Epoch: [77/1000] Step: [230 / 285] Batch Time: 0.1492 (0.1584) Data Time: 0.0139 (0.0248) Average Loss: 0.9561 (0.8535) Average CE Loss (Source):  0.9561 ( 0.8535) Learning Rate: 0.1000 (0.1000) Top1_base: 72.6562 (76.3485) Top1_base_per_class: 74.0638 (76.8858) 
Training Epoch: [77/1000] Step: [240 / 285] Batch Time: 0.1442 (0.1581) Data Time: 0.0124 (0.0245) Average Loss: 0.5534 (0.8527) Average CE Loss (Source):  0.5534 ( 0.8527) Learning Rate: 0.1000 (0.1000) Top1_base: 84.3750 (76.3411) Top1_base_per_class: 83.0747 (76.8555) 
Training Epoch: [77/1000] Step: [250 / 285] Batch Time: 0.1438 (0.1579) Data Time: 0.0119 (0.0243) Average Loss: 0.8403 (0.8540) Average CE Loss (Source):  0.8403 ( 0.8540) Learning Rate: 0.1000 (0.1000) Top1_base: 81.2500 (76.3719) Top1_base_per_class: 85.0943 (76.8450) 
Training Epoch: [77/1000] Step: [260 / 285] Batch Time: 0.1423 (0.1575) Data Time: 0.0103 (0.0239) Average Loss: 0.6403 (0.8536) Average CE Loss (Source):  0.6403 ( 0.8536) Learning Rate: 0.1000 (0.1000) Top1_base: 77.3438 (76.3642) Top1_base_per_class: 76.5254 (76.8116) 
Training Epoch: [77/1000] Step: [270 / 285] Batch Time: 0.1471 (0.1573) Data Time: 0.0136 (0.0238) Average Loss: 0.7866 (0.8516) Average CE Loss (Source):  0.7866 ( 0.8516) Learning Rate: 0.1000 (0.1000) Top1_base: 75.0000 (76.4641) Top1_base_per_class: 74.6361 (76.9238) 
Training Epoch: [77/1000] Step: [280 / 285] Batch Time: 0.1451 (0.1569) Data Time: 0.0138 (0.0234) Average Loss: 0.7533 (0.8517) Average CE Loss (Source):  0.7533 ( 0.8517) Learning Rate: 0.1000 (0.1000) Top1_base: 82.8125 (76.4927) Top1_base_per_class: 83.1579 (76.9751) 
Training Epoch: [78/1000] Step: [0] Batch Time: 0.1462 (0.1567) Data Time: 0.0108 (0.0232) Average Loss: 0.7672 (0.8512) Average CE Loss (Source):  0.7672 ( 0.8512) Learning Rate: 0.1000 (0.1000) Top1_base: 78.9062 (76.4857) Top1_base_per_class: 78.9524 (76.9750) 
  8%|▊         | 78/1000 [1:01:19<11:58:40, 46.77s/it]  8%|▊         | 79/1000 [1:02:04<11:48:59, 46.19s/it]Training Epoch: [78/1000] Step: [10 / 285] Batch Time: 0.1494 (0.2350) Data Time: 0.0139 (0.1012) Average Loss: 0.7987 (0.8105) Average CE Loss (Source):  0.7987 ( 0.8105) Learning Rate: 0.1000 (0.1000) Top1_base: 78.9062 (78.0469) Top1_base_per_class: 76.4465 (78.7232) 
Training Epoch: [78/1000] Step: [20 / 285] Batch Time: 0.1435 (0.1974) Data Time: 0.0110 (0.0643) Average Loss: 1.0157 (0.8282) Average CE Loss (Source):  1.0157 ( 0.8282) Learning Rate: 0.1000 (0.1000) Top1_base: 70.3125 (77.7344) Top1_base_per_class: 70.9836 (78.4216) 
Training Epoch: [78/1000] Step: [30 / 285] Batch Time: 0.1507 (0.1812) Data Time: 0.0143 (0.0477) Average Loss: 0.9078 (0.8219) Average CE Loss (Source):  0.9078 ( 0.8219) Learning Rate: 0.1000 (0.1000) Top1_base: 75.0000 (77.6562) Top1_base_per_class: 79.0000 (78.4364) 
Training Epoch: [78/1000] Step: [40 / 285] Batch Time: 0.1447 (0.1733) Data Time: 0.0126 (0.0402) Average Loss: 1.0408 (0.8274) Average CE Loss (Source):  1.0408 ( 0.8274) Learning Rate: 0.1000 (0.1000) Top1_base: 72.6562 (77.2461) Top1_base_per_class: 74.6296 (78.0423) 
Training Epoch: [78/1000] Step: [50 / 285] Batch Time: 0.1522 (0.1707) Data Time: 0.0140 (0.0372) Average Loss: 0.8070 (0.8140) Average CE Loss (Source):  0.8070 ( 0.8140) Learning Rate: 0.1000 (0.1000) Top1_base: 78.9062 (77.5469) Top1_base_per_class: 76.2767 (77.8763) 
Training Epoch: [78/1000] Step: [60 / 285] Batch Time: 0.1501 (0.1676) Data Time: 0.0140 (0.0342) Average Loss: 0.6033 (0.8246) Average CE Loss (Source):  0.6033 ( 0.8246) Learning Rate: 0.1000 (0.1000) Top1_base: 78.1250 (77.1354) Top1_base_per_class: 75.3030 (77.6189) 
Training Epoch: [78/1000] Step: [70 / 285] Batch Time: 0.1533 (0.1671) Data Time: 0.0147 (0.0334) Average Loss: 0.6381 (0.8204) Average CE Loss (Source):  0.6381 ( 0.8204) Learning Rate: 0.1000 (0.1000) Top1_base: 84.3750 (77.2321) Top1_base_per_class: 81.4081 (77.6738) 
Training Epoch: [78/1000] Step: [80 / 285] Batch Time: 0.1447 (0.1657) Data Time: 0.0105 (0.0317) Average Loss: 0.8774 (0.8259) Average CE Loss (Source):  0.8774 ( 0.8259) Learning Rate: 0.1000 (0.1000) Top1_base: 78.1250 (77.1289) Top1_base_per_class: 76.1905 (77.6816) 
Training Epoch: [78/1000] Step: [90 / 285] Batch Time: 0.1521 (0.1639) Data Time: 0.0141 (0.0297) Average Loss: 0.8678 (0.8229) Average CE Loss (Source):  0.8678 ( 0.8229) Learning Rate: 0.1000 (0.1000) Top1_base: 77.3438 (77.2656) Top1_base_per_class: 77.2531 (77.8057) 
Training Epoch: [78/1000] Step: [100 / 285] Batch Time: 0.1416 (0.1634) Data Time: 0.0108 (0.0292) Average Loss: 0.7882 (0.8251) Average CE Loss (Source):  0.7882 ( 0.8251) Learning Rate: 0.1000 (0.1000) Top1_base: 77.3438 (77.1250) Top1_base_per_class: 80.7407 (77.7614) 
Training Epoch: [78/1000] Step: [110 / 285] Batch Time: 0.1417 (0.1636) Data Time: 0.0117 (0.0295) Average Loss: 0.8754 (0.8225) Average CE Loss (Source):  0.8754 ( 0.8225) Learning Rate: 0.1000 (0.1000) Top1_base: 76.5625 (77.2443) Top1_base_per_class: 77.8571 (77.8275) 
Training Epoch: [78/1000] Step: [120 / 285] Batch Time: 0.1453 (0.1627) Data Time: 0.0120 (0.0289) Average Loss: 0.5540 (0.8223) Average CE Loss (Source):  0.5540 ( 0.8223) Learning Rate: 0.1000 (0.1000) Top1_base: 84.3750 (77.2201) Top1_base_per_class: 84.8563 (77.8138) 
Training Epoch: [78/1000] Step: [130 / 285] Batch Time: 0.1432 (0.1627) Data Time: 0.0120 (0.0290) Average Loss: 0.9617 (0.8294) Average CE Loss (Source):  0.9617 ( 0.8294) Learning Rate: 0.1000 (0.1000) Top1_base: 74.2188 (77.0312) Top1_base_per_class: 75.3672 (77.6558) 
Training Epoch: [78/1000] Step: [140 / 285] Batch Time: 0.1471 (0.1616) Data Time: 0.0139 (0.0279) Average Loss: 0.9367 (0.8328) Average CE Loss (Source):  0.9367 ( 0.8328) Learning Rate: 0.1000 (0.1000) Top1_base: 73.4375 (76.9308) Top1_base_per_class: 69.7452 (77.4931) 
Training Epoch: [78/1000] Step: [150 / 285] Batch Time: 0.1448 (0.1611) Data Time: 0.0115 (0.0275) Average Loss: 0.7145 (0.8313) Average CE Loss (Source):  0.7145 ( 0.8313) Learning Rate: 0.1000 (0.1000) Top1_base: 84.3750 (76.9688) Top1_base_per_class: 81.9445 (77.4266) 
Training Epoch: [78/1000] Step: [160 / 285] Batch Time: 0.1454 (0.1603) Data Time: 0.0127 (0.0267) Average Loss: 0.8722 (0.8339) Average CE Loss (Source):  0.8722 ( 0.8339) Learning Rate: 0.1000 (0.1000) Top1_base: 78.1250 (76.9482) Top1_base_per_class: 75.2469 (77.4131) 
Training Epoch: [78/1000] Step: [170 / 285] Batch Time: 0.1435 (0.1596) Data Time: 0.0116 (0.0262) Average Loss: 0.8281 (0.8349) Average CE Loss (Source):  0.8281 ( 0.8349) Learning Rate: 0.1000 (0.1000) Top1_base: 76.5625 (76.8796) Top1_base_per_class: 75.8772 (77.2277) 
Training Epoch: [78/1000] Step: [180 / 285] Batch Time: 0.1486 (0.1594) Data Time: 0.0134 (0.0259) Average Loss: 0.8813 (0.8336) Average CE Loss (Source):  0.8813 ( 0.8336) Learning Rate: 0.1000 (0.1000) Top1_base: 74.2188 (76.9141) Top1_base_per_class: 76.5230 (77.2807) 
Training Epoch: [78/1000] Step: [190 / 285] Batch Time: 0.1523 (0.1589) Data Time: 0.0151 (0.0253) Average Loss: 0.8173 (0.8344) Average CE Loss (Source):  0.8173 ( 0.8344) Learning Rate: 0.1000 (0.1000) Top1_base: 73.4375 (76.8997) Top1_base_per_class: 73.7719 (77.2520) 
Training Epoch: [78/1000] Step: [200 / 285] Batch Time: 0.1462 (0.1584) Data Time: 0.0125 (0.0248) Average Loss: 0.9957 (0.8356) Average CE Loss (Source):  0.9957 ( 0.8356) Learning Rate: 0.1000 (0.1000) Top1_base: 70.3125 (76.8438) Top1_base_per_class: 72.4680 (77.2569) 
Training Epoch: [78/1000] Step: [210 / 285] Batch Time: 0.1452 (0.1581) Data Time: 0.0122 (0.0245) Average Loss: 0.8314 (0.8366) Average CE Loss (Source):  0.8314 ( 0.8366) Learning Rate: 0.1000 (0.1000) Top1_base: 75.0000 (76.7820) Top1_base_per_class: 74.6199 (77.2481) 
Training Epoch: [78/1000] Step: [220 / 285] Batch Time: 0.1473 (0.1576) Data Time: 0.0154 (0.0240) Average Loss: 0.8435 (0.8382) Average CE Loss (Source):  0.8435 ( 0.8382) Learning Rate: 0.1000 (0.1000) Top1_base: 81.2500 (76.7223) Top1_base_per_class: 81.7901 (77.2143) 
Training Epoch: [78/1000] Step: [230 / 285] Batch Time: 0.1522 (0.1577) Data Time: 0.0136 (0.0241) Average Loss: 0.8625 (0.8408) Average CE Loss (Source):  0.8625 ( 0.8408) Learning Rate: 0.1000 (0.1000) Top1_base: 76.5625 (76.6644) Top1_base_per_class: 76.2356 (77.1501) 
Training Epoch: [78/1000] Step: [240 / 285] Batch Time: 0.1416 (0.1574) Data Time: 0.0106 (0.0238) Average Loss: 0.8253 (0.8424) Average CE Loss (Source):  0.8253 ( 0.8424) Learning Rate: 0.1000 (0.1000) Top1_base: 79.6875 (76.6374) Top1_base_per_class: 80.1923 (77.1515) 
Training Epoch: [78/1000] Step: [250 / 285] Batch Time: 0.1495 (0.1575) Data Time: 0.0147 (0.0239) Average Loss: 1.0034 (0.8437) Average CE Loss (Source):  1.0034 ( 0.8437) Learning Rate: 0.1000 (0.1000) Top1_base: 69.5312 (76.5938) Top1_base_per_class: 70.2121 (77.1015) 
Training Epoch: [78/1000] Step: [260 / 285] Batch Time: 0.1444 (0.1576) Data Time: 0.0133 (0.0240) Average Loss: 0.7954 (0.8439) Average CE Loss (Source):  0.7954 ( 0.8439) Learning Rate: 0.1000 (0.1000) Top1_base: 75.0000 (76.5535) Top1_base_per_class: 76.9910 (77.1095) 
Training Epoch: [78/1000] Step: [270 / 285] Batch Time: 0.1440 (0.1572) Data Time: 0.0115 (0.0236) Average Loss: 0.6705 (0.8439) Average CE Loss (Source):  0.6705 ( 0.8439) Learning Rate: 0.1000 (0.1000) Top1_base: 82.0312 (76.5509) Top1_base_per_class: 81.0345 (77.0810) 
Training Epoch: [78/1000] Step: [280 / 285] Batch Time: 0.1443 (0.1573) Data Time: 0.0111 (0.0238) Average Loss: 1.0481 (0.8421) Average CE Loss (Source):  1.0481 ( 0.8421) Learning Rate: 0.1000 (0.1000) Top1_base: 70.3125 (76.5737) Top1_base_per_class: 71.0819 (77.1308) 
Training Epoch: [79/1000] Step: [0] Batch Time: 0.1450 (0.1571) Data Time: 0.0102 (0.0236) Average Loss: 1.1411 (0.8434) Average CE Loss (Source):  1.1411 ( 0.8434) Learning Rate: 0.1000 (0.1000) Top1_base: 71.0938 (76.5625) Top1_base_per_class: 74.6541 (77.1103) 
Training Epoch: [79/1000] Step: [10 / 285] Batch Time: 0.1676 (0.2329) Data Time: 0.0350 (0.1007) Average Loss: 1.1681 (0.8872) Average CE Loss (Source):  1.1681 ( 0.8872) Learning Rate: 0.1000 (0.1000) Top1_base: 65.6250 (75.5469) Top1_base_per_class: 71.0345 (76.5813) 
Training Epoch: [79/1000] Step: [20 / 285] Batch Time: 0.1477 (0.1959) Data Time: 0.0134 (0.0634) Average Loss: 0.8433 (0.8341) Average CE Loss (Source):  0.8433 ( 0.8341) Learning Rate: 0.1000 (0.1000) Top1_base: 76.5625 (76.5234) Top1_base_per_class: 80.5769 (77.6401) 
Training Epoch: [79/1000] Step: [30 / 285] Batch Time: 0.1930 (0.1860) Data Time: 0.0612 (0.0533) Average Loss: 0.5681 (0.8115) Average CE Loss (Source):  0.5681 ( 0.8115) Learning Rate: 0.1000 (0.1000) Top1_base: 89.0625 (77.1354) Top1_base_per_class: 88.7273 (78.1172) 
Training Epoch: [79/1000] Step: [40 / 285] Batch Time: 0.1485 (0.1772) Data Time: 0.0142 (0.0444) Average Loss: 0.7562 (0.7951) Average CE Loss (Source):  0.7562 ( 0.7951) Learning Rate: 0.1000 (0.1000) Top1_base: 78.9062 (77.7344) Top1_base_per_class: 82.0546 (78.7991) 
Training Epoch: [79/1000] Step: [50 / 285] Batch Time: 0.1689 (0.1734) Data Time: 0.0366 (0.0406) Average Loss: 0.7711 (0.7992) Average CE Loss (Source):  0.7711 ( 0.7992) Learning Rate: 0.1000 (0.1000) Top1_base: 81.2500 (77.6250) Top1_base_per_class: 82.8231 (78.5964) 
Training Epoch: [79/1000] Step: [60 / 285] Batch Time: 0.1436 (0.1714) Data Time: 0.0121 (0.0386) Average Loss: 0.8368 (0.8014) Average CE Loss (Source):  0.8368 ( 0.8014) Learning Rate: 0.1000 (0.1000) Top1_base: 77.3438 (77.6953) Top1_base_per_class: 77.5758 (78.4967) 
Training Epoch: [79/1000] Step: [70 / 285] Batch Time: 0.1618 (0.1683) Data Time: 0.0315 (0.0355) Average Loss: 1.0473 (0.8003) Average CE Loss (Source):  1.0473 ( 0.8003) Learning Rate: 0.1000 (0.1000) Top1_base: 67.9688 (77.6228) Top1_base_per_class: 67.9739 (78.3670) 
Training Epoch: [79/1000] Step: [80 / 285] Batch Time: 0.1465 (0.1671) Data Time: 0.0133 (0.0343) Average Loss: 0.8366 (0.8010) Average CE Loss (Source):  0.8366 ( 0.8010) Learning Rate: 0.1000 (0.1000) Top1_base: 78.9062 (77.6367) Top1_base_per_class: 78.7427 (78.2943) 
Training Epoch: [79/1000] Step: [90 / 285] Batch Time: 0.1763 (0.1659) Data Time: 0.0453 (0.0331) Average Loss: 0.6525 (0.7924) Average CE Loss (Source):  0.6525 ( 0.7924) Learning Rate: 0.1000 (0.1000) Top1_base: 80.4688 (77.7344) Top1_base_per_class: 80.9697 (78.3291) 
Training Epoch: [79/1000] Step: [100 / 285] Batch Time: 0.1478 (0.1644) Data Time: 0.0140 (0.0316) Average Loss: 0.8632 (0.7924) Average CE Loss (Source):  0.8632 ( 0.7924) Learning Rate: 0.1000 (0.1000) Top1_base: 74.2188 (77.7500) Top1_base_per_class: 74.5614 (78.2948) 
Training Epoch: [79/1000] Step: [110 / 285] Batch Time: 0.1525 (0.1632) Data Time: 0.0208 (0.0304) Average Loss: 0.7894 (0.7960) Average CE Loss (Source):  0.7894 ( 0.7960) Learning Rate: 0.1000 (0.1000) Top1_base: 75.0000 (77.6918) Top1_base_per_class: 72.9630 (78.3338) 
Training Epoch: [79/1000] Step: [120 / 285] Batch Time: 0.1520 (0.1621) Data Time: 0.0138 (0.0290) Average Loss: 0.9911 (0.7963) Average CE Loss (Source):  0.9911 ( 0.7963) Learning Rate: 0.1000 (0.1000) Top1_base: 69.5312 (77.5911) Top1_base_per_class: 74.2048 (78.2443) 
Training Epoch: [79/1000] Step: [130 / 285] Batch Time: 0.1650 (0.1610) Data Time: 0.0348 (0.0280) Average Loss: 0.8029 (0.7943) Average CE Loss (Source):  0.8029 ( 0.7943) Learning Rate: 0.1000 (0.1000) Top1_base: 77.3438 (77.6743) Top1_base_per_class: 76.0494 (78.3648) 
Training Epoch: [79/1000] Step: [140 / 285] Batch Time: 0.1451 (0.1605) Data Time: 0.0129 (0.0275) Average Loss: 0.8539 (0.7953) Average CE Loss (Source):  0.8539 ( 0.7953) Learning Rate: 0.1000 (0.1000) Top1_base: 76.5625 (77.6842) Top1_base_per_class: 76.2160 (78.3645) 
Training Epoch: [79/1000] Step: [150 / 285] Batch Time: 0.1626 (0.1600) Data Time: 0.0305 (0.0271) Average Loss: 1.0119 (0.7997) Average CE Loss (Source):  1.0119 ( 0.7997) Learning Rate: 0.1000 (0.1000) Top1_base: 77.3438 (77.6146) Top1_base_per_class: 79.4122 (78.3051) 
Training Epoch: [79/1000] Step: [160 / 285] Batch Time: 0.1428 (0.1596) Data Time: 0.0124 (0.0268) Average Loss: 0.8633 (0.8051) Average CE Loss (Source):  0.8633 ( 0.8051) Learning Rate: 0.1000 (0.1000) Top1_base: 77.3438 (77.5195) Top1_base_per_class: 76.3580 (78.2126) 
Training Epoch: [79/1000] Step: [170 / 285] Batch Time: 0.1998 (0.1592) Data Time: 0.0682 (0.0263) Average Loss: 1.0126 (0.8117) Average CE Loss (Source):  1.0126 ( 0.8117) Learning Rate: 0.1000 (0.1000) Top1_base: 71.8750 (77.3575) Top1_base_per_class: 75.4301 (78.0912) 
Training Epoch: [79/1000] Step: [180 / 285] Batch Time: 0.1463 (0.1586) Data Time: 0.0136 (0.0257) Average Loss: 0.6887 (0.8155) Average CE Loss (Source):  0.6887 ( 0.8155) Learning Rate: 0.1000 (0.1000) Top1_base: 77.3438 (77.2439) Top1_base_per_class: 79.2738 (78.0357) 
Training Epoch: [79/1000] Step: [190 / 285] Batch Time: 0.1980 (0.1585) Data Time: 0.0602 (0.0255) Average Loss: 0.7738 (0.8163) Average CE Loss (Source):  0.7738 ( 0.8163) Learning Rate: 0.1000 (0.1000) Top1_base: 80.4688 (77.2656) Top1_base_per_class: 79.7126 (78.0470) 
Training Epoch: [79/1000] Step: [200 / 285] Batch Time: 0.1516 (0.1584) Data Time: 0.0142 (0.0253) Average Loss: 0.9137 (0.8184) Average CE Loss (Source):  0.9137 ( 0.8184) Learning Rate: 0.1000 (0.1000) Top1_base: 73.4375 (77.1836) Top1_base_per_class: 72.9096 (77.9371) 
Training Epoch: [79/1000] Step: [210 / 285] Batch Time: 0.1458 (0.1578) Data Time: 0.0141 (0.0248) Average Loss: 0.9206 (0.8221) Average CE Loss (Source):  0.9206 ( 0.8221) Learning Rate: 0.1000 (0.1000) Top1_base: 75.0000 (77.0908) Top1_base_per_class: 74.1326 (77.8325) 
Training Epoch: [79/1000] Step: [220 / 285] Batch Time: 0.1432 (0.1573) Data Time: 0.0122 (0.0244) Average Loss: 0.8764 (0.8223) Average CE Loss (Source):  0.8764 ( 0.8223) Learning Rate: 0.1000 (0.1000) Top1_base: 75.7812 (77.1129) Top1_base_per_class: 71.9048 (77.7764) 
Training Epoch: [79/1000] Step: [230 / 285] Batch Time: 0.1491 (0.1573) Data Time: 0.0145 (0.0244) Average Loss: 0.8947 (0.8245) Average CE Loss (Source):  0.8947 ( 0.8245) Learning Rate: 0.1000 (0.1000) Top1_base: 74.2188 (77.0516) Top1_base_per_class: 73.2897 (77.6820) 
Training Epoch: [79/1000] Step: [240 / 285] Batch Time: 0.1506 (0.1572) Data Time: 0.0136 (0.0242) Average Loss: 0.9022 (0.8245) Average CE Loss (Source):  0.9022 ( 0.8245) Learning Rate: 0.1000 (0.1000) Top1_base: 68.7500 (77.0443) Top1_base_per_class: 68.3974 (77.6787) 
Training Epoch: [79/1000] Step: [250 / 285] Batch Time: 0.1445 (0.1571) Data Time: 0.0114 (0.0241) Average Loss: 0.8361 (0.8258) Average CE Loss (Source):  0.8361 ( 0.8258) Learning Rate: 0.1000 (0.1000) Top1_base: 75.7812 (77.0187) Top1_base_per_class: 77.0468 (77.5701) 
Training Epoch: [79/1000] Step: [260 / 285] Batch Time: 0.1423 (0.1570) Data Time: 0.0114 (0.0241) Average Loss: 0.7797 (0.8269) Average CE Loss (Source):  0.7797 ( 0.8269) Learning Rate: 0.1000 (0.1000) Top1_base: 82.0312 (77.0192) Top1_base_per_class: 84.4253 (77.5505) 
Training Epoch: [79/1000] Step: [270 / 285] Batch Time: 0.1463 (0.1569) Data Time: 0.0115 (0.0240) Average Loss: 1.0249 (0.8295) Average CE Loss (Source):  1.0249 ( 0.8295) Learning Rate: 0.1000 (0.1000) Top1_base: 70.3125 (76.9387) Top1_base_per_class: 71.3393 (77.4268) 
Training Epoch: [79/1000] Step: [280 / 285] Batch Time: 0.1506 (0.1567) Data Time: 0.0139 (0.0237) Average Loss: 0.9725 (0.8340) Average CE Loss (Source):  0.9725 ( 0.8340) Learning Rate: 0.1000 (0.1000) Top1_base: 71.0938 (76.8220) Top1_base_per_class: 73.3962 (77.3169) 
Training Epoch: [80/1000] Step: [0] Batch Time: 0.1407 (0.1564) Data Time: 0.0101 (0.0235) Average Loss: 0.8630 (0.8351) Average CE Loss (Source):  0.8630 ( 0.8351) Learning Rate: 0.1000 (0.1000) Top1_base: 75.0000 (76.7845) Top1_base_per_class: 78.9623 (77.3218) 
  8%|▊         | 80/1000 [1:02:51<11:53:55, 46.56s/it]  8%|▊         | 81/1000 [1:03:37<11:49:04, 46.29s/it]Training Epoch: [80/1000] Step: [10 / 285] Batch Time: 0.1475 (0.2425) Data Time: 0.0150 (0.1086) Average Loss: 1.0110 (0.8246) Average CE Loss (Source):  1.0110 ( 0.8246) Learning Rate: 0.1000 (0.1000) Top1_base: 71.8750 (77.7344) Top1_base_per_class: 71.9551 (77.0561) 
Training Epoch: [80/1000] Step: [20 / 285] Batch Time: 0.1474 (0.1968) Data Time: 0.0109 (0.0628) Average Loss: 0.8072 (0.8351) Average CE Loss (Source):  0.8072 ( 0.8351) Learning Rate: 0.1000 (0.1000) Top1_base: 76.5625 (76.4844) Top1_base_per_class: 76.3450 (75.9991) 
Training Epoch: [80/1000] Step: [30 / 285] Batch Time: 0.1517 (0.1861) Data Time: 0.0190 (0.0521) Average Loss: 0.5765 (0.8058) Average CE Loss (Source):  0.5765 ( 0.8058) Learning Rate: 0.1000 (0.1000) Top1_base: 82.0312 (77.1615) Top1_base_per_class: 83.2184 (77.1809) 
Training Epoch: [80/1000] Step: [40 / 285] Batch Time: 0.1459 (0.1798) Data Time: 0.0109 (0.0457) Average Loss: 0.6615 (0.8083) Average CE Loss (Source):  0.6615 ( 0.8083) Learning Rate: 0.1000 (0.1000) Top1_base: 79.6875 (76.9727) Top1_base_per_class: 79.8721 (76.9222) 
Training Epoch: [80/1000] Step: [50 / 285] Batch Time: 0.1510 (0.1758) Data Time: 0.0174 (0.0416) Average Loss: 0.9444 (0.8107) Average CE Loss (Source):  0.9444 ( 0.8107) Learning Rate: 0.1000 (0.1000) Top1_base: 74.2188 (76.9219) Top1_base_per_class: 72.8752 (76.8225) 
Training Epoch: [80/1000] Step: [60 / 285] Batch Time: 0.1416 (0.1715) Data Time: 0.0102 (0.0375) Average Loss: 0.6526 (0.8231) Average CE Loss (Source):  0.6526 ( 0.8231) Learning Rate: 0.1000 (0.1000) Top1_base: 84.3750 (76.9141) Top1_base_per_class: 84.7170 (77.0148) 
Training Epoch: [80/1000] Step: [70 / 285] Batch Time: 0.1489 (0.1696) Data Time: 0.0163 (0.0357) Average Loss: 0.8676 (0.8195) Average CE Loss (Source):  0.8676 ( 0.8195) Learning Rate: 0.1000 (0.1000) Top1_base: 73.4375 (76.8192) Top1_base_per_class: 74.9326 (76.9501) 
Training Epoch: [80/1000] Step: [80 / 285] Batch Time: 0.1448 (0.1681) Data Time: 0.0125 (0.0343) Average Loss: 0.8487 (0.8269) Average CE Loss (Source):  0.8487 ( 0.8269) Learning Rate: 0.1000 (0.1000) Top1_base: 79.6875 (76.6504) Top1_base_per_class: 80.7407 (76.8358) 
Training Epoch: [80/1000] Step: [90 / 285] Batch Time: 0.1499 (0.1669) Data Time: 0.0144 (0.0331) Average Loss: 0.8609 (0.8301) Average CE Loss (Source):  0.8609 ( 0.8301) Learning Rate: 0.1000 (0.1000) Top1_base: 77.3438 (76.7448) Top1_base_per_class: 76.2573 (76.8886) 
Training Epoch: [80/1000] Step: [100 / 285] Batch Time: 0.1463 (0.1660) Data Time: 0.0111 (0.0322) Average Loss: 0.9769 (0.8294) Average CE Loss (Source):  0.9769 ( 0.8294) Learning Rate: 0.1000 (0.1000) Top1_base: 75.7812 (76.7734) Top1_base_per_class: 75.7051 (76.9719) 
Training Epoch: [80/1000] Step: [110 / 285] Batch Time: 0.1463 (0.1655) Data Time: 0.0143 (0.0318) Average Loss: 0.8056 (0.8257) Average CE Loss (Source):  0.8056 ( 0.8257) Learning Rate: 0.1000 (0.1000) Top1_base: 78.1250 (76.8395) Top1_base_per_class: 82.3585 (77.0169) 
Training Epoch: [80/1000] Step: [120 / 285] Batch Time: 0.1441 (0.1652) Data Time: 0.0120 (0.0315) Average Loss: 0.8418 (0.8278) Average CE Loss (Source):  0.8418 ( 0.8278) Learning Rate: 0.1000 (0.1000) Top1_base: 78.1250 (76.7904) Top1_base_per_class: 77.2701 (77.0600) 
Training Epoch: [80/1000] Step: [130 / 285] Batch Time: 0.1496 (0.1645) Data Time: 0.0118 (0.0308) Average Loss: 0.9803 (0.8278) Average CE Loss (Source):  0.9803 ( 0.8278) Learning Rate: 0.1000 (0.1000) Top1_base: 72.6562 (76.8990) Top1_base_per_class: 70.9444 (77.1166) 
Training Epoch: [80/1000] Step: [140 / 285] Batch Time: 0.1540 (0.1639) Data Time: 0.0141 (0.0300) Average Loss: 0.8735 (0.8327) Average CE Loss (Source):  0.8735 ( 0.8327) Learning Rate: 0.1000 (0.1000) Top1_base: 78.1250 (76.8304) Top1_base_per_class: 78.3951 (77.0922) 
Training Epoch: [80/1000] Step: [150 / 285] Batch Time: 0.1508 (0.1634) Data Time: 0.0157 (0.0293) Average Loss: 0.7558 (0.8350) Average CE Loss (Source):  0.7558 ( 0.8350) Learning Rate: 0.1000 (0.1000) Top1_base: 73.4375 (76.7760) Top1_base_per_class: 73.0449 (77.0701) 
Training Epoch: [80/1000] Step: [160 / 285] Batch Time: 0.1484 (0.1626) Data Time: 0.0141 (0.0284) Average Loss: 0.8224 (0.8359) Average CE Loss (Source):  0.8224 ( 0.8359) Learning Rate: 0.1000 (0.1000) Top1_base: 78.1250 (76.8115) Top1_base_per_class: 80.8772 (77.1455) 
Training Epoch: [80/1000] Step: [170 / 285] Batch Time: 0.1503 (0.1619) Data Time: 0.0158 (0.0276) Average Loss: 1.0727 (0.8383) Average CE Loss (Source):  1.0727 ( 0.8383) Learning Rate: 0.1000 (0.1000) Top1_base: 72.6562 (76.8199) Top1_base_per_class: 73.1410 (77.1238) 
Training Epoch: [80/1000] Step: [180 / 285] Batch Time: 0.1464 (0.1615) Data Time: 0.0137 (0.0272) Average Loss: 0.8234 (0.8392) Average CE Loss (Source):  0.8234 ( 0.8392) Learning Rate: 0.1000 (0.1000) Top1_base: 75.0000 (76.7969) Top1_base_per_class: 77.3099 (77.1075) 
Training Epoch: [80/1000] Step: [190 / 285] Batch Time: 0.1506 (0.1610) Data Time: 0.0154 (0.0268) Average Loss: 0.9742 (0.8415) Average CE Loss (Source):  0.9742 ( 0.8415) Learning Rate: 0.1000 (0.1000) Top1_base: 70.3125 (76.6859) Top1_base_per_class: 69.7917 (77.0318) 
Training Epoch: [80/1000] Step: [200 / 285] Batch Time: 0.1478 (0.1605) Data Time: 0.0128 (0.0263) Average Loss: 0.7487 (0.8439) Average CE Loss (Source):  0.7487 ( 0.8439) Learning Rate: 0.1000 (0.1000) Top1_base: 75.0000 (76.6016) Top1_base_per_class: 76.9048 (77.0326) 
Training Epoch: [80/1000] Step: [210 / 285] Batch Time: 0.1790 (0.1605) Data Time: 0.0461 (0.0263) Average Loss: 0.9838 (0.8441) Average CE Loss (Source):  0.9838 ( 0.8441) Learning Rate: 0.1000 (0.1000) Top1_base: 71.8750 (76.5997) Top1_base_per_class: 73.8485 (77.0280) 
Training Epoch: [80/1000] Step: [220 / 285] Batch Time: 0.1565 (0.1609) Data Time: 0.0186 (0.0266) Average Loss: 0.5622 (0.8425) Average CE Loss (Source):  0.5622 ( 0.8425) Learning Rate: 0.1000 (0.1000) Top1_base: 84.3750 (76.6300) Top1_base_per_class: 86.3030 (77.0816) 
Training Epoch: [80/1000] Step: [230 / 285] Batch Time: 0.1723 (0.1607) Data Time: 0.0407 (0.0264) Average Loss: 0.8157 (0.8431) Average CE Loss (Source):  0.8157 ( 0.8431) Learning Rate: 0.1000 (0.1000) Top1_base: 77.3438 (76.6101) Top1_base_per_class: 78.2026 (77.0902) 
Training Epoch: [80/1000] Step: [240 / 285] Batch Time: 0.1484 (0.1603) Data Time: 0.0150 (0.0260) Average Loss: 0.7735 (0.8453) Average CE Loss (Source):  0.7735 ( 0.8453) Learning Rate: 0.1000 (0.1000) Top1_base: 82.0312 (76.5299) Top1_base_per_class: 78.4153 (77.0296) 
Training Epoch: [80/1000] Step: [250 / 285] Batch Time: 0.1561 (0.1603) Data Time: 0.0233 (0.0261) Average Loss: 0.8528 (0.8457) Average CE Loss (Source):  0.8528 ( 0.8457) Learning Rate: 0.1000 (0.1000) Top1_base: 77.3438 (76.5094) Top1_base_per_class: 77.0833 (77.0144) 
Training Epoch: [80/1000] Step: [260 / 285] Batch Time: 0.1458 (0.1601) Data Time: 0.0152 (0.0259) Average Loss: 0.8308 (0.8468) Average CE Loss (Source):  0.8308 ( 0.8468) Learning Rate: 0.1000 (0.1000) Top1_base: 76.5625 (76.5054) Top1_base_per_class: 79.4152 (77.0535) 
Training Epoch: [80/1000] Step: [270 / 285] Batch Time: 0.1490 (0.1600) Data Time: 0.0169 (0.0257) Average Loss: 1.0303 (0.8499) Average CE Loss (Source):  1.0303 ( 0.8499) Learning Rate: 0.1000 (0.1000) Top1_base: 73.4375 (76.4612) Top1_base_per_class: 74.2544 (77.0529) 
Training Epoch: [80/1000] Step: [280 / 285] Batch Time: 0.1456 (0.1598) Data Time: 0.0114 (0.0256) Average Loss: 0.8944 (0.8487) Average CE Loss (Source):  0.8944 ( 0.8487) Learning Rate: 0.1000 (0.1000) Top1_base: 75.0000 (76.5011) Top1_base_per_class: 77.1136 (77.0749) 
Training Epoch: [81/1000] Step: [0] Batch Time: 0.1478 (0.1597) Data Time: 0.0141 (0.0255) Average Loss: 0.6764 (0.8494) Average CE Loss (Source):  0.6764 ( 0.8494) Learning Rate: 0.1000 (0.1000) Top1_base: 83.5938 (76.4857) Top1_base_per_class: 86.1988 (77.0707) 
Training Epoch: [81/1000] Step: [10 / 285] Batch Time: 0.1493 (0.2305) Data Time: 0.0145 (0.0949) Average Loss: 0.7430 (0.7852) Average CE Loss (Source):  0.7430 ( 0.7852) Learning Rate: 0.1000 (0.1000) Top1_base: 80.4688 (78.2031) Top1_base_per_class: 84.2575 (79.5635) 
Training Epoch: [81/1000] Step: [20 / 285] Batch Time: 0.1528 (0.1990) Data Time: 0.0146 (0.0630) Average Loss: 0.8375 (0.7774) Average CE Loss (Source):  0.8375 ( 0.7774) Learning Rate: 0.1000 (0.1000) Top1_base: 75.7812 (78.2031) Top1_base_per_class: 76.1635 (79.8267) 
Training Epoch: [81/1000] Step: [30 / 285] Batch Time: 0.1636 (0.1839) Data Time: 0.0289 (0.0478) Average Loss: 0.8404 (0.7886) Average CE Loss (Source):  0.8404 ( 0.7886) Learning Rate: 0.1000 (0.1000) Top1_base: 78.1250 (77.9948) Top1_base_per_class: 78.2749 (79.3441) 
Training Epoch: [81/1000] Step: [40 / 285] Batch Time: 0.1501 (0.1767) Data Time: 0.0111 (0.0409) Average Loss: 0.8255 (0.7985) Average CE Loss (Source):  0.8255 ( 0.7985) Learning Rate: 0.1000 (0.1000) Top1_base: 76.5625 (77.6758) Top1_base_per_class: 79.0230 (79.1889) 
Training Epoch: [81/1000] Step: [50 / 285] Batch Time: 0.1458 (0.1714) Data Time: 0.0141 (0.0360) Average Loss: 0.9524 (0.7938) Average CE Loss (Source):  0.9524 ( 0.7938) Learning Rate: 0.1000 (0.1000) Top1_base: 73.4375 (77.6250) Top1_base_per_class: 77.3333 (78.9855) 
Training Epoch: [81/1000] Step: [60 / 285] Batch Time: 0.1518 (0.1711) Data Time: 0.0142 (0.0358) Average Loss: 0.7699 (0.7951) Average CE Loss (Source):  0.7699 ( 0.7951) Learning Rate: 0.1000 (0.1000) Top1_base: 81.2500 (77.4479) Top1_base_per_class: 83.4463 (78.4876) 
Training Epoch: [81/1000] Step: [70 / 285] Batch Time: 0.1502 (0.1680) Data Time: 0.0172 (0.0328) Average Loss: 0.8693 (0.7945) Average CE Loss (Source):  0.8693 ( 0.7945) Learning Rate: 0.1000 (0.1000) Top1_base: 72.6562 (77.4107) Top1_base_per_class: 73.6601 (78.3187) 
Training Epoch: [81/1000] Step: [80 / 285] Batch Time: 0.1511 (0.1662) Data Time: 0.0137 (0.0312) Average Loss: 0.7522 (0.7954) Average CE Loss (Source):  0.7522 ( 0.7954) Learning Rate: 0.1000 (0.1000) Top1_base: 76.5625 (77.4219) Top1_base_per_class: 76.0185 (78.1428) 
Training Epoch: [81/1000] Step: [90 / 285] Batch Time: 0.1521 (0.1643) Data Time: 0.0185 (0.0293) Average Loss: 0.8890 (0.8032) Average CE Loss (Source):  0.8890 ( 0.8032) Learning Rate: 0.1000 (0.1000) Top1_base: 77.3438 (77.3872) Top1_base_per_class: 78.5455 (77.9889) 
Training Epoch: [81/1000] Step: [100 / 285] Batch Time: 0.1482 (0.1637) Data Time: 0.0136 (0.0289) Average Loss: 0.8378 (0.8083) Average CE Loss (Source):  0.8378 ( 0.8083) Learning Rate: 0.1000 (0.1000) Top1_base: 78.9062 (77.1953) Top1_base_per_class: 81.0119 (77.8287) 
Training Epoch: [81/1000] Step: [110 / 285] Batch Time: 0.1812 (0.1632) Data Time: 0.0487 (0.0285) Average Loss: 0.7583 (0.8052) Average CE Loss (Source):  0.7583 ( 0.8052) Learning Rate: 0.1000 (0.1000) Top1_base: 77.3438 (77.3366) Top1_base_per_class: 73.2407 (77.8885) 
Training Epoch: [81/1000] Step: [120 / 285] Batch Time: 0.1493 (0.1635) Data Time: 0.0143 (0.0290) Average Loss: 0.9488 (0.8064) Average CE Loss (Source):  0.9488 ( 0.8064) Learning Rate: 0.1000 (0.1000) Top1_base: 71.8750 (77.2982) Top1_base_per_class: 71.2147 (77.9555) 
Training Epoch: [81/1000] Step: [130 / 285] Batch Time: 0.1833 (0.1626) Data Time: 0.0525 (0.0281) Average Loss: 0.8160 (0.8039) Average CE Loss (Source):  0.8160 ( 0.8039) Learning Rate: 0.1000 (0.1000) Top1_base: 78.9062 (77.4159) Top1_base_per_class: 81.7628 (78.0880) 
Training Epoch: [81/1000] Step: [140 / 285] Batch Time: 0.1501 (0.1623) Data Time: 0.0153 (0.0278) Average Loss: 0.8510 (0.8043) Average CE Loss (Source):  0.8510 ( 0.8043) Learning Rate: 0.1000 (0.1000) Top1_base: 73.4375 (77.4498) Top1_base_per_class: 71.4947 (78.0739) 
Training Epoch: [81/1000] Step: [150 / 285] Batch Time: 0.1517 (0.1617) Data Time: 0.0174 (0.0273) Average Loss: 1.0039 (0.8095) Average CE Loss (Source):  1.0039 ( 0.8095) Learning Rate: 0.1000 (0.1000) Top1_base: 70.3125 (77.3646) Top1_base_per_class: 72.7160 (77.9515) 
Training Epoch: [81/1000] Step: [160 / 285] Batch Time: 0.1432 (0.1619) Data Time: 0.0113 (0.0276) Average Loss: 0.9225 (0.8111) Average CE Loss (Source):  0.9225 ( 0.8111) Learning Rate: 0.1000 (0.1000) Top1_base: 75.0000 (77.3486) Top1_base_per_class: 74.9697 (77.8550) 
Training Epoch: [81/1000] Step: [170 / 285] Batch Time: 0.1877 (0.1617) Data Time: 0.0556 (0.0275) Average Loss: 0.9950 (0.8137) Average CE Loss (Source):  0.9950 ( 0.8137) Learning Rate: 0.1000 (0.1000) Top1_base: 71.8750 (77.3254) Top1_base_per_class: 73.2440 (77.8815) 
Training Epoch: [81/1000] Step: [180 / 285] Batch Time: 0.1472 (0.1611) Data Time: 0.0138 (0.0269) Average Loss: 0.7682 (0.8129) Average CE Loss (Source):  0.7682 ( 0.8129) Learning Rate: 0.1000 (0.1000) Top1_base: 80.4688 (77.4219) Top1_base_per_class: 81.2418 (78.0141) 
Training Epoch: [81/1000] Step: [190 / 285] Batch Time: 0.1719 (0.1607) Data Time: 0.0399 (0.0266) Average Loss: 0.7819 (0.8159) Average CE Loss (Source):  0.7819 ( 0.8159) Learning Rate: 0.1000 (0.1000) Top1_base: 78.9062 (77.3273) Top1_base_per_class: 79.0606 (77.9254) 
Training Epoch: [81/1000] Step: [200 / 285] Batch Time: 0.1507 (0.1606) Data Time: 0.0150 (0.0264) Average Loss: 0.9882 (0.8186) Average CE Loss (Source):  0.9882 ( 0.8186) Learning Rate: 0.1000 (0.1000) Top1_base: 68.7500 (77.2188) Top1_base_per_class: 72.9351 (77.8745) 
Training Epoch: [81/1000] Step: [210 / 285] Batch Time: 0.1623 (0.1602) Data Time: 0.0309 (0.0260) Average Loss: 0.6748 (0.8220) Average CE Loss (Source):  0.6748 ( 0.8220) Learning Rate: 0.1000 (0.1000) Top1_base: 80.4688 (77.1280) Top1_base_per_class: 81.6964 (77.7933) 
Training Epoch: [81/1000] Step: [220 / 285] Batch Time: 0.1534 (0.1597) Data Time: 0.0156 (0.0255) Average Loss: 0.9138 (0.8227) Average CE Loss (Source):  0.9138 ( 0.8227) Learning Rate: 0.1000 (0.1000) Top1_base: 76.5625 (77.1023) Top1_base_per_class: 78.3621 (77.7488) 
Training Epoch: [81/1000] Step: [230 / 285] Batch Time: 0.1488 (0.1596) Data Time: 0.0153 (0.0252) Average Loss: 0.9417 (0.8268) Average CE Loss (Source):  0.9417 ( 0.8268) Learning Rate: 0.1000 (0.1000) Top1_base: 74.2188 (76.9769) Top1_base_per_class: 73.3951 (77.6388) 
Training Epoch: [81/1000] Step: [240 / 285] Batch Time: 0.1525 (0.1593) Data Time: 0.0150 (0.0250) Average Loss: 0.9112 (0.8281) Average CE Loss (Source):  0.9112 ( 0.8281) Learning Rate: 0.1000 (0.1000) Top1_base: 77.3438 (76.9010) Top1_base_per_class: 73.4503 (77.5664) 
Training Epoch: [81/1000] Step: [250 / 285] Batch Time: 0.1622 (0.1592) Data Time: 0.0312 (0.0248) Average Loss: 0.9170 (0.8330) Average CE Loss (Source):  0.9170 ( 0.8330) Learning Rate: 0.1000 (0.1000) Top1_base: 75.0000 (76.7438) Top1_base_per_class: 77.9874 (77.4157) 
Training Epoch: [81/1000] Step: [260 / 285] Batch Time: 0.1455 (0.1587) Data Time: 0.0121 (0.0244) Average Loss: 1.1008 (0.8370) Average CE Loss (Source):  1.1008 ( 0.8370) Learning Rate: 0.1000 (0.1000) Top1_base: 72.6562 (76.6677) Top1_base_per_class: 73.7500 (77.3108) 
Training Epoch: [81/1000] Step: [270 / 285] Batch Time: 0.1722 (0.1587) Data Time: 0.0402 (0.0245) Average Loss: 0.8370 (0.8389) Average CE Loss (Source):  0.8370 ( 0.8389) Learning Rate: 0.1000 (0.1000) Top1_base: 81.2500 (76.6551) Top1_base_per_class: 79.3518 (77.2823) 
Training Epoch: [81/1000] Step: [280 / 285] Batch Time: 0.1509 (0.1584) Data Time: 0.0135 (0.0242) Average Loss: 0.8446 (0.8392) Average CE Loss (Source):  0.8446 ( 0.8392) Learning Rate: 0.1000 (0.1000) Top1_base: 75.0000 (76.5932) Top1_base_per_class: 71.6374 (77.2249) 
Training Epoch: [82/1000] Step: [0] Batch Time: 0.1455 (0.1583) Data Time: 0.0117 (0.0240) Average Loss: 0.8856 (0.8407) Average CE Loss (Source):  0.8856 ( 0.8407) Learning Rate: 0.1000 (0.1000) Top1_base: 75.0000 (76.5707) Top1_base_per_class: 77.0760 (77.2113) 
  8%|▊         | 82/1000 [1:04:25<11:56:08, 46.81s/it]  8%|▊         | 83/1000 [1:05:10<11:49:40, 46.43s/it]Training Epoch: [82/1000] Step: [10 / 285] Batch Time: 0.1479 (0.2348) Data Time: 0.0122 (0.1016) Average Loss: 0.7765 (0.8358) Average CE Loss (Source):  0.7765 ( 0.8358) Learning Rate: 0.1000 (0.1000) Top1_base: 81.2500 (77.5000) Top1_base_per_class: 80.1843 (77.4899) 
Training Epoch: [82/1000] Step: [20 / 285] Batch Time: 0.1460 (0.2025) Data Time: 0.0121 (0.0694) Average Loss: 0.6690 (0.7944) Average CE Loss (Source):  0.6690 ( 0.7944) Learning Rate: 0.1000 (0.1000) Top1_base: 82.8125 (78.4375) Top1_base_per_class: 85.0132 (78.6760) 
Training Epoch: [82/1000] Step: [30 / 285] Batch Time: 0.1458 (0.1900) Data Time: 0.0115 (0.0571) Average Loss: 0.8299 (0.7978) Average CE Loss (Source):  0.8299 ( 0.7978) Learning Rate: 0.1000 (0.1000) Top1_base: 76.5625 (78.1250) Top1_base_per_class: 79.4340 (78.4162) 
Training Epoch: [82/1000] Step: [40 / 285] Batch Time: 0.1446 (0.1808) Data Time: 0.0110 (0.0478) Average Loss: 0.7921 (0.7955) Average CE Loss (Source):  0.7921 ( 0.7955) Learning Rate: 0.1000 (0.1000) Top1_base: 78.1250 (78.0273) Top1_base_per_class: 78.1000 (78.1942) 
Training Epoch: [82/1000] Step: [50 / 285] Batch Time: 0.1462 (0.1789) Data Time: 0.0106 (0.0458) Average Loss: 0.7835 (0.8026) Average CE Loss (Source):  0.7835 ( 0.8026) Learning Rate: 0.1000 (0.1000) Top1_base: 82.0312 (77.7969) Top1_base_per_class: 84.5459 (78.1964) 
Training Epoch: [82/1000] Step: [60 / 285] Batch Time: 0.1450 (0.1748) Data Time: 0.0136 (0.0417) Average Loss: 0.5495 (0.8075) Average CE Loss (Source):  0.5495 ( 0.8075) Learning Rate: 0.1000 (0.1000) Top1_base: 81.2500 (77.5260) Top1_base_per_class: 83.8988 (77.9895) 
Training Epoch: [82/1000] Step: [70 / 285] Batch Time: 0.1484 (0.1719) Data Time: 0.0150 (0.0388) Average Loss: 0.7601 (0.8099) Average CE Loss (Source):  0.7601 ( 0.8099) Learning Rate: 0.1000 (0.1000) Top1_base: 83.5938 (77.5446) Top1_base_per_class: 88.4127 (78.0001) 
Training Epoch: [82/1000] Step: [80 / 285] Batch Time: 0.1450 (0.1702) Data Time: 0.0123 (0.0370) Average Loss: 0.5764 (0.8132) Average CE Loss (Source):  0.5764 ( 0.8132) Learning Rate: 0.1000 (0.1000) Top1_base: 85.9375 (77.5781) Top1_base_per_class: 86.0913 (77.9939) 
Training Epoch: [82/1000] Step: [90 / 285] Batch Time: 0.1431 (0.1683) Data Time: 0.0121 (0.0352) Average Loss: 0.9697 (0.8186) Average CE Loss (Source):  0.9697 ( 0.8186) Learning Rate: 0.1000 (0.1000) Top1_base: 74.2188 (77.3351) Top1_base_per_class: 73.1548 (77.7314) 
Training Epoch: [82/1000] Step: [100 / 285] Batch Time: 0.1466 (0.1663) Data Time: 0.0143 (0.0332) Average Loss: 0.9176 (0.8197) Average CE Loss (Source):  0.9176 ( 0.8197) Learning Rate: 0.1000 (0.1000) Top1_base: 78.9062 (77.3047) Top1_base_per_class: 80.2946 (77.6578) 
Training Epoch: [82/1000] Step: [110 / 285] Batch Time: 0.1457 (0.1668) Data Time: 0.0123 (0.0336) Average Loss: 0.6306 (0.8218) Average CE Loss (Source):  0.6306 ( 0.8218) Learning Rate: 0.1000 (0.1000) Top1_base: 81.2500 (77.2017) Top1_base_per_class: 83.6728 (77.5288) 
Training Epoch: [82/1000] Step: [120 / 285] Batch Time: 0.1465 (0.1661) Data Time: 0.0111 (0.0329) Average Loss: 1.0638 (0.8254) Average CE Loss (Source):  1.0638 ( 0.8254) Learning Rate: 0.1000 (0.1000) Top1_base: 71.0938 (77.1224) Top1_base_per_class: 70.8128 (77.5016) 
Training Epoch: [82/1000] Step: [130 / 285] Batch Time: 0.1495 (0.1664) Data Time: 0.0119 (0.0331) Average Loss: 0.7646 (0.8232) Average CE Loss (Source):  0.7646 ( 0.8232) Learning Rate: 0.1000 (0.1000) Top1_base: 78.1250 (77.2236) Top1_base_per_class: 79.7661 (77.6095) 
Training Epoch: [82/1000] Step: [140 / 285] Batch Time: 0.1454 (0.1661) Data Time: 0.0109 (0.0328) Average Loss: 0.9245 (0.8210) Average CE Loss (Source):  0.9245 ( 0.8210) Learning Rate: 0.1000 (0.1000) Top1_base: 73.4375 (77.2489) Top1_base_per_class: 72.2002 (77.6086) 
Training Epoch: [82/1000] Step: [150 / 285] Batch Time: 0.1445 (0.1657) Data Time: 0.0126 (0.0323) Average Loss: 0.9002 (0.8210) Average CE Loss (Source):  0.9002 ( 0.8210) Learning Rate: 0.1000 (0.1000) Top1_base: 74.2188 (77.2135) Top1_base_per_class: 72.8788 (77.6267) 
Training Epoch: [82/1000] Step: [160 / 285] Batch Time: 0.1471 (0.1646) Data Time: 0.0135 (0.0312) Average Loss: 0.7681 (0.8241) Average CE Loss (Source):  0.7681 ( 0.8241) Learning Rate: 0.1000 (0.1000) Top1_base: 77.3438 (77.0605) Top1_base_per_class: 77.9630 (77.5187) 
Training Epoch: [82/1000] Step: [170 / 285] Batch Time: 0.1487 (0.1641) Data Time: 0.0120 (0.0306) Average Loss: 0.9175 (0.8241) Average CE Loss (Source):  0.9175 ( 0.8241) Learning Rate: 0.1000 (0.1000) Top1_base: 77.3438 (77.0404) Top1_base_per_class: 79.0260 (77.4744) 
Training Epoch: [82/1000] Step: [180 / 285] Batch Time: 0.1439 (0.1636) Data Time: 0.0123 (0.0303) Average Loss: 0.7013 (0.8230) Average CE Loss (Source):  0.7013 ( 0.8230) Learning Rate: 0.1000 (0.1000) Top1_base: 78.1250 (77.0443) Top1_base_per_class: 75.8772 (77.3782) 
Training Epoch: [82/1000] Step: [190 / 285] Batch Time: 0.1450 (0.1634) Data Time: 0.0129 (0.0300) Average Loss: 0.8202 (0.8269) Average CE Loss (Source):  0.8202 ( 0.8269) Learning Rate: 0.1000 (0.1000) Top1_base: 78.9062 (76.9367) Top1_base_per_class: 80.8139 (77.2792) 
Training Epoch: [82/1000] Step: [200 / 285] Batch Time: 0.1434 (0.1630) Data Time: 0.0136 (0.0296) Average Loss: 0.8469 (0.8271) Average CE Loss (Source):  0.8469 ( 0.8271) Learning Rate: 0.1000 (0.1000) Top1_base: 77.3438 (76.8867) Top1_base_per_class: 76.0450 (77.2033) 
Training Epoch: [82/1000] Step: [210 / 285] Batch Time: 0.1506 (0.1623) Data Time: 0.0138 (0.0290) Average Loss: 0.7741 (0.8303) Average CE Loss (Source):  0.7741 ( 0.8303) Learning Rate: 0.1000 (0.1000) Top1_base: 75.7812 (76.7597) Top1_base_per_class: 73.1548 (77.0795) 
Training Epoch: [82/1000] Step: [220 / 285] Batch Time: 0.1476 (0.1617) Data Time: 0.0111 (0.0283) Average Loss: 0.8401 (0.8323) Average CE Loss (Source):  0.8401 ( 0.8323) Learning Rate: 0.1000 (0.1000) Top1_base: 75.0000 (76.6761) Top1_base_per_class: 75.5660 (77.0041) 
Training Epoch: [82/1000] Step: [230 / 285] Batch Time: 0.1432 (0.1615) Data Time: 0.0121 (0.0281) Average Loss: 0.9424 (0.8322) Average CE Loss (Source):  0.9424 ( 0.8322) Learning Rate: 0.1000 (0.1000) Top1_base: 73.4375 (76.6780) Top1_base_per_class: 76.0632 (77.0335) 
Training Epoch: [82/1000] Step: [240 / 285] Batch Time: 0.1488 (0.1610) Data Time: 0.0124 (0.0275) Average Loss: 1.2204 (0.8350) Average CE Loss (Source):  1.2204 ( 0.8350) Learning Rate: 0.1000 (0.1000) Top1_base: 68.7500 (76.5951) Top1_base_per_class: 71.5758 (76.9785) 
Training Epoch: [82/1000] Step: [250 / 285] Batch Time: 0.1513 (0.1609) Data Time: 0.0122 (0.0273) Average Loss: 0.9065 (0.8366) Average CE Loss (Source):  0.9065 ( 0.8366) Learning Rate: 0.1000 (0.1000) Top1_base: 76.5625 (76.5500) Top1_base_per_class: 78.4226 (76.9526) 
Training Epoch: [82/1000] Step: [260 / 285] Batch Time: 0.1488 (0.1606) Data Time: 0.0113 (0.0270) Average Loss: 0.8327 (0.8381) Average CE Loss (Source):  0.8327 ( 0.8381) Learning Rate: 0.1000 (0.1000) Top1_base: 78.1250 (76.5535) Top1_base_per_class: 77.7897 (76.9764) 
Training Epoch: [82/1000] Step: [270 / 285] Batch Time: 0.1466 (0.1602) Data Time: 0.0106 (0.0265) Average Loss: 0.9617 (0.8385) Average CE Loss (Source):  0.9617 ( 0.8385) Learning Rate: 0.1000 (0.1000) Top1_base: 78.1250 (76.5220) Top1_base_per_class: 78.4973 (76.9680) 
Training Epoch: [82/1000] Step: [280 / 285] Batch Time: 0.1463 (0.1597) Data Time: 0.0144 (0.0261) Average Loss: 0.8841 (0.8377) Average CE Loss (Source):  0.8841 ( 0.8377) Learning Rate: 0.1000 (0.1000) Top1_base: 75.7812 (76.5346) Top1_base_per_class: 73.6613 (76.9857) 
Training Epoch: [83/1000] Step: [0] Batch Time: 0.2069 (0.1596) Data Time: 0.0742 (0.0260) Average Loss: 0.9704 (0.8382) Average CE Loss (Source):  0.9704 ( 0.8382) Learning Rate: 0.1000 (0.1000) Top1_base: 75.0000 (76.5214) Top1_base_per_class: 76.8966 (76.9848) 
Training Epoch: [83/1000] Step: [10 / 285] Batch Time: 0.1459 (0.2339) Data Time: 0.0148 (0.1015) Average Loss: 0.9062 (0.6995) Average CE Loss (Source):  0.9062 ( 0.6995) Learning Rate: 0.1000 (0.1000) Top1_base: 74.2188 (81.4844) Top1_base_per_class: 75.9226 (81.4155) 
Training Epoch: [83/1000] Step: [20 / 285] Batch Time: 0.1463 (0.1959) Data Time: 0.0139 (0.0638) Average Loss: 0.8399 (0.7429) Average CE Loss (Source):  0.8399 ( 0.7429) Learning Rate: 0.1000 (0.1000) Top1_base: 76.5625 (79.3359) Top1_base_per_class: 77.6608 (79.6179) 
Training Epoch: [83/1000] Step: [30 / 285] Batch Time: 0.1475 (0.1807) Data Time: 0.0169 (0.0484) Average Loss: 0.8113 (0.7615) Average CE Loss (Source):  0.8113 ( 0.7615) Learning Rate: 0.1000 (0.1000) Top1_base: 76.5625 (78.7500) Top1_base_per_class: 77.2321 (79.3339) 
Training Epoch: [83/1000] Step: [40 / 285] Batch Time: 0.1454 (0.1741) Data Time: 0.0129 (0.0419) Average Loss: 0.7588 (0.7723) Average CE Loss (Source):  0.7588 ( 0.7723) Learning Rate: 0.1000 (0.1000) Top1_base: 79.6875 (78.6328) Top1_base_per_class: 82.5595 (79.1009) 
Training Epoch: [83/1000] Step: [50 / 285] Batch Time: 0.1998 (0.1727) Data Time: 0.0684 (0.0405) Average Loss: 0.8876 (0.7709) Average CE Loss (Source):  0.8876 ( 0.7709) Learning Rate: 0.1000 (0.1000) Top1_base: 74.2188 (78.5156) Top1_base_per_class: 77.7976 (79.1397) 
Training Epoch: [83/1000] Step: [60 / 285] Batch Time: 0.1445 (0.1684) Data Time: 0.0116 (0.0361) Average Loss: 0.7518 (0.7750) Average CE Loss (Source):  0.7518 ( 0.7750) Learning Rate: 0.1000 (0.1000) Top1_base: 77.3438 (78.3464) Top1_base_per_class: 76.8678 (78.9121) 
Training Epoch: [83/1000] Step: [70 / 285] Batch Time: 0.1672 (0.1673) Data Time: 0.0301 (0.0346) Average Loss: 0.7027 (0.7800) Average CE Loss (Source):  0.7027 ( 0.7800) Learning Rate: 0.1000 (0.1000) Top1_base: 83.5938 (78.3371) Top1_base_per_class: 84.3056 (78.7832) 
Training Epoch: [83/1000] Step: [80 / 285] Batch Time: 0.1481 (0.1648) Data Time: 0.0167 (0.0320) Average Loss: 0.8369 (0.7882) Average CE Loss (Source):  0.8369 ( 0.7882) Learning Rate: 0.1000 (0.1000) Top1_base: 78.1250 (78.0371) Top1_base_per_class: 80.2469 (78.4567) 
Training Epoch: [83/1000] Step: [90 / 285] Batch Time: 0.1517 (0.1629) Data Time: 0.0165 (0.0300) Average Loss: 0.8066 (0.7971) Average CE Loss (Source):  0.8066 ( 0.7971) Learning Rate: 0.1000 (0.1000) Top1_base: 77.3438 (77.8819) Top1_base_per_class: 77.3214 (78.2876) 
Training Epoch: [83/1000] Step: [100 / 285] Batch Time: 0.1501 (0.1615) Data Time: 0.0157 (0.0284) Average Loss: 0.4372 (0.7979) Average CE Loss (Source):  0.4372 ( 0.7979) Learning Rate: 0.1000 (0.1000) Top1_base: 87.5000 (77.8281) Top1_base_per_class: 88.5058 (78.2568) 
Training Epoch: [83/1000] Step: [110 / 285] Batch Time: 0.1517 (0.1605) Data Time: 0.0145 (0.0271) Average Loss: 0.7216 (0.7944) Average CE Loss (Source):  0.7216 ( 0.7944) Learning Rate: 0.1000 (0.1000) Top1_base: 80.4688 (77.8906) Top1_base_per_class: 82.9023 (78.3247) 
Training Epoch: [83/1000] Step: [120 / 285] Batch Time: 0.1475 (0.1596) Data Time: 0.0145 (0.0260) Average Loss: 0.8550 (0.7971) Average CE Loss (Source):  0.8550 ( 0.7971) Learning Rate: 0.1000 (0.1000) Top1_base: 74.2188 (77.8646) Top1_base_per_class: 75.0000 (78.2230) 
Training Epoch: [83/1000] Step: [130 / 285] Batch Time: 0.1488 (0.1587) Data Time: 0.0173 (0.0251) Average Loss: 0.8285 (0.8001) Average CE Loss (Source):  0.8285 ( 0.8001) Learning Rate: 0.1000 (0.1000) Top1_base: 75.0000 (77.7644) Top1_base_per_class: 76.7879 (78.1132) 
Training Epoch: [83/1000] Step: [140 / 285] Batch Time: 0.1514 (0.1580) Data Time: 0.0179 (0.0244) Average Loss: 0.9221 (0.8043) Average CE Loss (Source):  0.9221 ( 0.8043) Learning Rate: 0.1000 (0.1000) Top1_base: 74.2188 (77.6507) Top1_base_per_class: 79.1379 (78.0510) 
Training Epoch: [83/1000] Step: [150 / 285] Batch Time: 0.1479 (0.1573) Data Time: 0.0138 (0.0237) Average Loss: 0.8320 (0.8079) Average CE Loss (Source):  0.8320 ( 0.8079) Learning Rate: 0.1000 (0.1000) Top1_base: 76.5625 (77.5052) Top1_base_per_class: 76.7775 (77.8848) 
Training Epoch: [83/1000] Step: [160 / 285] Batch Time: 0.1553 (0.1567) Data Time: 0.0240 (0.0231) Average Loss: 0.9394 (0.8105) Average CE Loss (Source):  0.9394 ( 0.8105) Learning Rate: 0.1000 (0.1000) Top1_base: 75.0000 (77.4121) Top1_base_per_class: 77.2222 (77.7990) 
Training Epoch: [83/1000] Step: [170 / 285] Batch Time: 0.1474 (0.1566) Data Time: 0.0153 (0.0230) Average Loss: 0.8955 (0.8134) Average CE Loss (Source):  0.8955 ( 0.8134) Learning Rate: 0.1000 (0.1000) Top1_base: 75.0000 (77.2518) Top1_base_per_class: 78.1746 (77.6734) 
Training Epoch: [83/1000] Step: [180 / 285] Batch Time: 0.1517 (0.1562) Data Time: 0.0185 (0.0226) Average Loss: 0.8488 (0.8157) Average CE Loss (Source):  0.8488 ( 0.8157) Learning Rate: 0.1000 (0.1000) Top1_base: 78.1250 (77.2352) Top1_base_per_class: 79.2424 (77.6497) 
Training Epoch: [83/1000] Step: [190 / 285] Batch Time: 0.1503 (0.1563) Data Time: 0.0142 (0.0226) Average Loss: 0.9037 (0.8188) Average CE Loss (Source):  0.9037 ( 0.8188) Learning Rate: 0.1000 (0.1000) Top1_base: 78.9062 (77.1382) Top1_base_per_class: 76.9546 (77.5431) 
Training Epoch: [83/1000] Step: [200 / 285] Batch Time: 0.1503 (0.1560) Data Time: 0.0175 (0.0221) Average Loss: 0.7934 (0.8194) Average CE Loss (Source):  0.7934 ( 0.8194) Learning Rate: 0.1000 (0.1000) Top1_base: 75.0000 (77.1016) Top1_base_per_class: 77.7160 (77.5093) 
Training Epoch: [83/1000] Step: [210 / 285] Batch Time: 0.1490 (0.1557) Data Time: 0.0169 (0.0218) Average Loss: 0.7254 (0.8185) Average CE Loss (Source):  0.7254 ( 0.8185) Learning Rate: 0.1000 (0.1000) Top1_base: 81.2500 (77.1577) Top1_base_per_class: 81.9345 (77.5041) 
Training Epoch: [83/1000] Step: [220 / 285] Batch Time: 0.1508 (0.1553) Data Time: 0.0155 (0.0214) Average Loss: 0.9503 (0.8169) Average CE Loss (Source):  0.9503 ( 0.8169) Learning Rate: 0.1000 (0.1000) Top1_base: 73.4375 (77.1520) Top1_base_per_class: 71.2281 (77.5270) 
Training Epoch: [83/1000] Step: [230 / 285] Batch Time: 0.1496 (0.1551) Data Time: 0.0115 (0.0211) Average Loss: 0.7749 (0.8225) Average CE Loss (Source):  0.7749 ( 0.8225) Learning Rate: 0.1000 (0.1000) Top1_base: 75.7812 (76.9837) Top1_base_per_class: 76.8788 (77.3681) 
Training Epoch: [83/1000] Step: [240 / 285] Batch Time: 0.1495 (0.1548) Data Time: 0.0178 (0.0208) Average Loss: 0.7401 (0.8213) Average CE Loss (Source):  0.7401 ( 0.8213) Learning Rate: 0.1000 (0.1000) Top1_base: 78.1250 (77.0345) Top1_base_per_class: 79.3155 (77.4211) 
Training Epoch: [83/1000] Step: [250 / 285] Batch Time: 0.1488 (0.1549) Data Time: 0.0115 (0.0209) Average Loss: 0.8446 (0.8206) Average CE Loss (Source):  0.8446 ( 0.8206) Learning Rate: 0.1000 (0.1000) Top1_base: 79.6875 (77.0906) Top1_base_per_class: 80.0926 (77.5055) 
Training Epoch: [83/1000] Step: [260 / 285] Batch Time: 0.2075 (0.1552) Data Time: 0.0763 (0.0212) Average Loss: 0.8930 (0.8229) Average CE Loss (Source):  0.8930 ( 0.8229) Learning Rate: 0.1000 (0.1000) Top1_base: 77.3438 (77.0012) Top1_base_per_class: 79.3593 (77.4633) 
Training Epoch: [83/1000] Step: [270 / 285] Batch Time: 0.1462 (0.1549) Data Time: 0.0134 (0.0209) Average Loss: 0.6616 (0.8203) Average CE Loss (Source):  0.6616 ( 0.8203) Learning Rate: 0.1000 (0.1000) Top1_base: 80.4688 (77.0631) Top1_base_per_class: 79.2092 (77.5255) 
Training Epoch: [83/1000] Step: [280 / 285] Batch Time: 0.2081 (0.1552) Data Time: 0.0779 (0.0213) Average Loss: 1.0092 (0.8225) Average CE Loss (Source):  1.0092 ( 0.8225) Learning Rate: 0.1000 (0.1000) Top1_base: 74.2188 (77.0201) Top1_base_per_class: 73.8889 (77.4611) 
Training Epoch: [84/1000] Step: [0] Batch Time: 0.1421 (0.1552) Data Time: 0.0117 (0.0213) Average Loss: 0.9971 (0.8254) Average CE Loss (Source):  0.9971 ( 0.8254) Learning Rate: 0.1000 (0.1000) Top1_base: 68.7500 (76.9079) Top1_base_per_class: 67.8351 (77.3752) 
  8%|▊         | 84/1000 [1:05:57<11:51:31, 46.61s/it]  8%|▊         | 85/1000 [1:06:42<11:41:42, 46.01s/it]Training Epoch: [84/1000] Step: [10 / 285] Batch Time: 0.1468 (0.2275) Data Time: 0.0115 (0.0926) Average Loss: 0.8000 (0.8453) Average CE Loss (Source):  0.8000 ( 0.8453) Learning Rate: 0.1000 (0.1000) Top1_base: 77.3438 (75.6250) Top1_base_per_class: 76.3837 (76.6533) 
Training Epoch: [84/1000] Step: [20 / 285] Batch Time: 0.1496 (0.1926) Data Time: 0.0142 (0.0579) Average Loss: 0.6907 (0.8020) Average CE Loss (Source):  0.6907 ( 0.8020) Learning Rate: 0.1000 (0.1000) Top1_base: 80.4688 (77.5391) Top1_base_per_class: 81.8644 (78.7636) 
Training Epoch: [84/1000] Step: [30 / 285] Batch Time: 0.1472 (0.1860) Data Time: 0.0125 (0.0510) Average Loss: 0.9123 (0.7991) Average CE Loss (Source):  0.9123 ( 0.7991) Learning Rate: 0.1000 (0.1000) Top1_base: 74.2188 (77.8646) Top1_base_per_class: 77.4537 (78.7340) 
Training Epoch: [84/1000] Step: [40 / 285] Batch Time: 0.1461 (0.1791) Data Time: 0.0136 (0.0443) Average Loss: 0.5823 (0.7872) Average CE Loss (Source):  0.5823 ( 0.7872) Learning Rate: 0.1000 (0.1000) Top1_base: 84.3750 (77.9297) Top1_base_per_class: 87.9394 (78.5075) 
Training Epoch: [84/1000] Step: [50 / 285] Batch Time: 0.1440 (0.1753) Data Time: 0.0102 (0.0408) Average Loss: 0.8968 (0.7841) Average CE Loss (Source):  0.8968 ( 0.7841) Learning Rate: 0.1000 (0.1000) Top1_base: 77.3438 (78.0312) Top1_base_per_class: 78.0174 (78.6508) 
Training Epoch: [84/1000] Step: [60 / 285] Batch Time: 0.1495 (0.1708) Data Time: 0.0144 (0.0364) Average Loss: 0.9227 (0.7957) Average CE Loss (Source):  0.9227 ( 0.7957) Learning Rate: 0.1000 (0.1000) Top1_base: 77.3438 (77.6693) Top1_base_per_class: 74.2241 (78.3400) 
Training Epoch: [84/1000] Step: [70 / 285] Batch Time: 0.1420 (0.1702) Data Time: 0.0117 (0.0360) Average Loss: 0.7255 (0.7897) Average CE Loss (Source):  0.7255 ( 0.7897) Learning Rate: 0.1000 (0.1000) Top1_base: 78.9062 (77.9241) Top1_base_per_class: 80.1543 (78.5646) 
Training Epoch: [84/1000] Step: [80 / 285] Batch Time: 0.1445 (0.1672) Data Time: 0.0122 (0.0332) Average Loss: 0.5510 (0.7944) Average CE Loss (Source):  0.5510 ( 0.7944) Learning Rate: 0.1000 (0.1000) Top1_base: 83.5938 (77.9297) Top1_base_per_class: 79.8485 (78.5081) 
Training Epoch: [84/1000] Step: [90 / 285] Batch Time: 0.1436 (0.1653) Data Time: 0.0121 (0.0315) Average Loss: 0.9480 (0.7975) Average CE Loss (Source):  0.9480 ( 0.7975) Learning Rate: 0.1000 (0.1000) Top1_base: 74.2188 (77.7691) Top1_base_per_class: 72.7056 (78.3385) 
Training Epoch: [84/1000] Step: [100 / 285] Batch Time: 0.1479 (0.1648) Data Time: 0.0142 (0.0311) Average Loss: 0.7589 (0.7962) Average CE Loss (Source):  0.7589 ( 0.7962) Learning Rate: 0.1000 (0.1000) Top1_base: 82.0312 (77.8516) Top1_base_per_class: 80.1078 (78.4072) 
Training Epoch: [84/1000] Step: [110 / 285] Batch Time: 0.1416 (0.1633) Data Time: 0.0120 (0.0297) Average Loss: 0.7962 (0.7994) Average CE Loss (Source):  0.7962 ( 0.7994) Learning Rate: 0.1000 (0.1000) Top1_base: 78.1250 (77.7273) Top1_base_per_class: 79.0566 (78.1898) 
Training Epoch: [84/1000] Step: [120 / 285] Batch Time: 0.1492 (0.1618) Data Time: 0.0145 (0.0284) Average Loss: 0.6215 (0.8013) Average CE Loss (Source):  0.6215 ( 0.8013) Learning Rate: 0.1000 (0.1000) Top1_base: 82.0312 (77.7214) Top1_base_per_class: 80.2469 (78.1382) 
Training Epoch: [84/1000] Step: [130 / 285] Batch Time: 0.1482 (0.1609) Data Time: 0.0108 (0.0274) Average Loss: 0.8855 (0.8107) Average CE Loss (Source):  0.8855 ( 0.8107) Learning Rate: 0.1000 (0.1000) Top1_base: 75.7812 (77.4399) Top1_base_per_class: 72.0468 (77.8096) 
Training Epoch: [84/1000] Step: [140 / 285] Batch Time: 0.1504 (0.1608) Data Time: 0.0175 (0.0273) Average Loss: 0.7701 (0.8117) Average CE Loss (Source):  0.7701 ( 0.8117) Learning Rate: 0.1000 (0.1000) Top1_base: 79.6875 (77.4665) Top1_base_per_class: 79.3452 (77.8254) 
Training Epoch: [84/1000] Step: [150 / 285] Batch Time: 0.1462 (0.1609) Data Time: 0.0109 (0.0274) Average Loss: 0.7634 (0.8092) Average CE Loss (Source):  0.7634 ( 0.8092) Learning Rate: 0.1000 (0.1000) Top1_base: 78.1250 (77.5469) Top1_base_per_class: 77.6190 (77.9212) 
Training Epoch: [84/1000] Step: [160 / 285] Batch Time: 0.1487 (0.1601) Data Time: 0.0163 (0.0266) Average Loss: 0.9087 (0.8093) Average CE Loss (Source):  0.9087 ( 0.8093) Learning Rate: 0.1000 (0.1000) Top1_base: 75.7812 (77.5342) Top1_base_per_class: 80.2533 (77.8696) 
Training Epoch: [84/1000] Step: [170 / 285] Batch Time: 0.1483 (0.1599) Data Time: 0.0113 (0.0264) Average Loss: 0.8003 (0.8109) Average CE Loss (Source):  0.8003 ( 0.8109) Learning Rate: 0.1000 (0.1000) Top1_base: 78.1250 (77.4678) Top1_base_per_class: 74.2105 (77.7631) 
Training Epoch: [84/1000] Step: [180 / 285] Batch Time: 0.1463 (0.1593) Data Time: 0.0149 (0.0258) Average Loss: 0.9225 (0.8099) Average CE Loss (Source):  0.9225 ( 0.8099) Learning Rate: 0.1000 (0.1000) Top1_base: 72.6562 (77.4262) Top1_base_per_class: 72.6543 (77.6470) 
Training Epoch: [84/1000] Step: [190 / 285] Batch Time: 0.1438 (0.1593) Data Time: 0.0128 (0.0257) Average Loss: 0.8600 (0.8140) Average CE Loss (Source):  0.8600 ( 0.8140) Learning Rate: 0.1000 (0.1000) Top1_base: 74.2188 (77.2574) Top1_base_per_class: 75.3145 (77.5227) 
Training Epoch: [84/1000] Step: [200 / 285] Batch Time: 0.1486 (0.1587) Data Time: 0.0140 (0.0252) Average Loss: 0.7574 (0.8183) Average CE Loss (Source):  0.7574 ( 0.8183) Learning Rate: 0.1000 (0.1000) Top1_base: 75.0000 (77.1328) Top1_base_per_class: 75.6061 (77.3707) 
Training Epoch: [84/1000] Step: [210 / 285] Batch Time: 0.1452 (0.1582) Data Time: 0.0132 (0.0247) Average Loss: 1.0236 (0.8180) Average CE Loss (Source):  1.0236 ( 0.8180) Learning Rate: 0.1000 (0.1000) Top1_base: 70.3125 (77.1057) Top1_base_per_class: 70.5357 (77.3738) 
Training Epoch: [84/1000] Step: [220 / 285] Batch Time: 0.1475 (0.1577) Data Time: 0.0145 (0.0242) Average Loss: 0.9117 (0.8195) Average CE Loss (Source):  0.9117 ( 0.8195) Learning Rate: 0.1000 (0.1000) Top1_base: 75.0000 (77.1129) Top1_base_per_class: 77.9825 (77.3818) 
Training Epoch: [84/1000] Step: [230 / 285] Batch Time: 0.1459 (0.1580) Data Time: 0.0137 (0.0245) Average Loss: 0.7808 (0.8243) Average CE Loss (Source):  0.7808 ( 0.8243) Learning Rate: 0.1000 (0.1000) Top1_base: 78.1250 (76.9429) Top1_base_per_class: 77.0000 (77.2286) 
Training Epoch: [84/1000] Step: [240 / 285] Batch Time: 0.1494 (0.1576) Data Time: 0.0137 (0.0241) Average Loss: 0.6865 (0.8232) Average CE Loss (Source):  0.6865 ( 0.8232) Learning Rate: 0.1000 (0.1000) Top1_base: 78.9062 (76.9889) Top1_base_per_class: 79.1520 (77.2183) 
Training Epoch: [84/1000] Step: [250 / 285] Batch Time: 0.1483 (0.1573) Data Time: 0.0112 (0.0239) Average Loss: 0.8400 (0.8241) Average CE Loss (Source):  0.8400 ( 0.8241) Learning Rate: 0.1000 (0.1000) Top1_base: 77.3438 (76.9781) Top1_base_per_class: 75.1488 (77.2101) 
Training Epoch: [84/1000] Step: [260 / 285] Batch Time: 0.1468 (0.1569) Data Time: 0.0124 (0.0235) Average Loss: 0.4954 (0.8248) Average CE Loss (Source):  0.4954 ( 0.8248) Learning Rate: 0.1000 (0.1000) Top1_base: 87.5000 (77.0252) Top1_base_per_class: 86.9492 (77.2902) 
Training Epoch: [84/1000] Step: [270 / 285] Batch Time: 0.1429 (0.1565) Data Time: 0.0120 (0.0231) Average Loss: 0.8092 (0.8249) Average CE Loss (Source):  0.8092 ( 0.8249) Learning Rate: 0.1000 (0.1000) Top1_base: 76.5625 (77.0139) Top1_base_per_class: 76.5205 (77.2562) 
Training Epoch: [84/1000] Step: [280 / 285] Batch Time: 0.1465 (0.1563) Data Time: 0.0137 (0.0229) Average Loss: 0.9256 (0.8252) Average CE Loss (Source):  0.9256 ( 0.8252) Learning Rate: 0.1000 (0.1000) Top1_base: 73.4375 (76.9810) Top1_base_per_class: 78.0555 (77.2118) 
Training Epoch: [85/1000] Step: [0] Batch Time: 0.1732 (0.1564) Data Time: 0.0433 (0.0231) Average Loss: 0.7788 (0.8239) Average CE Loss (Source):  0.7788 ( 0.8239) Learning Rate: 0.1000 (0.1000) Top1_base: 80.4688 (77.0203) Top1_base_per_class: 80.0000 (77.2371) 
Training Epoch: [85/1000] Step: [10 / 285] Batch Time: 0.1457 (0.2440) Data Time: 0.0108 (0.1087) Average Loss: 0.6169 (0.7547) Average CE Loss (Source):  0.6169 ( 0.7547) Learning Rate: 0.1000 (0.1000) Top1_base: 83.5938 (78.9062) Top1_base_per_class: 82.2881 (78.9685) 
Training Epoch: [85/1000] Step: [20 / 285] Batch Time: 0.1484 (0.2003) Data Time: 0.0136 (0.0654) Average Loss: 0.7826 (0.7833) Average CE Loss (Source):  0.7826 ( 0.7833) Learning Rate: 0.1000 (0.1000) Top1_base: 77.3438 (78.8281) Top1_base_per_class: 78.6218 (78.8401) 
Training Epoch: [85/1000] Step: [30 / 285] Batch Time: 0.1478 (0.1838) Data Time: 0.0157 (0.0499) Average Loss: 0.9592 (0.7935) Average CE Loss (Source):  0.9592 ( 0.7935) Learning Rate: 0.1000 (0.1000) Top1_base: 75.7812 (78.5156) Top1_base_per_class: 76.9091 (78.7556) 
Training Epoch: [85/1000] Step: [40 / 285] Batch Time: 0.1425 (0.1742) Data Time: 0.0109 (0.0406) Average Loss: 0.7675 (0.8027) Average CE Loss (Source):  0.7675 ( 0.8027) Learning Rate: 0.1000 (0.1000) Top1_base: 75.7812 (78.1250) Top1_base_per_class: 77.9245 (78.5462) 
Training Epoch: [85/1000] Step: [50 / 285] Batch Time: 0.1710 (0.1714) Data Time: 0.0390 (0.0381) Average Loss: 0.7971 (0.7937) Average CE Loss (Source):  0.7971 ( 0.7937) Learning Rate: 0.1000 (0.1000) Top1_base: 78.9062 (78.3125) Top1_base_per_class: 80.0045 (78.7771) 
Training Epoch: [85/1000] Step: [60 / 285] Batch Time: 0.1475 (0.1674) Data Time: 0.0120 (0.0340) Average Loss: 0.9366 (0.7978) Average CE Loss (Source):  0.9366 ( 0.7978) Learning Rate: 0.1000 (0.1000) Top1_base: 75.7812 (78.2031) Top1_base_per_class: 74.2510 (78.6838) 
Training Epoch: [85/1000] Step: [70 / 285] Batch Time: 0.1545 (0.1669) Data Time: 0.0217 (0.0333) Average Loss: 0.8538 (0.8076) Average CE Loss (Source):  0.8538 ( 0.8076) Learning Rate: 0.1000 (0.1000) Top1_base: 75.7812 (77.8348) Top1_base_per_class: 77.7299 (78.4935) 
Training Epoch: [85/1000] Step: [80 / 285] Batch Time: 0.1486 (0.1650) Data Time: 0.0144 (0.0313) Average Loss: 0.7913 (0.8063) Average CE Loss (Source):  0.7913 ( 0.8063) Learning Rate: 0.1000 (0.1000) Top1_base: 75.7812 (77.8223) Top1_base_per_class: 74.0179 (78.3681) 
Training Epoch: [85/1000] Step: [90 / 285] Batch Time: 0.1483 (0.1637) Data Time: 0.0157 (0.0301) Average Loss: 0.9341 (0.8068) Average CE Loss (Source):  0.9341 ( 0.8068) Learning Rate: 0.1000 (0.1000) Top1_base: 72.6562 (77.8385) Top1_base_per_class: 67.8869 (78.3968) 
Training Epoch: [85/1000] Step: [100 / 285] Batch Time: 0.1487 (0.1627) Data Time: 0.0135 (0.0291) Average Loss: 0.8863 (0.8072) Average CE Loss (Source):  0.8863 ( 0.8072) Learning Rate: 0.1000 (0.1000) Top1_base: 76.5625 (77.7344) Top1_base_per_class: 75.0000 (78.3618) 
Training Epoch: [85/1000] Step: [110 / 285] Batch Time: 0.1921 (0.1628) Data Time: 0.0598 (0.0292) Average Loss: 0.7541 (0.8072) Average CE Loss (Source):  0.7541 ( 0.8072) Learning Rate: 0.1000 (0.1000) Top1_base: 78.1250 (77.6918) Top1_base_per_class: 79.5536 (78.3073) 
Training Epoch: [85/1000] Step: [120 / 285] Batch Time: 0.1475 (0.1624) Data Time: 0.0145 (0.0288) Average Loss: 0.8931 (0.8086) Average CE Loss (Source):  0.8931 ( 0.8086) Learning Rate: 0.1000 (0.1000) Top1_base: 71.0938 (77.6628) Top1_base_per_class: 70.6140 (78.2946) 
Training Epoch: [85/1000] Step: [130 / 285] Batch Time: 0.2034 (0.1622) Data Time: 0.0722 (0.0287) Average Loss: 0.7215 (0.8154) Average CE Loss (Source):  0.7215 ( 0.8154) Learning Rate: 0.1000 (0.1000) Top1_base: 78.9062 (77.4459) Top1_base_per_class: 78.7963 (78.1318) 
Training Epoch: [85/1000] Step: [140 / 285] Batch Time: 0.1468 (0.1617) Data Time: 0.0134 (0.0282) Average Loss: 0.9496 (0.8171) Average CE Loss (Source):  0.9496 ( 0.8171) Learning Rate: 0.1000 (0.1000) Top1_base: 74.2188 (77.4219) Top1_base_per_class: 71.6049 (78.0800) 
Training Epoch: [85/1000] Step: [150 / 285] Batch Time: 0.2089 (0.1616) Data Time: 0.0770 (0.0282) Average Loss: 0.9707 (0.8165) Average CE Loss (Source):  0.9707 ( 0.8165) Learning Rate: 0.1000 (0.1000) Top1_base: 74.2188 (77.4948) Top1_base_per_class: 77.5989 (78.1119) 
Training Epoch: [85/1000] Step: [160 / 285] Batch Time: 0.1489 (0.1611) Data Time: 0.0137 (0.0276) Average Loss: 0.9659 (0.8205) Average CE Loss (Source):  0.9659 ( 0.8205) Learning Rate: 0.1000 (0.1000) Top1_base: 73.4375 (77.2803) Top1_base_per_class: 73.7576 (77.8685) 
Training Epoch: [85/1000] Step: [170 / 285] Batch Time: 0.1477 (0.1603) Data Time: 0.0167 (0.0269) Average Loss: 0.9889 (0.8224) Average CE Loss (Source):  0.9889 ( 0.8224) Learning Rate: 0.1000 (0.1000) Top1_base: 73.4375 (77.2059) Top1_base_per_class: 77.8485 (77.8068) 
Training Epoch: [85/1000] Step: [180 / 285] Batch Time: 0.1469 (0.1597) Data Time: 0.0140 (0.0264) Average Loss: 0.7935 (0.8235) Average CE Loss (Source):  0.7935 ( 0.8235) Learning Rate: 0.1000 (0.1000) Top1_base: 79.6875 (77.2396) Top1_base_per_class: 82.0833 (77.8606) 
Training Epoch: [85/1000] Step: [190 / 285] Batch Time: 0.1579 (0.1600) Data Time: 0.0276 (0.0267) Average Loss: 0.7590 (0.8202) Average CE Loss (Source):  0.7590 ( 0.8202) Learning Rate: 0.1000 (0.1000) Top1_base: 78.9062 (77.3438) Top1_base_per_class: 82.8947 (77.9720) 
Training Epoch: [85/1000] Step: [200 / 285] Batch Time: 0.1491 (0.1599) Data Time: 0.0136 (0.0266) Average Loss: 0.9604 (0.8190) Average CE Loss (Source):  0.9604 ( 0.8190) Learning Rate: 0.1000 (0.1000) Top1_base: 75.7812 (77.3281) Top1_base_per_class: 73.1034 (77.9386) 
Training Epoch: [85/1000] Step: [210 / 285] Batch Time: 0.1939 (0.1601) Data Time: 0.0626 (0.0269) Average Loss: 0.9883 (0.8202) Average CE Loss (Source):  0.9883 ( 0.8202) Learning Rate: 0.1000 (0.1000) Top1_base: 73.4375 (77.3289) Top1_base_per_class: 74.6541 (77.9351) 
Training Epoch: [85/1000] Step: [220 / 285] Batch Time: 0.1487 (0.1600) Data Time: 0.0114 (0.0267) Average Loss: 0.7624 (0.8185) Average CE Loss (Source):  0.7624 ( 0.8185) Learning Rate: 0.1000 (0.1000) Top1_base: 76.5625 (77.3473) Top1_base_per_class: 72.8889 (77.9217) 
Training Epoch: [85/1000] Step: [230 / 285] Batch Time: 0.1597 (0.1600) Data Time: 0.0271 (0.0267) Average Loss: 0.7161 (0.8188) Average CE Loss (Source):  0.7161 ( 0.8188) Learning Rate: 0.1000 (0.1000) Top1_base: 78.9062 (77.3234) Top1_base_per_class: 75.6034 (77.9132) 
Training Epoch: [85/1000] Step: [240 / 285] Batch Time: 0.1431 (0.1596) Data Time: 0.0128 (0.0263) Average Loss: 0.6778 (0.8158) Average CE Loss (Source):  0.6778 ( 0.8158) Learning Rate: 0.1000 (0.1000) Top1_base: 78.1250 (77.3535) Top1_base_per_class: 76.9753 (77.9198) 
Training Epoch: [85/1000] Step: [250 / 285] Batch Time: 0.2038 (0.1595) Data Time: 0.0712 (0.0262) Average Loss: 0.9693 (0.8151) Average CE Loss (Source):  0.9693 ( 0.8151) Learning Rate: 0.1000 (0.1000) Top1_base: 76.5625 (77.3969) Top1_base_per_class: 77.7586 (77.9357) 
Training Epoch: [85/1000] Step: [260 / 285] Batch Time: 0.1474 (0.1593) Data Time: 0.0139 (0.0261) Average Loss: 0.9225 (0.8157) Average CE Loss (Source):  0.9225 ( 0.8157) Learning Rate: 0.1000 (0.1000) Top1_base: 73.4375 (77.3738) Top1_base_per_class: 74.6017 (77.9460) 
Training Epoch: [85/1000] Step: [270 / 285] Batch Time: 0.2245 (0.1594) Data Time: 0.0930 (0.0262) Average Loss: 0.7549 (0.8177) Average CE Loss (Source):  0.7549 ( 0.8177) Learning Rate: 0.1000 (0.1000) Top1_base: 80.4688 (77.2917) Top1_base_per_class: 80.6970 (77.8391) 
Training Epoch: [85/1000] Step: [280 / 285] Batch Time: 0.1484 (0.1593) Data Time: 0.0149 (0.0261) Average Loss: 0.8483 (0.8179) Average CE Loss (Source):  0.8483 ( 0.8179) Learning Rate: 0.1000 (0.1000) Top1_base: 74.2188 (77.2545) Top1_base_per_class: 72.9100 (77.7536) 
Training Epoch: [86/1000] Step: [0] Batch Time: 0.1434 (0.1594) Data Time: 0.0115 (0.0261) Average Loss: 1.0259 (0.8176) Average CE Loss (Source):  1.0259 ( 0.8176) Learning Rate: 0.1000 (0.1000) Top1_base: 71.0938 (77.2780) Top1_base_per_class: 69.8182 (77.7942) 
  9%|▊         | 86/1000 [1:07:30<11:50:46, 46.66s/it]  9%|▊         | 87/1000 [1:08:15<11:41:31, 46.10s/it]Training Epoch: [86/1000] Step: [10 / 285] Batch Time: 0.1445 (0.2458) Data Time: 0.0108 (0.1136) Average Loss: 0.8369 (0.8515) Average CE Loss (Source):  0.8369 ( 0.8515) Learning Rate: 0.1000 (0.1000) Top1_base: 76.5625 (76.8750) Top1_base_per_class: 73.3858 (76.8646) 
Training Epoch: [86/1000] Step: [20 / 285] Batch Time: 0.1465 (0.1993) Data Time: 0.0125 (0.0666) Average Loss: 1.0376 (0.8364) Average CE Loss (Source):  1.0376 ( 0.8364) Learning Rate: 0.1000 (0.1000) Top1_base: 73.4375 (76.9141) Top1_base_per_class: 72.8363 (76.6121) 
Training Epoch: [86/1000] Step: [30 / 285] Batch Time: 0.1437 (0.1859) Data Time: 0.0126 (0.0529) Average Loss: 0.9585 (0.8199) Average CE Loss (Source):  0.9585 ( 0.8199) Learning Rate: 0.1000 (0.1000) Top1_base: 71.8750 (76.9792) Top1_base_per_class: 71.3988 (76.7121) 
Training Epoch: [86/1000] Step: [40 / 285] Batch Time: 0.1424 (0.1789) Data Time: 0.0112 (0.0459) Average Loss: 0.9762 (0.8143) Average CE Loss (Source):  0.9762 ( 0.8143) Learning Rate: 0.1000 (0.1000) Top1_base: 70.3125 (77.1484) Top1_base_per_class: 69.1049 (76.9102) 
Training Epoch: [86/1000] Step: [50 / 285] Batch Time: 0.1474 (0.1734) Data Time: 0.0126 (0.0404) Average Loss: 0.9775 (0.8301) Average CE Loss (Source):  0.9775 ( 0.8301) Learning Rate: 0.1000 (0.1000) Top1_base: 70.3125 (76.4375) Top1_base_per_class: 70.7143 (76.6291) 
Training Epoch: [86/1000] Step: [60 / 285] Batch Time: 0.1440 (0.1708) Data Time: 0.0118 (0.0379) Average Loss: 0.8476 (0.8338) Average CE Loss (Source):  0.8476 ( 0.8338) Learning Rate: 0.1000 (0.1000) Top1_base: 74.2188 (76.1979) Top1_base_per_class: 75.6497 (76.3980) 
Training Epoch: [86/1000] Step: [70 / 285] Batch Time: 0.1449 (0.1679) Data Time: 0.0118 (0.0349) Average Loss: 0.7551 (0.8248) Average CE Loss (Source):  0.7551 ( 0.8248) Learning Rate: 0.1000 (0.1000) Top1_base: 79.6875 (76.5625) Top1_base_per_class: 80.3704 (76.9404) 
Training Epoch: [86/1000] Step: [80 / 285] Batch Time: 0.1433 (0.1657) Data Time: 0.0111 (0.0328) Average Loss: 1.1130 (0.8306) Average CE Loss (Source):  1.1130 ( 0.8306) Learning Rate: 0.1000 (0.1000) Top1_base: 67.1875 (76.3574) Top1_base_per_class: 70.2586 (76.8127) 
Training Epoch: [86/1000] Step: [90 / 285] Batch Time: 0.1431 (0.1647) Data Time: 0.0105 (0.0317) Average Loss: 0.7065 (0.8265) Average CE Loss (Source):  0.7065 ( 0.8265) Learning Rate: 0.1000 (0.1000) Top1_base: 77.3438 (76.5104) Top1_base_per_class: 74.8810 (77.0082) 
Training Epoch: [86/1000] Step: [100 / 285] Batch Time: 0.1475 (0.1631) Data Time: 0.0120 (0.0300) Average Loss: 0.7581 (0.8217) Average CE Loss (Source):  0.7581 ( 0.8217) Learning Rate: 0.1000 (0.1000) Top1_base: 79.6875 (76.6406) Top1_base_per_class: 81.3393 (77.1220) 
Training Epoch: [86/1000] Step: [110 / 285] Batch Time: 0.1463 (0.1623) Data Time: 0.0105 (0.0292) Average Loss: 0.8187 (0.8187) Average CE Loss (Source):  0.8187 ( 0.8187) Learning Rate: 0.1000 (0.1000) Top1_base: 77.3438 (76.7898) Top1_base_per_class: 77.6364 (77.2001) 
Training Epoch: [86/1000] Step: [120 / 285] Batch Time: 0.1466 (0.1620) Data Time: 0.0134 (0.0289) Average Loss: 0.9599 (0.8195) Average CE Loss (Source):  0.9599 ( 0.8195) Learning Rate: 0.1000 (0.1000) Top1_base: 69.5312 (76.6406) Top1_base_per_class: 66.3416 (77.0709) 
Training Epoch: [86/1000] Step: [130 / 285] Batch Time: 0.1448 (0.1613) Data Time: 0.0113 (0.0282) Average Loss: 0.7559 (0.8186) Average CE Loss (Source):  0.7559 ( 0.8186) Learning Rate: 0.1000 (0.1000) Top1_base: 78.1250 (76.6526) Top1_base_per_class: 79.4941 (77.0352) 
Training Epoch: [86/1000] Step: [140 / 285] Batch Time: 0.1430 (0.1611) Data Time: 0.0102 (0.0279) Average Loss: 0.9575 (0.8157) Average CE Loss (Source):  0.9575 ( 0.8157) Learning Rate: 0.1000 (0.1000) Top1_base: 75.7812 (76.7299) Top1_base_per_class: 77.7358 (76.9878) 
Training Epoch: [86/1000] Step: [150 / 285] Batch Time: 0.1431 (0.1602) Data Time: 0.0104 (0.0270) Average Loss: 0.7889 (0.8157) Average CE Loss (Source):  0.7889 ( 0.8157) Learning Rate: 0.1000 (0.1000) Top1_base: 77.3438 (76.7448) Top1_base_per_class: 77.5439 (77.0223) 
Training Epoch: [86/1000] Step: [160 / 285] Batch Time: 0.1460 (0.1593) Data Time: 0.0122 (0.0262) Average Loss: 0.8872 (0.8176) Average CE Loss (Source):  0.8872 ( 0.8176) Learning Rate: 0.1000 (0.1000) Top1_base: 73.4375 (76.6846) Top1_base_per_class: 74.2408 (76.9446) 
Training Epoch: [86/1000] Step: [170 / 285] Batch Time: 0.1435 (0.1587) Data Time: 0.0103 (0.0256) Average Loss: 0.7633 (0.8165) Average CE Loss (Source):  0.7633 ( 0.8165) Learning Rate: 0.1000 (0.1000) Top1_base: 78.1250 (76.7279) Top1_base_per_class: 75.2679 (76.9483) 
Training Epoch: [86/1000] Step: [180 / 285] Batch Time: 0.1471 (0.1583) Data Time: 0.0133 (0.0252) Average Loss: 0.5735 (0.8131) Average CE Loss (Source):  0.5735 ( 0.8131) Learning Rate: 0.1000 (0.1000) Top1_base: 81.2500 (76.8099) Top1_base_per_class: 84.2349 (77.0024) 
Training Epoch: [86/1000] Step: [190 / 285] Batch Time: 0.1424 (0.1582) Data Time: 0.0100 (0.0251) Average Loss: 0.7416 (0.8113) Average CE Loss (Source):  0.7416 ( 0.8113) Learning Rate: 0.1000 (0.1000) Top1_base: 77.3438 (76.8462) Top1_base_per_class: 76.6970 (77.0583) 
Training Epoch: [86/1000] Step: [200 / 285] Batch Time: 0.1486 (0.1579) Data Time: 0.0138 (0.0248) Average Loss: 0.4944 (0.8100) Average CE Loss (Source):  0.4944 ( 0.8100) Learning Rate: 0.1000 (0.1000) Top1_base: 84.3750 (76.8906) Top1_base_per_class: 83.0606 (77.0575) 
Training Epoch: [86/1000] Step: [210 / 285] Batch Time: 0.1469 (0.1575) Data Time: 0.0146 (0.0244) Average Loss: 1.1282 (0.8135) Average CE Loss (Source):  1.1282 ( 0.8135) Learning Rate: 0.1000 (0.1000) Top1_base: 69.5312 (76.8118) Top1_base_per_class: 68.4480 (76.9847) 
Training Epoch: [86/1000] Step: [220 / 285] Batch Time: 0.1476 (0.1571) Data Time: 0.0139 (0.0239) Average Loss: 0.8418 (0.8138) Average CE Loss (Source):  0.8418 ( 0.8138) Learning Rate: 0.1000 (0.1000) Top1_base: 77.3438 (76.8537) Top1_base_per_class: 77.0303 (77.0826) 
Training Epoch: [86/1000] Step: [230 / 285] Batch Time: 0.1481 (0.1571) Data Time: 0.0142 (0.0239) Average Loss: 0.8167 (0.8132) Average CE Loss (Source):  0.8167 ( 0.8132) Learning Rate: 0.1000 (0.1000) Top1_base: 76.5625 (76.9056) Top1_base_per_class: 80.6364 (77.1588) 
Training Epoch: [86/1000] Step: [240 / 285] Batch Time: 0.1522 (0.1568) Data Time: 0.0161 (0.0235) Average Loss: 0.7729 (0.8160) Average CE Loss (Source):  0.7729 ( 0.8160) Learning Rate: 0.1000 (0.1000) Top1_base: 78.9062 (76.8490) Top1_base_per_class: 79.7619 (77.1222) 
Training Epoch: [86/1000] Step: [250 / 285] Batch Time: 0.1468 (0.1571) Data Time: 0.0109 (0.0237) Average Loss: 0.7783 (0.8160) Average CE Loss (Source):  0.7783 ( 0.8160) Learning Rate: 0.1000 (0.1000) Top1_base: 75.0000 (76.8187) Top1_base_per_class: 74.5115 (77.0695) 
Training Epoch: [86/1000] Step: [260 / 285] Batch Time: 0.1483 (0.1569) Data Time: 0.0142 (0.0234) Average Loss: 0.5886 (0.8135) Average CE Loss (Source):  0.5886 ( 0.8135) Learning Rate: 0.1000 (0.1000) Top1_base: 83.5938 (76.8930) Top1_base_per_class: 81.1111 (77.0956) 
Training Epoch: [86/1000] Step: [270 / 285] Batch Time: 0.1479 (0.1573) Data Time: 0.0127 (0.0239) Average Loss: 0.8036 (0.8125) Average CE Loss (Source):  0.8036 ( 0.8125) Learning Rate: 0.1000 (0.1000) Top1_base: 80.4688 (76.8953) Top1_base_per_class: 82.2222 (77.1011) 
Training Epoch: [86/1000] Step: [280 / 285] Batch Time: 0.1414 (0.1571) Data Time: 0.0115 (0.0237) Average Loss: 0.8281 (0.8126) Average CE Loss (Source):  0.8281 ( 0.8126) Learning Rate: 0.1000 (0.1000) Top1_base: 74.2188 (76.8806) Top1_base_per_class: 74.9713 (77.0415) 
Training Epoch: [87/1000] Step: [0] Batch Time: 0.1763 (0.1570) Data Time: 0.0453 (0.0236) Average Loss: 0.6995 (0.8124) Average CE Loss (Source):  0.6995 ( 0.8124) Learning Rate: 0.1000 (0.1000) Top1_base: 77.3438 (76.8942) Top1_base_per_class: 80.3736 (77.0616) 
Training Epoch: [87/1000] Step: [10 / 285] Batch Time: 0.1762 (0.2334) Data Time: 0.0453 (0.1015) Average Loss: 0.7756 (0.7799) Average CE Loss (Source):  0.7756 ( 0.7799) Learning Rate: 0.1000 (0.1000) Top1_base: 78.1250 (79.0625) Top1_base_per_class: 77.3563 (80.0699) 
Training Epoch: [87/1000] Step: [20 / 285] Batch Time: 0.1451 (0.1969) Data Time: 0.0144 (0.0645) Average Loss: 0.7712 (0.7532) Average CE Loss (Source):  0.7712 ( 0.7532) Learning Rate: 0.1000 (0.1000) Top1_base: 78.9062 (79.3750) Top1_base_per_class: 79.9697 (79.7644) 
Training Epoch: [87/1000] Step: [30 / 285] Batch Time: 0.1494 (0.1825) Data Time: 0.0159 (0.0498) Average Loss: 0.7238 (0.7592) Average CE Loss (Source):  0.7238 ( 0.7592) Learning Rate: 0.1000 (0.1000) Top1_base: 77.3438 (78.5677) Top1_base_per_class: 81.6071 (79.6130) 
Training Epoch: [87/1000] Step: [40 / 285] Batch Time: 0.1476 (0.1742) Data Time: 0.0130 (0.0417) Average Loss: 0.8096 (0.7680) Average CE Loss (Source):  0.8096 ( 0.7680) Learning Rate: 0.1000 (0.1000) Top1_base: 75.0000 (78.3398) Top1_base_per_class: 77.3810 (79.3524) 
Training Epoch: [87/1000] Step: [50 / 285] Batch Time: 0.1492 (0.1717) Data Time: 0.0159 (0.0389) Average Loss: 1.0842 (0.7941) Average CE Loss (Source):  1.0842 ( 0.7941) Learning Rate: 0.1000 (0.1000) Top1_base: 67.9688 (77.8594) Top1_base_per_class: 73.4962 (78.7853) 
Training Epoch: [87/1000] Step: [60 / 285] Batch Time: 0.1425 (0.1693) Data Time: 0.0104 (0.0365) Average Loss: 0.8216 (0.8053) Average CE Loss (Source):  0.8216 ( 0.8053) Learning Rate: 0.1000 (0.1000) Top1_base: 78.9062 (77.6302) Top1_base_per_class: 81.6369 (78.5566) 
Training Epoch: [87/1000] Step: [70 / 285] Batch Time: 0.1434 (0.1687) Data Time: 0.0130 (0.0359) Average Loss: 0.6342 (0.8055) Average CE Loss (Source):  0.6342 ( 0.8055) Learning Rate: 0.1000 (0.1000) Top1_base: 84.3750 (77.4888) Top1_base_per_class: 84.6914 (78.4019) 
Training Epoch: [87/1000] Step: [80 / 285] Batch Time: 0.1430 (0.1675) Data Time: 0.0104 (0.0348) Average Loss: 0.7413 (0.7995) Average CE Loss (Source):  0.7413 ( 0.7995) Learning Rate: 0.1000 (0.1000) Top1_base: 78.1250 (77.7539) Top1_base_per_class: 78.4167 (78.4466) 
Training Epoch: [87/1000] Step: [90 / 285] Batch Time: 0.1484 (0.1672) Data Time: 0.0122 (0.0345) Average Loss: 0.7146 (0.8029) Average CE Loss (Source):  0.7146 ( 0.8029) Learning Rate: 0.1000 (0.1000) Top1_base: 80.4688 (77.7604) Top1_base_per_class: 79.8435 (78.3767) 
Training Epoch: [87/1000] Step: [100 / 285] Batch Time: 0.1417 (0.1662) Data Time: 0.0112 (0.0335) Average Loss: 0.8535 (0.7971) Average CE Loss (Source):  0.8535 ( 0.7971) Learning Rate: 0.1000 (0.1000) Top1_base: 74.2188 (77.8984) Top1_base_per_class: 73.4570 (78.4773) 
Training Epoch: [87/1000] Step: [110 / 285] Batch Time: 0.1478 (0.1657) Data Time: 0.0126 (0.0329) Average Loss: 0.5733 (0.7931) Average CE Loss (Source):  0.5733 ( 0.7931) Learning Rate: 0.1000 (0.1000) Top1_base: 84.3750 (77.9474) Top1_base_per_class: 84.3590 (78.6054) 
Training Epoch: [87/1000] Step: [120 / 285] Batch Time: 0.1454 (0.1648) Data Time: 0.0128 (0.0320) Average Loss: 0.8382 (0.7962) Average CE Loss (Source):  0.8382 ( 0.7962) Learning Rate: 0.1000 (0.1000) Top1_base: 75.7812 (77.8581) Top1_base_per_class: 78.2164 (78.5127) 
Training Epoch: [87/1000] Step: [130 / 285] Batch Time: 0.1468 (0.1641) Data Time: 0.0139 (0.0313) Average Loss: 0.8960 (0.8004) Average CE Loss (Source):  0.8960 ( 0.8004) Learning Rate: 0.1000 (0.1000) Top1_base: 75.7812 (77.7284) Top1_base_per_class: 75.1282 (78.3425) 
Training Epoch: [87/1000] Step: [140 / 285] Batch Time: 0.1428 (0.1631) Data Time: 0.0113 (0.0303) Average Loss: 0.6897 (0.7981) Average CE Loss (Source):  0.6897 ( 0.7981) Learning Rate: 0.1000 (0.1000) Top1_base: 81.2500 (77.7344) Top1_base_per_class: 81.3095 (78.3566) 
Training Epoch: [87/1000] Step: [150 / 285] Batch Time: 0.1473 (0.1627) Data Time: 0.0121 (0.0299) Average Loss: 0.7554 (0.7998) Average CE Loss (Source):  0.7554 ( 0.7998) Learning Rate: 0.1000 (0.1000) Top1_base: 81.2500 (77.7292) Top1_base_per_class: 82.7576 (78.3205) 
Training Epoch: [87/1000] Step: [160 / 285] Batch Time: 0.1426 (0.1619) Data Time: 0.0107 (0.0291) Average Loss: 0.6987 (0.8022) Average CE Loss (Source):  0.6987 ( 0.8022) Learning Rate: 0.1000 (0.1000) Top1_base: 80.4688 (77.6904) Top1_base_per_class: 78.4524 (78.2410) 
Training Epoch: [87/1000] Step: [170 / 285] Batch Time: 0.1473 (0.1616) Data Time: 0.0137 (0.0288) Average Loss: 0.6457 (0.8043) Average CE Loss (Source):  0.6457 ( 0.8043) Learning Rate: 0.1000 (0.1000) Top1_base: 81.2500 (77.5689) Top1_base_per_class: 84.3452 (78.1315) 
Training Epoch: [87/1000] Step: [180 / 285] Batch Time: 0.1420 (0.1616) Data Time: 0.0108 (0.0287) Average Loss: 0.8992 (0.8059) Average CE Loss (Source):  0.8992 ( 0.8059) Learning Rate: 0.1000 (0.1000) Top1_base: 74.2188 (77.5260) Top1_base_per_class: 75.2469 (78.1539) 
Training Epoch: [87/1000] Step: [190 / 285] Batch Time: 0.1463 (0.1610) Data Time: 0.0124 (0.0282) Average Loss: 0.5155 (0.8057) Average CE Loss (Source):  0.5155 ( 0.8057) Learning Rate: 0.1000 (0.1000) Top1_base: 88.2812 (77.5329) Top1_base_per_class: 87.2424 (78.1415) 
Training Epoch: [87/1000] Step: [200 / 285] Batch Time: 0.1425 (0.1610) Data Time: 0.0113 (0.0282) Average Loss: 0.7467 (0.8085) Average CE Loss (Source):  0.7467 ( 0.8085) Learning Rate: 0.1000 (0.1000) Top1_base: 82.0312 (77.4844) Top1_base_per_class: 81.6667 (78.1146) 
Training Epoch: [87/1000] Step: [210 / 285] Batch Time: 0.1494 (0.1605) Data Time: 0.0145 (0.0277) Average Loss: 0.7125 (0.8090) Average CE Loss (Source):  0.7125 ( 0.8090) Learning Rate: 0.1000 (0.1000) Top1_base: 78.1250 (77.4814) Top1_base_per_class: 76.9494 (78.1024) 
Training Epoch: [87/1000] Step: [220 / 285] Batch Time: 0.1425 (0.1604) Data Time: 0.0104 (0.0276) Average Loss: 1.0077 (0.8084) Average CE Loss (Source):  1.0077 ( 0.8084) Learning Rate: 0.1000 (0.1000) Top1_base: 74.2188 (77.4822) Top1_base_per_class: 75.5315 (78.0992) 
Training Epoch: [87/1000] Step: [230 / 285] Batch Time: 0.1476 (0.1598) Data Time: 0.0140 (0.0270) Average Loss: 0.9151 (0.8108) Average CE Loss (Source):  0.9151 ( 0.8108) Learning Rate: 0.1000 (0.1000) Top1_base: 75.0000 (77.4185) Top1_base_per_class: 78.9655 (77.9859) 
Training Epoch: [87/1000] Step: [240 / 285] Batch Time: 0.1420 (0.1597) Data Time: 0.0106 (0.0269) Average Loss: 0.9100 (0.8138) Average CE Loss (Source):  0.9100 ( 0.8138) Learning Rate: 0.1000 (0.1000) Top1_base: 77.3438 (77.3405) Top1_base_per_class: 79.8810 (77.8921) 
Training Epoch: [87/1000] Step: [250 / 285] Batch Time: 0.1417 (0.1592) Data Time: 0.0121 (0.0264) Average Loss: 0.9965 (0.8162) Average CE Loss (Source):  0.9965 ( 0.8162) Learning Rate: 0.1000 (0.1000) Top1_base: 68.7500 (77.2438) Top1_base_per_class: 67.3636 (77.7928) 
Training Epoch: [87/1000] Step: [260 / 285] Batch Time: 0.1440 (0.1590) Data Time: 0.0122 (0.0263) Average Loss: 0.9040 (0.8183) Average CE Loss (Source):  0.9040 ( 0.8183) Learning Rate: 0.1000 (0.1000) Top1_base: 73.4375 (77.1785) Top1_base_per_class: 75.2381 (77.7668) 
Training Epoch: [87/1000] Step: [270 / 285] Batch Time: 0.1485 (0.1587) Data Time: 0.0144 (0.0260) Average Loss: 0.7889 (0.8195) Average CE Loss (Source):  0.7889 ( 0.8195) Learning Rate: 0.1000 (0.1000) Top1_base: 76.5625 (77.1557) Top1_base_per_class: 75.7310 (77.7534) 
Training Epoch: [87/1000] Step: [280 / 285] Batch Time: 0.1419 (0.1589) Data Time: 0.0104 (0.0261) Average Loss: 0.8838 (0.8221) Average CE Loss (Source):  0.8838 ( 0.8221) Learning Rate: 0.1000 (0.1000) Top1_base: 79.6875 (77.0926) Top1_base_per_class: 81.7559 (77.7320) 
Training Epoch: [88/1000] Step: [0] Batch Time: 0.1400 (0.1586) Data Time: 0.0106 (0.0259) Average Loss: 0.8730 (0.8230) Average CE Loss (Source):  0.8730 ( 0.8230) Learning Rate: 0.1000 (0.1000) Top1_base: 76.5625 (77.0916) Top1_base_per_class: 78.5965 (77.7151) 
  9%|▉         | 88/1000 [1:09:03<11:49:48, 46.70s/it]  9%|▉         | 89/1000 [1:09:48<11:41:23, 46.20s/it]Training Epoch: [88/1000] Step: [10 / 285] Batch Time: 0.1458 (0.2308) Data Time: 0.0119 (0.0983) Average Loss: 1.0251 (0.8448) Average CE Loss (Source):  1.0251 ( 0.8448) Learning Rate: 0.1000 (0.1000) Top1_base: 69.5312 (76.4062) Top1_base_per_class: 69.3785 (77.7975) 
Training Epoch: [88/1000] Step: [20 / 285] Batch Time: 0.1445 (0.1921) Data Time: 0.0103 (0.0592) Average Loss: 1.0877 (0.8702) Average CE Loss (Source):  1.0877 ( 0.8702) Learning Rate: 0.1000 (0.1000) Top1_base: 71.0938 (75.9766) Top1_base_per_class: 74.6296 (76.7125) 
Training Epoch: [88/1000] Step: [30 / 285] Batch Time: 0.1474 (0.1786) Data Time: 0.0128 (0.0455) Average Loss: 0.9930 (0.8589) Average CE Loss (Source):  0.9930 ( 0.8589) Learning Rate: 0.1000 (0.1000) Top1_base: 71.0938 (76.3021) Top1_base_per_class: 70.0606 (77.3723) 
Training Epoch: [88/1000] Step: [40 / 285] Batch Time: 0.1444 (0.1758) Data Time: 0.0106 (0.0427) Average Loss: 0.8150 (0.8543) Average CE Loss (Source):  0.8150 ( 0.8543) Learning Rate: 0.1000 (0.1000) Top1_base: 78.1250 (76.4258) Top1_base_per_class: 81.7797 (77.2939) 
Training Epoch: [88/1000] Step: [50 / 285] Batch Time: 0.1440 (0.1729) Data Time: 0.0116 (0.0399) Average Loss: 0.9913 (0.8574) Average CE Loss (Source):  0.9913 ( 0.8574) Learning Rate: 0.1000 (0.1000) Top1_base: 71.8750 (76.3125) Top1_base_per_class: 72.7044 (77.3818) 
Training Epoch: [88/1000] Step: [60 / 285] Batch Time: 0.1425 (0.1698) Data Time: 0.0118 (0.0367) Average Loss: 0.8746 (0.8489) Average CE Loss (Source):  0.8746 ( 0.8489) Learning Rate: 0.1000 (0.1000) Top1_base: 73.4375 (76.5104) Top1_base_per_class: 74.3103 (77.3974) 
Training Epoch: [88/1000] Step: [70 / 285] Batch Time: 0.1465 (0.1680) Data Time: 0.0144 (0.0350) Average Loss: 0.6312 (0.8508) Average CE Loss (Source):  0.6312 ( 0.8508) Learning Rate: 0.1000 (0.1000) Top1_base: 80.4688 (76.4621) Top1_base_per_class: 80.0606 (77.3824) 
Training Epoch: [88/1000] Step: [80 / 285] Batch Time: 0.1443 (0.1685) Data Time: 0.0103 (0.0353) Average Loss: 0.6809 (0.8447) Average CE Loss (Source):  0.6809 ( 0.8447) Learning Rate: 0.1000 (0.1000) Top1_base: 78.1250 (76.6406) Top1_base_per_class: 76.3793 (77.4207) 
Training Epoch: [88/1000] Step: [90 / 285] Batch Time: 0.1473 (0.1668) Data Time: 0.0128 (0.0336) Average Loss: 0.8321 (0.8453) Average CE Loss (Source):  0.8321 ( 0.8453) Learning Rate: 0.1000 (0.1000) Top1_base: 78.9062 (76.6753) Top1_base_per_class: 77.4383 (77.2735) 
Training Epoch: [88/1000] Step: [100 / 285] Batch Time: 0.1446 (0.1668) Data Time: 0.0103 (0.0336) Average Loss: 0.6343 (0.8383) Average CE Loss (Source):  0.6343 ( 0.8383) Learning Rate: 0.1000 (0.1000) Top1_base: 82.0312 (76.8359) Top1_base_per_class: 82.2857 (77.3756) 
Training Epoch: [88/1000] Step: [110 / 285] Batch Time: 0.1422 (0.1652) Data Time: 0.0108 (0.0321) Average Loss: 1.0306 (0.8351) Average CE Loss (Source):  1.0306 ( 0.8351) Learning Rate: 0.1000 (0.1000) Top1_base: 68.7500 (76.8679) Top1_base_per_class: 67.9453 (77.3636) 
Training Epoch: [88/1000] Step: [120 / 285] Batch Time: 0.1446 (0.1642) Data Time: 0.0103 (0.0312) Average Loss: 0.6774 (0.8301) Average CE Loss (Source):  0.6774 ( 0.8301) Learning Rate: 0.1000 (0.1000) Top1_base: 79.6875 (76.9661) Top1_base_per_class: 78.9744 (77.4814) 
Training Epoch: [88/1000] Step: [130 / 285] Batch Time: 0.1436 (0.1630) Data Time: 0.0122 (0.0300) Average Loss: 0.9524 (0.8298) Average CE Loss (Source):  0.9524 ( 0.8298) Learning Rate: 0.1000 (0.1000) Top1_base: 75.7812 (76.9772) Top1_base_per_class: 80.4762 (77.5167) 
Training Epoch: [88/1000] Step: [140 / 285] Batch Time: 0.1451 (0.1622) Data Time: 0.0105 (0.0292) Average Loss: 0.8621 (0.8316) Average CE Loss (Source):  0.8621 ( 0.8316) Learning Rate: 0.1000 (0.1000) Top1_base: 77.3438 (76.7969) Top1_base_per_class: 81.3736 (77.3843) 
Training Epoch: [88/1000] Step: [150 / 285] Batch Time: 0.1433 (0.1622) Data Time: 0.0121 (0.0293) Average Loss: 0.9923 (0.8321) Average CE Loss (Source):  0.9923 ( 0.8321) Learning Rate: 0.1000 (0.1000) Top1_base: 76.5625 (76.8073) Top1_base_per_class: 78.2185 (77.3932) 
Training Epoch: [88/1000] Step: [160 / 285] Batch Time: 0.1445 (0.1618) Data Time: 0.0101 (0.0289) Average Loss: 0.8673 (0.8335) Average CE Loss (Source):  0.8673 ( 0.8335) Learning Rate: 0.1000 (0.1000) Top1_base: 78.9062 (76.8506) Top1_base_per_class: 77.0833 (77.4113) 
Training Epoch: [88/1000] Step: [170 / 285] Batch Time: 0.1458 (0.1614) Data Time: 0.0126 (0.0285) Average Loss: 0.9999 (0.8354) Average CE Loss (Source):  0.9999 ( 0.8354) Learning Rate: 0.1000 (0.1000) Top1_base: 73.4375 (76.7785) Top1_base_per_class: 75.7680 (77.2801) 
Training Epoch: [88/1000] Step: [180 / 285] Batch Time: 0.1419 (0.1610) Data Time: 0.0116 (0.0281) Average Loss: 0.8953 (0.8379) Average CE Loss (Source):  0.8953 ( 0.8379) Learning Rate: 0.1000 (0.1000) Top1_base: 79.6875 (76.7057) Top1_base_per_class: 82.6144 (77.1820) 
Training Epoch: [88/1000] Step: [190 / 285] Batch Time: 0.1473 (0.1603) Data Time: 0.0114 (0.0274) Average Loss: 0.7059 (0.8382) Average CE Loss (Source):  0.7059 ( 0.8382) Learning Rate: 0.1000 (0.1000) Top1_base: 79.6875 (76.6900) Top1_base_per_class: 78.0226 (77.0774) 
Training Epoch: [88/1000] Step: [200 / 285] Batch Time: 0.1445 (0.1596) Data Time: 0.0111 (0.0268) Average Loss: 0.7172 (0.8398) Average CE Loss (Source):  0.7172 ( 0.8398) Learning Rate: 0.1000 (0.1000) Top1_base: 80.4688 (76.6328) Top1_base_per_class: 84.3678 (77.0761) 
Training Epoch: [88/1000] Step: [210 / 285] Batch Time: 0.1436 (0.1596) Data Time: 0.0121 (0.0267) Average Loss: 0.7920 (0.8432) Average CE Loss (Source):  0.7920 ( 0.8432) Learning Rate: 0.1000 (0.1000) Top1_base: 75.7812 (76.5625) Top1_base_per_class: 74.3452 (76.9328) 
Training Epoch: [88/1000] Step: [220 / 285] Batch Time: 0.1444 (0.1594) Data Time: 0.0103 (0.0265) Average Loss: 0.7766 (0.8448) Average CE Loss (Source):  0.7766 ( 0.8448) Learning Rate: 0.1000 (0.1000) Top1_base: 78.1250 (76.4986) Top1_base_per_class: 79.2690 (76.8766) 
Training Epoch: [88/1000] Step: [230 / 285] Batch Time: 0.1461 (0.1592) Data Time: 0.0110 (0.0263) Average Loss: 0.9529 (0.8451) Average CE Loss (Source):  0.9529 ( 0.8451) Learning Rate: 0.1000 (0.1000) Top1_base: 71.0938 (76.4538) Top1_base_per_class: 74.2424 (76.8221) 
Training Epoch: [88/1000] Step: [240 / 285] Batch Time: 0.1435 (0.1589) Data Time: 0.0114 (0.0261) Average Loss: 0.7584 (0.8460) Average CE Loss (Source):  0.7584 ( 0.8460) Learning Rate: 0.1000 (0.1000) Top1_base: 78.1250 (76.4421) Top1_base_per_class: 81.1864 (76.8418) 
Training Epoch: [88/1000] Step: [250 / 285] Batch Time: 0.1449 (0.1585) Data Time: 0.0113 (0.0257) Average Loss: 0.8071 (0.8467) Average CE Loss (Source):  0.8071 ( 0.8467) Learning Rate: 0.1000 (0.1000) Top1_base: 78.1250 (76.3625) Top1_base_per_class: 78.6792 (76.7613) 
Training Epoch: [88/1000] Step: [260 / 285] Batch Time: 0.1453 (0.1583) Data Time: 0.0104 (0.0254) Average Loss: 0.9983 (0.8476) Average CE Loss (Source):  0.9983 ( 0.8476) Learning Rate: 0.1000 (0.1000) Top1_base: 71.0938 (76.3492) Top1_base_per_class: 72.7576 (76.7776) 
Training Epoch: [88/1000] Step: [270 / 285] Batch Time: 0.1446 (0.1581) Data Time: 0.0115 (0.0253) Average Loss: 0.7014 (0.8452) Average CE Loss (Source):  0.7014 ( 0.8452) Learning Rate: 0.1000 (0.1000) Top1_base: 80.4688 (76.3918) Top1_base_per_class: 79.7701 (76.8107) 
Training Epoch: [88/1000] Step: [280 / 285] Batch Time: 0.1441 (0.1579) Data Time: 0.0099 (0.0251) Average Loss: 1.0866 (0.8446) Average CE Loss (Source):  1.0866 ( 0.8446) Learning Rate: 0.1000 (0.1000) Top1_base: 66.4062 (76.3449) Top1_base_per_class: 65.2679 (76.7611) 
Training Epoch: [89/1000] Step: [0] Batch Time: 0.1418 (0.1577) Data Time: 0.0116 (0.0249) Average Loss: 0.9823 (0.8451) Average CE Loss (Source):  0.9823 ( 0.8451) Learning Rate: 0.1000 (0.1000) Top1_base: 71.0938 (76.3048) Top1_base_per_class: 71.0333 (76.7310) 
Training Epoch: [89/1000] Step: [10 / 285] Batch Time: 0.1448 (0.2335) Data Time: 0.0110 (0.1011) Average Loss: 0.7780 (0.8042) Average CE Loss (Source):  0.7780 ( 0.8042) Learning Rate: 0.1000 (0.1000) Top1_base: 76.5625 (76.4844) Top1_base_per_class: 77.3889 (76.3321) 
Training Epoch: [89/1000] Step: [20 / 285] Batch Time: 0.1441 (0.1910) Data Time: 0.0105 (0.0585) Average Loss: 0.8101 (0.7778) Average CE Loss (Source):  0.8101 ( 0.7778) Learning Rate: 0.1000 (0.1000) Top1_base: 75.0000 (78.0859) Top1_base_per_class: 74.3750 (78.4269) 
Training Epoch: [89/1000] Step: [30 / 285] Batch Time: 0.1506 (0.1787) Data Time: 0.0180 (0.0460) Average Loss: 0.6896 (0.7623) Average CE Loss (Source):  0.6896 ( 0.7623) Learning Rate: 0.1000 (0.1000) Top1_base: 79.6875 (78.6719) Top1_base_per_class: 78.9181 (78.8323) 
Training Epoch: [89/1000] Step: [40 / 285] Batch Time: 0.1428 (0.1732) Data Time: 0.0104 (0.0404) Average Loss: 0.7857 (0.7727) Average CE Loss (Source):  0.7857 ( 0.7727) Learning Rate: 0.1000 (0.1000) Top1_base: 77.3438 (78.1836) Top1_base_per_class: 78.8095 (78.4490) 
Training Epoch: [89/1000] Step: [50 / 285] Batch Time: 0.1465 (0.1703) Data Time: 0.0164 (0.0375) Average Loss: 0.8366 (0.7728) Average CE Loss (Source):  0.8366 ( 0.7728) Learning Rate: 0.1000 (0.1000) Top1_base: 79.6875 (78.3125) Top1_base_per_class: 82.7273 (78.7754) 
Training Epoch: [89/1000] Step: [60 / 285] Batch Time: 0.1449 (0.1674) Data Time: 0.0113 (0.0348) Average Loss: 0.7164 (0.7801) Average CE Loss (Source):  0.7164 ( 0.7801) Learning Rate: 0.1000 (0.1000) Top1_base: 79.6875 (78.0859) Top1_base_per_class: 82.3939 (78.7360) 
Training Epoch: [89/1000] Step: [70 / 285] Batch Time: 0.1478 (0.1652) Data Time: 0.0158 (0.0326) Average Loss: 0.8849 (0.7821) Average CE Loss (Source):  0.8849 ( 0.7821) Learning Rate: 0.1000 (0.1000) Top1_base: 75.7812 (78.0580) Top1_base_per_class: 78.2748 (78.6722) 
Training Epoch: [89/1000] Step: [80 / 285] Batch Time: 0.1421 (0.1639) Data Time: 0.0114 (0.0313) Average Loss: 0.8407 (0.7898) Average CE Loss (Source):  0.8407 ( 0.7898) Learning Rate: 0.1000 (0.1000) Top1_base: 75.0000 (77.7734) Top1_base_per_class: 72.7422 (78.3049) 
Training Epoch: [89/1000] Step: [90 / 285] Batch Time: 0.2395 (0.1642) Data Time: 0.1084 (0.0316) Average Loss: 0.8286 (0.7871) Average CE Loss (Source):  0.8286 ( 0.7871) Learning Rate: 0.1000 (0.1000) Top1_base: 76.5625 (77.8993) Top1_base_per_class: 78.2121 (78.5044) 
Training Epoch: [89/1000] Step: [100 / 285] Batch Time: 0.1448 (0.1626) Data Time: 0.0111 (0.0300) Average Loss: 0.7676 (0.7881) Average CE Loss (Source):  0.7676 ( 0.7881) Learning Rate: 0.1000 (0.1000) Top1_base: 78.9062 (78.0234) Top1_base_per_class: 81.8210 (78.6935) 
Training Epoch: [89/1000] Step: [110 / 285] Batch Time: 0.1596 (0.1625) Data Time: 0.0291 (0.0300) Average Loss: 0.8281 (0.7877) Average CE Loss (Source):  0.8281 ( 0.7877) Learning Rate: 0.1000 (0.1000) Top1_base: 76.5625 (77.8906) Top1_base_per_class: 76.6369 (78.5631) 
Training Epoch: [89/1000] Step: [120 / 285] Batch Time: 0.1442 (0.1622) Data Time: 0.0127 (0.0297) Average Loss: 0.8001 (0.7924) Average CE Loss (Source):  0.8001 ( 0.7924) Learning Rate: 0.1000 (0.1000) Top1_base: 76.5625 (77.7669) Top1_base_per_class: 79.6199 (78.5353) 
Training Epoch: [89/1000] Step: [130 / 285] Batch Time: 0.1691 (0.1611) Data Time: 0.0371 (0.0286) Average Loss: 0.7871 (0.7938) Average CE Loss (Source):  0.7871 ( 0.7938) Learning Rate: 0.1000 (0.1000) Top1_base: 81.2500 (77.7224) Top1_base_per_class: 81.6667 (78.4145) 
Training Epoch: [89/1000] Step: [140 / 285] Batch Time: 0.1422 (0.1600) Data Time: 0.0113 (0.0275) Average Loss: 0.7694 (0.7963) Average CE Loss (Source):  0.7694 ( 0.7963) Learning Rate: 0.1000 (0.1000) Top1_base: 82.8125 (77.6674) Top1_base_per_class: 82.5000 (78.3044) 
Training Epoch: [89/1000] Step: [150 / 285] Batch Time: 0.1580 (0.1594) Data Time: 0.0248 (0.0269) Average Loss: 0.9605 (0.7985) Average CE Loss (Source):  0.9605 ( 0.7985) Learning Rate: 0.1000 (0.1000) Top1_base: 69.5312 (77.5469) Top1_base_per_class: 70.7018 (78.2268) 
Training Epoch: [89/1000] Step: [160 / 285] Batch Time: 0.1421 (0.1592) Data Time: 0.0116 (0.0268) Average Loss: 0.8109 (0.8002) Average CE Loss (Source):  0.8109 ( 0.8002) Learning Rate: 0.1000 (0.1000) Top1_base: 72.6562 (77.5098) Top1_base_per_class: 75.5650 (78.1487) 
Training Epoch: [89/1000] Step: [170 / 285] Batch Time: 0.1730 (0.1589) Data Time: 0.0396 (0.0264) Average Loss: 0.8250 (0.7958) Average CE Loss (Source):  0.8250 ( 0.7958) Learning Rate: 0.1000 (0.1000) Top1_base: 76.5625 (77.6287) Top1_base_per_class: 79.4915 (78.2547) 
Training Epoch: [89/1000] Step: [180 / 285] Batch Time: 0.1430 (0.1585) Data Time: 0.0103 (0.0261) Average Loss: 0.8606 (0.7977) Average CE Loss (Source):  0.8606 ( 0.7977) Learning Rate: 0.1000 (0.1000) Top1_base: 78.9062 (77.6476) Top1_base_per_class: 77.8572 (78.2784) 
Training Epoch: [89/1000] Step: [190 / 285] Batch Time: 0.1944 (0.1583) Data Time: 0.0622 (0.0259) Average Loss: 0.9661 (0.7986) Average CE Loss (Source):  0.9661 ( 0.7986) Learning Rate: 0.1000 (0.1000) Top1_base: 73.4375 (77.5740) Top1_base_per_class: 75.1299 (78.2160) 
Training Epoch: [89/1000] Step: [200 / 285] Batch Time: 0.1474 (0.1588) Data Time: 0.0116 (0.0263) Average Loss: 0.8348 (0.8010) Average CE Loss (Source):  0.8348 ( 0.8010) Learning Rate: 0.1000 (0.1000) Top1_base: 78.1250 (77.5352) Top1_base_per_class: 77.3030 (78.1184) 
Training Epoch: [89/1000] Step: [210 / 285] Batch Time: 0.1529 (0.1586) Data Time: 0.0183 (0.0260) Average Loss: 0.9847 (0.8022) Average CE Loss (Source):  0.9847 ( 0.8022) Learning Rate: 0.1000 (0.1000) Top1_base: 73.4375 (77.5000) Top1_base_per_class: 70.3766 (78.0723) 
Training Epoch: [89/1000] Step: [220 / 285] Batch Time: 0.1428 (0.1583) Data Time: 0.0107 (0.0255) Average Loss: 0.8498 (0.8027) Average CE Loss (Source):  0.8498 ( 0.8027) Learning Rate: 0.1000 (0.1000) Top1_base: 76.5625 (77.4716) Top1_base_per_class: 75.7576 (77.9968) 
Training Epoch: [89/1000] Step: [230 / 285] Batch Time: 0.1477 (0.1577) Data Time: 0.0164 (0.0250) Average Loss: 0.9820 (0.8052) Average CE Loss (Source):  0.9820 ( 0.8052) Learning Rate: 0.1000 (0.1000) Top1_base: 71.0938 (77.4490) Top1_base_per_class: 71.1538 (77.9877) 
Training Epoch: [89/1000] Step: [240 / 285] Batch Time: 0.1441 (0.1577) Data Time: 0.0108 (0.0249) Average Loss: 0.9049 (0.8060) Average CE Loss (Source):  0.9049 ( 0.8060) Learning Rate: 0.1000 (0.1000) Top1_base: 76.5625 (77.3958) Top1_base_per_class: 74.5062 (77.8898) 
Training Epoch: [89/1000] Step: [250 / 285] Batch Time: 0.1486 (0.1573) Data Time: 0.0154 (0.0245) Average Loss: 0.8264 (0.8057) Average CE Loss (Source):  0.8264 ( 0.8057) Learning Rate: 0.1000 (0.1000) Top1_base: 76.5625 (77.3812) Top1_base_per_class: 76.0758 (77.8566) 
Training Epoch: [89/1000] Step: [260 / 285] Batch Time: 0.1448 (0.1571) Data Time: 0.0103 (0.0243) Average Loss: 0.9061 (0.8087) Average CE Loss (Source):  0.9061 ( 0.8087) Learning Rate: 0.1000 (0.1000) Top1_base: 77.3438 (77.2957) Top1_base_per_class: 79.0936 (77.7979) 
Training Epoch: [89/1000] Step: [270 / 285] Batch Time: 0.1514 (0.1568) Data Time: 0.0166 (0.0239) Average Loss: 0.9197 (0.8103) Average CE Loss (Source):  0.9197 ( 0.8103) Learning Rate: 0.1000 (0.1000) Top1_base: 75.7812 (77.2714) Top1_base_per_class: 79.1092 (77.8305) 
Training Epoch: [89/1000] Step: [280 / 285] Batch Time: 0.1441 (0.1564) Data Time: 0.0099 (0.0235) Average Loss: 0.6607 (0.8127) Average CE Loss (Source):  0.6607 ( 0.8127) Learning Rate: 0.1000 (0.1000) Top1_base: 77.3438 (77.2321) Top1_base_per_class: 74.8268 (77.7951) 
Training Epoch: [90/1000] Step: [0] Batch Time: 0.1451 (0.1564) Data Time: 0.0121 (0.0235) Average Loss: 1.0066 (0.8125) Average CE Loss (Source):  1.0066 ( 0.8125) Learning Rate: 0.1000 (0.1000) Top1_base: 72.6562 (77.2423) Top1_base_per_class: 72.4510 (77.8120) 
  9%|▉         | 90/1000 [1:10:35<11:46:04, 46.55s/it]  9%|▉         | 91/1000 [1:11:20<11:35:59, 45.94s/it]Training Epoch: [90/1000] Step: [10 / 285] Batch Time: 0.1443 (0.2407) Data Time: 0.0100 (0.1080) Average Loss: 0.6788 (0.7382) Average CE Loss (Source):  0.6788 ( 0.7382) Learning Rate: 0.1000 (0.1000) Top1_base: 82.0312 (80.2344) Top1_base_per_class: 84.3301 (79.6962) 
Training Epoch: [90/1000] Step: [20 / 285] Batch Time: 0.1471 (0.2026) Data Time: 0.0112 (0.0702) Average Loss: 0.8559 (0.7622) Average CE Loss (Source):  0.8559 ( 0.7622) Learning Rate: 0.1000 (0.1000) Top1_base: 71.8750 (78.7891) Top1_base_per_class: 72.9240 (78.9068) 
Training Epoch: [90/1000] Step: [30 / 285] Batch Time: 0.1430 (0.1870) Data Time: 0.0103 (0.0548) Average Loss: 0.8010 (0.7726) Average CE Loss (Source):  0.8010 ( 0.7726) Learning Rate: 0.1000 (0.1000) Top1_base: 75.7812 (78.7500) Top1_base_per_class: 75.0127 (78.8651) 
Training Epoch: [90/1000] Step: [40 / 285] Batch Time: 0.1441 (0.1792) Data Time: 0.0125 (0.0470) Average Loss: 0.8875 (0.7817) Average CE Loss (Source):  0.8875 ( 0.7817) Learning Rate: 0.1000 (0.1000) Top1_base: 75.7812 (78.3398) Top1_base_per_class: 75.2083 (78.3244) 
Training Epoch: [90/1000] Step: [50 / 285] Batch Time: 0.1450 (0.1744) Data Time: 0.0121 (0.0420) Average Loss: 0.8784 (0.7954) Average CE Loss (Source):  0.8784 ( 0.7954) Learning Rate: 0.1000 (0.1000) Top1_base: 75.0000 (77.7969) Top1_base_per_class: 73.6970 (77.8799) 
Training Epoch: [90/1000] Step: [60 / 285] Batch Time: 0.1477 (0.1704) Data Time: 0.0147 (0.0377) Average Loss: 0.9011 (0.8006) Average CE Loss (Source):  0.9011 ( 0.8006) Learning Rate: 0.1000 (0.1000) Top1_base: 75.0000 (77.9036) Top1_base_per_class: 76.1696 (78.0808) 
Training Epoch: [90/1000] Step: [70 / 285] Batch Time: 0.1458 (0.1686) Data Time: 0.0106 (0.0358) Average Loss: 0.6623 (0.8049) Average CE Loss (Source):  0.6623 ( 0.8049) Learning Rate: 0.1000 (0.1000) Top1_base: 82.0312 (77.6228) Top1_base_per_class: 82.0833 (77.8498) 
Training Epoch: [90/1000] Step: [80 / 285] Batch Time: 0.1465 (0.1658) Data Time: 0.0129 (0.0330) Average Loss: 0.8875 (0.8067) Average CE Loss (Source):  0.8875 ( 0.8067) Learning Rate: 0.1000 (0.1000) Top1_base: 76.5625 (77.5293) Top1_base_per_class: 74.5679 (77.9479) 
Training Epoch: [90/1000] Step: [90 / 285] Batch Time: 0.1464 (0.1652) Data Time: 0.0105 (0.0324) Average Loss: 0.7422 (0.8098) Average CE Loss (Source):  0.7422 ( 0.8098) Learning Rate: 0.1000 (0.1000) Top1_base: 78.1250 (77.3872) Top1_base_per_class: 79.7222 (77.8740) 
Training Epoch: [90/1000] Step: [100 / 285] Batch Time: 0.1502 (0.1641) Data Time: 0.0151 (0.0312) Average Loss: 0.5713 (0.8104) Average CE Loss (Source):  0.5713 ( 0.8104) Learning Rate: 0.1000 (0.1000) Top1_base: 79.6875 (77.2500) Top1_base_per_class: 81.5278 (77.6927) 
Training Epoch: [90/1000] Step: [110 / 285] Batch Time: 0.1444 (0.1626) Data Time: 0.0108 (0.0298) Average Loss: 0.7411 (0.8125) Average CE Loss (Source):  0.7411 ( 0.8125) Learning Rate: 0.1000 (0.1000) Top1_base: 81.2500 (77.2301) Top1_base_per_class: 82.9762 (77.7882) 
Training Epoch: [90/1000] Step: [120 / 285] Batch Time: 0.1473 (0.1613) Data Time: 0.0134 (0.0284) Average Loss: 0.8357 (0.8134) Average CE Loss (Source):  0.8357 ( 0.8134) Learning Rate: 0.1000 (0.1000) Top1_base: 75.0000 (77.2331) Top1_base_per_class: 74.7576 (77.8115) 
Training Epoch: [90/1000] Step: [130 / 285] Batch Time: 0.1423 (0.1605) Data Time: 0.0113 (0.0277) Average Loss: 0.9230 (0.8129) Average CE Loss (Source):  0.9230 ( 0.8129) Learning Rate: 0.1000 (0.1000) Top1_base: 73.4375 (77.1815) Top1_base_per_class: 73.2372 (77.7702) 
Training Epoch: [90/1000] Step: [140 / 285] Batch Time: 0.1461 (0.1604) Data Time: 0.0136 (0.0275) Average Loss: 1.0198 (0.8181) Average CE Loss (Source):  1.0198 ( 0.8181) Learning Rate: 0.1000 (0.1000) Top1_base: 73.4375 (77.1429) Top1_base_per_class: 73.7500 (77.7576) 
Training Epoch: [90/1000] Step: [150 / 285] Batch Time: 0.1452 (0.1604) Data Time: 0.0110 (0.0276) Average Loss: 0.7929 (0.8167) Average CE Loss (Source):  0.7929 ( 0.8167) Learning Rate: 0.1000 (0.1000) Top1_base: 78.1250 (77.2188) Top1_base_per_class: 79.4048 (77.8187) 
Training Epoch: [90/1000] Step: [160 / 285] Batch Time: 0.2194 (0.1604) Data Time: 0.0869 (0.0276) Average Loss: 0.6796 (0.8184) Average CE Loss (Source):  0.6796 ( 0.8184) Learning Rate: 0.1000 (0.1000) Top1_base: 81.2500 (77.1387) Top1_base_per_class: 79.8148 (77.7530) 
Training Epoch: [90/1000] Step: [170 / 285] Batch Time: 0.1422 (0.1595) Data Time: 0.0124 (0.0268) Average Loss: 0.9192 (0.8185) Average CE Loss (Source):  0.9192 ( 0.8185) Learning Rate: 0.1000 (0.1000) Top1_base: 75.0000 (77.1553) Top1_base_per_class: 80.4762 (77.8192) 
Training Epoch: [90/1000] Step: [180 / 285] Batch Time: 0.1955 (0.1600) Data Time: 0.0633 (0.0273) Average Loss: 0.8508 (0.8170) Average CE Loss (Source):  0.8508 ( 0.8170) Learning Rate: 0.1000 (0.1000) Top1_base: 75.7812 (77.1788) Top1_base_per_class: 72.0278 (77.8173) 
Training Epoch: [90/1000] Step: [190 / 285] Batch Time: 0.1445 (0.1593) Data Time: 0.0128 (0.0267) Average Loss: 0.8304 (0.8196) Average CE Loss (Source):  0.8304 ( 0.8196) Learning Rate: 0.1000 (0.1000) Top1_base: 78.9062 (77.1382) Top1_base_per_class: 82.0909 (77.7787) 
Training Epoch: [90/1000] Step: [200 / 285] Batch Time: 0.1503 (0.1587) Data Time: 0.0163 (0.0260) Average Loss: 0.7512 (0.8196) Average CE Loss (Source):  0.7512 ( 0.8196) Learning Rate: 0.1000 (0.1000) Top1_base: 77.3438 (77.1133) Top1_base_per_class: 80.4094 (77.7520) 
Training Epoch: [90/1000] Step: [210 / 285] Batch Time: 0.1487 (0.1586) Data Time: 0.0111 (0.0257) Average Loss: 0.7862 (0.8199) Average CE Loss (Source):  0.7862 ( 0.8199) Learning Rate: 0.1000 (0.1000) Top1_base: 76.5625 (77.1131) Top1_base_per_class: 78.6926 (77.7752) 
Training Epoch: [90/1000] Step: [220 / 285] Batch Time: 0.1539 (0.1584) Data Time: 0.0207 (0.0254) Average Loss: 0.7587 (0.8191) Average CE Loss (Source):  0.7587 ( 0.8191) Learning Rate: 0.1000 (0.1000) Top1_base: 76.5625 (77.1484) Top1_base_per_class: 74.4136 (77.7542) 
Training Epoch: [90/1000] Step: [230 / 285] Batch Time: 0.1469 (0.1580) Data Time: 0.0147 (0.0249) Average Loss: 0.7621 (0.8168) Average CE Loss (Source):  0.7621 ( 0.8168) Learning Rate: 0.1000 (0.1000) Top1_base: 78.1250 (77.1807) Top1_base_per_class: 82.3611 (77.7787) 
Training Epoch: [90/1000] Step: [240 / 285] Batch Time: 0.1531 (0.1578) Data Time: 0.0197 (0.0247) Average Loss: 0.8389 (0.8176) Average CE Loss (Source):  0.8389 ( 0.8176) Learning Rate: 0.1000 (0.1000) Top1_base: 79.6875 (77.1908) Top1_base_per_class: 78.9474 (77.7552) 
Training Epoch: [90/1000] Step: [250 / 285] Batch Time: 0.1482 (0.1574) Data Time: 0.0111 (0.0243) Average Loss: 0.8918 (0.8202) Average CE Loss (Source):  0.8918 ( 0.8202) Learning Rate: 0.1000 (0.1000) Top1_base: 75.0000 (77.1031) Top1_base_per_class: 72.8448 (77.6759) 
Training Epoch: [90/1000] Step: [260 / 285] Batch Time: 0.1475 (0.1570) Data Time: 0.0160 (0.0239) Average Loss: 0.9055 (0.8204) Average CE Loss (Source):  0.9055 ( 0.8204) Learning Rate: 0.1000 (0.1000) Top1_base: 75.0000 (77.1094) Top1_base_per_class: 72.4980 (77.6932) 
Training Epoch: [90/1000] Step: [270 / 285] Batch Time: 0.1474 (0.1566) Data Time: 0.0122 (0.0235) Average Loss: 0.8898 (0.8212) Average CE Loss (Source):  0.8898 ( 0.8212) Learning Rate: 0.1000 (0.1000) Top1_base: 77.3438 (77.1123) Top1_base_per_class: 77.9240 (77.6967) 
Training Epoch: [90/1000] Step: [280 / 285] Batch Time: 0.1454 (0.1562) Data Time: 0.0127 (0.0231) Average Loss: 0.8769 (0.8206) Average CE Loss (Source):  0.8769 ( 0.8206) Learning Rate: 0.1000 (0.1000) Top1_base: 78.9062 (77.1122) Top1_base_per_class: 77.9661 (77.6941) 
Training Epoch: [91/1000] Step: [0] Batch Time: 0.1412 (0.1559) Data Time: 0.0109 (0.0229) Average Loss: 0.9812 (0.8220) Average CE Loss (Source):  0.9812 ( 0.8220) Learning Rate: 0.1000 (0.1000) Top1_base: 71.0938 (77.0696) Top1_base_per_class: 68.4726 (77.6452) 
Training Epoch: [91/1000] Step: [10 / 285] Batch Time: 0.1433 (0.2395) Data Time: 0.0104 (0.1068) Average Loss: 0.7208 (0.7600) Average CE Loss (Source):  0.7208 ( 0.7600) Learning Rate: 0.1000 (0.1000) Top1_base: 78.1250 (77.5781) Top1_base_per_class: 79.5238 (77.0813) 
Training Epoch: [91/1000] Step: [20 / 285] Batch Time: 0.1480 (0.2086) Data Time: 0.0140 (0.0755) Average Loss: 0.6878 (0.7496) Average CE Loss (Source):  0.6878 ( 0.7496) Learning Rate: 0.1000 (0.1000) Top1_base: 77.3438 (78.0469) Top1_base_per_class: 80.5152 (78.3138) 
Training Epoch: [91/1000] Step: [30 / 285] Batch Time: 0.1428 (0.1937) Data Time: 0.0104 (0.0610) Average Loss: 0.8967 (0.7725) Average CE Loss (Source):  0.8967 ( 0.7725) Learning Rate: 0.1000 (0.1000) Top1_base: 71.8750 (77.5260) Top1_base_per_class: 71.9374 (77.9939) 
Training Epoch: [91/1000] Step: [40 / 285] Batch Time: 0.1427 (0.1819) Data Time: 0.0119 (0.0491) Average Loss: 0.5193 (0.7751) Average CE Loss (Source):  0.5193 ( 0.7751) Learning Rate: 0.1000 (0.1000) Top1_base: 85.9375 (77.6758) Top1_base_per_class: 86.6667 (78.1742) 
Training Epoch: [91/1000] Step: [50 / 285] Batch Time: 0.1462 (0.1791) Data Time: 0.0116 (0.0463) Average Loss: 0.9048 (0.7704) Average CE Loss (Source):  0.9048 ( 0.7704) Learning Rate: 0.1000 (0.1000) Top1_base: 80.4688 (77.9062) Top1_base_per_class: 77.1470 (78.4430) 
Training Epoch: [91/1000] Step: [60 / 285] Batch Time: 0.1466 (0.1742) Data Time: 0.0126 (0.0413) Average Loss: 0.9357 (0.7722) Average CE Loss (Source):  0.9357 ( 0.7722) Learning Rate: 0.1000 (0.1000) Top1_base: 70.3125 (77.9948) Top1_base_per_class: 67.9240 (78.4384) 
Training Epoch: [91/1000] Step: [70 / 285] Batch Time: 0.1427 (0.1727) Data Time: 0.0108 (0.0398) Average Loss: 0.9538 (0.7768) Average CE Loss (Source):  0.9538 ( 0.7768) Learning Rate: 0.1000 (0.1000) Top1_base: 73.4375 (77.9688) Top1_base_per_class: 78.0303 (78.3905) 
Training Epoch: [91/1000] Step: [80 / 285] Batch Time: 0.1459 (0.1727) Data Time: 0.0127 (0.0398) Average Loss: 0.8312 (0.7791) Average CE Loss (Source):  0.8312 ( 0.7791) Learning Rate: 0.1000 (0.1000) Top1_base: 77.3438 (77.9590) Top1_base_per_class: 78.3109 (78.4444) 
Training Epoch: [91/1000] Step: [90 / 285] Batch Time: 0.1440 (0.1707) Data Time: 0.0112 (0.0377) Average Loss: 0.7019 (0.7832) Average CE Loss (Source):  0.7019 ( 0.7832) Learning Rate: 0.1000 (0.1000) Top1_base: 78.1250 (77.8299) Top1_base_per_class: 76.9006 (78.2927) 
Training Epoch: [91/1000] Step: [100 / 285] Batch Time: 0.1483 (0.1687) Data Time: 0.0140 (0.0357) Average Loss: 0.8138 (0.7863) Average CE Loss (Source):  0.8138 ( 0.7863) Learning Rate: 0.1000 (0.1000) Top1_base: 74.2188 (77.6953) Top1_base_per_class: 72.3684 (78.0917) 
Training Epoch: [91/1000] Step: [110 / 285] Batch Time: 0.1424 (0.1684) Data Time: 0.0110 (0.0354) Average Loss: 0.9967 (0.7978) Average CE Loss (Source):  0.9967 ( 0.7978) Learning Rate: 0.1000 (0.1000) Top1_base: 69.5312 (77.3438) Top1_base_per_class: 71.1111 (77.7975) 
Training Epoch: [91/1000] Step: [120 / 285] Batch Time: 0.1468 (0.1672) Data Time: 0.0137 (0.0342) Average Loss: 0.7916 (0.7979) Average CE Loss (Source):  0.7916 ( 0.7979) Learning Rate: 0.1000 (0.1000) Top1_base: 77.3438 (77.3633) Top1_base_per_class: 78.2525 (77.8925) 
Training Epoch: [91/1000] Step: [130 / 285] Batch Time: 0.1429 (0.1677) Data Time: 0.0110 (0.0346) Average Loss: 0.6401 (0.7954) Average CE Loss (Source):  0.6401 ( 0.7954) Learning Rate: 0.1000 (0.1000) Top1_base: 80.4688 (77.4820) Top1_base_per_class: 81.1207 (78.0365) 
Training Epoch: [91/1000] Step: [140 / 285] Batch Time: 0.1426 (0.1673) Data Time: 0.0115 (0.0343) Average Loss: 0.6213 (0.7976) Average CE Loss (Source):  0.6213 ( 0.7976) Learning Rate: 0.1000 (0.1000) Top1_base: 84.3750 (77.3772) Top1_base_per_class: 83.8690 (77.8195) 
Training Epoch: [91/1000] Step: [150 / 285] Batch Time: 0.1470 (0.1662) Data Time: 0.0146 (0.0332) Average Loss: 0.8011 (0.8037) Average CE Loss (Source):  0.8011 ( 0.8037) Learning Rate: 0.1000 (0.1000) Top1_base: 78.9062 (77.2708) Top1_base_per_class: 80.8036 (77.7595) 
Training Epoch: [91/1000] Step: [160 / 285] Batch Time: 0.1459 (0.1653) Data Time: 0.0132 (0.0323) Average Loss: 0.7241 (0.8049) Average CE Loss (Source):  0.7241 ( 0.8049) Learning Rate: 0.1000 (0.1000) Top1_base: 80.4688 (77.2363) Top1_base_per_class: 77.5731 (77.7360) 
Training Epoch: [91/1000] Step: [170 / 285] Batch Time: 0.1480 (0.1647) Data Time: 0.0156 (0.0317) Average Loss: 0.9137 (0.8042) Average CE Loss (Source):  0.9137 ( 0.8042) Learning Rate: 0.1000 (0.1000) Top1_base: 78.9062 (77.2886) Top1_base_per_class: 80.2632 (77.8029) 
Training Epoch: [91/1000] Step: [180 / 285] Batch Time: 0.1482 (0.1642) Data Time: 0.0138 (0.0313) Average Loss: 0.7226 (0.8077) Average CE Loss (Source):  0.7226 ( 0.8077) Learning Rate: 0.1000 (0.1000) Top1_base: 76.5625 (77.2092) Top1_base_per_class: 77.5595 (77.7162) 
Training Epoch: [91/1000] Step: [190 / 285] Batch Time: 0.1430 (0.1638) Data Time: 0.0112 (0.0309) Average Loss: 0.8400 (0.8062) Average CE Loss (Source):  0.8400 ( 0.8062) Learning Rate: 0.1000 (0.1000) Top1_base: 78.9062 (77.2451) Top1_base_per_class: 75.5655 (77.6974) 
Training Epoch: [91/1000] Step: [200 / 285] Batch Time: 0.1470 (0.1634) Data Time: 0.0122 (0.0304) Average Loss: 0.8824 (0.8062) Average CE Loss (Source):  0.8824 ( 0.8062) Learning Rate: 0.1000 (0.1000) Top1_base: 75.0000 (77.2695) Top1_base_per_class: 76.4620 (77.7374) 
Training Epoch: [91/1000] Step: [210 / 285] Batch Time: 0.1427 (0.1632) Data Time: 0.0115 (0.0302) Average Loss: 0.7738 (0.8049) Average CE Loss (Source):  0.7738 ( 0.8049) Learning Rate: 0.1000 (0.1000) Top1_base: 78.1250 (77.2991) Top1_base_per_class: 76.1905 (77.7163) 
Training Epoch: [91/1000] Step: [220 / 285] Batch Time: 0.1459 (0.1633) Data Time: 0.0137 (0.0303) Average Loss: 0.7747 (0.8060) Average CE Loss (Source):  0.7747 ( 0.8060) Learning Rate: 0.1000 (0.1000) Top1_base: 77.3438 (77.2869) Top1_base_per_class: 77.4679 (77.6757) 
Training Epoch: [91/1000] Step: [230 / 285] Batch Time: 0.1450 (0.1628) Data Time: 0.0118 (0.0299) Average Loss: 0.9932 (0.8078) Average CE Loss (Source):  0.9932 ( 0.8078) Learning Rate: 0.1000 (0.1000) Top1_base: 71.0938 (77.2554) Top1_base_per_class: 67.5152 (77.5887) 
Training Epoch: [91/1000] Step: [240 / 285] Batch Time: 0.1426 (0.1625) Data Time: 0.0115 (0.0296) Average Loss: 0.7938 (0.8102) Average CE Loss (Source):  0.7938 ( 0.8102) Learning Rate: 0.1000 (0.1000) Top1_base: 79.6875 (77.2005) Top1_base_per_class: 81.4972 (77.5642) 
Training Epoch: [91/1000] Step: [250 / 285] Batch Time: 0.1425 (0.1623) Data Time: 0.0111 (0.0294) Average Loss: 0.7870 (0.8115) Average CE Loss (Source):  0.7870 ( 0.8115) Learning Rate: 0.1000 (0.1000) Top1_base: 77.3438 (77.1813) Top1_base_per_class: 79.3860 (77.5712) 
Training Epoch: [91/1000] Step: [260 / 285] Batch Time: 0.1472 (0.1617) Data Time: 0.0144 (0.0288) Average Loss: 0.9855 (0.8120) Average CE Loss (Source):  0.9855 ( 0.8120) Learning Rate: 0.1000 (0.1000) Top1_base: 74.2188 (77.1815) Top1_base_per_class: 72.0056 (77.5748) 
Training Epoch: [91/1000] Step: [270 / 285] Batch Time: 0.1419 (0.1611) Data Time: 0.0102 (0.0283) Average Loss: 0.7391 (0.8128) Average CE Loss (Source):  0.7391 ( 0.8128) Learning Rate: 0.1000 (0.1000) Top1_base: 78.9062 (77.1470) Top1_base_per_class: 81.0345 (77.5771) 
Training Epoch: [91/1000] Step: [280 / 285] Batch Time: 0.1447 (0.1607) Data Time: 0.0112 (0.0278) Average Loss: 0.6472 (0.8154) Average CE Loss (Source):  0.6472 ( 0.8154) Learning Rate: 0.1000 (0.1000) Top1_base: 82.8125 (77.1122) Top1_base_per_class: 81.5723 (77.5797) 
Training Epoch: [92/1000] Step: [0] Batch Time: 0.1630 (0.1605) Data Time: 0.0324 (0.0277) Average Loss: 0.8493 (0.8167) Average CE Loss (Source):  0.8493 ( 0.8167) Learning Rate: 0.1000 (0.1000) Top1_base: 75.7812 (77.0669) Top1_base_per_class: 78.1212 (77.5476) 
  9%|▉         | 92/1000 [1:12:08<11:47:00, 46.72s/it]  9%|▉         | 93/1000 [1:12:53<11:38:02, 46.18s/it]Training Epoch: [92/1000] Step: [10 / 285] Batch Time: 0.1471 (0.2285) Data Time: 0.0162 (0.0955) Average Loss: 0.8983 (0.8049) Average CE Loss (Source):  0.8983 ( 0.8049) Learning Rate: 0.1000 (0.1000) Top1_base: 71.0938 (76.2500) Top1_base_per_class: 72.8571 (75.9388) 
Training Epoch: [92/1000] Step: [20 / 285] Batch Time: 0.1455 (0.1905) Data Time: 0.0134 (0.0575) Average Loss: 0.7898 (0.7662) Average CE Loss (Source):  0.7898 ( 0.7662) Learning Rate: 0.1000 (0.1000) Top1_base: 77.3438 (78.5547) Top1_base_per_class: 78.2407 (78.4449) 
Training Epoch: [92/1000] Step: [30 / 285] Batch Time: 0.1904 (0.1821) Data Time: 0.0579 (0.0490) Average Loss: 0.7886 (0.7861) Average CE Loss (Source):  0.7886 ( 0.7861) Learning Rate: 0.1000 (0.1000) Top1_base: 78.9062 (77.8385) Top1_base_per_class: 80.7576 (78.1730) 
Training Epoch: [92/1000] Step: [40 / 285] Batch Time: 0.1482 (0.1758) Data Time: 0.0171 (0.0428) Average Loss: 0.8458 (0.8005) Average CE Loss (Source):  0.8458 ( 0.8005) Learning Rate: 0.1000 (0.1000) Top1_base: 77.3438 (77.7344) Top1_base_per_class: 80.2641 (78.2444) 
Training Epoch: [92/1000] Step: [50 / 285] Batch Time: 0.1519 (0.1712) Data Time: 0.0181 (0.0379) Average Loss: 0.7288 (0.8058) Average CE Loss (Source):  0.7288 ( 0.8058) Learning Rate: 0.1000 (0.1000) Top1_base: 78.1250 (77.8281) Top1_base_per_class: 78.4242 (78.2585) 
Training Epoch: [92/1000] Step: [60 / 285] Batch Time: 0.1452 (0.1672) Data Time: 0.0132 (0.0339) Average Loss: 0.5794 (0.8115) Average CE Loss (Source):  0.5794 ( 0.8115) Learning Rate: 0.1000 (0.1000) Top1_base: 85.1562 (77.7083) Top1_base_per_class: 84.6364 (78.2008) 
Training Epoch: [92/1000] Step: [70 / 285] Batch Time: 0.1719 (0.1659) Data Time: 0.0408 (0.0327) Average Loss: 0.7193 (0.8007) Average CE Loss (Source):  0.7193 ( 0.8007) Learning Rate: 0.1000 (0.1000) Top1_base: 79.6875 (77.7902) Top1_base_per_class: 81.2654 (78.2212) 
Training Epoch: [92/1000] Step: [80 / 285] Batch Time: 0.1459 (0.1642) Data Time: 0.0149 (0.0310) Average Loss: 0.5680 (0.7974) Average CE Loss (Source):  0.5680 ( 0.7974) Learning Rate: 0.1000 (0.1000) Top1_base: 84.3750 (77.7539) Top1_base_per_class: 85.0585 (78.2947) 
Training Epoch: [92/1000] Step: [90 / 285] Batch Time: 0.1491 (0.1630) Data Time: 0.0139 (0.0299) Average Loss: 1.0563 (0.7978) Average CE Loss (Source):  1.0563 ( 0.7978) Learning Rate: 0.1000 (0.1000) Top1_base: 71.8750 (77.7344) Top1_base_per_class: 73.7135 (78.3277) 
Training Epoch: [92/1000] Step: [100 / 285] Batch Time: 0.1452 (0.1626) Data Time: 0.0107 (0.0296) Average Loss: 1.0091 (0.7987) Average CE Loss (Source):  1.0091 ( 0.7987) Learning Rate: 0.1000 (0.1000) Top1_base: 74.2188 (77.7266) Top1_base_per_class: 76.2893 (78.3524) 
Training Epoch: [92/1000] Step: [110 / 285] Batch Time: 0.1560 (0.1613) Data Time: 0.0233 (0.0283) Average Loss: 0.7975 (0.8035) Average CE Loss (Source):  0.7975 ( 0.8035) Learning Rate: 0.1000 (0.1000) Top1_base: 76.5625 (77.5142) Top1_base_per_class: 73.9462 (78.1627) 
Training Epoch: [92/1000] Step: [120 / 285] Batch Time: 0.1455 (0.1600) Data Time: 0.0144 (0.0270) Average Loss: 0.8099 (0.8074) Average CE Loss (Source):  0.8099 ( 0.8074) Learning Rate: 0.1000 (0.1000) Top1_base: 78.1250 (77.2461) Top1_base_per_class: 81.1818 (77.9075) 
Training Epoch: [92/1000] Step: [130 / 285] Batch Time: 0.1504 (0.1594) Data Time: 0.0153 (0.0263) Average Loss: 0.8678 (0.8095) Average CE Loss (Source):  0.8678 ( 0.8095) Learning Rate: 0.1000 (0.1000) Top1_base: 76.5625 (77.2175) Top1_base_per_class: 74.5833 (77.7946) 
Training Epoch: [92/1000] Step: [140 / 285] Batch Time: 0.1434 (0.1584) Data Time: 0.0130 (0.0254) Average Loss: 0.6147 (0.8030) Average CE Loss (Source):  0.6147 ( 0.8030) Learning Rate: 0.1000 (0.1000) Top1_base: 81.2500 (77.3382) Top1_base_per_class: 81.5774 (78.0093) 
Training Epoch: [92/1000] Step: [150 / 285] Batch Time: 0.1793 (0.1581) Data Time: 0.0473 (0.0251) Average Loss: 0.7115 (0.8034) Average CE Loss (Source):  0.7115 ( 0.8034) Learning Rate: 0.1000 (0.1000) Top1_base: 82.8125 (77.3646) Top1_base_per_class: 81.3842 (78.0427) 
Training Epoch: [92/1000] Step: [160 / 285] Batch Time: 0.1494 (0.1577) Data Time: 0.0170 (0.0247) Average Loss: 0.7934 (0.8021) Average CE Loss (Source):  0.7934 ( 0.8021) Learning Rate: 0.1000 (0.1000) Top1_base: 75.7812 (77.3242) Top1_base_per_class: 76.8485 (77.9586) 
Training Epoch: [92/1000] Step: [170 / 285] Batch Time: 0.1450 (0.1577) Data Time: 0.0142 (0.0246) Average Loss: 0.9231 (0.8064) Average CE Loss (Source):  0.9231 ( 0.8064) Learning Rate: 0.1000 (0.1000) Top1_base: 75.7812 (77.2518) Top1_base_per_class: 76.9253 (77.9054) 
Training Epoch: [92/1000] Step: [180 / 285] Batch Time: 0.2318 (0.1580) Data Time: 0.0993 (0.0250) Average Loss: 0.8008 (0.8084) Average CE Loss (Source):  0.8008 ( 0.8084) Learning Rate: 0.1000 (0.1000) Top1_base: 77.3438 (77.1918) Top1_base_per_class: 77.2641 (77.8056) 
Training Epoch: [92/1000] Step: [190 / 285] Batch Time: 0.1458 (0.1581) Data Time: 0.0111 (0.0250) Average Loss: 0.8367 (0.8110) Average CE Loss (Source):  0.8367 ( 0.8110) Learning Rate: 0.1000 (0.1000) Top1_base: 73.4375 (77.0970) Top1_base_per_class: 76.5758 (77.6812) 
Training Epoch: [92/1000] Step: [200 / 285] Batch Time: 0.1756 (0.1583) Data Time: 0.0405 (0.0252) Average Loss: 0.9346 (0.8109) Average CE Loss (Source):  0.9346 ( 0.8109) Learning Rate: 0.1000 (0.1000) Top1_base: 78.9062 (77.1133) Top1_base_per_class: 79.1228 (77.6533) 
Training Epoch: [92/1000] Step: [210 / 285] Batch Time: 0.1442 (0.1579) Data Time: 0.0108 (0.0248) Average Loss: 0.8895 (0.8116) Average CE Loss (Source):  0.8895 ( 0.8116) Learning Rate: 0.1000 (0.1000) Top1_base: 74.2188 (77.0685) Top1_base_per_class: 70.3869 (77.5799) 
Training Epoch: [92/1000] Step: [220 / 285] Batch Time: 0.1484 (0.1574) Data Time: 0.0175 (0.0243) Average Loss: 0.7598 (0.8112) Average CE Loss (Source):  0.7598 ( 0.8112) Learning Rate: 0.1000 (0.1000) Top1_base: 78.9062 (77.1023) Top1_base_per_class: 76.7901 (77.6475) 
Training Epoch: [92/1000] Step: [230 / 285] Batch Time: 0.1445 (0.1575) Data Time: 0.0119 (0.0245) Average Loss: 0.7117 (0.8098) Average CE Loss (Source):  0.7117 ( 0.8098) Learning Rate: 0.1000 (0.1000) Top1_base: 82.0312 (77.1433) Top1_base_per_class: 81.8350 (77.6670) 
Training Epoch: [92/1000] Step: [240 / 285] Batch Time: 0.2359 (0.1577) Data Time: 0.1025 (0.0247) Average Loss: 0.7444 (0.8125) Average CE Loss (Source):  0.7444 ( 0.8125) Learning Rate: 0.1000 (0.1000) Top1_base: 77.3438 (77.0931) Top1_base_per_class: 77.4359 (77.6290) 
Training Epoch: [92/1000] Step: [250 / 285] Batch Time: 0.1446 (0.1578) Data Time: 0.0122 (0.0248) Average Loss: 0.7944 (0.8124) Average CE Loss (Source):  0.7944 ( 0.8124) Learning Rate: 0.1000 (0.1000) Top1_base: 78.1250 (77.1594) Top1_base_per_class: 81.6369 (77.7307) 
Training Epoch: [92/1000] Step: [260 / 285] Batch Time: 0.1756 (0.1578) Data Time: 0.0432 (0.0247) Average Loss: 0.8440 (0.8130) Average CE Loss (Source):  0.8440 ( 0.8130) Learning Rate: 0.1000 (0.1000) Top1_base: 78.1250 (77.1725) Top1_base_per_class: 79.2857 (77.7658) 
Training Epoch: [92/1000] Step: [270 / 285] Batch Time: 0.1459 (0.1573) Data Time: 0.0122 (0.0243) Average Loss: 0.8689 (0.8128) Average CE Loss (Source):  0.8689 ( 0.8128) Learning Rate: 0.1000 (0.1000) Top1_base: 77.3438 (77.1672) Top1_base_per_class: 73.7346 (77.7264) 
Training Epoch: [92/1000] Step: [280 / 285] Batch Time: 0.1485 (0.1571) Data Time: 0.0162 (0.0241) Average Loss: 1.0592 (0.8123) Average CE Loss (Source):  1.0592 ( 0.8123) Learning Rate: 0.1000 (0.1000) Top1_base: 74.2188 (77.1931) Top1_base_per_class: 71.6182 (77.7384) 
Training Epoch: [93/1000] Step: [0] Batch Time: 0.1423 (0.1573) Data Time: 0.0108 (0.0243) Average Loss: 1.0883 (0.8119) Average CE Loss (Source):  1.0883 ( 0.8119) Learning Rate: 0.1000 (0.1000) Top1_base: 71.8750 (77.2149) Top1_base_per_class: 77.1569 (77.7851) 
Training Epoch: [93/1000] Step: [10 / 285] Batch Time: 0.1468 (0.2299) Data Time: 0.0135 (0.0974) Average Loss: 0.7573 (0.7092) Average CE Loss (Source):  0.7573 ( 0.7092) Learning Rate: 0.1000 (0.1000) Top1_base: 79.6875 (79.1406) Top1_base_per_class: 79.5192 (79.1008) 
Training Epoch: [93/1000] Step: [20 / 285] Batch Time: 0.1453 (0.1944) Data Time: 0.0131 (0.0616) Average Loss: 0.7828 (0.7138) Average CE Loss (Source):  0.7828 ( 0.7138) Learning Rate: 0.1000 (0.1000) Top1_base: 80.4688 (79.6484) Top1_base_per_class: 80.8929 (79.7769) 
Training Epoch: [93/1000] Step: [30 / 285] Batch Time: 0.1435 (0.1828) Data Time: 0.0127 (0.0497) Average Loss: 0.8478 (0.7161) Average CE Loss (Source):  0.8478 ( 0.7161) Learning Rate: 0.1000 (0.1000) Top1_base: 77.3438 (79.8958) Top1_base_per_class: 80.1190 (80.1808) 
Training Epoch: [93/1000] Step: [40 / 285] Batch Time: 0.1452 (0.1743) Data Time: 0.0123 (0.0415) Average Loss: 0.5209 (0.7229) Average CE Loss (Source):  0.5209 ( 0.7229) Learning Rate: 0.1000 (0.1000) Top1_base: 81.2500 (79.6680) Top1_base_per_class: 81.5789 (80.1422) 
Training Epoch: [93/1000] Step: [50 / 285] Batch Time: 0.1468 (0.1692) Data Time: 0.0132 (0.0365) Average Loss: 0.7342 (0.7308) Average CE Loss (Source):  0.7342 ( 0.7308) Learning Rate: 0.1000 (0.1000) Top1_base: 78.1250 (79.5000) Top1_base_per_class: 79.8077 (79.7968) 
Training Epoch: [93/1000] Step: [60 / 285] Batch Time: 0.1482 (0.1682) Data Time: 0.0157 (0.0354) Average Loss: 0.8787 (0.7470) Average CE Loss (Source):  0.8787 ( 0.7470) Learning Rate: 0.1000 (0.1000) Top1_base: 75.0000 (79.1927) Top1_base_per_class: 76.7017 (79.6157) 
Training Epoch: [93/1000] Step: [70 / 285] Batch Time: 0.1442 (0.1671) Data Time: 0.0124 (0.0342) Average Loss: 0.5822 (0.7468) Average CE Loss (Source):  0.5822 ( 0.7468) Learning Rate: 0.1000 (0.1000) Top1_base: 84.3750 (79.1853) Top1_base_per_class: 79.3220 (79.6103) 
Training Epoch: [93/1000] Step: [80 / 285] Batch Time: 0.1510 (0.1646) Data Time: 0.0124 (0.0316) Average Loss: 0.8338 (0.7516) Average CE Loss (Source):  0.8338 ( 0.7516) Learning Rate: 0.1000 (0.1000) Top1_base: 78.1250 (79.0723) Top1_base_per_class: 73.1871 (79.4710) 
Training Epoch: [93/1000] Step: [90 / 285] Batch Time: 0.1453 (0.1636) Data Time: 0.0115 (0.0306) Average Loss: 0.9362 (0.7584) Average CE Loss (Source):  0.9362 ( 0.7584) Learning Rate: 0.1000 (0.1000) Top1_base: 71.0938 (78.8368) Top1_base_per_class: 72.1818 (79.3318) 
Training Epoch: [93/1000] Step: [100 / 285] Batch Time: 0.1487 (0.1626) Data Time: 0.0148 (0.0295) Average Loss: 0.7316 (0.7629) Average CE Loss (Source):  0.7316 ( 0.7629) Learning Rate: 0.1000 (0.1000) Top1_base: 79.6875 (78.6797) Top1_base_per_class: 76.3095 (79.1827) 
Training Epoch: [93/1000] Step: [110 / 285] Batch Time: 0.1463 (0.1613) Data Time: 0.0107 (0.0282) Average Loss: 0.8174 (0.7668) Average CE Loss (Source):  0.8174 ( 0.7668) Learning Rate: 0.1000 (0.1000) Top1_base: 82.0312 (78.5156) Top1_base_per_class: 84.5283 (78.9551) 
Training Epoch: [93/1000] Step: [120 / 285] Batch Time: 0.1494 (0.1610) Data Time: 0.0162 (0.0278) Average Loss: 1.0252 (0.7723) Average CE Loss (Source):  1.0252 ( 0.7723) Learning Rate: 0.1000 (0.1000) Top1_base: 71.8750 (78.2422) Top1_base_per_class: 71.6358 (78.6855) 
Training Epoch: [93/1000] Step: [130 / 285] Batch Time: 0.1457 (0.1605) Data Time: 0.0104 (0.0273) Average Loss: 0.8045 (0.7760) Average CE Loss (Source):  0.8045 ( 0.7760) Learning Rate: 0.1000 (0.1000) Top1_base: 73.4375 (78.1190) Top1_base_per_class: 74.7024 (78.5881) 
Training Epoch: [93/1000] Step: [140 / 285] Batch Time: 0.1811 (0.1599) Data Time: 0.0487 (0.0267) Average Loss: 0.8681 (0.7804) Average CE Loss (Source):  0.8681 ( 0.7804) Learning Rate: 0.1000 (0.1000) Top1_base: 74.2188 (78.0357) Top1_base_per_class: 74.4025 (78.5421) 
Training Epoch: [93/1000] Step: [150 / 285] Batch Time: 0.1461 (0.1597) Data Time: 0.0115 (0.0264) Average Loss: 0.7943 (0.7835) Average CE Loss (Source):  0.7943 ( 0.7835) Learning Rate: 0.1000 (0.1000) Top1_base: 75.7812 (77.9062) Top1_base_per_class: 79.5887 (78.4816) 
Training Epoch: [93/1000] Step: [160 / 285] Batch Time: 0.1980 (0.1599) Data Time: 0.0650 (0.0267) Average Loss: 0.6152 (0.7835) Average CE Loss (Source):  0.6152 ( 0.7835) Learning Rate: 0.1000 (0.1000) Top1_base: 82.0312 (77.9395) Top1_base_per_class: 82.2321 (78.5348) 
Training Epoch: [93/1000] Step: [170 / 285] Batch Time: 0.1445 (0.1596) Data Time: 0.0108 (0.0264) Average Loss: 0.9661 (0.7886) Average CE Loss (Source):  0.9661 ( 0.7886) Learning Rate: 0.1000 (0.1000) Top1_base: 72.6562 (77.8125) Top1_base_per_class: 71.3095 (78.3048) 
Training Epoch: [93/1000] Step: [180 / 285] Batch Time: 0.1505 (0.1599) Data Time: 0.0152 (0.0268) Average Loss: 0.8540 (0.7928) Average CE Loss (Source):  0.8540 ( 0.7928) Learning Rate: 0.1000 (0.1000) Top1_base: 79.6875 (77.6823) Top1_base_per_class: 80.7273 (78.1388) 
Training Epoch: [93/1000] Step: [190 / 285] Batch Time: 0.1442 (0.1598) Data Time: 0.0127 (0.0266) Average Loss: 0.9800 (0.7930) Average CE Loss (Source):  0.9800 ( 0.7930) Learning Rate: 0.1000 (0.1000) Top1_base: 75.7812 (77.7179) Top1_base_per_class: 79.1092 (78.1934) 
Training Epoch: [93/1000] Step: [200 / 285] Batch Time: 0.1805 (0.1600) Data Time: 0.0496 (0.0269) Average Loss: 0.6046 (0.7925) Average CE Loss (Source):  0.6046 ( 0.7925) Learning Rate: 0.1000 (0.1000) Top1_base: 78.9062 (77.7344) Top1_base_per_class: 77.9667 (78.2109) 
Training Epoch: [93/1000] Step: [210 / 285] Batch Time: 0.1440 (0.1595) Data Time: 0.0103 (0.0264) Average Loss: 0.7643 (0.7926) Average CE Loss (Source):  0.7643 ( 0.7926) Learning Rate: 0.1000 (0.1000) Top1_base: 78.1250 (77.7753) Top1_base_per_class: 77.5706 (78.1710) 
Training Epoch: [93/1000] Step: [220 / 285] Batch Time: 0.1487 (0.1597) Data Time: 0.0172 (0.0267) Average Loss: 0.9521 (0.7930) Average CE Loss (Source):  0.9521 ( 0.7930) Learning Rate: 0.1000 (0.1000) Top1_base: 70.3125 (77.7273) Top1_base_per_class: 71.1767 (78.1550) 
Training Epoch: [93/1000] Step: [230 / 285] Batch Time: 0.1482 (0.1592) Data Time: 0.0114 (0.0260) Average Loss: 0.6716 (0.7943) Average CE Loss (Source):  0.6716 ( 0.7943) Learning Rate: 0.1000 (0.1000) Top1_base: 78.1250 (77.6936) Top1_base_per_class: 76.4197 (78.1246) 
Training Epoch: [93/1000] Step: [240 / 285] Batch Time: 0.1516 (0.1588) Data Time: 0.0168 (0.0255) Average Loss: 0.8857 (0.7945) Average CE Loss (Source):  0.8857 ( 0.7945) Learning Rate: 0.1000 (0.1000) Top1_base: 77.3438 (77.6758) Top1_base_per_class: 79.2262 (78.1092) 
Training Epoch: [93/1000] Step: [250 / 285] Batch Time: 0.1453 (0.1583) Data Time: 0.0141 (0.0250) Average Loss: 0.6647 (0.7955) Average CE Loss (Source):  0.6647 ( 0.7955) Learning Rate: 0.1000 (0.1000) Top1_base: 79.6875 (77.6281) Top1_base_per_class: 75.8805 (78.0525) 
Training Epoch: [93/1000] Step: [260 / 285] Batch Time: 0.1492 (0.1579) Data Time: 0.0172 (0.0246) Average Loss: 0.8245 (0.7990) Average CE Loss (Source):  0.8245 ( 0.7990) Learning Rate: 0.1000 (0.1000) Top1_base: 75.0000 (77.5090) Top1_base_per_class: 79.9425 (77.9819) 
Training Epoch: [93/1000] Step: [270 / 285] Batch Time: 0.1501 (0.1575) Data Time: 0.0150 (0.0242) Average Loss: 0.8188 (0.8015) Average CE Loss (Source):  0.8188 ( 0.8015) Learning Rate: 0.1000 (0.1000) Top1_base: 76.5625 (77.4219) Top1_base_per_class: 76.6747 (77.8735) 
Training Epoch: [93/1000] Step: [280 / 285] Batch Time: 0.1759 (0.1572) Data Time: 0.0410 (0.0239) Average Loss: 0.9864 (0.8020) Average CE Loss (Source):  0.9864 ( 0.8020) Learning Rate: 0.1000 (0.1000) Top1_base: 71.0938 (77.3856) Top1_base_per_class: 70.4586 (77.8128) 
Training Epoch: [94/1000] Step: [0] Batch Time: 0.1427 (0.1570) Data Time: 0.0099 (0.0238) Average Loss: 0.8175 (0.8025) Average CE Loss (Source):  0.8175 ( 0.8025) Learning Rate: 0.1000 (0.1000) Top1_base: 75.7812 (77.3575) Top1_base_per_class: 78.3918 (77.7872) 
  9%|▉         | 94/1000 [1:13:41<11:43:26, 46.59s/it] 10%|▉         | 95/1000 [1:14:25<11:31:55, 45.87s/it]Training Epoch: [94/1000] Step: [10 / 285] Batch Time: 0.1454 (0.2383) Data Time: 0.0107 (0.1052) Average Loss: 0.7028 (0.7522) Average CE Loss (Source):  0.7028 ( 0.7522) Learning Rate: 0.1000 (0.1000) Top1_base: 80.4688 (79.7656) Top1_base_per_class: 81.5179 (80.9851) 
Training Epoch: [94/1000] Step: [20 / 285] Batch Time: 0.1465 (0.1969) Data Time: 0.0126 (0.0638) Average Loss: 0.7837 (0.7481) Average CE Loss (Source):  0.7837 ( 0.7481) Learning Rate: 0.1000 (0.1000) Top1_base: 77.3438 (79.2578) Top1_base_per_class: 74.8686 (79.4934) 
Training Epoch: [94/1000] Step: [30 / 285] Batch Time: 0.1438 (0.1823) Data Time: 0.0100 (0.0494) Average Loss: 0.7606 (0.7518) Average CE Loss (Source):  0.7606 ( 0.7518) Learning Rate: 0.1000 (0.1000) Top1_base: 78.9062 (79.3490) Top1_base_per_class: 78.3046 (79.8486) 
Training Epoch: [94/1000] Step: [40 / 285] Batch Time: 0.1440 (0.1739) Data Time: 0.0128 (0.0411) Average Loss: 0.9040 (0.7690) Average CE Loss (Source):  0.9040 ( 0.7690) Learning Rate: 0.1000 (0.1000) Top1_base: 73.4375 (78.7500) Top1_base_per_class: 78.7963 (79.5147) 
Training Epoch: [94/1000] Step: [50 / 285] Batch Time: 0.1443 (0.1682) Data Time: 0.0129 (0.0356) Average Loss: 0.7390 (0.7772) Average CE Loss (Source):  0.7390 ( 0.7772) Learning Rate: 0.1000 (0.1000) Top1_base: 83.5938 (78.6562) Top1_base_per_class: 85.2121 (79.1746) 
Training Epoch: [94/1000] Step: [60 / 285] Batch Time: 0.1478 (0.1662) Data Time: 0.0112 (0.0332) Average Loss: 0.7760 (0.7765) Average CE Loss (Source):  0.7760 ( 0.7765) Learning Rate: 0.1000 (0.1000) Top1_base: 78.9062 (78.5677) Top1_base_per_class: 77.3684 (79.0032) 
Training Epoch: [94/1000] Step: [70 / 285] Batch Time: 0.1477 (0.1637) Data Time: 0.0114 (0.0303) Average Loss: 0.8789 (0.7779) Average CE Loss (Source):  0.8789 ( 0.7779) Learning Rate: 0.1000 (0.1000) Top1_base: 73.4375 (78.5714) Top1_base_per_class: 76.6384 (79.2078) 
Training Epoch: [94/1000] Step: [80 / 285] Batch Time: 0.1462 (0.1619) Data Time: 0.0111 (0.0282) Average Loss: 0.9149 (0.7847) Average CE Loss (Source):  0.9149 ( 0.7847) Learning Rate: 0.1000 (0.1000) Top1_base: 78.9062 (78.4668) Top1_base_per_class: 80.7716 (79.2412) 
Training Epoch: [94/1000] Step: [90 / 285] Batch Time: 0.1480 (0.1602) Data Time: 0.0114 (0.0266) Average Loss: 0.6363 (0.7882) Average CE Loss (Source):  0.6363 ( 0.7882) Learning Rate: 0.1000 (0.1000) Top1_base: 78.1250 (78.2812) Top1_base_per_class: 80.0292 (78.9266) 
Training Epoch: [94/1000] Step: [100 / 285] Batch Time: 0.1468 (0.1595) Data Time: 0.0121 (0.0259) Average Loss: 0.8444 (0.7870) Average CE Loss (Source):  0.8444 ( 0.7870) Learning Rate: 0.1000 (0.1000) Top1_base: 74.2188 (78.4062) Top1_base_per_class: 76.6667 (79.1099) 
Training Epoch: [94/1000] Step: [110 / 285] Batch Time: 0.1440 (0.1592) Data Time: 0.0114 (0.0257) Average Loss: 0.6738 (0.7936) Average CE Loss (Source):  0.6738 ( 0.7936) Learning Rate: 0.1000 (0.1000) Top1_base: 83.5938 (78.2812) Top1_base_per_class: 80.0298 (78.8910) 
Training Epoch: [94/1000] Step: [120 / 285] Batch Time: 0.1471 (0.1582) Data Time: 0.0125 (0.0247) Average Loss: 0.7036 (0.7915) Average CE Loss (Source):  0.7036 ( 0.7915) Learning Rate: 0.1000 (0.1000) Top1_base: 78.9062 (78.3659) Top1_base_per_class: 77.5758 (78.8867) 
Training Epoch: [94/1000] Step: [130 / 285] Batch Time: 0.1471 (0.1574) Data Time: 0.0136 (0.0239) Average Loss: 0.6836 (0.7950) Average CE Loss (Source):  0.6836 ( 0.7950) Learning Rate: 0.1000 (0.1000) Top1_base: 77.3438 (78.1611) Top1_base_per_class: 79.4136 (78.6371) 
Training Epoch: [94/1000] Step: [140 / 285] Batch Time: 0.1472 (0.1569) Data Time: 0.0136 (0.0234) Average Loss: 0.8919 (0.8011) Average CE Loss (Source):  0.8919 ( 0.8011) Learning Rate: 0.1000 (0.1000) Top1_base: 78.1250 (78.0301) Top1_base_per_class: 79.8596 (78.4949) 
Training Epoch: [94/1000] Step: [150 / 285] Batch Time: 0.1507 (0.1565) Data Time: 0.0128 (0.0230) Average Loss: 1.0676 (0.8015) Average CE Loss (Source):  1.0676 ( 0.8015) Learning Rate: 0.1000 (0.1000) Top1_base: 71.8750 (78.0104) Top1_base_per_class: 75.6845 (78.4827) 
Training Epoch: [94/1000] Step: [160 / 285] Batch Time: 0.1488 (0.1564) Data Time: 0.0123 (0.0228) Average Loss: 0.8055 (0.8036) Average CE Loss (Source):  0.8055 ( 0.8036) Learning Rate: 0.1000 (0.1000) Top1_base: 78.1250 (77.8418) Top1_base_per_class: 74.6667 (78.3224) 
Training Epoch: [94/1000] Step: [170 / 285] Batch Time: 0.1449 (0.1562) Data Time: 0.0112 (0.0225) Average Loss: 0.7774 (0.8044) Average CE Loss (Source):  0.7774 ( 0.8044) Learning Rate: 0.1000 (0.1000) Top1_base: 79.6875 (77.7803) Top1_base_per_class: 83.5935 (78.3212) 
Training Epoch: [94/1000] Step: [180 / 285] Batch Time: 0.1444 (0.1569) Data Time: 0.0107 (0.0233) Average Loss: 0.9825 (0.8077) Average CE Loss (Source):  0.9825 ( 0.8077) Learning Rate: 0.1000 (0.1000) Top1_base: 73.4375 (77.6259) Top1_base_per_class: 70.9394 (78.1628) 
Training Epoch: [94/1000] Step: [190 / 285] Batch Time: 0.1420 (0.1564) Data Time: 0.0113 (0.0228) Average Loss: 0.9258 (0.8105) Average CE Loss (Source):  0.9258 ( 0.8105) Learning Rate: 0.1000 (0.1000) Top1_base: 77.3438 (77.5822) Top1_base_per_class: 79.0207 (78.1184) 
Training Epoch: [94/1000] Step: [200 / 285] Batch Time: 0.1480 (0.1563) Data Time: 0.0107 (0.0227) Average Loss: 0.8125 (0.8122) Average CE Loss (Source):  0.8125 ( 0.8122) Learning Rate: 0.1000 (0.1000) Top1_base: 79.6875 (77.5469) Top1_base_per_class: 81.3054 (78.0075) 
Training Epoch: [94/1000] Step: [210 / 285] Batch Time: 0.1458 (0.1558) Data Time: 0.0129 (0.0222) Average Loss: 0.8943 (0.8133) Average CE Loss (Source):  0.8943 ( 0.8133) Learning Rate: 0.1000 (0.1000) Top1_base: 75.0000 (77.5186) Top1_base_per_class: 73.4722 (78.0119) 
Training Epoch: [94/1000] Step: [220 / 285] Batch Time: 0.1461 (0.1554) Data Time: 0.0144 (0.0218) Average Loss: 0.7204 (0.8140) Average CE Loss (Source):  0.7204 ( 0.8140) Learning Rate: 0.1000 (0.1000) Top1_base: 82.0312 (77.5000) Top1_base_per_class: 81.9006 (78.0331) 
Training Epoch: [94/1000] Step: [230 / 285] Batch Time: 0.1430 (0.1550) Data Time: 0.0115 (0.0215) Average Loss: 0.9516 (0.8158) Average CE Loss (Source):  0.9516 ( 0.8158) Learning Rate: 0.1000 (0.1000) Top1_base: 71.8750 (77.4389) Top1_base_per_class: 74.3550 (77.9863) 
Training Epoch: [94/1000] Step: [240 / 285] Batch Time: 0.1687 (0.1548) Data Time: 0.0332 (0.0213) Average Loss: 0.6864 (0.8168) Average CE Loss (Source):  0.6864 ( 0.8168) Learning Rate: 0.1000 (0.1000) Top1_base: 79.6875 (77.4121) Top1_base_per_class: 82.4576 (77.9587) 
Training Epoch: [94/1000] Step: [250 / 285] Batch Time: 0.1485 (0.1546) Data Time: 0.0136 (0.0211) Average Loss: 0.9493 (0.8178) Average CE Loss (Source):  0.9493 ( 0.8178) Learning Rate: 0.1000 (0.1000) Top1_base: 72.6562 (77.3719) Top1_base_per_class: 69.2411 (77.8788) 
Training Epoch: [94/1000] Step: [260 / 285] Batch Time: 0.1468 (0.1545) Data Time: 0.0131 (0.0210) Average Loss: 0.7711 (0.8167) Average CE Loss (Source):  0.7711 ( 0.8167) Learning Rate: 0.1000 (0.1000) Top1_base: 78.1250 (77.3498) Top1_base_per_class: 77.0909 (77.8661) 
Training Epoch: [94/1000] Step: [270 / 285] Batch Time: 0.1485 (0.1547) Data Time: 0.0154 (0.0212) Average Loss: 0.7866 (0.8164) Average CE Loss (Source):  0.7866 ( 0.8164) Learning Rate: 0.1000 (0.1000) Top1_base: 76.5625 (77.3611) Top1_base_per_class: 77.1839 (77.8711) 
Training Epoch: [94/1000] Step: [280 / 285] Batch Time: 0.1437 (0.1549) Data Time: 0.0126 (0.0215) Average Loss: 0.8007 (0.8170) Average CE Loss (Source):  0.8007 ( 0.8170) Learning Rate: 0.1000 (0.1000) Top1_base: 75.7812 (77.3158) Top1_base_per_class: 74.8246 (77.8398) 
Training Epoch: [95/1000] Step: [0] Batch Time: 0.1440 (0.1549) Data Time: 0.0123 (0.0215) Average Loss: 0.8936 (0.8176) Average CE Loss (Source):  0.8936 ( 0.8176) Learning Rate: 0.1000 (0.1000) Top1_base: 76.5625 (77.3026) Top1_base_per_class: 76.0494 (77.8208) 
Training Epoch: [95/1000] Step: [10 / 285] Batch Time: 0.1455 (0.2490) Data Time: 0.0101 (0.1155) Average Loss: 0.9829 (0.7759) Average CE Loss (Source):  0.9829 ( 0.7759) Learning Rate: 0.1000 (0.1000) Top1_base: 73.4375 (78.8281) Top1_base_per_class: 71.1696 (79.4856) 
Training Epoch: [95/1000] Step: [20 / 285] Batch Time: 0.1459 (0.1976) Data Time: 0.0129 (0.0644) Average Loss: 0.7540 (0.7523) Average CE Loss (Source):  0.7540 ( 0.7523) Learning Rate: 0.1000 (0.1000) Top1_base: 77.3438 (79.2969) Top1_base_per_class: 74.2177 (80.0787) 
Training Epoch: [95/1000] Step: [30 / 285] Batch Time: 0.1475 (0.1837) Data Time: 0.0119 (0.0506) Average Loss: 0.7228 (0.7606) Average CE Loss (Source):  0.7228 ( 0.7606) Learning Rate: 0.1000 (0.1000) Top1_base: 80.4688 (79.1927) Top1_base_per_class: 81.1111 (79.7190) 
Training Epoch: [95/1000] Step: [40 / 285] Batch Time: 0.1454 (0.1758) Data Time: 0.0124 (0.0427) Average Loss: 0.6690 (0.7523) Average CE Loss (Source):  0.6690 ( 0.7523) Learning Rate: 0.1000 (0.1000) Top1_base: 81.2500 (79.4336) Top1_base_per_class: 83.3636 (79.8848) 
Training Epoch: [95/1000] Step: [50 / 285] Batch Time: 0.1520 (0.1743) Data Time: 0.0154 (0.0411) Average Loss: 0.6736 (0.7594) Average CE Loss (Source):  0.6736 ( 0.7594) Learning Rate: 0.1000 (0.1000) Top1_base: 80.4688 (78.8750) Top1_base_per_class: 80.2381 (79.2658) 
Training Epoch: [95/1000] Step: [60 / 285] Batch Time: 0.1436 (0.1699) Data Time: 0.0106 (0.0364) Average Loss: 1.1490 (0.7773) Average CE Loss (Source):  1.1490 ( 0.7773) Learning Rate: 0.1000 (0.1000) Top1_base: 68.7500 (78.3333) Top1_base_per_class: 71.0234 (78.7162) 
Training Epoch: [95/1000] Step: [70 / 285] Batch Time: 0.1403 (0.1665) Data Time: 0.0106 (0.0332) Average Loss: 0.6602 (0.7841) Average CE Loss (Source):  0.6602 ( 0.7841) Learning Rate: 0.1000 (0.1000) Top1_base: 78.9062 (78.1473) Top1_base_per_class: 77.4528 (78.3223) 
Training Epoch: [95/1000] Step: [80 / 285] Batch Time: 0.1468 (0.1645) Data Time: 0.0124 (0.0313) Average Loss: 0.6582 (0.7791) Average CE Loss (Source):  0.6582 ( 0.7791) Learning Rate: 0.1000 (0.1000) Top1_base: 83.5938 (78.1934) Top1_base_per_class: 83.6844 (78.3583) 
Training Epoch: [95/1000] Step: [90 / 285] Batch Time: 0.1449 (0.1631) Data Time: 0.0115 (0.0300) Average Loss: 0.5475 (0.7759) Average CE Loss (Source):  0.5475 ( 0.7759) Learning Rate: 0.1000 (0.1000) Top1_base: 85.9375 (78.2726) Top1_base_per_class: 86.1111 (78.4562) 
Training Epoch: [95/1000] Step: [100 / 285] Batch Time: 0.1442 (0.1632) Data Time: 0.0118 (0.0301) Average Loss: 0.8763 (0.7796) Average CE Loss (Source):  0.8763 ( 0.7796) Learning Rate: 0.1000 (0.1000) Top1_base: 75.0000 (78.1953) Top1_base_per_class: 79.7799 (78.5792) 
Training Epoch: [95/1000] Step: [110 / 285] Batch Time: 0.1480 (0.1620) Data Time: 0.0143 (0.0289) Average Loss: 0.6079 (0.7829) Average CE Loss (Source):  0.6079 ( 0.7829) Learning Rate: 0.1000 (0.1000) Top1_base: 79.6875 (78.0043) Top1_base_per_class: 77.0988 (78.3713) 
Training Epoch: [95/1000] Step: [120 / 285] Batch Time: 0.1468 (0.1613) Data Time: 0.0150 (0.0283) Average Loss: 0.5237 (0.7787) Average CE Loss (Source):  0.5237 ( 0.7787) Learning Rate: 0.1000 (0.1000) Top1_base: 82.8125 (78.0990) Top1_base_per_class: 82.8968 (78.5076) 
Training Epoch: [95/1000] Step: [130 / 285] Batch Time: 0.1449 (0.1605) Data Time: 0.0125 (0.0275) Average Loss: 0.8720 (0.7768) Average CE Loss (Source):  0.8720 ( 0.7768) Learning Rate: 0.1000 (0.1000) Top1_base: 76.5625 (78.1671) Top1_base_per_class: 77.4405 (78.6596) 
Training Epoch: [95/1000] Step: [140 / 285] Batch Time: 0.1450 (0.1602) Data Time: 0.0121 (0.0272) Average Loss: 0.7671 (0.7774) Average CE Loss (Source):  0.7671 ( 0.7774) Learning Rate: 0.1000 (0.1000) Top1_base: 82.0312 (78.2310) Top1_base_per_class: 83.7908 (78.7801) 
Training Epoch: [95/1000] Step: [150 / 285] Batch Time: 0.1419 (0.1602) Data Time: 0.0109 (0.0273) Average Loss: 0.8354 (0.7801) Average CE Loss (Source):  0.8354 ( 0.7801) Learning Rate: 0.1000 (0.1000) Top1_base: 78.1250 (78.1771) Top1_base_per_class: 80.0595 (78.7034) 
Training Epoch: [95/1000] Step: [160 / 285] Batch Time: 0.1461 (0.1599) Data Time: 0.0127 (0.0269) Average Loss: 0.8995 (0.7814) Average CE Loss (Source):  0.8995 ( 0.7814) Learning Rate: 0.1000 (0.1000) Top1_base: 73.4375 (78.1836) Top1_base_per_class: 74.7273 (78.7344) 
Training Epoch: [95/1000] Step: [170 / 285] Batch Time: 0.1428 (0.1597) Data Time: 0.0125 (0.0268) Average Loss: 0.6560 (0.7839) Average CE Loss (Source):  0.6560 ( 0.7839) Learning Rate: 0.1000 (0.1000) Top1_base: 85.9375 (78.2077) Top1_base_per_class: 80.0287 (78.7130) 
Training Epoch: [95/1000] Step: [180 / 285] Batch Time: 0.1467 (0.1591) Data Time: 0.0118 (0.0260) Average Loss: 0.6855 (0.7839) Average CE Loss (Source):  0.6855 ( 0.7839) Learning Rate: 0.1000 (0.1000) Top1_base: 80.4688 (78.1510) Top1_base_per_class: 80.4321 (78.6901) 
Training Epoch: [95/1000] Step: [190 / 285] Batch Time: 0.1418 (0.1585) Data Time: 0.0114 (0.0254) Average Loss: 0.9051 (0.7824) Average CE Loss (Source):  0.9051 ( 0.7824) Learning Rate: 0.1000 (0.1000) Top1_base: 75.7812 (78.1497) Top1_base_per_class: 77.8874 (78.6789) 
Training Epoch: [95/1000] Step: [200 / 285] Batch Time: 0.1479 (0.1578) Data Time: 0.0138 (0.0248) Average Loss: 0.6794 (0.7852) Average CE Loss (Source):  0.6794 ( 0.7852) Learning Rate: 0.1000 (0.1000) Top1_base: 78.1250 (78.0781) Top1_base_per_class: 80.7471 (78.6333) 
Training Epoch: [95/1000] Step: [210 / 285] Batch Time: 0.1503 (0.1574) Data Time: 0.0141 (0.0242) Average Loss: 0.8206 (0.7868) Average CE Loss (Source):  0.8206 ( 0.7868) Learning Rate: 0.1000 (0.1000) Top1_base: 76.5625 (78.0506) Top1_base_per_class: 79.5411 (78.6888) 
Training Epoch: [95/1000] Step: [220 / 285] Batch Time: 0.1484 (0.1571) Data Time: 0.0119 (0.0237) Average Loss: 0.6642 (0.7856) Average CE Loss (Source):  0.6642 ( 0.7856) Learning Rate: 0.1000 (0.1000) Top1_base: 82.8125 (78.1143) Top1_base_per_class: 83.5454 (78.7750) 
Training Epoch: [95/1000] Step: [230 / 285] Batch Time: 0.1515 (0.1567) Data Time: 0.0123 (0.0233) Average Loss: 0.9066 (0.7897) Average CE Loss (Source):  0.9066 ( 0.7897) Learning Rate: 0.1000 (0.1000) Top1_base: 72.6562 (78.0808) Top1_base_per_class: 77.1339 (78.7666) 
Training Epoch: [95/1000] Step: [240 / 285] Batch Time: 0.1441 (0.1564) Data Time: 0.0115 (0.0229) Average Loss: 0.5376 (0.7910) Average CE Loss (Source):  0.5376 ( 0.7910) Learning Rate: 0.1000 (0.1000) Top1_base: 86.7188 (78.0371) Top1_base_per_class: 85.4678 (78.6817) 
Training Epoch: [95/1000] Step: [250 / 285] Batch Time: 0.1460 (0.1561) Data Time: 0.0120 (0.0225) Average Loss: 0.7998 (0.7935) Average CE Loss (Source):  0.7998 ( 0.7935) Learning Rate: 0.1000 (0.1000) Top1_base: 79.6875 (78.0312) Top1_base_per_class: 78.9757 (78.6646) 
Training Epoch: [95/1000] Step: [260 / 285] Batch Time: 0.1448 (0.1557) Data Time: 0.0129 (0.0222) Average Loss: 0.7491 (0.7913) Average CE Loss (Source):  0.7491 ( 0.7913) Learning Rate: 0.1000 (0.1000) Top1_base: 78.9062 (78.1250) Top1_base_per_class: 77.6852 (78.7658) 
Training Epoch: [95/1000] Step: [270 / 285] Batch Time: 0.1473 (0.1554) Data Time: 0.0121 (0.0220) Average Loss: 0.9815 (0.7932) Average CE Loss (Source):  0.9815 ( 0.7932) Learning Rate: 0.1000 (0.1000) Top1_base: 73.4375 (78.0295) Top1_base_per_class: 76.6026 (78.6892) 
Training Epoch: [95/1000] Step: [280 / 285] Batch Time: 0.1465 (0.1551) Data Time: 0.0139 (0.0217) Average Loss: 0.7809 (0.7962) Average CE Loss (Source):  0.7809 ( 0.7962) Learning Rate: 0.1000 (0.1000) Top1_base: 82.0312 (77.9799) Top1_base_per_class: 82.5000 (78.6474) 
Training Epoch: [96/1000] Step: [0] Batch Time: 0.1467 (0.1549) Data Time: 0.0142 (0.0215) Average Loss: 0.8628 (0.7971) Average CE Loss (Source):  0.8628 ( 0.7971) Learning Rate: 0.1000 (0.1000) Top1_base: 76.5625 (77.9633) Top1_base_per_class: 76.5574 (78.6148) 
 10%|▉         | 96/1000 [1:15:12<11:35:47, 46.18s/it] 10%|▉         | 97/1000 [1:15:56<11:26:37, 45.62s/it]Training Epoch: [96/1000] Step: [10 / 285] Batch Time: 0.1447 (0.2341) Data Time: 0.0125 (0.1022) Average Loss: 0.8189 (0.7202) Average CE Loss (Source):  0.8189 ( 0.7202) Learning Rate: 0.1000 (0.1000) Top1_base: 78.1250 (79.8438) Top1_base_per_class: 81.3218 (80.9790) 
Training Epoch: [96/1000] Step: [20 / 285] Batch Time: 0.1443 (0.1909) Data Time: 0.0115 (0.0586) Average Loss: 0.7377 (0.7029) Average CE Loss (Source):  0.7377 ( 0.7029) Learning Rate: 0.1000 (0.1000) Top1_base: 78.9062 (80.3906) Top1_base_per_class: 75.4386 (80.8064) 
Training Epoch: [96/1000] Step: [30 / 285] Batch Time: 0.1442 (0.1851) Data Time: 0.0120 (0.0526) Average Loss: 0.8299 (0.7231) Average CE Loss (Source):  0.8299 ( 0.7231) Learning Rate: 0.1000 (0.1000) Top1_base: 77.3438 (79.7135) Top1_base_per_class: 79.1808 (80.2185) 
Training Epoch: [96/1000] Step: [40 / 285] Batch Time: 0.1470 (0.1758) Data Time: 0.0115 (0.0430) Average Loss: 0.9987 (0.7687) Average CE Loss (Source):  0.9987 ( 0.7687) Learning Rate: 0.1000 (0.1000) Top1_base: 64.0625 (78.3789) Top1_base_per_class: 65.4242 (78.8971) 
Training Epoch: [96/1000] Step: [50 / 285] Batch Time: 0.1470 (0.1703) Data Time: 0.0151 (0.0372) Average Loss: 0.6878 (0.7695) Average CE Loss (Source):  0.6878 ( 0.7695) Learning Rate: 0.1000 (0.1000) Top1_base: 85.1562 (78.4375) Top1_base_per_class: 86.5476 (78.9489) 
Training Epoch: [96/1000] Step: [60 / 285] Batch Time: 0.1435 (0.1662) Data Time: 0.0113 (0.0332) Average Loss: 0.7151 (0.7610) Average CE Loss (Source):  0.7151 ( 0.7610) Learning Rate: 0.1000 (0.1000) Top1_base: 82.0312 (78.7109) Top1_base_per_class: 83.8788 (79.2441) 
Training Epoch: [96/1000] Step: [70 / 285] Batch Time: 0.1479 (0.1637) Data Time: 0.0141 (0.0306) Average Loss: 0.9462 (0.7634) Average CE Loss (Source):  0.9462 ( 0.7634) Learning Rate: 0.1000 (0.1000) Top1_base: 71.8750 (78.6272) Top1_base_per_class: 75.5455 (79.1678) 
Training Epoch: [96/1000] Step: [80 / 285] Batch Time: 0.1469 (0.1621) Data Time: 0.0102 (0.0289) Average Loss: 0.7909 (0.7646) Average CE Loss (Source):  0.7909 ( 0.7646) Learning Rate: 0.1000 (0.1000) Top1_base: 75.7812 (78.4863) Top1_base_per_class: 76.1389 (79.0471) 
Training Epoch: [96/1000] Step: [90 / 285] Batch Time: 0.1480 (0.1620) Data Time: 0.0150 (0.0287) Average Loss: 0.7013 (0.7690) Average CE Loss (Source):  0.7013 ( 0.7690) Learning Rate: 0.1000 (0.1000) Top1_base: 82.8125 (78.4549) Top1_base_per_class: 84.6199 (78.9749) 
Training Epoch: [96/1000] Step: [100 / 285] Batch Time: 0.1468 (0.1608) Data Time: 0.0108 (0.0275) Average Loss: 0.6746 (0.7692) Average CE Loss (Source):  0.6746 ( 0.7692) Learning Rate: 0.1000 (0.1000) Top1_base: 81.2500 (78.4922) Top1_base_per_class: 82.3104 (79.0719) 
Training Epoch: [96/1000] Step: [110 / 285] Batch Time: 0.1465 (0.1598) Data Time: 0.0144 (0.0265) Average Loss: 0.7664 (0.7769) Average CE Loss (Source):  0.7664 ( 0.7769) Learning Rate: 0.1000 (0.1000) Top1_base: 75.0000 (78.2884) Top1_base_per_class: 75.9748 (78.8432) 
Training Epoch: [96/1000] Step: [120 / 285] Batch Time: 0.1502 (0.1593) Data Time: 0.0137 (0.0259) Average Loss: 0.6594 (0.7780) Average CE Loss (Source):  0.6594 ( 0.7780) Learning Rate: 0.1000 (0.1000) Top1_base: 78.9062 (78.2487) Top1_base_per_class: 75.3955 (78.8289) 
Training Epoch: [96/1000] Step: [130 / 285] Batch Time: 0.1472 (0.1583) Data Time: 0.0145 (0.0250) Average Loss: 0.5518 (0.7782) Average CE Loss (Source):  0.5518 ( 0.7782) Learning Rate: 0.1000 (0.1000) Top1_base: 85.9375 (78.2933) Top1_base_per_class: 88.3046 (78.8928) 
Training Epoch: [96/1000] Step: [140 / 285] Batch Time: 0.1453 (0.1575) Data Time: 0.0102 (0.0242) Average Loss: 0.9426 (0.7837) Average CE Loss (Source):  0.9426 ( 0.7837) Learning Rate: 0.1000 (0.1000) Top1_base: 74.2188 (78.1250) Top1_base_per_class: 70.7895 (78.6837) 
Training Epoch: [96/1000] Step: [150 / 285] Batch Time: 0.1464 (0.1568) Data Time: 0.0131 (0.0235) Average Loss: 0.8103 (0.7838) Average CE Loss (Source):  0.8103 ( 0.7838) Learning Rate: 0.1000 (0.1000) Top1_base: 78.9062 (78.1562) Top1_base_per_class: 79.3590 (78.6418) 
Training Epoch: [96/1000] Step: [160 / 285] Batch Time: 0.1447 (0.1566) Data Time: 0.0106 (0.0234) Average Loss: 1.0177 (0.7878) Average CE Loss (Source):  1.0177 ( 0.7878) Learning Rate: 0.1000 (0.1000) Top1_base: 74.2188 (78.1006) Top1_base_per_class: 70.7292 (78.4722) 
Training Epoch: [96/1000] Step: [170 / 285] Batch Time: 0.1460 (0.1563) Data Time: 0.0141 (0.0231) Average Loss: 0.8509 (0.7911) Average CE Loss (Source):  0.8509 ( 0.7911) Learning Rate: 0.1000 (0.1000) Top1_base: 75.7812 (77.9688) Top1_base_per_class: 77.6282 (78.3948) 
Training Epoch: [96/1000] Step: [180 / 285] Batch Time: 0.1449 (0.1559) Data Time: 0.0127 (0.0227) Average Loss: 0.6319 (0.7916) Average CE Loss (Source):  0.6319 ( 0.7916) Learning Rate: 0.1000 (0.1000) Top1_base: 82.8125 (77.9688) Top1_base_per_class: 81.3207 (78.3180) 
Training Epoch: [96/1000] Step: [190 / 285] Batch Time: 0.1459 (0.1557) Data Time: 0.0118 (0.0226) Average Loss: 0.7398 (0.7912) Average CE Loss (Source):  0.7398 ( 0.7912) Learning Rate: 0.1000 (0.1000) Top1_base: 77.3438 (77.9400) Top1_base_per_class: 77.2807 (78.2727) 
Training Epoch: [96/1000] Step: [200 / 285] Batch Time: 0.1443 (0.1561) Data Time: 0.0120 (0.0230) Average Loss: 0.7283 (0.7925) Average CE Loss (Source):  0.7283 ( 0.7925) Learning Rate: 0.1000 (0.1000) Top1_base: 80.4688 (77.9062) Top1_base_per_class: 78.0818 (78.1999) 
Training Epoch: [96/1000] Step: [210 / 285] Batch Time: 0.1425 (0.1563) Data Time: 0.0105 (0.0231) Average Loss: 0.7228 (0.7926) Average CE Loss (Source):  0.7228 ( 0.7926) Learning Rate: 0.1000 (0.1000) Top1_base: 77.3438 (77.9129) Top1_base_per_class: 80.2924 (78.1976) 
Training Epoch: [96/1000] Step: [220 / 285] Batch Time: 0.1440 (0.1566) Data Time: 0.0106 (0.0235) Average Loss: 1.0218 (0.7926) Average CE Loss (Source):  1.0218 ( 0.7926) Learning Rate: 0.1000 (0.1000) Top1_base: 69.5312 (77.8516) Top1_base_per_class: 68.7107 (78.0954) 
Training Epoch: [96/1000] Step: [230 / 285] Batch Time: 0.1473 (0.1562) Data Time: 0.0137 (0.0231) Average Loss: 0.8890 (0.7936) Average CE Loss (Source):  0.8890 ( 0.7936) Learning Rate: 0.1000 (0.1000) Top1_base: 75.7812 (77.8193) Top1_base_per_class: 78.5220 (78.0723) 
Training Epoch: [96/1000] Step: [240 / 285] Batch Time: 0.1434 (0.1562) Data Time: 0.0102 (0.0231) Average Loss: 0.7870 (0.7948) Average CE Loss (Source):  0.7870 ( 0.7948) Learning Rate: 0.1000 (0.1000) Top1_base: 80.4688 (77.8320) Top1_base_per_class: 85.0000 (78.1071) 
Training Epoch: [96/1000] Step: [250 / 285] Batch Time: 0.1448 (0.1559) Data Time: 0.0114 (0.0229) Average Loss: 0.8518 (0.7951) Average CE Loss (Source):  0.8518 ( 0.7951) Learning Rate: 0.1000 (0.1000) Top1_base: 81.2500 (77.8375) Top1_base_per_class: 83.8788 (78.1485) 
Training Epoch: [96/1000] Step: [260 / 285] Batch Time: 0.1447 (0.1558) Data Time: 0.0102 (0.0227) Average Loss: 0.9044 (0.7965) Average CE Loss (Source):  0.9044 ( 0.7965) Learning Rate: 0.1000 (0.1000) Top1_base: 74.2188 (77.7734) Top1_base_per_class: 73.0367 (78.1180) 
Training Epoch: [96/1000] Step: [270 / 285] Batch Time: 0.1459 (0.1556) Data Time: 0.0138 (0.0225) Average Loss: 0.7912 (0.7979) Average CE Loss (Source):  0.7912 ( 0.7979) Learning Rate: 0.1000 (0.1000) Top1_base: 73.4375 (77.7431) Top1_base_per_class: 73.1609 (78.0868) 
Training Epoch: [96/1000] Step: [280 / 285] Batch Time: 0.1450 (0.1553) Data Time: 0.0097 (0.0223) Average Loss: 0.9328 (0.8004) Average CE Loss (Source):  0.9328 ( 0.8004) Learning Rate: 0.1000 (0.1000) Top1_base: 76.5625 (77.6814) Top1_base_per_class: 73.4795 (78.0261) 
Training Epoch: [97/1000] Step: [0] Batch Time: 0.1437 (0.1553) Data Time: 0.0116 (0.0222) Average Loss: 0.6633 (0.8016) Average CE Loss (Source):  0.6633 ( 0.8016) Learning Rate: 0.1000 (0.1000) Top1_base: 80.4688 (77.6480) Top1_base_per_class: 82.0468 (77.9949) 
Training Epoch: [97/1000] Step: [10 / 285] Batch Time: 0.1424 (0.2376) Data Time: 0.0107 (0.1050) Average Loss: 0.8091 (0.7317) Average CE Loss (Source):  0.8091 ( 0.7317) Learning Rate: 0.1000 (0.1000) Top1_base: 78.9062 (80.4688) Top1_base_per_class: 81.6667 (81.0723) 
Training Epoch: [97/1000] Step: [20 / 285] Batch Time: 0.1485 (0.1967) Data Time: 0.0132 (0.0641) Average Loss: 0.7686 (0.7559) Average CE Loss (Source):  0.7686 ( 0.7559) Learning Rate: 0.1000 (0.1000) Top1_base: 77.3438 (78.7891) Top1_base_per_class: 78.1111 (79.1851) 
Training Epoch: [97/1000] Step: [30 / 285] Batch Time: 0.1501 (0.1832) Data Time: 0.0165 (0.0503) Average Loss: 0.8869 (0.7367) Average CE Loss (Source):  0.8869 ( 0.7367) Learning Rate: 0.1000 (0.1000) Top1_base: 73.4375 (79.3490) Top1_base_per_class: 76.8170 (79.8972) 
Training Epoch: [97/1000] Step: [40 / 285] Batch Time: 0.1473 (0.1762) Data Time: 0.0134 (0.0432) Average Loss: 0.7985 (0.7529) Average CE Loss (Source):  0.7985 ( 0.7529) Learning Rate: 0.1000 (0.1000) Top1_base: 75.7812 (79.0039) Top1_base_per_class: 72.3302 (79.1850) 
Training Epoch: [97/1000] Step: [50 / 285] Batch Time: 0.1468 (0.1736) Data Time: 0.0136 (0.0403) Average Loss: 0.7093 (0.7594) Average CE Loss (Source):  0.7093 ( 0.7594) Learning Rate: 0.1000 (0.1000) Top1_base: 81.2500 (78.9062) Top1_base_per_class: 83.3333 (79.1302) 
Training Epoch: [97/1000] Step: [60 / 285] Batch Time: 0.1464 (0.1752) Data Time: 0.0119 (0.0417) Average Loss: 0.7467 (0.7559) Average CE Loss (Source):  0.7467 ( 0.7559) Learning Rate: 0.1000 (0.1000) Top1_base: 81.2500 (79.0755) Top1_base_per_class: 79.5679 (79.4338) 
Training Epoch: [97/1000] Step: [70 / 285] Batch Time: 0.1484 (0.1721) Data Time: 0.0162 (0.0387) Average Loss: 0.7808 (0.7568) Average CE Loss (Source):  0.7808 ( 0.7568) Learning Rate: 0.1000 (0.1000) Top1_base: 78.1250 (79.1071) Top1_base_per_class: 77.0346 (79.4696) 
Training Epoch: [97/1000] Step: [80 / 285] Batch Time: 0.1430 (0.1714) Data Time: 0.0119 (0.0380) Average Loss: 0.6581 (0.7587) Average CE Loss (Source):  0.6581 ( 0.7587) Learning Rate: 0.1000 (0.1000) Top1_base: 83.5938 (78.9941) Top1_base_per_class: 80.6970 (79.3342) 
Training Epoch: [97/1000] Step: [90 / 285] Batch Time: 0.1485 (0.1701) Data Time: 0.0146 (0.0365) Average Loss: 0.8246 (0.7614) Average CE Loss (Source):  0.8246 ( 0.7614) Learning Rate: 0.1000 (0.1000) Top1_base: 74.2188 (78.8194) Top1_base_per_class: 74.6047 (79.1037) 
Training Epoch: [97/1000] Step: [100 / 285] Batch Time: 0.1451 (0.1692) Data Time: 0.0128 (0.0356) Average Loss: 0.6954 (0.7674) Average CE Loss (Source):  0.6954 ( 0.7674) Learning Rate: 0.1000 (0.1000) Top1_base: 78.1250 (78.7734) Top1_base_per_class: 76.7284 (79.0526) 
Training Epoch: [97/1000] Step: [110 / 285] Batch Time: 0.1468 (0.1673) Data Time: 0.0129 (0.0337) Average Loss: 0.7420 (0.7744) Average CE Loss (Source):  0.7420 ( 0.7744) Learning Rate: 0.1000 (0.1000) Top1_base: 76.5625 (78.5866) Top1_base_per_class: 75.3869 (78.8485) 
Training Epoch: [97/1000] Step: [120 / 285] Batch Time: 0.1445 (0.1660) Data Time: 0.0122 (0.0324) Average Loss: 0.8428 (0.7761) Average CE Loss (Source):  0.8428 ( 0.7761) Learning Rate: 0.1000 (0.1000) Top1_base: 76.5625 (78.5482) Top1_base_per_class: 75.4167 (78.9210) 
Training Epoch: [97/1000] Step: [130 / 285] Batch Time: 0.1490 (0.1650) Data Time: 0.0157 (0.0314) Average Loss: 0.8742 (0.7787) Average CE Loss (Source):  0.8742 ( 0.7787) Learning Rate: 0.1000 (0.1000) Top1_base: 78.1250 (78.4796) Top1_base_per_class: 76.4578 (78.7966) 
Training Epoch: [97/1000] Step: [140 / 285] Batch Time: 0.1463 (0.1644) Data Time: 0.0133 (0.0308) Average Loss: 0.8740 (0.7792) Average CE Loss (Source):  0.8740 ( 0.7792) Learning Rate: 0.1000 (0.1000) Top1_base: 75.0000 (78.4431) Top1_base_per_class: 76.6092 (78.7495) 
Training Epoch: [97/1000] Step: [150 / 285] Batch Time: 0.1462 (0.1632) Data Time: 0.0151 (0.0297) Average Loss: 0.7541 (0.7792) Average CE Loss (Source):  0.7541 ( 0.7792) Learning Rate: 0.1000 (0.1000) Top1_base: 81.2500 (78.3854) Top1_base_per_class: 80.6548 (78.6830) 
Training Epoch: [97/1000] Step: [160 / 285] Batch Time: 0.1449 (0.1627) Data Time: 0.0122 (0.0292) Average Loss: 0.9048 (0.7838) Average CE Loss (Source):  0.9048 ( 0.7838) Learning Rate: 0.1000 (0.1000) Top1_base: 71.8750 (78.2080) Top1_base_per_class: 71.7549 (78.4806) 
Training Epoch: [97/1000] Step: [170 / 285] Batch Time: 0.1820 (0.1630) Data Time: 0.0503 (0.0295) Average Loss: 0.6472 (0.7885) Average CE Loss (Source):  0.6472 ( 0.7885) Learning Rate: 0.1000 (0.1000) Top1_base: 80.4688 (78.0790) Top1_base_per_class: 81.9753 (78.4066) 
Training Epoch: [97/1000] Step: [180 / 285] Batch Time: 0.1432 (0.1624) Data Time: 0.0115 (0.0290) Average Loss: 0.6952 (0.7893) Average CE Loss (Source):  0.6952 ( 0.7893) Learning Rate: 0.1000 (0.1000) Top1_base: 78.1250 (78.0295) Top1_base_per_class: 75.7738 (78.3582) 
Training Epoch: [97/1000] Step: [190 / 285] Batch Time: 0.2326 (0.1624) Data Time: 0.1004 (0.0290) Average Loss: 0.6224 (0.7924) Average CE Loss (Source):  0.6224 ( 0.7924) Learning Rate: 0.1000 (0.1000) Top1_base: 80.4688 (77.9646) Top1_base_per_class: 82.1637 (78.3119) 
Training Epoch: [97/1000] Step: [200 / 285] Batch Time: 0.1458 (0.1620) Data Time: 0.0117 (0.0286) Average Loss: 0.5879 (0.7952) Average CE Loss (Source):  0.5879 ( 0.7952) Learning Rate: 0.1000 (0.1000) Top1_base: 81.2500 (77.8711) Top1_base_per_class: 83.7134 (78.2572) 
Training Epoch: [97/1000] Step: [210 / 285] Batch Time: 0.2495 (0.1618) Data Time: 0.1161 (0.0284) Average Loss: 0.9434 (0.7974) Average CE Loss (Source):  0.9434 ( 0.7974) Learning Rate: 0.1000 (0.1000) Top1_base: 70.3125 (77.7939) Top1_base_per_class: 71.2644 (78.1901) 
Training Epoch: [97/1000] Step: [220 / 285] Batch Time: 0.1465 (0.1611) Data Time: 0.0109 (0.0277) Average Loss: 0.6459 (0.7982) Average CE Loss (Source):  0.6459 ( 0.7982) Learning Rate: 0.1000 (0.1000) Top1_base: 79.6875 (77.7770) Top1_base_per_class: 82.2577 (78.1975) 
Training Epoch: [97/1000] Step: [230 / 285] Batch Time: 0.1525 (0.1606) Data Time: 0.0169 (0.0272) Average Loss: 0.8914 (0.7967) Average CE Loss (Source):  0.8914 ( 0.7967) Learning Rate: 0.1000 (0.1000) Top1_base: 71.0938 (77.7989) Top1_base_per_class: 72.0000 (78.2247) 
Training Epoch: [97/1000] Step: [240 / 285] Batch Time: 0.1460 (0.1600) Data Time: 0.0117 (0.0266) Average Loss: 0.5400 (0.7951) Average CE Loss (Source):  0.5400 ( 0.7951) Learning Rate: 0.1000 (0.1000) Top1_base: 85.1562 (77.8385) Top1_base_per_class: 83.1173 (78.2470) 
Training Epoch: [97/1000] Step: [250 / 285] Batch Time: 0.1513 (0.1596) Data Time: 0.0167 (0.0262) Average Loss: 0.7532 (0.7951) Average CE Loss (Source):  0.7532 ( 0.7951) Learning Rate: 0.1000 (0.1000) Top1_base: 80.4688 (77.8156) Top1_base_per_class: 80.0862 (78.1815) 
Training Epoch: [97/1000] Step: [260 / 285] Batch Time: 0.1490 (0.1593) Data Time: 0.0134 (0.0258) Average Loss: 0.8835 (0.7951) Average CE Loss (Source):  0.8835 ( 0.7951) Learning Rate: 0.1000 (0.1000) Top1_base: 71.8750 (77.7434) Top1_base_per_class: 68.3025 (78.1179) 
Training Epoch: [97/1000] Step: [270 / 285] Batch Time: 0.2001 (0.1591) Data Time: 0.0646 (0.0256) Average Loss: 0.7015 (0.7956) Average CE Loss (Source):  0.7015 ( 0.7956) Learning Rate: 0.1000 (0.1000) Top1_base: 82.8125 (77.7373) Top1_base_per_class: 80.6433 (78.0812) 
Training Epoch: [97/1000] Step: [280 / 285] Batch Time: 0.1438 (0.1588) Data Time: 0.0111 (0.0254) Average Loss: 0.8647 (0.7990) Average CE Loss (Source):  0.8647 ( 0.7990) Learning Rate: 0.1000 (0.1000) Top1_base: 73.4375 (77.5809) Top1_base_per_class: 77.5786 (77.9760) 
Training Epoch: [98/1000] Step: [0] Batch Time: 0.1448 (0.1587) Data Time: 0.0106 (0.0252) Average Loss: 0.8265 (0.7994) Average CE Loss (Source):  0.8265 ( 0.7994) Learning Rate: 0.1000 (0.1000) Top1_base: 77.3438 (77.6014) Top1_base_per_class: 77.6374 (78.0026) 
 10%|▉         | 98/1000 [1:16:44<11:36:41, 46.34s/it] 10%|▉         | 99/1000 [1:17:29<11:30:03, 45.95s/it]Training Epoch: [98/1000] Step: [10 / 285] Batch Time: 0.1468 (0.2328) Data Time: 0.0136 (0.1005) Average Loss: 0.7638 (0.7509) Average CE Loss (Source):  0.7638 ( 0.7509) Learning Rate: 0.1000 (0.1000) Top1_base: 78.1250 (78.8281) Top1_base_per_class: 78.5152 (79.0796) 
Training Epoch: [98/1000] Step: [20 / 285] Batch Time: 0.1466 (0.1964) Data Time: 0.0130 (0.0638) Average Loss: 0.7085 (0.7323) Average CE Loss (Source):  0.7085 ( 0.7323) Learning Rate: 0.1000 (0.1000) Top1_base: 82.0312 (79.2578) Top1_base_per_class: 82.5397 (79.9159) 
Training Epoch: [98/1000] Step: [30 / 285] Batch Time: 0.1636 (0.1832) Data Time: 0.0319 (0.0507) Average Loss: 0.7878 (0.7530) Average CE Loss (Source):  0.7878 ( 0.7530) Learning Rate: 0.1000 (0.1000) Top1_base: 78.9062 (78.8802) Top1_base_per_class: 79.8077 (79.4722) 
Training Epoch: [98/1000] Step: [40 / 285] Batch Time: 0.1427 (0.1760) Data Time: 0.0111 (0.0431) Average Loss: 0.6290 (0.7433) Average CE Loss (Source):  0.6290 ( 0.7433) Learning Rate: 0.1000 (0.1000) Top1_base: 82.0312 (79.2188) Top1_base_per_class: 84.4444 (80.1446) 
Training Epoch: [98/1000] Step: [50 / 285] Batch Time: 0.1474 (0.1737) Data Time: 0.0160 (0.0409) Average Loss: 0.8505 (0.7408) Average CE Loss (Source):  0.8505 ( 0.7408) Learning Rate: 0.1000 (0.1000) Top1_base: 71.0938 (79.2656) Top1_base_per_class: 68.8485 (79.9521) 
Training Epoch: [98/1000] Step: [60 / 285] Batch Time: 0.1478 (0.1709) Data Time: 0.0137 (0.0380) Average Loss: 0.8388 (0.7376) Average CE Loss (Source):  0.8388 ( 0.7376) Learning Rate: 0.1000 (0.1000) Top1_base: 79.6875 (79.4141) Top1_base_per_class: 81.0185 (79.8913) 
Training Epoch: [98/1000] Step: [70 / 285] Batch Time: 0.1613 (0.1685) Data Time: 0.0307 (0.0356) Average Loss: 0.8279 (0.7434) Average CE Loss (Source):  0.8279 ( 0.7434) Learning Rate: 0.1000 (0.1000) Top1_base: 76.5625 (79.2188) Top1_base_per_class: 77.4425 (79.6758) 
Training Epoch: [98/1000] Step: [80 / 285] Batch Time: 0.1428 (0.1658) Data Time: 0.0121 (0.0330) Average Loss: 0.8781 (0.7496) Average CE Loss (Source):  0.8781 ( 0.7496) Learning Rate: 0.1000 (0.1000) Top1_base: 77.3438 (79.0332) Top1_base_per_class: 77.8788 (79.4786) 
Training Epoch: [98/1000] Step: [90 / 285] Batch Time: 0.1491 (0.1653) Data Time: 0.0172 (0.0326) Average Loss: 0.4947 (0.7520) Average CE Loss (Source):  0.4947 ( 0.7520) Learning Rate: 0.1000 (0.1000) Top1_base: 84.3750 (78.8715) Top1_base_per_class: 81.0345 (79.4075) 
Training Epoch: [98/1000] Step: [100 / 285] Batch Time: 0.1436 (0.1635) Data Time: 0.0118 (0.0308) Average Loss: 0.8050 (0.7586) Average CE Loss (Source):  0.8050 ( 0.7586) Learning Rate: 0.1000 (0.1000) Top1_base: 75.0000 (78.6484) Top1_base_per_class: 74.1195 (79.1251) 
Training Epoch: [98/1000] Step: [110 / 285] Batch Time: 0.2662 (0.1636) Data Time: 0.1351 (0.0309) Average Loss: 0.7492 (0.7600) Average CE Loss (Source):  0.7492 ( 0.7600) Learning Rate: 0.1000 (0.1000) Top1_base: 77.3438 (78.6080) Top1_base_per_class: 77.4713 (78.9746) 
Training Epoch: [98/1000] Step: [120 / 285] Batch Time: 0.1436 (0.1626) Data Time: 0.0124 (0.0298) Average Loss: 1.0509 (0.7635) Average CE Loss (Source):  1.0509 ( 0.7635) Learning Rate: 0.1000 (0.1000) Top1_base: 73.4375 (78.5612) Top1_base_per_class: 72.0126 (78.9732) 
Training Epoch: [98/1000] Step: [130 / 285] Batch Time: 0.1495 (0.1615) Data Time: 0.0147 (0.0286) Average Loss: 0.7153 (0.7721) Average CE Loss (Source):  0.7153 ( 0.7721) Learning Rate: 0.1000 (0.1000) Top1_base: 78.1250 (78.3954) Top1_base_per_class: 80.6548 (78.8644) 
Training Epoch: [98/1000] Step: [140 / 285] Batch Time: 0.1420 (0.1605) Data Time: 0.0107 (0.0275) Average Loss: 0.7711 (0.7741) Average CE Loss (Source):  0.7711 ( 0.7741) Learning Rate: 0.1000 (0.1000) Top1_base: 78.9062 (78.3705) Top1_base_per_class: 80.3395 (78.7445) 
Training Epoch: [98/1000] Step: [150 / 285] Batch Time: 0.1650 (0.1599) Data Time: 0.0330 (0.0270) Average Loss: 0.6143 (0.7767) Average CE Loss (Source):  0.6143 ( 0.7767) Learning Rate: 0.1000 (0.1000) Top1_base: 84.3750 (78.3073) Top1_base_per_class: 85.8951 (78.7159) 
Training Epoch: [98/1000] Step: [160 / 285] Batch Time: 0.1501 (0.1593) Data Time: 0.0137 (0.0262) Average Loss: 0.8235 (0.7776) Average CE Loss (Source):  0.8235 ( 0.7776) Learning Rate: 0.1000 (0.1000) Top1_base: 75.7812 (78.3057) Top1_base_per_class: 74.7953 (78.7827) 
Training Epoch: [98/1000] Step: [170 / 285] Batch Time: 0.1482 (0.1589) Data Time: 0.0157 (0.0258) Average Loss: 0.7245 (0.7763) Average CE Loss (Source):  0.7245 ( 0.7763) Learning Rate: 0.1000 (0.1000) Top1_base: 81.2500 (78.3456) Top1_base_per_class: 84.6364 (78.8434) 
Training Epoch: [98/1000] Step: [180 / 285] Batch Time: 0.1429 (0.1583) Data Time: 0.0125 (0.0252) Average Loss: 0.8038 (0.7776) Average CE Loss (Source):  0.8038 ( 0.7776) Learning Rate: 0.1000 (0.1000) Top1_base: 79.6875 (78.3637) Top1_base_per_class: 78.5152 (78.9331) 
Training Epoch: [98/1000] Step: [190 / 285] Batch Time: 0.1439 (0.1582) Data Time: 0.0127 (0.0250) Average Loss: 0.7793 (0.7792) Average CE Loss (Source):  0.7793 ( 0.7792) Learning Rate: 0.1000 (0.1000) Top1_base: 80.4688 (78.3018) Top1_base_per_class: 80.8227 (78.8360) 
Training Epoch: [98/1000] Step: [200 / 285] Batch Time: 0.1499 (0.1581) Data Time: 0.0133 (0.0249) Average Loss: 0.9457 (0.7810) Average CE Loss (Source):  0.9457 ( 0.7810) Learning Rate: 0.1000 (0.1000) Top1_base: 74.2188 (78.2461) Top1_base_per_class: 73.7970 (78.7381) 
Training Epoch: [98/1000] Step: [210 / 285] Batch Time: 0.1449 (0.1582) Data Time: 0.0137 (0.0250) Average Loss: 0.7426 (0.7842) Average CE Loss (Source):  0.7426 ( 0.7842) Learning Rate: 0.1000 (0.1000) Top1_base: 78.1250 (78.0915) Top1_base_per_class: 79.6491 (78.6420) 
Training Epoch: [98/1000] Step: [220 / 285] Batch Time: 0.1417 (0.1583) Data Time: 0.0114 (0.0252) Average Loss: 0.6764 (0.7840) Average CE Loss (Source):  0.6764 ( 0.7840) Learning Rate: 0.1000 (0.1000) Top1_base: 79.6875 (78.1001) Top1_base_per_class: 78.5152 (78.6249) 
Training Epoch: [98/1000] Step: [230 / 285] Batch Time: 0.1448 (0.1581) Data Time: 0.0114 (0.0250) Average Loss: 0.6570 (0.7856) Average CE Loss (Source):  0.6570 ( 0.7856) Learning Rate: 0.1000 (0.1000) Top1_base: 81.2500 (78.0265) Top1_base_per_class: 80.5655 (78.5263) 
Training Epoch: [98/1000] Step: [240 / 285] Batch Time: 0.1427 (0.1579) Data Time: 0.0109 (0.0249) Average Loss: 0.7420 (0.7875) Average CE Loss (Source):  0.7420 ( 0.7875) Learning Rate: 0.1000 (0.1000) Top1_base: 78.9062 (77.9688) Top1_base_per_class: 77.2876 (78.5406) 
Training Epoch: [98/1000] Step: [250 / 285] Batch Time: 0.1432 (0.1583) Data Time: 0.0105 (0.0252) Average Loss: 0.7383 (0.7879) Average CE Loss (Source):  0.7383 ( 0.7879) Learning Rate: 0.1000 (0.1000) Top1_base: 74.2188 (77.9344) Top1_base_per_class: 75.0298 (78.5256) 
Training Epoch: [98/1000] Step: [260 / 285] Batch Time: 0.1508 (0.1579) Data Time: 0.0162 (0.0248) Average Loss: 0.6593 (0.7890) Average CE Loss (Source):  0.6593 ( 0.7890) Learning Rate: 0.1000 (0.1000) Top1_base: 80.4688 (77.9267) Top1_base_per_class: 80.2201 (78.5072) 
Training Epoch: [98/1000] Step: [270 / 285] Batch Time: 0.1420 (0.1575) Data Time: 0.0104 (0.0245) Average Loss: 0.9133 (0.7891) Average CE Loss (Source):  0.9133 ( 0.7891) Learning Rate: 0.1000 (0.1000) Top1_base: 75.0000 (77.8819) Top1_base_per_class: 76.1515 (78.4361) 
Training Epoch: [98/1000] Step: [280 / 285] Batch Time: 0.1454 (0.1578) Data Time: 0.0128 (0.0247) Average Loss: 0.8695 (0.7920) Average CE Loss (Source):  0.8695 ( 0.7920) Learning Rate: 0.1000 (0.1000) Top1_base: 73.4375 (77.7790) Top1_base_per_class: 74.4133 (78.3608) 
Training Epoch: [99/1000] Step: [0] Batch Time: 0.1700 (0.1578) Data Time: 0.0390 (0.0248) Average Loss: 1.0221 (0.7933) Average CE Loss (Source):  1.0221 ( 0.7933) Learning Rate: 0.1000 (0.1000) Top1_base: 71.8750 (77.7604) Top1_base_per_class: 69.5758 (78.3233) 
Training Epoch: [99/1000] Step: [10 / 285] Batch Time: 0.1429 (0.2312) Data Time: 0.0125 (0.0993) Average Loss: 0.8075 (0.8086) Average CE Loss (Source):  0.8075 ( 0.8086) Learning Rate: 0.1000 (0.1000) Top1_base: 76.5625 (77.3438) Top1_base_per_class: 77.0468 (77.6678) 
Training Epoch: [99/1000] Step: [20 / 285] Batch Time: 0.1498 (0.1950) Data Time: 0.0151 (0.0630) Average Loss: 0.6423 (0.7606) Average CE Loss (Source):  0.6423 ( 0.7606) Learning Rate: 0.1000 (0.1000) Top1_base: 79.6875 (78.8672) Top1_base_per_class: 78.9204 (77.9277) 
Training Epoch: [99/1000] Step: [30 / 285] Batch Time: 0.1515 (0.1837) Data Time: 0.0156 (0.0504) Average Loss: 0.8010 (0.7536) Average CE Loss (Source):  0.8010 ( 0.7536) Learning Rate: 0.1000 (0.1000) Top1_base: 75.7812 (78.6458) Top1_base_per_class: 76.7628 (78.5372) 
Training Epoch: [99/1000] Step: [40 / 285] Batch Time: 0.1460 (0.1756) Data Time: 0.0111 (0.0419) Average Loss: 0.8657 (0.7552) Average CE Loss (Source):  0.8657 ( 0.7552) Learning Rate: 0.1000 (0.1000) Top1_base: 76.5625 (78.6523) Top1_base_per_class: 78.5454 (78.6828) 
Training Epoch: [99/1000] Step: [50 / 285] Batch Time: 0.1518 (0.1708) Data Time: 0.0149 (0.0366) Average Loss: 0.6305 (0.7515) Average CE Loss (Source):  0.6305 ( 0.7515) Learning Rate: 0.1000 (0.1000) Top1_base: 83.5938 (78.6250) Top1_base_per_class: 80.1887 (78.4826) 
Training Epoch: [99/1000] Step: [60 / 285] Batch Time: 0.1441 (0.1673) Data Time: 0.0099 (0.0330) Average Loss: 0.6313 (0.7535) Average CE Loss (Source):  0.6313 ( 0.7535) Learning Rate: 0.1000 (0.1000) Top1_base: 84.3750 (78.4505) Top1_base_per_class: 85.2011 (78.2368) 
Training Epoch: [99/1000] Step: [70 / 285] Batch Time: 0.1508 (0.1649) Data Time: 0.0170 (0.0307) Average Loss: 0.8883 (0.7583) Average CE Loss (Source):  0.8883 ( 0.7583) Learning Rate: 0.1000 (0.1000) Top1_base: 77.3438 (78.3929) Top1_base_per_class: 79.2424 (78.3013) 
Training Epoch: [99/1000] Step: [80 / 285] Batch Time: 0.1454 (0.1632) Data Time: 0.0146 (0.0292) Average Loss: 0.8727 (0.7597) Average CE Loss (Source):  0.8727 ( 0.7597) Learning Rate: 0.1000 (0.1000) Top1_base: 71.8750 (78.2324) Top1_base_per_class: 70.5660 (78.3566) 
Training Epoch: [99/1000] Step: [90 / 285] Batch Time: 0.1468 (0.1623) Data Time: 0.0124 (0.0284) Average Loss: 0.7273 (0.7651) Average CE Loss (Source):  0.7273 ( 0.7651) Learning Rate: 0.1000 (0.1000) Top1_base: 82.8125 (78.0816) Top1_base_per_class: 86.6364 (78.3230) 
Training Epoch: [99/1000] Step: [100 / 285] Batch Time: 0.1440 (0.1611) Data Time: 0.0131 (0.0274) Average Loss: 0.8231 (0.7674) Average CE Loss (Source):  0.8231 ( 0.7674) Learning Rate: 0.1000 (0.1000) Top1_base: 78.9062 (78.0469) Top1_base_per_class: 82.4242 (78.4361) 
Training Epoch: [99/1000] Step: [110 / 285] Batch Time: 0.1478 (0.1602) Data Time: 0.0120 (0.0265) Average Loss: 0.7322 (0.7698) Average CE Loss (Source):  0.7322 ( 0.7698) Learning Rate: 0.1000 (0.1000) Top1_base: 79.6875 (78.0469) Top1_base_per_class: 80.7650 (78.3775) 
Training Epoch: [99/1000] Step: [120 / 285] Batch Time: 0.1801 (0.1594) Data Time: 0.0483 (0.0257) Average Loss: 0.6284 (0.7741) Average CE Loss (Source):  0.6284 ( 0.7741) Learning Rate: 0.1000 (0.1000) Top1_base: 78.9062 (77.9102) Top1_base_per_class: 81.2478 (78.2052) 
Training Epoch: [99/1000] Step: [130 / 285] Batch Time: 0.1430 (0.1591) Data Time: 0.0111 (0.0255) Average Loss: 0.6896 (0.7776) Average CE Loss (Source):  0.6896 ( 0.7776) Learning Rate: 0.1000 (0.1000) Top1_base: 79.6875 (77.8005) Top1_base_per_class: 80.5152 (78.1241) 
Training Epoch: [99/1000] Step: [140 / 285] Batch Time: 0.1616 (0.1592) Data Time: 0.0300 (0.0257) Average Loss: 0.8866 (0.7812) Average CE Loss (Source):  0.8866 ( 0.7812) Learning Rate: 0.1000 (0.1000) Top1_base: 76.5625 (77.7511) Top1_base_per_class: 74.2857 (78.0511) 
Training Epoch: [99/1000] Step: [150 / 285] Batch Time: 0.1468 (0.1591) Data Time: 0.0120 (0.0257) Average Loss: 0.9279 (0.7843) Average CE Loss (Source):  0.9279 ( 0.7843) Learning Rate: 0.1000 (0.1000) Top1_base: 72.6562 (77.6615) Top1_base_per_class: 70.9040 (78.0184) 
Training Epoch: [99/1000] Step: [160 / 285] Batch Time: 0.2101 (0.1594) Data Time: 0.0779 (0.0261) Average Loss: 0.7039 (0.7817) Average CE Loss (Source):  0.7039 ( 0.7817) Learning Rate: 0.1000 (0.1000) Top1_base: 79.6875 (77.7441) Top1_base_per_class: 81.2792 (78.1384) 
Training Epoch: [99/1000] Step: [170 / 285] Batch Time: 0.1459 (0.1591) Data Time: 0.0128 (0.0258) Average Loss: 0.7842 (0.7840) Average CE Loss (Source):  0.7842 ( 0.7840) Learning Rate: 0.1000 (0.1000) Top1_base: 77.3438 (77.7206) Top1_base_per_class: 76.6026 (78.1157) 
Training Epoch: [99/1000] Step: [180 / 285] Batch Time: 0.1712 (0.1589) Data Time: 0.0373 (0.0256) Average Loss: 0.8581 (0.7815) Average CE Loss (Source):  0.8581 ( 0.7815) Learning Rate: 0.1000 (0.1000) Top1_base: 75.0000 (77.8038) Top1_base_per_class: 76.6667 (78.2282) 
Training Epoch: [99/1000] Step: [190 / 285] Batch Time: 0.1498 (0.1587) Data Time: 0.0152 (0.0253) Average Loss: 0.9421 (0.7811) Average CE Loss (Source):  0.9421 ( 0.7811) Learning Rate: 0.1000 (0.1000) Top1_base: 72.6562 (77.8125) Top1_base_per_class: 73.8182 (78.2354) 
Training Epoch: [99/1000] Step: [200 / 285] Batch Time: 0.1482 (0.1582) Data Time: 0.0138 (0.0247) Average Loss: 0.7325 (0.7777) Average CE Loss (Source):  0.7325 ( 0.7777) Learning Rate: 0.1000 (0.1000) Top1_base: 77.3438 (77.9023) Top1_base_per_class: 79.3557 (78.3002) 
Training Epoch: [99/1000] Step: [210 / 285] Batch Time: 0.1472 (0.1580) Data Time: 0.0139 (0.0245) Average Loss: 0.6051 (0.7803) Average CE Loss (Source):  0.6051 ( 0.7803) Learning Rate: 0.1000 (0.1000) Top1_base: 82.0312 (77.8385) Top1_base_per_class: 83.0449 (78.2382) 
Training Epoch: [99/1000] Step: [220 / 285] Batch Time: 0.1605 (0.1580) Data Time: 0.0251 (0.0245) Average Loss: 0.7048 (0.7801) Average CE Loss (Source):  0.7048 ( 0.7801) Learning Rate: 0.1000 (0.1000) Top1_base: 83.5938 (77.8445) Top1_base_per_class: 80.7576 (78.2962) 
Training Epoch: [99/1000] Step: [230 / 285] Batch Time: 0.1486 (0.1577) Data Time: 0.0136 (0.0243) Average Loss: 0.7060 (0.7810) Average CE Loss (Source):  0.7060 ( 0.7810) Learning Rate: 0.1000 (0.1000) Top1_base: 81.2500 (77.8533) Top1_base_per_class: 82.1914 (78.3142) 
Training Epoch: [99/1000] Step: [240 / 285] Batch Time: 0.1739 (0.1574) Data Time: 0.0395 (0.0239) Average Loss: 0.7347 (0.7807) Average CE Loss (Source):  0.7347 ( 0.7807) Learning Rate: 0.1000 (0.1000) Top1_base: 81.2500 (77.8613) Top1_base_per_class: 79.6811 (78.3237) 
Training Epoch: [99/1000] Step: [250 / 285] Batch Time: 0.1500 (0.1571) Data Time: 0.0141 (0.0235) Average Loss: 0.6335 (0.7831) Average CE Loss (Source):  0.6335 ( 0.7831) Learning Rate: 0.1000 (0.1000) Top1_base: 81.2500 (77.7781) Top1_base_per_class: 79.8742 (78.2575) 
Training Epoch: [99/1000] Step: [260 / 285] Batch Time: 0.1491 (0.1567) Data Time: 0.0164 (0.0231) Average Loss: 0.8272 (0.7839) Average CE Loss (Source):  0.8272 ( 0.7839) Learning Rate: 0.1000 (0.1000) Top1_base: 77.3438 (77.7644) Top1_base_per_class: 77.7874 (78.2404) 
Training Epoch: [99/1000] Step: [270 / 285] Batch Time: 0.1486 (0.1564) Data Time: 0.0133 (0.0228) Average Loss: 0.8019 (0.7842) Average CE Loss (Source):  0.8019 ( 0.7842) Learning Rate: 0.1000 (0.1000) Top1_base: 75.7812 (77.7633) Top1_base_per_class: 70.4537 (78.2193) 
Training Epoch: [99/1000] Step: [280 / 285] Batch Time: 0.1481 (0.1562) Data Time: 0.0137 (0.0224) Average Loss: 0.8358 (0.7853) Average CE Loss (Source):  0.8358 ( 0.7853) Learning Rate: 0.1000 (0.1000) Top1_base: 72.6562 (77.7065) Top1_base_per_class: 76.7262 (78.1800) 
Training Epoch: [100/1000] Step: [0] Batch Time: 0.1467 (0.1560) Data Time: 0.0096 (0.0223) Average Loss: 0.8796 (0.7863) Average CE Loss (Source):  0.8796 ( 0.7863) Learning Rate: 0.1000 (0.1000) Top1_base: 72.6562 (77.6453) Top1_base_per_class: 71.2268 (78.1348) 
 10%|█         | 100/1000 [1:18:17<11:35:31, 46.37s/it] 10%|█         | 101/1000 [1:19:02<11:27:39, 45.89s/it]Training Epoch: [100/1000] Step: [10 / 285] Batch Time: 0.1456 (0.2552) Data Time: 0.0108 (0.1216) Average Loss: 0.8425 (0.7411) Average CE Loss (Source):  0.8425 ( 0.7411) Learning Rate: 0.1000 (0.1000) Top1_base: 78.1250 (79.2188) Top1_base_per_class: 79.3860 (80.1120) 
Training Epoch: [100/1000] Step: [20 / 285] Batch Time: 0.1469 (0.2043) Data Time: 0.0158 (0.0708) Average Loss: 0.6188 (0.7366) Average CE Loss (Source):  0.6188 ( 0.7366) Learning Rate: 0.1000 (0.1000) Top1_base: 84.3750 (79.2969) Top1_base_per_class: 83.3626 (80.2905) 
Training Epoch: [100/1000] Step: [30 / 285] Batch Time: 0.1442 (0.1882) Data Time: 0.0129 (0.0550) Average Loss: 0.8186 (0.7487) Average CE Loss (Source):  0.8186 ( 0.7487) Learning Rate: 0.1000 (0.1000) Top1_base: 77.3438 (79.2188) Top1_base_per_class: 78.6164 (80.3200) 
Training Epoch: [100/1000] Step: [40 / 285] Batch Time: 0.1495 (0.1794) Data Time: 0.0143 (0.0462) Average Loss: 0.8692 (0.7478) Average CE Loss (Source):  0.8692 ( 0.7478) Learning Rate: 0.1000 (0.1000) Top1_base: 78.9062 (79.2969) Top1_base_per_class: 83.1212 (80.2810) 
Training Epoch: [100/1000] Step: [50 / 285] Batch Time: 0.1491 (0.1752) Data Time: 0.0113 (0.0414) Average Loss: 0.6903 (0.7350) Average CE Loss (Source):  0.6903 ( 0.7350) Learning Rate: 0.1000 (0.1000) Top1_base: 78.1250 (79.5312) Top1_base_per_class: 82.8274 (80.2216) 
Training Epoch: [100/1000] Step: [60 / 285] Batch Time: 0.1461 (0.1703) Data Time: 0.0126 (0.0367) Average Loss: 1.0830 (0.7577) Average CE Loss (Source):  1.0830 ( 0.7577) Learning Rate: 0.1000 (0.1000) Top1_base: 68.7500 (78.9844) Top1_base_per_class: 70.8046 (79.7798) 
Training Epoch: [100/1000] Step: [70 / 285] Batch Time: 0.1490 (0.1678) Data Time: 0.0137 (0.0343) Average Loss: 1.0338 (0.7569) Average CE Loss (Source):  1.0338 ( 0.7569) Learning Rate: 0.1000 (0.1000) Top1_base: 74.2188 (78.9509) Top1_base_per_class: 73.5057 (79.7750) 
Training Epoch: [100/1000] Step: [80 / 285] Batch Time: 0.1486 (0.1651) Data Time: 0.0140 (0.0316) Average Loss: 0.6385 (0.7573) Average CE Loss (Source):  0.6385 ( 0.7573) Learning Rate: 0.1000 (0.1000) Top1_base: 84.3750 (78.9844) Top1_base_per_class: 84.0113 (79.7853) 
Training Epoch: [100/1000] Step: [90 / 285] Batch Time: 0.1514 (0.1648) Data Time: 0.0143 (0.0312) Average Loss: 0.7949 (0.7517) Average CE Loss (Source):  0.7949 ( 0.7517) Learning Rate: 0.1000 (0.1000) Top1_base: 76.5625 (79.1406) Top1_base_per_class: 76.0303 (79.9470) 
Training Epoch: [100/1000] Step: [100 / 285] Batch Time: 0.1421 (0.1628) Data Time: 0.0108 (0.0294) Average Loss: 0.8309 (0.7562) Average CE Loss (Source):  0.8309 ( 0.7562) Learning Rate: 0.1000 (0.1000) Top1_base: 78.9062 (79.0000) Top1_base_per_class: 81.6364 (79.8468) 
Training Epoch: [100/1000] Step: [110 / 285] Batch Time: 0.1464 (0.1614) Data Time: 0.0156 (0.0280) Average Loss: 0.7508 (0.7570) Average CE Loss (Source):  0.7508 ( 0.7570) Learning Rate: 0.1000 (0.1000) Top1_base: 82.0312 (78.9773) Top1_base_per_class: 79.7619 (79.7264) 
Training Epoch: [100/1000] Step: [120 / 285] Batch Time: 0.1438 (0.1602) Data Time: 0.0129 (0.0269) Average Loss: 0.6805 (0.7652) Average CE Loss (Source):  0.6805 ( 0.7652) Learning Rate: 0.1000 (0.1000) Top1_base: 80.4688 (78.8542) Top1_base_per_class: 80.5556 (79.5339) 
Training Epoch: [100/1000] Step: [130 / 285] Batch Time: 0.1965 (0.1599) Data Time: 0.0634 (0.0266) Average Loss: 0.8462 (0.7712) Average CE Loss (Source):  0.8462 ( 0.7712) Learning Rate: 0.1000 (0.1000) Top1_base: 75.7812 (78.6478) Top1_base_per_class: 73.3660 (79.3247) 
Training Epoch: [100/1000] Step: [140 / 285] Batch Time: 0.1461 (0.1601) Data Time: 0.0139 (0.0268) Average Loss: 0.9145 (0.7757) Average CE Loss (Source):  0.9145 ( 0.7757) Learning Rate: 0.1000 (0.1000) Top1_base: 74.2188 (78.4654) Top1_base_per_class: 73.8889 (79.1323) 
Training Epoch: [100/1000] Step: [150 / 285] Batch Time: 0.1486 (0.1591) Data Time: 0.0139 (0.0259) Average Loss: 0.7835 (0.7743) Average CE Loss (Source):  0.7835 ( 0.7743) Learning Rate: 0.1000 (0.1000) Top1_base: 74.2188 (78.5156) Top1_base_per_class: 76.5230 (79.2006) 
Training Epoch: [100/1000] Step: [160 / 285] Batch Time: 0.1420 (0.1585) Data Time: 0.0110 (0.0253) Average Loss: 1.0025 (0.7763) Average CE Loss (Source):  1.0025 ( 0.7763) Learning Rate: 0.1000 (0.1000) Top1_base: 74.2188 (78.4521) Top1_base_per_class: 76.8615 (79.1045) 
Training Epoch: [100/1000] Step: [170 / 285] Batch Time: 0.1981 (0.1583) Data Time: 0.0629 (0.0251) Average Loss: 0.6724 (0.7809) Average CE Loss (Source):  0.6724 ( 0.7809) Learning Rate: 0.1000 (0.1000) Top1_base: 78.9062 (78.3226) Top1_base_per_class: 78.9474 (79.0077) 
Training Epoch: [100/1000] Step: [180 / 285] Batch Time: 0.1451 (0.1577) Data Time: 0.0132 (0.0245) Average Loss: 0.7345 (0.7822) Average CE Loss (Source):  0.7345 ( 0.7822) Learning Rate: 0.1000 (0.1000) Top1_base: 79.6875 (78.3073) Top1_base_per_class: 82.1212 (78.9875) 
Training Epoch: [100/1000] Step: [190 / 285] Batch Time: 0.2001 (0.1577) Data Time: 0.0694 (0.0246) Average Loss: 0.6801 (0.7826) Average CE Loss (Source):  0.6801 ( 0.7826) Learning Rate: 0.1000 (0.1000) Top1_base: 82.8125 (78.3183) Top1_base_per_class: 88.1633 (78.9626) 
Training Epoch: [100/1000] Step: [200 / 285] Batch Time: 0.1460 (0.1571) Data Time: 0.0129 (0.0241) Average Loss: 0.8336 (0.7816) Average CE Loss (Source):  0.8336 ( 0.7816) Learning Rate: 0.1000 (0.1000) Top1_base: 78.1250 (78.3242) Top1_base_per_class: 74.2308 (78.8841) 
Training Epoch: [100/1000] Step: [210 / 285] Batch Time: 0.1432 (0.1571) Data Time: 0.0128 (0.0241) Average Loss: 0.7720 (0.7818) Average CE Loss (Source):  0.7720 ( 0.7818) Learning Rate: 0.1000 (0.1000) Top1_base: 80.4688 (78.4226) Top1_base_per_class: 80.3801 (78.9709) 
Training Epoch: [100/1000] Step: [220 / 285] Batch Time: 0.1466 (0.1570) Data Time: 0.0139 (0.0241) Average Loss: 0.7806 (0.7850) Average CE Loss (Source):  0.7806 ( 0.7850) Learning Rate: 0.1000 (0.1000) Top1_base: 78.9062 (78.3452) Top1_base_per_class: 83.2372 (78.9204) 
Training Epoch: [100/1000] Step: [230 / 285] Batch Time: 0.1514 (0.1570) Data Time: 0.0176 (0.0241) Average Loss: 0.7197 (0.7882) Average CE Loss (Source):  0.7197 ( 0.7882) Learning Rate: 0.1000 (0.1000) Top1_base: 76.5625 (78.2303) Top1_base_per_class: 78.1515 (78.8196) 
Training Epoch: [100/1000] Step: [240 / 285] Batch Time: 0.1423 (0.1569) Data Time: 0.0106 (0.0241) Average Loss: 0.8467 (0.7885) Average CE Loss (Source):  0.8467 ( 0.7885) Learning Rate: 0.1000 (0.1000) Top1_base: 78.9062 (78.1934) Top1_base_per_class: 75.7667 (78.7298) 
Training Epoch: [100/1000] Step: [250 / 285] Batch Time: 0.1439 (0.1573) Data Time: 0.0131 (0.0245) Average Loss: 0.8450 (0.7889) Average CE Loss (Source):  0.8450 ( 0.7889) Learning Rate: 0.1000 (0.1000) Top1_base: 74.2188 (78.1813) Top1_base_per_class: 77.4242 (78.7251) 
Training Epoch: [100/1000] Step: [260 / 285] Batch Time: 0.1455 (0.1569) Data Time: 0.0117 (0.0241) Average Loss: 0.8021 (0.7920) Average CE Loss (Source):  0.8021 ( 0.7920) Learning Rate: 0.1000 (0.1000) Top1_base: 78.9062 (78.1160) Top1_base_per_class: 80.2299 (78.6855) 
Training Epoch: [100/1000] Step: [270 / 285] Batch Time: 0.1802 (0.1569) Data Time: 0.0450 (0.0241) Average Loss: 0.7711 (0.7923) Average CE Loss (Source):  0.7711 ( 0.7923) Learning Rate: 0.1000 (0.1000) Top1_base: 76.5625 (78.0903) Top1_base_per_class: 76.0819 (78.6870) 
Training Epoch: [100/1000] Step: [280 / 285] Batch Time: 0.1450 (0.1566) Data Time: 0.0132 (0.0238) Average Loss: 0.8168 (0.7951) Average CE Loss (Source):  0.8168 ( 0.7951) Learning Rate: 0.1000 (0.1000) Top1_base: 80.4688 (78.0329) Top1_base_per_class: 78.8983 (78.6319) 
Training Epoch: [101/1000] Step: [0] Batch Time: 0.2522 (0.1569) Data Time: 0.1228 (0.0242) Average Loss: 0.9456 (0.7960) Average CE Loss (Source):  0.9456 ( 0.7960) Learning Rate: 0.1000 (0.1000) Top1_base: 74.2188 (78.0044) Top1_base_per_class: 72.4143 (78.5953) 
Training Epoch: [101/1000] Step: [10 / 285] Batch Time: 0.1435 (0.2372) Data Time: 0.0107 (0.1047) Average Loss: 0.6310 (0.7138) Average CE Loss (Source):  0.6310 ( 0.7138) Learning Rate: 0.1000 (0.1000) Top1_base: 82.0312 (80.3125) Top1_base_per_class: 80.2874 (79.8723) 
Training Epoch: [101/1000] Step: [20 / 285] Batch Time: 0.1454 (0.1960) Data Time: 0.0107 (0.0635) Average Loss: 0.6714 (0.7151) Average CE Loss (Source):  0.6714 ( 0.7151) Learning Rate: 0.1000 (0.1000) Top1_base: 78.9062 (80.1953) Top1_base_per_class: 77.8182 (79.8367) 
Training Epoch: [101/1000] Step: [30 / 285] Batch Time: 0.1438 (0.1820) Data Time: 0.0121 (0.0496) Average Loss: 0.8144 (0.7562) Average CE Loss (Source):  0.8144 ( 0.7562) Learning Rate: 0.1000 (0.1000) Top1_base: 78.1250 (79.2448) Top1_base_per_class: 77.8195 (78.9151) 
Training Epoch: [101/1000] Step: [40 / 285] Batch Time: 0.1458 (0.1752) Data Time: 0.0118 (0.0427) Average Loss: 0.8983 (0.7505) Average CE Loss (Source):  0.8983 ( 0.7505) Learning Rate: 0.1000 (0.1000) Top1_base: 82.8125 (79.3750) Top1_base_per_class: 85.7547 (79.1119) 
Training Epoch: [101/1000] Step: [50 / 285] Batch Time: 0.1857 (0.1719) Data Time: 0.0548 (0.0394) Average Loss: 0.8032 (0.7576) Average CE Loss (Source):  0.8032 ( 0.7576) Learning Rate: 0.1000 (0.1000) Top1_base: 79.6875 (79.1250) Top1_base_per_class: 80.0000 (78.9660) 
Training Epoch: [101/1000] Step: [60 / 285] Batch Time: 0.1424 (0.1703) Data Time: 0.0124 (0.0380) Average Loss: 0.6746 (0.7534) Average CE Loss (Source):  0.6746 ( 0.7534) Learning Rate: 0.1000 (0.1000) Top1_base: 79.6875 (79.1146) Top1_base_per_class: 80.4938 (79.0638) 
Training Epoch: [101/1000] Step: [70 / 285] Batch Time: 0.2225 (0.1703) Data Time: 0.0901 (0.0380) Average Loss: 0.8559 (0.7607) Average CE Loss (Source):  0.8559 ( 0.7607) Learning Rate: 0.1000 (0.1000) Top1_base: 75.7812 (78.8058) Top1_base_per_class: 74.4253 (78.9489) 
Training Epoch: [101/1000] Step: [80 / 285] Batch Time: 0.1456 (0.1683) Data Time: 0.0113 (0.0358) Average Loss: 0.8214 (0.7673) Average CE Loss (Source):  0.8214 ( 0.7673) Learning Rate: 0.1000 (0.1000) Top1_base: 78.1250 (78.6523) Top1_base_per_class: 76.4197 (78.7885) 
Training Epoch: [101/1000] Step: [90 / 285] Batch Time: 0.2537 (0.1673) Data Time: 0.1225 (0.0348) Average Loss: 0.6833 (0.7705) Average CE Loss (Source):  0.6833 ( 0.7705) Learning Rate: 0.1000 (0.1000) Top1_base: 79.6875 (78.5417) Top1_base_per_class: 78.8485 (78.7484) 
Training Epoch: [101/1000] Step: [100 / 285] Batch Time: 0.1459 (0.1659) Data Time: 0.0120 (0.0335) Average Loss: 0.7149 (0.7663) Average CE Loss (Source):  0.7149 ( 0.7663) Learning Rate: 0.1000 (0.1000) Top1_base: 76.5625 (78.5547) Top1_base_per_class: 73.2441 (78.7636) 
Training Epoch: [101/1000] Step: [110 / 285] Batch Time: 0.1595 (0.1656) Data Time: 0.0273 (0.0332) Average Loss: 0.8121 (0.7697) Average CE Loss (Source):  0.8121 ( 0.7697) Learning Rate: 0.1000 (0.1000) Top1_base: 78.9062 (78.5298) Top1_base_per_class: 80.6790 (78.7577) 
Training Epoch: [101/1000] Step: [120 / 285] Batch Time: 0.1466 (0.1642) Data Time: 0.0106 (0.0318) Average Loss: 0.5990 (0.7712) Average CE Loss (Source):  0.5990 ( 0.7712) Learning Rate: 0.1000 (0.1000) Top1_base: 82.0312 (78.5482) Top1_base_per_class: 83.4503 (78.8445) 
Training Epoch: [101/1000] Step: [130 / 285] Batch Time: 0.1766 (0.1632) Data Time: 0.0449 (0.0308) Average Loss: 0.7839 (0.7757) Average CE Loss (Source):  0.7839 ( 0.7757) Learning Rate: 0.1000 (0.1000) Top1_base: 79.6875 (78.4796) Top1_base_per_class: 79.8765 (78.7674) 
Training Epoch: [101/1000] Step: [140 / 285] Batch Time: 0.1430 (0.1625) Data Time: 0.0103 (0.0301) Average Loss: 0.8078 (0.7766) Average CE Loss (Source):  0.8078 ( 0.7766) Learning Rate: 0.1000 (0.1000) Top1_base: 78.1250 (78.4263) Top1_base_per_class: 76.9351 (78.6851) 
Training Epoch: [101/1000] Step: [150 / 285] Batch Time: 0.1556 (0.1620) Data Time: 0.0247 (0.0296) Average Loss: 0.7091 (0.7748) Average CE Loss (Source):  0.7091 ( 0.7748) Learning Rate: 0.1000 (0.1000) Top1_base: 80.4688 (78.4323) Top1_base_per_class: 81.0714 (78.7215) 
Training Epoch: [101/1000] Step: [160 / 285] Batch Time: 0.1447 (0.1622) Data Time: 0.0115 (0.0297) Average Loss: 0.7600 (0.7739) Average CE Loss (Source):  0.7600 ( 0.7739) Learning Rate: 0.1000 (0.1000) Top1_base: 75.7812 (78.4082) Top1_base_per_class: 77.6608 (78.7107) 
Training Epoch: [101/1000] Step: [170 / 285] Batch Time: 0.2151 (0.1620) Data Time: 0.0836 (0.0296) Average Loss: 0.7938 (0.7770) Average CE Loss (Source):  0.7938 ( 0.7770) Learning Rate: 0.1000 (0.1000) Top1_base: 78.9062 (78.3410) Top1_base_per_class: 80.9604 (78.7362) 
Training Epoch: [101/1000] Step: [180 / 285] Batch Time: 0.1455 (0.1615) Data Time: 0.0104 (0.0290) Average Loss: 0.6085 (0.7737) Average CE Loss (Source):  0.6085 ( 0.7737) Learning Rate: 0.1000 (0.1000) Top1_base: 81.2500 (78.4418) Top1_base_per_class: 82.0468 (78.8481) 
Training Epoch: [101/1000] Step: [190 / 285] Batch Time: 0.2140 (0.1616) Data Time: 0.0820 (0.0291) Average Loss: 0.7713 (0.7709) Average CE Loss (Source):  0.7713 ( 0.7709) Learning Rate: 0.1000 (0.1000) Top1_base: 77.3438 (78.4786) Top1_base_per_class: 80.8974 (78.9034) 
Training Epoch: [101/1000] Step: [200 / 285] Batch Time: 0.1454 (0.1614) Data Time: 0.0105 (0.0290) Average Loss: 0.7948 (0.7712) Average CE Loss (Source):  0.7948 ( 0.7712) Learning Rate: 0.1000 (0.1000) Top1_base: 77.3438 (78.4453) Top1_base_per_class: 74.0497 (78.8178) 
Training Epoch: [101/1000] Step: [210 / 285] Batch Time: 0.2068 (0.1618) Data Time: 0.0749 (0.0293) Average Loss: 0.7461 (0.7717) Average CE Loss (Source):  0.7461 ( 0.7717) Learning Rate: 0.1000 (0.1000) Top1_base: 80.4688 (78.4784) Top1_base_per_class: 79.8663 (78.8727) 
Training Epoch: [101/1000] Step: [220 / 285] Batch Time: 0.1436 (0.1615) Data Time: 0.0102 (0.0290) Average Loss: 0.6024 (0.7715) Average CE Loss (Source):  0.6024 ( 0.7715) Learning Rate: 0.1000 (0.1000) Top1_base: 84.3750 (78.5334) Top1_base_per_class: 84.3791 (78.9540) 
Training Epoch: [101/1000] Step: [230 / 285] Batch Time: 0.2847 (0.1615) Data Time: 0.1524 (0.0290) Average Loss: 0.8814 (0.7719) Average CE Loss (Source):  0.8814 ( 0.7719) Learning Rate: 0.1000 (0.1000) Top1_base: 76.5625 (78.5156) Top1_base_per_class: 79.9708 (78.9424) 
Training Epoch: [101/1000] Step: [240 / 285] Batch Time: 0.1430 (0.1615) Data Time: 0.0120 (0.0291) Average Loss: 0.7835 (0.7734) Average CE Loss (Source):  0.7835 ( 0.7734) Learning Rate: 0.1000 (0.1000) Top1_base: 75.0000 (78.4505) Top1_base_per_class: 78.8580 (78.9256) 
Training Epoch: [101/1000] Step: [250 / 285] Batch Time: 0.1614 (0.1612) Data Time: 0.0287 (0.0288) Average Loss: 0.8778 (0.7747) Average CE Loss (Source):  0.8778 ( 0.7747) Learning Rate: 0.1000 (0.1000) Top1_base: 71.8750 (78.4281) Top1_base_per_class: 69.8788 (78.8720) 
Training Epoch: [101/1000] Step: [260 / 285] Batch Time: 0.1453 (0.1607) Data Time: 0.0108 (0.0284) Average Loss: 0.8773 (0.7778) Average CE Loss (Source):  0.8773 ( 0.7778) Learning Rate: 0.1000 (0.1000) Top1_base: 78.9062 (78.3654) Top1_base_per_class: 80.8605 (78.8361) 
Training Epoch: [101/1000] Step: [270 / 285] Batch Time: 0.1635 (0.1604) Data Time: 0.0305 (0.0280) Average Loss: 1.1494 (0.7807) Average CE Loss (Source):  1.1494 ( 0.7807) Learning Rate: 0.1000 (0.1000) Top1_base: 68.7500 (78.2263) Top1_base_per_class: 60.1190 (78.6606) 
Training Epoch: [101/1000] Step: [280 / 285] Batch Time: 0.1416 (0.1605) Data Time: 0.0115 (0.0282) Average Loss: 0.8303 (0.7824) Average CE Loss (Source):  0.8303 ( 0.7824) Learning Rate: 0.1000 (0.1000) Top1_base: 75.7812 (78.1445) Top1_base_per_class: 80.1587 (78.5356) 
Training Epoch: [102/1000] Step: [0] Batch Time: 0.1370 (0.1603) Data Time: 0.0094 (0.0280) Average Loss: 1.0103 (0.7828) Average CE Loss (Source):  1.0103 ( 0.7828) Learning Rate: 0.1000 (0.1000) Top1_base: 71.8750 (78.1223) Top1_base_per_class: 71.5432 (78.5007) 
 10%|█         | 102/1000 [1:19:50<11:38:34, 46.68s/it] 10%|█         | 103/1000 [1:20:35<11:27:56, 46.02s/it]Training Epoch: [102/1000] Step: [10 / 285] Batch Time: 0.1447 (0.2246) Data Time: 0.0134 (0.0920) Average Loss: 0.7633 (0.8294) Average CE Loss (Source):  0.7633 ( 0.8294) Learning Rate: 0.1000 (0.1000) Top1_base: 80.4688 (77.0312) Top1_base_per_class: 77.0909 (77.5053) 
Training Epoch: [102/1000] Step: [20 / 285] Batch Time: 0.1464 (0.1895) Data Time: 0.0102 (0.0565) Average Loss: 0.7221 (0.7912) Average CE Loss (Source):  0.7221 ( 0.7912) Learning Rate: 0.1000 (0.1000) Top1_base: 80.4688 (78.2812) Top1_base_per_class: 80.2424 (79.0639) 
Training Epoch: [102/1000] Step: [30 / 285] Batch Time: 0.1456 (0.1856) Data Time: 0.0102 (0.0523) Average Loss: 0.7794 (0.7851) Average CE Loss (Source):  0.7794 ( 0.7851) Learning Rate: 0.1000 (0.1000) Top1_base: 78.1250 (77.9688) Top1_base_per_class: 80.9277 (79.0641) 
Training Epoch: [102/1000] Step: [40 / 285] Batch Time: 0.1452 (0.1759) Data Time: 0.0120 (0.0426) Average Loss: 0.7435 (0.7874) Average CE Loss (Source):  0.7435 ( 0.7874) Learning Rate: 0.1000 (0.1000) Top1_base: 80.4688 (78.1055) Top1_base_per_class: 80.7099 (79.0515) 
Training Epoch: [102/1000] Step: [50 / 285] Batch Time: 0.1445 (0.1712) Data Time: 0.0123 (0.0378) Average Loss: 0.6246 (0.7781) Average CE Loss (Source):  0.6246 ( 0.7781) Learning Rate: 0.1000 (0.1000) Top1_base: 82.8125 (78.3594) Top1_base_per_class: 84.4199 (79.1884) 
Training Epoch: [102/1000] Step: [60 / 285] Batch Time: 0.1511 (0.1680) Data Time: 0.0149 (0.0345) Average Loss: 0.8010 (0.7789) Average CE Loss (Source):  0.8010 ( 0.7789) Learning Rate: 0.1000 (0.1000) Top1_base: 78.9062 (78.3203) Top1_base_per_class: 80.6034 (79.1142) 
Training Epoch: [102/1000] Step: [70 / 285] Batch Time: 0.1425 (0.1662) Data Time: 0.0113 (0.0328) Average Loss: 0.7077 (0.7777) Average CE Loss (Source):  0.7077 ( 0.7777) Learning Rate: 0.1000 (0.1000) Top1_base: 78.1250 (78.0804) Top1_base_per_class: 78.1305 (78.9250) 
Training Epoch: [102/1000] Step: [80 / 285] Batch Time: 0.1535 (0.1639) Data Time: 0.0138 (0.0304) Average Loss: 0.9394 (0.7699) Average CE Loss (Source):  0.9394 ( 0.7699) Learning Rate: 0.1000 (0.1000) Top1_base: 72.6562 (78.2227) Top1_base_per_class: 71.0606 (79.0720) 
Training Epoch: [102/1000] Step: [90 / 285] Batch Time: 0.1452 (0.1621) Data Time: 0.0136 (0.0286) Average Loss: 0.9009 (0.7714) Average CE Loss (Source):  0.9009 ( 0.7714) Learning Rate: 0.1000 (0.1000) Top1_base: 75.7812 (78.1684) Top1_base_per_class: 74.1228 (78.8786) 
Training Epoch: [102/1000] Step: [100 / 285] Batch Time: 0.1486 (0.1607) Data Time: 0.0120 (0.0271) Average Loss: 0.9850 (0.7745) Average CE Loss (Source):  0.9850 ( 0.7745) Learning Rate: 0.1000 (0.1000) Top1_base: 75.0000 (78.0703) Top1_base_per_class: 75.2241 (78.7116) 
Training Epoch: [102/1000] Step: [110 / 285] Batch Time: 0.1493 (0.1600) Data Time: 0.0119 (0.0262) Average Loss: 0.6991 (0.7748) Average CE Loss (Source):  0.6991 ( 0.7748) Learning Rate: 0.1000 (0.1000) Top1_base: 77.3438 (78.0256) Top1_base_per_class: 81.1515 (78.7065) 
Training Epoch: [102/1000] Step: [120 / 285] Batch Time: 0.1489 (0.1600) Data Time: 0.0119 (0.0259) Average Loss: 0.8085 (0.7799) Average CE Loss (Source):  0.8085 ( 0.7799) Learning Rate: 0.1000 (0.1000) Top1_base: 75.7812 (77.8646) Top1_base_per_class: 77.2424 (78.5682) 
Training Epoch: [102/1000] Step: [130 / 285] Batch Time: 0.1446 (0.1606) Data Time: 0.0136 (0.0265) Average Loss: 0.7654 (0.7832) Average CE Loss (Source):  0.7654 ( 0.7832) Learning Rate: 0.1000 (0.1000) Top1_base: 77.3438 (77.9026) Top1_base_per_class: 79.5988 (78.6209) 
Training Epoch: [102/1000] Step: [140 / 285] Batch Time: 0.1440 (0.1597) Data Time: 0.0121 (0.0257) Average Loss: 0.8704 (0.7813) Average CE Loss (Source):  0.8704 ( 0.7813) Learning Rate: 0.1000 (0.1000) Top1_base: 75.0000 (78.0301) Top1_base_per_class: 74.0079 (78.7360) 
Training Epoch: [102/1000] Step: [150 / 285] Batch Time: 0.1478 (0.1592) Data Time: 0.0153 (0.0253) Average Loss: 0.7431 (0.7795) Average CE Loss (Source):  0.7431 ( 0.7795) Learning Rate: 0.1000 (0.1000) Top1_base: 77.3438 (78.1302) Top1_base_per_class: 75.9649 (78.7808) 
Training Epoch: [102/1000] Step: [160 / 285] Batch Time: 0.1466 (0.1586) Data Time: 0.0111 (0.0247) Average Loss: 0.7253 (0.7798) Average CE Loss (Source):  0.7253 ( 0.7798) Learning Rate: 0.1000 (0.1000) Top1_base: 81.2500 (78.1396) Top1_base_per_class: 84.8709 (78.7784) 
Training Epoch: [102/1000] Step: [170 / 285] Batch Time: 0.1493 (0.1583) Data Time: 0.0128 (0.0245) Average Loss: 0.6954 (0.7783) Average CE Loss (Source):  0.6954 ( 0.7783) Learning Rate: 0.1000 (0.1000) Top1_base: 77.3438 (78.2169) Top1_base_per_class: 79.2687 (78.8303) 
Training Epoch: [102/1000] Step: [180 / 285] Batch Time: 0.1461 (0.1585) Data Time: 0.0116 (0.0247) Average Loss: 0.7747 (0.7798) Average CE Loss (Source):  0.7747 ( 0.7798) Learning Rate: 0.1000 (0.1000) Top1_base: 76.5625 (78.1510) Top1_base_per_class: 72.7883 (78.7238) 
Training Epoch: [102/1000] Step: [190 / 285] Batch Time: 0.1423 (0.1583) Data Time: 0.0117 (0.0245) Average Loss: 0.9496 (0.7818) Average CE Loss (Source):  0.9496 ( 0.7818) Learning Rate: 0.1000 (0.1000) Top1_base: 71.8750 (78.0633) Top1_base_per_class: 77.5309 (78.6538) 
Training Epoch: [102/1000] Step: [200 / 285] Batch Time: 0.1450 (0.1583) Data Time: 0.0120 (0.0246) Average Loss: 0.8103 (0.7813) Average CE Loss (Source):  0.8103 ( 0.7813) Learning Rate: 0.1000 (0.1000) Top1_base: 75.7812 (78.0195) Top1_base_per_class: 78.8588 (78.5569) 
Training Epoch: [102/1000] Step: [210 / 285] Batch Time: 0.1462 (0.1580) Data Time: 0.0116 (0.0242) Average Loss: 0.8010 (0.7830) Average CE Loss (Source):  0.8010 ( 0.7830) Learning Rate: 0.1000 (0.1000) Top1_base: 77.3438 (77.9539) Top1_base_per_class: 79.0448 (78.5169) 
Training Epoch: [102/1000] Step: [220 / 285] Batch Time: 0.1460 (0.1576) Data Time: 0.0117 (0.0238) Average Loss: 0.8007 (0.7871) Average CE Loss (Source):  0.8007 ( 0.7871) Learning Rate: 0.1000 (0.1000) Top1_base: 76.5625 (77.8906) Top1_base_per_class: 78.2738 (78.4449) 
Training Epoch: [102/1000] Step: [230 / 285] Batch Time: 0.1461 (0.1574) Data Time: 0.0108 (0.0237) Average Loss: 0.8011 (0.7883) Average CE Loss (Source):  0.8011 ( 0.7883) Learning Rate: 0.1000 (0.1000) Top1_base: 78.1250 (77.8295) Top1_base_per_class: 75.6548 (78.3297) 
Training Epoch: [102/1000] Step: [240 / 285] Batch Time: 0.1447 (0.1569) Data Time: 0.0105 (0.0232) Average Loss: 0.4349 (0.7851) Average CE Loss (Source):  0.4349 ( 0.7851) Learning Rate: 0.1000 (0.1000) Top1_base: 89.0625 (77.9167) Top1_base_per_class: 88.4242 (78.4222) 
Training Epoch: [102/1000] Step: [250 / 285] Batch Time: 0.1482 (0.1565) Data Time: 0.0136 (0.0229) Average Loss: 1.0353 (0.7876) Average CE Loss (Source):  1.0353 ( 0.7876) Learning Rate: 0.1000 (0.1000) Top1_base: 74.2188 (77.8937) Top1_base_per_class: 76.3611 (78.4443) 
Training Epoch: [102/1000] Step: [260 / 285] Batch Time: 0.1472 (0.1564) Data Time: 0.0106 (0.0228) Average Loss: 0.7303 (0.7903) Average CE Loss (Source):  0.7303 ( 0.7903) Learning Rate: 0.1000 (0.1000) Top1_base: 80.4688 (77.8245) Top1_base_per_class: 76.9089 (78.3425) 
Training Epoch: [102/1000] Step: [270 / 285] Batch Time: 0.1443 (0.1563) Data Time: 0.0139 (0.0226) Average Loss: 0.8704 (0.7923) Average CE Loss (Source):  0.8704 ( 0.7923) Learning Rate: 0.1000 (0.1000) Top1_base: 82.0312 (77.7807) Top1_base_per_class: 85.4545 (78.3007) 
Training Epoch: [102/1000] Step: [280 / 285] Batch Time: 0.1459 (0.1560) Data Time: 0.0136 (0.0223) Average Loss: 0.9971 (0.7935) Average CE Loss (Source):  0.9971 ( 0.7935) Learning Rate: 0.1000 (0.1000) Top1_base: 68.7500 (77.7427) Top1_base_per_class: 75.8908 (78.2676) 
Training Epoch: [103/1000] Step: [0] Batch Time: 0.1429 (0.1558) Data Time: 0.0106 (0.0222) Average Loss: 0.7556 (0.7939) Average CE Loss (Source):  0.7556 ( 0.7939) Learning Rate: 0.1000 (0.1000) Top1_base: 75.7812 (77.7330) Top1_base_per_class: 80.0606 (78.2832) 
Training Epoch: [103/1000] Step: [10 / 285] Batch Time: 0.1444 (0.2337) Data Time: 0.0106 (0.1006) Average Loss: 0.6631 (0.7961) Average CE Loss (Source):  0.6631 ( 0.7961) Learning Rate: 0.1000 (0.1000) Top1_base: 83.5938 (77.9688) Top1_base_per_class: 88.3766 (78.5096) 
Training Epoch: [103/1000] Step: [20 / 285] Batch Time: 0.1455 (0.1965) Data Time: 0.0131 (0.0633) Average Loss: 0.6320 (0.7561) Average CE Loss (Source):  0.6320 ( 0.7561) Learning Rate: 0.1000 (0.1000) Top1_base: 85.9375 (78.8672) Top1_base_per_class: 88.8272 (79.4519) 
Training Epoch: [103/1000] Step: [30 / 285] Batch Time: 0.1442 (0.1844) Data Time: 0.0103 (0.0511) Average Loss: 0.9504 (0.7677) Average CE Loss (Source):  0.9504 ( 0.7677) Learning Rate: 0.1000 (0.1000) Top1_base: 75.7812 (78.7500) Top1_base_per_class: 77.5247 (79.7780) 
Training Epoch: [103/1000] Step: [40 / 285] Batch Time: 0.1450 (0.1794) Data Time: 0.0132 (0.0461) Average Loss: 0.7303 (0.7624) Average CE Loss (Source):  0.7303 ( 0.7624) Learning Rate: 0.1000 (0.1000) Top1_base: 75.7812 (78.3594) Top1_base_per_class: 78.1948 (79.4581) 
Training Epoch: [103/1000] Step: [50 / 285] Batch Time: 0.1457 (0.1743) Data Time: 0.0107 (0.0410) Average Loss: 0.9053 (0.7695) Average CE Loss (Source):  0.9053 ( 0.7695) Learning Rate: 0.1000 (0.1000) Top1_base: 78.1250 (77.9688) Top1_base_per_class: 82.1698 (78.8329) 
Training Epoch: [103/1000] Step: [60 / 285] Batch Time: 0.1440 (0.1708) Data Time: 0.0121 (0.0375) Average Loss: 0.8680 (0.7796) Average CE Loss (Source):  0.8680 ( 0.7796) Learning Rate: 0.1000 (0.1000) Top1_base: 74.2188 (77.6953) Top1_base_per_class: 71.3393 (78.6099) 
Training Epoch: [103/1000] Step: [70 / 285] Batch Time: 0.1457 (0.1684) Data Time: 0.0116 (0.0350) Average Loss: 0.7675 (0.7746) Average CE Loss (Source):  0.7675 ( 0.7746) Learning Rate: 0.1000 (0.1000) Top1_base: 75.0000 (77.7455) Top1_base_per_class: 75.5263 (78.4570) 
Training Epoch: [103/1000] Step: [80 / 285] Batch Time: 0.1442 (0.1659) Data Time: 0.0119 (0.0326) Average Loss: 0.8340 (0.7748) Average CE Loss (Source):  0.8340 ( 0.7748) Learning Rate: 0.1000 (0.1000) Top1_base: 73.4375 (77.7344) Top1_base_per_class: 71.6049 (78.3632) 
Training Epoch: [103/1000] Step: [90 / 285] Batch Time: 0.1446 (0.1647) Data Time: 0.0104 (0.0315) Average Loss: 0.6164 (0.7824) Average CE Loss (Source):  0.6164 ( 0.7824) Learning Rate: 0.1000 (0.1000) Top1_base: 81.2500 (77.5694) Top1_base_per_class: 81.1207 (78.2168) 
Training Epoch: [103/1000] Step: [100 / 285] Batch Time: 0.1455 (0.1633) Data Time: 0.0138 (0.0302) Average Loss: 0.8550 (0.7849) Average CE Loss (Source):  0.8550 ( 0.7849) Learning Rate: 0.1000 (0.1000) Top1_base: 77.3438 (77.6797) Top1_base_per_class: 78.9881 (78.2850) 
Training Epoch: [103/1000] Step: [110 / 285] Batch Time: 0.1432 (0.1626) Data Time: 0.0103 (0.0294) Average Loss: 0.7527 (0.7835) Average CE Loss (Source):  0.7527 ( 0.7835) Learning Rate: 0.1000 (0.1000) Top1_base: 79.6875 (77.8338) Top1_base_per_class: 81.4327 (78.4711) 
Training Epoch: [103/1000] Step: [120 / 285] Batch Time: 0.1437 (0.1611) Data Time: 0.0116 (0.0282) Average Loss: 0.8957 (0.7861) Average CE Loss (Source):  0.8957 ( 0.7861) Learning Rate: 0.1000 (0.1000) Top1_base: 73.4375 (77.7604) Top1_base_per_class: 72.3046 (78.3749) 
Training Epoch: [103/1000] Step: [130 / 285] Batch Time: 0.1457 (0.1602) Data Time: 0.0114 (0.0272) Average Loss: 0.6447 (0.7858) Average CE Loss (Source):  0.6447 ( 0.7858) Learning Rate: 0.1000 (0.1000) Top1_base: 82.0312 (77.7644) Top1_base_per_class: 84.1813 (78.3376) 
Training Epoch: [103/1000] Step: [140 / 285] Batch Time: 0.1473 (0.1596) Data Time: 0.0147 (0.0266) Average Loss: 0.8609 (0.7855) Average CE Loss (Source):  0.8609 ( 0.7855) Learning Rate: 0.1000 (0.1000) Top1_base: 77.3438 (77.8292) Top1_base_per_class: 79.2500 (78.3380) 
Training Epoch: [103/1000] Step: [150 / 285] Batch Time: 0.1473 (0.1592) Data Time: 0.0105 (0.0262) Average Loss: 0.8324 (0.7885) Average CE Loss (Source):  0.8324 ( 0.7885) Learning Rate: 0.1000 (0.1000) Top1_base: 79.6875 (77.8073) Top1_base_per_class: 81.1494 (78.3609) 
Training Epoch: [103/1000] Step: [160 / 285] Batch Time: 0.1479 (0.1591) Data Time: 0.0152 (0.0259) Average Loss: 0.6341 (0.7902) Average CE Loss (Source):  0.6341 ( 0.7902) Learning Rate: 0.1000 (0.1000) Top1_base: 82.0312 (77.8369) Top1_base_per_class: 79.1818 (78.3043) 
Training Epoch: [103/1000] Step: [170 / 285] Batch Time: 0.1426 (0.1583) Data Time: 0.0113 (0.0253) Average Loss: 0.8699 (0.7899) Average CE Loss (Source):  0.8699 ( 0.7899) Learning Rate: 0.1000 (0.1000) Top1_base: 75.0000 (77.8585) Top1_base_per_class: 76.8965 (78.3246) 
Training Epoch: [103/1000] Step: [180 / 285] Batch Time: 0.1473 (0.1577) Data Time: 0.0159 (0.0247) Average Loss: 0.9571 (0.7904) Average CE Loss (Source):  0.9571 ( 0.7904) Learning Rate: 0.1000 (0.1000) Top1_base: 75.0000 (77.9080) Top1_base_per_class: 78.9697 (78.3549) 
Training Epoch: [103/1000] Step: [190 / 285] Batch Time: 0.1441 (0.1572) Data Time: 0.0109 (0.0242) Average Loss: 0.7949 (0.7892) Average CE Loss (Source):  0.7949 ( 0.7892) Learning Rate: 0.1000 (0.1000) Top1_base: 75.0000 (77.9071) Top1_base_per_class: 76.8182 (78.3800) 
Training Epoch: [103/1000] Step: [200 / 285] Batch Time: 0.1485 (0.1567) Data Time: 0.0141 (0.0237) Average Loss: 0.7310 (0.7863) Average CE Loss (Source):  0.7310 ( 0.7863) Learning Rate: 0.1000 (0.1000) Top1_base: 79.6875 (78.0312) Top1_base_per_class: 77.2322 (78.4772) 
Training Epoch: [103/1000] Step: [210 / 285] Batch Time: 0.1471 (0.1566) Data Time: 0.0109 (0.0237) Average Loss: 0.6703 (0.7837) Average CE Loss (Source):  0.6703 ( 0.7837) Learning Rate: 0.1000 (0.1000) Top1_base: 79.6875 (78.0915) Top1_base_per_class: 77.6675 (78.5142) 
Training Epoch: [103/1000] Step: [220 / 285] Batch Time: 0.1502 (0.1569) Data Time: 0.0182 (0.0239) Average Loss: 0.6350 (0.7844) Average CE Loss (Source):  0.6350 ( 0.7844) Learning Rate: 0.1000 (0.1000) Top1_base: 79.6875 (78.0540) Top1_base_per_class: 79.6429 (78.4890) 
Training Epoch: [103/1000] Step: [230 / 285] Batch Time: 0.1429 (0.1568) Data Time: 0.0129 (0.0239) Average Loss: 0.9900 (0.7837) Average CE Loss (Source):  0.9900 ( 0.7837) Learning Rate: 0.1000 (0.1000) Top1_base: 75.0000 (78.1012) Top1_base_per_class: 76.4423 (78.5734) 
Training Epoch: [103/1000] Step: [240 / 285] Batch Time: 0.1507 (0.1566) Data Time: 0.0178 (0.0235) Average Loss: 0.7913 (0.7836) Average CE Loss (Source):  0.7913 ( 0.7836) Learning Rate: 0.1000 (0.1000) Top1_base: 78.1250 (78.0762) Top1_base_per_class: 77.8274 (78.5414) 
Training Epoch: [103/1000] Step: [250 / 285] Batch Time: 0.1427 (0.1561) Data Time: 0.0122 (0.0231) Average Loss: 0.7931 (0.7838) Average CE Loss (Source):  0.7931 ( 0.7838) Learning Rate: 0.1000 (0.1000) Top1_base: 81.2500 (78.0594) Top1_base_per_class: 77.6101 (78.5224) 
Training Epoch: [103/1000] Step: [260 / 285] Batch Time: 0.1511 (0.1560) Data Time: 0.0159 (0.0230) Average Loss: 0.8676 (0.7886) Average CE Loss (Source):  0.8676 ( 0.7886) Learning Rate: 0.1000 (0.1000) Top1_base: 74.2188 (77.9507) Top1_base_per_class: 73.9583 (78.3711) 
Training Epoch: [103/1000] Step: [270 / 285] Batch Time: 0.1469 (0.1558) Data Time: 0.0107 (0.0227) Average Loss: 0.8392 (0.7914) Average CE Loss (Source):  0.8392 ( 0.7914) Learning Rate: 0.1000 (0.1000) Top1_base: 76.5625 (77.8935) Top1_base_per_class: 77.4383 (78.3354) 
Training Epoch: [103/1000] Step: [280 / 285] Batch Time: 0.2898 (0.1562) Data Time: 0.1560 (0.0231) Average Loss: 0.7418 (0.7890) Average CE Loss (Source):  0.7418 ( 0.7890) Learning Rate: 0.1000 (0.1000) Top1_base: 80.4688 (77.9688) Top1_base_per_class: 80.6061 (78.3794) 
Training Epoch: [104/1000] Step: [0] Batch Time: 0.1442 (0.1560) Data Time: 0.0099 (0.0229) Average Loss: 0.9788 (0.7899) Average CE Loss (Source):  0.9788 ( 0.7899) Learning Rate: 0.1000 (0.1000) Top1_base: 71.8750 (77.9221) Top1_base_per_class: 70.6111 (78.3372) 
 10%|█         | 104/1000 [1:21:22<11:32:57, 46.40s/it] 10%|█         | 105/1000 [1:22:06<11:23:29, 45.82s/it]Training Epoch: [104/1000] Step: [10 / 285] Batch Time: 0.1400 (0.2287) Data Time: 0.0104 (0.0972) Average Loss: 0.6033 (0.7634) Average CE Loss (Source):  0.6033 ( 0.7634) Learning Rate: 0.1000 (0.1000) Top1_base: 78.1250 (78.5156) Top1_base_per_class: 80.3145 (80.1618) 
Training Epoch: [104/1000] Step: [20 / 285] Batch Time: 0.1460 (0.1925) Data Time: 0.0137 (0.0609) Average Loss: 0.7655 (0.7652) Average CE Loss (Source):  0.7655 ( 0.7652) Learning Rate: 0.1000 (0.1000) Top1_base: 81.2500 (79.1016) Top1_base_per_class: 85.5460 (80.4837) 
Training Epoch: [104/1000] Step: [30 / 285] Batch Time: 0.1481 (0.1848) Data Time: 0.0123 (0.0527) Average Loss: 0.7882 (0.7790) Average CE Loss (Source):  0.7882 ( 0.7790) Learning Rate: 0.1000 (0.1000) Top1_base: 77.3438 (78.2292) Top1_base_per_class: 78.6842 (79.8293) 
Training Epoch: [104/1000] Step: [40 / 285] Batch Time: 0.1430 (0.1767) Data Time: 0.0126 (0.0443) Average Loss: 0.9154 (0.7923) Average CE Loss (Source):  0.9154 ( 0.7923) Learning Rate: 0.1000 (0.1000) Top1_base: 75.7812 (78.0078) Top1_base_per_class: 75.7273 (79.2913) 
Training Epoch: [104/1000] Step: [50 / 285] Batch Time: 0.1445 (0.1731) Data Time: 0.0120 (0.0407) Average Loss: 0.6793 (0.7780) Average CE Loss (Source):  0.6793 ( 0.7780) Learning Rate: 0.1000 (0.1000) Top1_base: 78.9062 (78.1562) Top1_base_per_class: 81.4080 (79.1056) 
Training Epoch: [104/1000] Step: [60 / 285] Batch Time: 0.1441 (0.1703) Data Time: 0.0132 (0.0378) Average Loss: 0.7690 (0.7763) Average CE Loss (Source):  0.7690 ( 0.7763) Learning Rate: 0.1000 (0.1000) Top1_base: 80.4688 (78.3464) Top1_base_per_class: 84.0434 (79.1078) 
Training Epoch: [104/1000] Step: [70 / 285] Batch Time: 0.1440 (0.1679) Data Time: 0.0108 (0.0353) Average Loss: 0.8783 (0.7789) Average CE Loss (Source):  0.8783 ( 0.7789) Learning Rate: 0.1000 (0.1000) Top1_base: 74.2188 (78.3482) Top1_base_per_class: 74.9074 (79.0489) 
Training Epoch: [104/1000] Step: [80 / 285] Batch Time: 0.1443 (0.1654) Data Time: 0.0125 (0.0328) Average Loss: 0.8259 (0.7782) Average CE Loss (Source):  0.8259 ( 0.7782) Learning Rate: 0.1000 (0.1000) Top1_base: 74.2188 (78.3789) Top1_base_per_class: 72.8302 (79.1193) 
Training Epoch: [104/1000] Step: [90 / 285] Batch Time: 0.1427 (0.1635) Data Time: 0.0108 (0.0307) Average Loss: 0.7864 (0.7831) Average CE Loss (Source):  0.7864 ( 0.7831) Learning Rate: 0.1000 (0.1000) Top1_base: 75.7812 (78.2639) Top1_base_per_class: 74.4048 (79.0701) 
Training Epoch: [104/1000] Step: [100 / 285] Batch Time: 0.1469 (0.1622) Data Time: 0.0138 (0.0293) Average Loss: 0.7647 (0.7744) Average CE Loss (Source):  0.7647 ( 0.7744) Learning Rate: 0.1000 (0.1000) Top1_base: 78.1250 (78.4219) Top1_base_per_class: 77.9762 (79.1863) 
Training Epoch: [104/1000] Step: [110 / 285] Batch Time: 0.1465 (0.1619) Data Time: 0.0136 (0.0290) Average Loss: 0.5735 (0.7738) Average CE Loss (Source):  0.5735 ( 0.7738) Learning Rate: 0.1000 (0.1000) Top1_base: 82.8125 (78.3807) Top1_base_per_class: 84.3103 (79.1269) 
Training Epoch: [104/1000] Step: [120 / 285] Batch Time: 0.1482 (0.1608) Data Time: 0.0117 (0.0278) Average Loss: 0.6342 (0.7686) Average CE Loss (Source):  0.6342 ( 0.7686) Learning Rate: 0.1000 (0.1000) Top1_base: 79.6875 (78.5091) Top1_base_per_class: 81.7262 (79.2816) 
Training Epoch: [104/1000] Step: [130 / 285] Batch Time: 0.1440 (0.1610) Data Time: 0.0126 (0.0280) Average Loss: 0.6393 (0.7708) Average CE Loss (Source):  0.6393 ( 0.7708) Learning Rate: 0.1000 (0.1000) Top1_base: 81.2500 (78.3413) Top1_base_per_class: 82.9321 (79.1508) 
Training Epoch: [104/1000] Step: [140 / 285] Batch Time: 0.1450 (0.1613) Data Time: 0.0113 (0.0282) Average Loss: 0.8879 (0.7732) Average CE Loss (Source):  0.8879 ( 0.7732) Learning Rate: 0.1000 (0.1000) Top1_base: 77.3438 (78.2924) Top1_base_per_class: 78.2441 (79.0290) 
Training Epoch: [104/1000] Step: [150 / 285] Batch Time: 0.1469 (0.1603) Data Time: 0.0137 (0.0273) Average Loss: 0.7241 (0.7724) Average CE Loss (Source):  0.7241 ( 0.7724) Learning Rate: 0.1000 (0.1000) Top1_base: 85.1562 (78.2760) Top1_base_per_class: 86.7219 (78.9604) 
Training Epoch: [104/1000] Step: [160 / 285] Batch Time: 0.1430 (0.1596) Data Time: 0.0125 (0.0266) Average Loss: 0.5518 (0.7687) Average CE Loss (Source):  0.5518 ( 0.7687) Learning Rate: 0.1000 (0.1000) Top1_base: 82.0312 (78.2764) Top1_base_per_class: 83.2456 (78.9411) 
Training Epoch: [104/1000] Step: [170 / 285] Batch Time: 0.1469 (0.1590) Data Time: 0.0122 (0.0260) Average Loss: 0.8131 (0.7692) Average CE Loss (Source):  0.8131 ( 0.7692) Learning Rate: 0.1000 (0.1000) Top1_base: 79.6875 (78.2583) Top1_base_per_class: 80.6845 (78.8829) 
Training Epoch: [104/1000] Step: [180 / 285] Batch Time: 0.1452 (0.1585) Data Time: 0.0124 (0.0255) Average Loss: 0.7621 (0.7715) Average CE Loss (Source):  0.7621 ( 0.7715) Learning Rate: 0.1000 (0.1000) Top1_base: 78.9062 (78.2161) Top1_base_per_class: 80.1235 (78.8338) 
Training Epoch: [104/1000] Step: [190 / 285] Batch Time: 0.1459 (0.1582) Data Time: 0.0134 (0.0252) Average Loss: 0.6524 (0.7699) Average CE Loss (Source):  0.6524 ( 0.7699) Learning Rate: 0.1000 (0.1000) Top1_base: 82.8125 (78.3141) Top1_base_per_class: 83.1790 (78.8685) 
Training Epoch: [104/1000] Step: [200 / 285] Batch Time: 0.1451 (0.1580) Data Time: 0.0125 (0.0249) Average Loss: 0.6401 (0.7715) Average CE Loss (Source):  0.6401 ( 0.7715) Learning Rate: 0.1000 (0.1000) Top1_base: 79.6875 (78.2812) Top1_base_per_class: 79.6448 (78.8270) 
Training Epoch: [104/1000] Step: [210 / 285] Batch Time: 0.1487 (0.1579) Data Time: 0.0146 (0.0249) Average Loss: 0.7413 (0.7758) Average CE Loss (Source):  0.7413 ( 0.7758) Learning Rate: 0.1000 (0.1000) Top1_base: 80.4688 (78.2031) Top1_base_per_class: 80.4464 (78.7494) 
Training Epoch: [104/1000] Step: [220 / 285] Batch Time: 0.1450 (0.1573) Data Time: 0.0123 (0.0244) Average Loss: 0.9180 (0.7789) Average CE Loss (Source):  0.9180 ( 0.7789) Learning Rate: 0.1000 (0.1000) Top1_base: 72.6562 (78.1179) Top1_base_per_class: 76.7262 (78.6415) 
Training Epoch: [104/1000] Step: [230 / 285] Batch Time: 0.1489 (0.1569) Data Time: 0.0135 (0.0239) Average Loss: 0.7845 (0.7796) Average CE Loss (Source):  0.7845 ( 0.7796) Learning Rate: 0.1000 (0.1000) Top1_base: 77.3438 (78.1454) Top1_base_per_class: 77.9894 (78.6762) 
Training Epoch: [104/1000] Step: [240 / 285] Batch Time: 0.1488 (0.1566) Data Time: 0.0108 (0.0235) Average Loss: 0.6795 (0.7794) Average CE Loss (Source):  0.6795 ( 0.7794) Learning Rate: 0.1000 (0.1000) Top1_base: 77.3438 (78.1673) Top1_base_per_class: 81.2654 (78.6606) 
Training Epoch: [104/1000] Step: [250 / 285] Batch Time: 0.1477 (0.1564) Data Time: 0.0139 (0.0231) Average Loss: 0.7939 (0.7806) Average CE Loss (Source):  0.7939 ( 0.7806) Learning Rate: 0.1000 (0.1000) Top1_base: 76.5625 (78.0875) Top1_base_per_class: 78.6012 (78.6181) 
Training Epoch: [104/1000] Step: [260 / 285] Batch Time: 0.1480 (0.1563) Data Time: 0.0106 (0.0230) Average Loss: 1.0769 (0.7803) Average CE Loss (Source):  1.0769 ( 0.7803) Learning Rate: 0.1000 (0.1000) Top1_base: 71.0938 (78.0469) Top1_base_per_class: 72.2619 (78.5921) 
Training Epoch: [104/1000] Step: [270 / 285] Batch Time: 0.1479 (0.1561) Data Time: 0.0148 (0.0227) Average Loss: 0.6820 (0.7826) Average CE Loss (Source):  0.6820 ( 0.7826) Learning Rate: 0.1000 (0.1000) Top1_base: 78.1250 (77.9861) Top1_base_per_class: 80.6482 (78.5206) 
Training Epoch: [104/1000] Step: [280 / 285] Batch Time: 0.1431 (0.1559) Data Time: 0.0103 (0.0226) Average Loss: 0.6607 (0.7824) Average CE Loss (Source):  0.6607 ( 0.7824) Learning Rate: 0.1000 (0.1000) Top1_base: 81.2500 (77.9967) Top1_base_per_class: 80.4971 (78.5131) 
Training Epoch: [105/1000] Step: [0] Batch Time: 0.1636 (0.1558) Data Time: 0.0281 (0.0225) Average Loss: 0.9264 (0.7826) Average CE Loss (Source):  0.9264 ( 0.7826) Learning Rate: 0.1000 (0.1000) Top1_base: 75.0000 (77.9907) Top1_base_per_class: 74.4340 (78.4982) 
Training Epoch: [105/1000] Step: [10 / 285] Batch Time: 0.1425 (0.2467) Data Time: 0.0106 (0.1135) Average Loss: 0.7280 (0.7502) Average CE Loss (Source):  0.7280 ( 0.7502) Learning Rate: 0.1000 (0.1000) Top1_base: 79.6875 (78.6719) Top1_base_per_class: 74.7799 (79.2443) 
Training Epoch: [105/1000] Step: [20 / 285] Batch Time: 0.1432 (0.2086) Data Time: 0.0107 (0.0753) Average Loss: 0.4994 (0.7475) Average CE Loss (Source):  0.4994 ( 0.7475) Learning Rate: 0.1000 (0.1000) Top1_base: 85.1562 (79.2578) Top1_base_per_class: 85.7471 (79.6674) 
Training Epoch: [105/1000] Step: [30 / 285] Batch Time: 0.1473 (0.1899) Data Time: 0.0123 (0.0566) Average Loss: 0.6823 (0.7410) Average CE Loss (Source):  0.6823 ( 0.7410) Learning Rate: 0.1000 (0.1000) Top1_base: 82.8125 (79.8177) Top1_base_per_class: 82.4405 (80.3873) 
Training Epoch: [105/1000] Step: [40 / 285] Batch Time: 0.1450 (0.1815) Data Time: 0.0125 (0.0482) Average Loss: 0.8618 (0.7455) Average CE Loss (Source):  0.8618 ( 0.7455) Learning Rate: 0.1000 (0.1000) Top1_base: 75.7812 (79.4141) Top1_base_per_class: 75.6780 (79.7553) 
Training Epoch: [105/1000] Step: [50 / 285] Batch Time: 0.1440 (0.1767) Data Time: 0.0106 (0.0434) Average Loss: 0.8485 (0.7581) Average CE Loss (Source):  0.8485 ( 0.7581) Learning Rate: 0.1000 (0.1000) Top1_base: 79.6875 (79.0781) Top1_base_per_class: 81.9351 (79.6440) 
Training Epoch: [105/1000] Step: [60 / 285] Batch Time: 0.1475 (0.1731) Data Time: 0.0137 (0.0396) Average Loss: 0.6289 (0.7567) Average CE Loss (Source):  0.6289 ( 0.7567) Learning Rate: 0.1000 (0.1000) Top1_base: 84.3750 (78.9453) Top1_base_per_class: 84.7879 (79.3208) 
Training Epoch: [105/1000] Step: [70 / 285] Batch Time: 0.1435 (0.1703) Data Time: 0.0121 (0.0369) Average Loss: 0.8296 (0.7543) Average CE Loss (Source):  0.8296 ( 0.7543) Learning Rate: 0.1000 (0.1000) Top1_base: 77.3438 (78.8839) Top1_base_per_class: 79.2857 (79.2283) 
Training Epoch: [105/1000] Step: [80 / 285] Batch Time: 0.1482 (0.1687) Data Time: 0.0147 (0.0352) Average Loss: 0.9324 (0.7540) Average CE Loss (Source):  0.9324 ( 0.7540) Learning Rate: 0.1000 (0.1000) Top1_base: 75.0000 (78.8867) Top1_base_per_class: 73.5849 (79.2256) 
Training Epoch: [105/1000] Step: [90 / 285] Batch Time: 0.1453 (0.1669) Data Time: 0.0125 (0.0334) Average Loss: 0.8398 (0.7599) Average CE Loss (Source):  0.8398 ( 0.7599) Learning Rate: 0.1000 (0.1000) Top1_base: 78.1250 (78.7500) Top1_base_per_class: 83.1780 (79.2143) 
Training Epoch: [105/1000] Step: [100 / 285] Batch Time: 0.1468 (0.1659) Data Time: 0.0129 (0.0324) Average Loss: 0.7368 (0.7621) Average CE Loss (Source):  0.7368 ( 0.7621) Learning Rate: 0.1000 (0.1000) Top1_base: 78.1250 (78.6797) Top1_base_per_class: 80.9697 (79.1009) 
Training Epoch: [105/1000] Step: [110 / 285] Batch Time: 0.1428 (0.1658) Data Time: 0.0124 (0.0324) Average Loss: 0.8385 (0.7639) Average CE Loss (Source):  0.8385 ( 0.7639) Learning Rate: 0.1000 (0.1000) Top1_base: 77.3438 (78.5653) Top1_base_per_class: 76.5789 (78.9914) 
Training Epoch: [105/1000] Step: [120 / 285] Batch Time: 0.1484 (0.1654) Data Time: 0.0145 (0.0319) Average Loss: 0.8680 (0.7647) Average CE Loss (Source):  0.8680 ( 0.7647) Learning Rate: 0.1000 (0.1000) Top1_base: 75.7812 (78.6068) Top1_base_per_class: 77.6471 (79.0797) 
Training Epoch: [105/1000] Step: [130 / 285] Batch Time: 0.1476 (0.1643) Data Time: 0.0165 (0.0309) Average Loss: 0.6491 (0.7623) Average CE Loss (Source):  0.6491 ( 0.7623) Learning Rate: 0.1000 (0.1000) Top1_base: 78.9062 (78.6238) Top1_base_per_class: 76.3095 (79.1399) 
Training Epoch: [105/1000] Step: [140 / 285] Batch Time: 0.1494 (0.1635) Data Time: 0.0134 (0.0301) Average Loss: 0.7430 (0.7604) Average CE Loss (Source):  0.7430 ( 0.7604) Learning Rate: 0.1000 (0.1000) Top1_base: 78.1250 (78.6607) Top1_base_per_class: 77.2619 (79.2376) 
Training Epoch: [105/1000] Step: [150 / 285] Batch Time: 0.1457 (0.1624) Data Time: 0.0150 (0.0290) Average Loss: 0.7239 (0.7604) Average CE Loss (Source):  0.7239 ( 0.7604) Learning Rate: 0.1000 (0.1000) Top1_base: 75.7812 (78.6250) Top1_base_per_class: 78.6257 (79.2234) 
Training Epoch: [105/1000] Step: [160 / 285] Batch Time: 0.1533 (0.1615) Data Time: 0.0159 (0.0281) Average Loss: 0.7243 (0.7619) Average CE Loss (Source):  0.7243 ( 0.7619) Learning Rate: 0.1000 (0.1000) Top1_base: 80.4688 (78.5742) Top1_base_per_class: 81.4972 (79.0971) 
Training Epoch: [105/1000] Step: [170 / 285] Batch Time: 0.1455 (0.1608) Data Time: 0.0117 (0.0273) Average Loss: 0.8547 (0.7631) Average CE Loss (Source):  0.8547 ( 0.7631) Learning Rate: 0.1000 (0.1000) Top1_base: 78.1250 (78.5662) Top1_base_per_class: 78.3184 (79.0395) 
Training Epoch: [105/1000] Step: [180 / 285] Batch Time: 0.1444 (0.1600) Data Time: 0.0128 (0.0265) Average Loss: 0.8813 (0.7679) Average CE Loss (Source):  0.8813 ( 0.7679) Learning Rate: 0.1000 (0.1000) Top1_base: 71.8750 (78.4245) Top1_base_per_class: 74.4136 (78.8808) 
Training Epoch: [105/1000] Step: [190 / 285] Batch Time: 0.1486 (0.1595) Data Time: 0.0146 (0.0259) Average Loss: 0.9195 (0.7696) Average CE Loss (Source):  0.9195 ( 0.7696) Learning Rate: 0.1000 (0.1000) Top1_base: 71.0938 (78.3717) Top1_base_per_class: 67.8274 (78.7877) 
Training Epoch: [105/1000] Step: [200 / 285] Batch Time: 0.1477 (0.1588) Data Time: 0.0113 (0.0253) Average Loss: 0.5966 (0.7732) Average CE Loss (Source):  0.5966 ( 0.7732) Learning Rate: 0.1000 (0.1000) Top1_base: 84.3750 (78.2930) Top1_base_per_class: 87.1345 (78.7435) 
Training Epoch: [105/1000] Step: [210 / 285] Batch Time: 0.1469 (0.1583) Data Time: 0.0129 (0.0248) Average Loss: 0.7967 (0.7749) Average CE Loss (Source):  0.7967 ( 0.7749) Learning Rate: 0.1000 (0.1000) Top1_base: 79.6875 (78.2068) Top1_base_per_class: 80.3145 (78.6660) 
Training Epoch: [105/1000] Step: [220 / 285] Batch Time: 0.1447 (0.1580) Data Time: 0.0126 (0.0243) Average Loss: 1.0895 (0.7741) Average CE Loss (Source):  1.0895 ( 0.7741) Learning Rate: 0.1000 (0.1000) Top1_base: 68.7500 (78.2812) Top1_base_per_class: 70.0275 (78.6859) 
Training Epoch: [105/1000] Step: [230 / 285] Batch Time: 0.1486 (0.1577) Data Time: 0.0142 (0.0241) Average Loss: 0.7838 (0.7749) Average CE Loss (Source):  0.7838 ( 0.7749) Learning Rate: 0.1000 (0.1000) Top1_base: 78.9062 (78.2439) Top1_base_per_class: 78.8177 (78.6705) 
Training Epoch: [105/1000] Step: [240 / 285] Batch Time: 0.1556 (0.1575) Data Time: 0.0165 (0.0238) Average Loss: 0.8115 (0.7758) Average CE Loss (Source):  0.8115 ( 0.7758) Learning Rate: 0.1000 (0.1000) Top1_base: 75.7812 (78.2454) Top1_base_per_class: 75.4802 (78.6570) 
Training Epoch: [105/1000] Step: [250 / 285] Batch Time: 0.1478 (0.1575) Data Time: 0.0154 (0.0237) Average Loss: 0.5546 (0.7768) Average CE Loss (Source):  0.5546 ( 0.7768) Learning Rate: 0.1000 (0.1000) Top1_base: 87.5000 (78.2562) Top1_base_per_class: 88.0117 (78.6508) 
Training Epoch: [105/1000] Step: [260 / 285] Batch Time: 0.1483 (0.1578) Data Time: 0.0146 (0.0240) Average Loss: 0.6340 (0.7776) Average CE Loss (Source):  0.6340 ( 0.7776) Learning Rate: 0.1000 (0.1000) Top1_base: 79.6875 (78.2212) Top1_base_per_class: 76.5497 (78.6101) 
Training Epoch: [105/1000] Step: [270 / 285] Batch Time: 0.1470 (0.1575) Data Time: 0.0105 (0.0236) Average Loss: 0.8120 (0.7797) Average CE Loss (Source):  0.8120 ( 0.7797) Learning Rate: 0.1000 (0.1000) Top1_base: 76.5625 (78.1510) Top1_base_per_class: 80.5152 (78.5470) 
Training Epoch: [105/1000] Step: [280 / 285] Batch Time: 0.1508 (0.1572) Data Time: 0.0143 (0.0233) Average Loss: 0.7589 (0.7799) Average CE Loss (Source):  0.7589 ( 0.7799) Learning Rate: 0.1000 (0.1000) Top1_base: 76.5625 (78.1278) Top1_base_per_class: 78.9181 (78.5348) 
Training Epoch: [106/1000] Step: [0] Batch Time: 0.1461 (0.1571) Data Time: 0.0122 (0.0231) Average Loss: 0.8223 (0.7811) Average CE Loss (Source):  0.8223 ( 0.7811) Learning Rate: 0.1000 (0.1000) Top1_base: 78.9062 (78.0894) Top1_base_per_class: 78.5965 (78.5069) 
 11%|█         | 106/1000 [1:22:54<11:30:45, 46.36s/it] 11%|█         | 107/1000 [1:23:39<11:22:34, 45.86s/it]Training Epoch: [106/1000] Step: [10 / 285] Batch Time: 0.1444 (0.2280) Data Time: 0.0130 (0.0951) Average Loss: 0.8450 (0.7765) Average CE Loss (Source):  0.8450 ( 0.7765) Learning Rate: 0.1000 (0.1000) Top1_base: 74.2188 (77.6562) Top1_base_per_class: 75.4762 (76.8601) 
Training Epoch: [106/1000] Step: [20 / 285] Batch Time: 0.1454 (0.1956) Data Time: 0.0112 (0.0631) Average Loss: 0.8428 (0.7813) Average CE Loss (Source):  0.8428 ( 0.7813) Learning Rate: 0.1000 (0.1000) Top1_base: 78.9062 (77.7734) Top1_base_per_class: 79.3503 (77.7750) 
Training Epoch: [106/1000] Step: [30 / 285] Batch Time: 0.1448 (0.1830) Data Time: 0.0129 (0.0504) Average Loss: 1.0012 (0.7797) Average CE Loss (Source):  1.0012 ( 0.7797) Learning Rate: 0.1000 (0.1000) Top1_base: 68.7500 (77.7344) Top1_base_per_class: 68.9583 (78.0735) 
Training Epoch: [106/1000] Step: [40 / 285] Batch Time: 0.1501 (0.1791) Data Time: 0.0165 (0.0465) Average Loss: 0.7309 (0.7894) Average CE Loss (Source):  0.7309 ( 0.7894) Learning Rate: 0.1000 (0.1000) Top1_base: 77.3438 (77.4414) Top1_base_per_class: 77.5758 (77.9640) 
Training Epoch: [106/1000] Step: [50 / 285] Batch Time: 0.1449 (0.1739) Data Time: 0.0125 (0.0415) Average Loss: 0.9648 (0.7799) Average CE Loss (Source):  0.9648 ( 0.7799) Learning Rate: 0.1000 (0.1000) Top1_base: 75.0000 (77.9062) Top1_base_per_class: 70.6080 (78.4851) 
Training Epoch: [106/1000] Step: [60 / 285] Batch Time: 0.1479 (0.1704) Data Time: 0.0135 (0.0379) Average Loss: 0.8440 (0.7819) Average CE Loss (Source):  0.8440 ( 0.7819) Learning Rate: 0.1000 (0.1000) Top1_base: 75.0000 (77.9036) Top1_base_per_class: 75.1543 (78.5437) 
Training Epoch: [106/1000] Step: [70 / 285] Batch Time: 0.1421 (0.1686) Data Time: 0.0104 (0.0360) Average Loss: 0.8802 (0.7868) Average CE Loss (Source):  0.8802 ( 0.7868) Learning Rate: 0.1000 (0.1000) Top1_base: 75.0000 (77.7790) Top1_base_per_class: 77.6543 (78.5483) 
Training Epoch: [106/1000] Step: [80 / 285] Batch Time: 0.1428 (0.1664) Data Time: 0.0124 (0.0338) Average Loss: 0.7145 (0.7814) Average CE Loss (Source):  0.7145 ( 0.7814) Learning Rate: 0.1000 (0.1000) Top1_base: 75.0000 (77.8516) Top1_base_per_class: 72.2222 (78.5150) 
Training Epoch: [106/1000] Step: [90 / 285] Batch Time: 0.1454 (0.1643) Data Time: 0.0119 (0.0318) Average Loss: 0.9038 (0.7802) Average CE Loss (Source):  0.9038 ( 0.7802) Learning Rate: 0.1000 (0.1000) Top1_base: 76.5625 (78.0035) Top1_base_per_class: 81.0333 (78.6757) 
Training Epoch: [106/1000] Step: [100 / 285] Batch Time: 0.1423 (0.1630) Data Time: 0.0114 (0.0306) Average Loss: 0.6472 (0.7813) Average CE Loss (Source):  0.6472 ( 0.7813) Learning Rate: 0.1000 (0.1000) Top1_base: 85.1562 (77.8828) Top1_base_per_class: 84.7619 (78.5508) 
Training Epoch: [106/1000] Step: [110 / 285] Batch Time: 0.1439 (0.1618) Data Time: 0.0104 (0.0291) Average Loss: 0.8814 (0.7826) Average CE Loss (Source):  0.8814 ( 0.7826) Learning Rate: 0.1000 (0.1000) Top1_base: 76.5625 (77.8267) Top1_base_per_class: 75.1543 (78.4544) 
Training Epoch: [106/1000] Step: [120 / 285] Batch Time: 0.1512 (0.1608) Data Time: 0.0137 (0.0280) Average Loss: 0.7600 (0.7769) Average CE Loss (Source):  0.7600 ( 0.7769) Learning Rate: 0.1000 (0.1000) Top1_base: 77.3438 (78.0013) Top1_base_per_class: 73.0409 (78.5386) 
Training Epoch: [106/1000] Step: [130 / 285] Batch Time: 0.1445 (0.1598) Data Time: 0.0110 (0.0269) Average Loss: 0.7339 (0.7755) Average CE Loss (Source):  0.7339 ( 0.7755) Learning Rate: 0.1000 (0.1000) Top1_base: 80.4688 (77.9808) Top1_base_per_class: 79.1821 (78.4670) 
Training Epoch: [106/1000] Step: [140 / 285] Batch Time: 0.1433 (0.1591) Data Time: 0.0126 (0.0261) Average Loss: 0.9034 (0.7808) Average CE Loss (Source):  0.9034 ( 0.7808) Learning Rate: 0.1000 (0.1000) Top1_base: 76.5625 (77.8404) Top1_base_per_class: 75.1212 (78.2653) 
Training Epoch: [106/1000] Step: [150 / 285] Batch Time: 0.1418 (0.1583) Data Time: 0.0105 (0.0254) Average Loss: 0.5638 (0.7845) Average CE Loss (Source):  0.5638 ( 0.7845) Learning Rate: 0.1000 (0.1000) Top1_base: 87.5000 (77.8333) Top1_base_per_class: 89.0517 (78.3564) 
Training Epoch: [106/1000] Step: [160 / 285] Batch Time: 0.1481 (0.1577) Data Time: 0.0142 (0.0247) Average Loss: 0.6658 (0.7845) Average CE Loss (Source):  0.6658 ( 0.7845) Learning Rate: 0.1000 (0.1000) Top1_base: 82.8125 (77.8662) Top1_base_per_class: 79.6990 (78.4052) 
Training Epoch: [106/1000] Step: [170 / 285] Batch Time: 0.1438 (0.1575) Data Time: 0.0136 (0.0246) Average Loss: 0.6746 (0.7823) Average CE Loss (Source):  0.6746 ( 0.7823) Learning Rate: 0.1000 (0.1000) Top1_base: 79.6875 (77.9825) Top1_base_per_class: 80.2976 (78.5096) 
Training Epoch: [106/1000] Step: [180 / 285] Batch Time: 0.1460 (0.1574) Data Time: 0.0116 (0.0245) Average Loss: 0.8580 (0.7843) Average CE Loss (Source):  0.8580 ( 0.7843) Learning Rate: 0.1000 (0.1000) Top1_base: 76.5625 (77.9427) Top1_base_per_class: 77.1667 (78.4108) 
Training Epoch: [106/1000] Step: [190 / 285] Batch Time: 0.1428 (0.1574) Data Time: 0.0118 (0.0246) Average Loss: 0.9421 (0.7856) Average CE Loss (Source):  0.9421 ( 0.7856) Learning Rate: 0.1000 (0.1000) Top1_base: 74.2188 (77.8824) Top1_base_per_class: 71.2963 (78.3332) 
Training Epoch: [106/1000] Step: [200 / 285] Batch Time: 0.1457 (0.1570) Data Time: 0.0117 (0.0241) Average Loss: 0.9365 (0.7866) Average CE Loss (Source):  0.9365 ( 0.7866) Learning Rate: 0.1000 (0.1000) Top1_base: 75.0000 (77.8789) Top1_base_per_class: 74.4026 (78.3061) 
Training Epoch: [106/1000] Step: [210 / 285] Batch Time: 0.1772 (0.1570) Data Time: 0.0454 (0.0242) Average Loss: 0.7655 (0.7882) Average CE Loss (Source):  0.7655 ( 0.7882) Learning Rate: 0.1000 (0.1000) Top1_base: 81.2500 (77.9018) Top1_base_per_class: 79.4643 (78.3290) 
Training Epoch: [106/1000] Step: [220 / 285] Batch Time: 0.1463 (0.1569) Data Time: 0.0119 (0.0242) Average Loss: 0.7705 (0.7852) Average CE Loss (Source):  0.7705 ( 0.7852) Learning Rate: 0.1000 (0.1000) Top1_base: 78.1250 (77.9545) Top1_base_per_class: 79.3210 (78.4015) 
Training Epoch: [106/1000] Step: [230 / 285] Batch Time: 0.1853 (0.1568) Data Time: 0.0546 (0.0240) Average Loss: 0.6511 (0.7872) Average CE Loss (Source):  0.6511 ( 0.7872) Learning Rate: 0.1000 (0.1000) Top1_base: 82.0312 (77.8838) Top1_base_per_class: 81.6804 (78.3805) 
Training Epoch: [106/1000] Step: [240 / 285] Batch Time: 0.1448 (0.1568) Data Time: 0.0121 (0.0240) Average Loss: 0.6977 (0.7857) Average CE Loss (Source):  0.6977 ( 0.7857) Learning Rate: 0.1000 (0.1000) Top1_base: 83.5938 (77.9102) Top1_base_per_class: 85.2830 (78.4410) 
Training Epoch: [106/1000] Step: [250 / 285] Batch Time: 0.2350 (0.1569) Data Time: 0.1018 (0.0241) Average Loss: 1.1526 (0.7883) Average CE Loss (Source):  1.1526 ( 0.7883) Learning Rate: 0.1000 (0.1000) Top1_base: 70.3125 (77.8688) Top1_base_per_class: 75.4585 (78.3909) 
Training Epoch: [106/1000] Step: [260 / 285] Batch Time: 0.1459 (0.1567) Data Time: 0.0123 (0.0239) Average Loss: 0.8865 (0.7886) Average CE Loss (Source):  0.8865 ( 0.7886) Learning Rate: 0.1000 (0.1000) Top1_base: 76.5625 (77.8516) Top1_base_per_class: 77.8655 (78.4078) 
Training Epoch: [106/1000] Step: [270 / 285] Batch Time: 0.1771 (0.1569) Data Time: 0.0455 (0.0242) Average Loss: 0.7626 (0.7881) Average CE Loss (Source):  0.7626 ( 0.7881) Learning Rate: 0.1000 (0.1000) Top1_base: 82.0312 (77.9167) Top1_base_per_class: 84.0278 (78.5090) 
Training Epoch: [106/1000] Step: [280 / 285] Batch Time: 0.1411 (0.1567) Data Time: 0.0113 (0.0239) Average Loss: 0.7061 (0.7876) Average CE Loss (Source):  0.7061 ( 0.7876) Learning Rate: 0.1000 (0.1000) Top1_base: 82.8125 (77.9548) Top1_base_per_class: 80.8908 (78.4949) 
Training Epoch: [107/1000] Step: [0] Batch Time: 0.1400 (0.1566) Data Time: 0.0094 (0.0239) Average Loss: 0.8203 (0.7867) Average CE Loss (Source):  0.8203 ( 0.7867) Learning Rate: 0.1000 (0.1000) Top1_base: 78.1250 (77.9633) Top1_base_per_class: 81.6750 (78.4986) 
Training Epoch: [107/1000] Step: [10 / 285] Batch Time: 0.1483 (0.2274) Data Time: 0.0137 (0.0926) Average Loss: 0.7042 (0.7596) Average CE Loss (Source):  0.7042 ( 0.7596) Learning Rate: 0.1000 (0.1000) Top1_base: 82.0312 (78.5938) Top1_base_per_class: 80.5454 (77.4240) 
Training Epoch: [107/1000] Step: [20 / 285] Batch Time: 0.1432 (0.1937) Data Time: 0.0112 (0.0601) Average Loss: 0.8319 (0.7465) Average CE Loss (Source):  0.8319 ( 0.7465) Learning Rate: 0.1000 (0.1000) Top1_base: 78.1250 (78.9453) Top1_base_per_class: 76.0736 (78.4752) 
Training Epoch: [107/1000] Step: [30 / 285] Batch Time: 0.1439 (0.1795) Data Time: 0.0112 (0.0462) Average Loss: 0.7456 (0.7599) Average CE Loss (Source):  0.7456 ( 0.7599) Learning Rate: 0.1000 (0.1000) Top1_base: 79.6875 (78.6458) Top1_base_per_class: 82.0000 (78.8596) 
Training Epoch: [107/1000] Step: [40 / 285] Batch Time: 0.1416 (0.1764) Data Time: 0.0107 (0.0431) Average Loss: 0.7705 (0.7661) Average CE Loss (Source):  0.7705 ( 0.7661) Learning Rate: 0.1000 (0.1000) Top1_base: 76.5625 (78.5156) Top1_base_per_class: 76.7687 (78.7330) 
Training Epoch: [107/1000] Step: [50 / 285] Batch Time: 0.1470 (0.1714) Data Time: 0.0124 (0.0381) Average Loss: 0.8486 (0.7667) Average CE Loss (Source):  0.8486 ( 0.7667) Learning Rate: 0.1000 (0.1000) Top1_base: 78.1250 (78.7188) Top1_base_per_class: 78.3019 (79.0614) 
Training Epoch: [107/1000] Step: [60 / 285] Batch Time: 0.1471 (0.1695) Data Time: 0.0131 (0.0364) Average Loss: 1.0322 (0.7700) Average CE Loss (Source):  1.0322 ( 0.7700) Learning Rate: 0.1000 (0.1000) Top1_base: 70.3125 (78.5547) Top1_base_per_class: 72.0977 (78.8450) 
Training Epoch: [107/1000] Step: [70 / 285] Batch Time: 0.1490 (0.1672) Data Time: 0.0143 (0.0340) Average Loss: 0.6717 (0.7634) Average CE Loss (Source):  0.6717 ( 0.7634) Learning Rate: 0.1000 (0.1000) Top1_base: 78.1250 (78.6607) Top1_base_per_class: 77.3276 (78.9007) 
Training Epoch: [107/1000] Step: [80 / 285] Batch Time: 0.1425 (0.1655) Data Time: 0.0106 (0.0324) Average Loss: 0.6690 (0.7610) Average CE Loss (Source):  0.6690 ( 0.7610) Learning Rate: 0.1000 (0.1000) Top1_base: 81.2500 (78.8281) Top1_base_per_class: 82.1169 (79.1609) 
Training Epoch: [107/1000] Step: [90 / 285] Batch Time: 0.1471 (0.1636) Data Time: 0.0130 (0.0304) Average Loss: 0.7274 (0.7615) Average CE Loss (Source):  0.7274 ( 0.7615) Learning Rate: 0.1000 (0.1000) Top1_base: 75.0000 (78.7326) Top1_base_per_class: 76.7576 (79.0987) 
Training Epoch: [107/1000] Step: [100 / 285] Batch Time: 0.1438 (0.1637) Data Time: 0.0111 (0.0306) Average Loss: 0.7560 (0.7622) Average CE Loss (Source):  0.7560 ( 0.7622) Learning Rate: 0.1000 (0.1000) Top1_base: 80.4688 (78.7344) Top1_base_per_class: 76.7544 (79.0421) 
Training Epoch: [107/1000] Step: [110 / 285] Batch Time: 0.1453 (0.1633) Data Time: 0.0124 (0.0302) Average Loss: 0.8179 (0.7650) Average CE Loss (Source):  0.8179 ( 0.7650) Learning Rate: 0.1000 (0.1000) Top1_base: 76.5625 (78.6719) Top1_base_per_class: 77.3030 (79.0400) 
Training Epoch: [107/1000] Step: [120 / 285] Batch Time: 0.1426 (0.1622) Data Time: 0.0119 (0.0291) Average Loss: 0.7099 (0.7649) Average CE Loss (Source):  0.7099 ( 0.7649) Learning Rate: 0.1000 (0.1000) Top1_base: 80.4688 (78.6003) Top1_base_per_class: 78.3929 (78.9290) 
Training Epoch: [107/1000] Step: [130 / 285] Batch Time: 0.1428 (0.1614) Data Time: 0.0121 (0.0283) Average Loss: 0.6758 (0.7668) Average CE Loss (Source):  0.6758 ( 0.7668) Learning Rate: 0.1000 (0.1000) Top1_base: 79.6875 (78.5156) Top1_base_per_class: 78.4311 (78.9125) 
Training Epoch: [107/1000] Step: [140 / 285] Batch Time: 0.1467 (0.1618) Data Time: 0.0142 (0.0287) Average Loss: 0.9866 (0.7708) Average CE Loss (Source):  0.9866 ( 0.7708) Learning Rate: 0.1000 (0.1000) Top1_base: 75.0000 (78.3426) Top1_base_per_class: 77.7778 (78.7225) 
Training Epoch: [107/1000] Step: [150 / 285] Batch Time: 0.1479 (0.1613) Data Time: 0.0146 (0.0283) Average Loss: 0.7424 (0.7716) Average CE Loss (Source):  0.7424 ( 0.7716) Learning Rate: 0.1000 (0.1000) Top1_base: 76.5625 (78.2969) Top1_base_per_class: 76.9753 (78.6851) 
Training Epoch: [107/1000] Step: [160 / 285] Batch Time: 0.1437 (0.1613) Data Time: 0.0117 (0.0283) Average Loss: 1.1043 (0.7768) Average CE Loss (Source):  1.1043 ( 0.7768) Learning Rate: 0.1000 (0.1000) Top1_base: 70.3125 (78.1738) Top1_base_per_class: 70.4847 (78.5151) 
Training Epoch: [107/1000] Step: [170 / 285] Batch Time: 0.1480 (0.1606) Data Time: 0.0135 (0.0276) Average Loss: 0.7422 (0.7778) Average CE Loss (Source):  0.7422 ( 0.7778) Learning Rate: 0.1000 (0.1000) Top1_base: 79.6875 (78.1204) Top1_base_per_class: 80.2243 (78.4570) 
Training Epoch: [107/1000] Step: [180 / 285] Batch Time: 0.1426 (0.1602) Data Time: 0.0108 (0.0272) Average Loss: 0.8124 (0.7764) Average CE Loss (Source):  0.8124 ( 0.7764) Learning Rate: 0.1000 (0.1000) Top1_base: 78.9062 (78.1684) Top1_base_per_class: 80.0000 (78.4812) 
Training Epoch: [107/1000] Step: [190 / 285] Batch Time: 0.1458 (0.1600) Data Time: 0.0139 (0.0270) Average Loss: 0.8129 (0.7764) Average CE Loss (Source):  0.8129 ( 0.7764) Learning Rate: 0.1000 (0.1000) Top1_base: 78.9062 (78.1538) Top1_base_per_class: 78.8462 (78.5391) 
Training Epoch: [107/1000] Step: [200 / 285] Batch Time: 0.1459 (0.1596) Data Time: 0.0126 (0.0266) Average Loss: 0.6256 (0.7771) Average CE Loss (Source):  0.6256 ( 0.7771) Learning Rate: 0.1000 (0.1000) Top1_base: 82.8125 (78.1367) Top1_base_per_class: 78.4770 (78.5146) 
Training Epoch: [107/1000] Step: [210 / 285] Batch Time: 0.1405 (0.1591) Data Time: 0.0110 (0.0262) Average Loss: 0.6413 (0.7769) Average CE Loss (Source):  0.6413 ( 0.7769) Learning Rate: 0.1000 (0.1000) Top1_base: 81.2500 (78.1510) Top1_base_per_class: 81.9400 (78.5222) 
Training Epoch: [107/1000] Step: [220 / 285] Batch Time: 0.1459 (0.1588) Data Time: 0.0121 (0.0260) Average Loss: 0.9295 (0.7780) Average CE Loss (Source):  0.9295 ( 0.7780) Learning Rate: 0.1000 (0.1000) Top1_base: 74.2188 (78.1357) Top1_base_per_class: 74.3860 (78.5084) 
Training Epoch: [107/1000] Step: [230 / 285] Batch Time: 0.1405 (0.1586) Data Time: 0.0111 (0.0257) Average Loss: 0.8303 (0.7780) Average CE Loss (Source):  0.8303 ( 0.7780) Learning Rate: 0.1000 (0.1000) Top1_base: 75.7812 (78.1046) Top1_base_per_class: 75.9259 (78.4779) 
Training Epoch: [107/1000] Step: [240 / 285] Batch Time: 0.1426 (0.1582) Data Time: 0.0110 (0.0254) Average Loss: 0.8684 (0.7783) Average CE Loss (Source):  0.8684 ( 0.7783) Learning Rate: 0.1000 (0.1000) Top1_base: 75.0000 (78.0859) Top1_base_per_class: 76.1859 (78.4792) 
Training Epoch: [107/1000] Step: [250 / 285] Batch Time: 0.1488 (0.1577) Data Time: 0.0140 (0.0249) Average Loss: 0.8512 (0.7776) Average CE Loss (Source):  0.8512 ( 0.7776) Learning Rate: 0.1000 (0.1000) Top1_base: 74.2188 (78.1250) Top1_base_per_class: 72.7966 (78.4828) 
Training Epoch: [107/1000] Step: [260 / 285] Batch Time: 0.1485 (0.1581) Data Time: 0.0144 (0.0252) Average Loss: 0.9149 (0.7788) Average CE Loss (Source):  0.9149 ( 0.7788) Learning Rate: 0.1000 (0.1000) Top1_base: 76.5625 (78.1460) Top1_base_per_class: 76.0632 (78.5155) 
Training Epoch: [107/1000] Step: [270 / 285] Batch Time: 0.1465 (0.1577) Data Time: 0.0138 (0.0248) Average Loss: 0.6532 (0.7792) Average CE Loss (Source):  0.6532 ( 0.7792) Learning Rate: 0.1000 (0.1000) Top1_base: 79.6875 (78.1250) Top1_base_per_class: 80.5975 (78.4607) 
Training Epoch: [107/1000] Step: [280 / 285] Batch Time: 0.1438 (0.1584) Data Time: 0.0104 (0.0255) Average Loss: 0.5958 (0.7811) Average CE Loss (Source):  0.5958 ( 0.7811) Learning Rate: 0.1000 (0.1000) Top1_base: 82.0312 (78.0748) Top1_base_per_class: 77.8274 (78.4225) 
Training Epoch: [108/1000] Step: [0] Batch Time: 0.1438 (0.1581) Data Time: 0.0092 (0.0252) Average Loss: 0.9490 (0.7827) Average CE Loss (Source):  0.9490 ( 0.7827) Learning Rate: 0.1000 (0.1000) Top1_base: 73.4375 (78.0263) Top1_base_per_class: 76.4198 (78.3708) 
 11%|█         | 108/1000 [1:24:27<11:31:01, 46.48s/it] 11%|█         | 109/1000 [1:25:11<11:23:16, 46.01s/it]Training Epoch: [108/1000] Step: [10 / 285] Batch Time: 0.1456 (0.2265) Data Time: 0.0135 (0.0933) Average Loss: 0.7827 (0.7815) Average CE Loss (Source):  0.7827 ( 0.7815) Learning Rate: 0.1000 (0.1000) Top1_base: 80.4688 (78.3594) Top1_base_per_class: 78.7273 (77.8997) 
Training Epoch: [108/1000] Step: [20 / 285] Batch Time: 0.1472 (0.1947) Data Time: 0.0129 (0.0613) Average Loss: 0.7097 (0.7681) Average CE Loss (Source):  0.7097 ( 0.7681) Learning Rate: 0.1000 (0.1000) Top1_base: 78.9062 (78.5938) Top1_base_per_class: 81.3208 (78.6483) 
Training Epoch: [108/1000] Step: [30 / 285] Batch Time: 0.1460 (0.1863) Data Time: 0.0115 (0.0529) Average Loss: 0.6737 (0.7509) Average CE Loss (Source):  0.6737 ( 0.7509) Learning Rate: 0.1000 (0.1000) Top1_base: 77.3438 (79.0104) Top1_base_per_class: 79.6693 (79.2555) 
Training Epoch: [108/1000] Step: [40 / 285] Batch Time: 0.1520 (0.1794) Data Time: 0.0137 (0.0460) Average Loss: 0.6051 (0.7425) Average CE Loss (Source):  0.6051 ( 0.7425) Learning Rate: 0.1000 (0.1000) Top1_base: 81.2500 (79.2383) Top1_base_per_class: 84.9405 (80.0408) 
Training Epoch: [108/1000] Step: [50 / 285] Batch Time: 0.1444 (0.1740) Data Time: 0.0108 (0.0405) Average Loss: 0.5914 (0.7431) Average CE Loss (Source):  0.5914 ( 0.7431) Learning Rate: 0.1000 (0.1000) Top1_base: 82.8125 (79.0781) Top1_base_per_class: 83.6158 (79.6555) 
Training Epoch: [108/1000] Step: [60 / 285] Batch Time: 0.1517 (0.1714) Data Time: 0.0171 (0.0377) Average Loss: 0.5725 (0.7480) Average CE Loss (Source):  0.5725 ( 0.7480) Learning Rate: 0.1000 (0.1000) Top1_base: 79.6875 (78.9583) Top1_base_per_class: 83.9216 (79.5640) 
Training Epoch: [108/1000] Step: [70 / 285] Batch Time: 0.1442 (0.1687) Data Time: 0.0106 (0.0347) Average Loss: 0.8693 (0.7615) Average CE Loss (Source):  0.8693 ( 0.7615) Learning Rate: 0.1000 (0.1000) Top1_base: 75.7812 (78.6830) Top1_base_per_class: 74.2424 (79.1090) 
Training Epoch: [108/1000] Step: [80 / 285] Batch Time: 0.1419 (0.1663) Data Time: 0.0110 (0.0324) Average Loss: 0.8000 (0.7607) Average CE Loss (Source):  0.8000 ( 0.7607) Learning Rate: 0.1000 (0.1000) Top1_base: 79.6875 (78.8281) Top1_base_per_class: 76.2424 (79.1262) 
Training Epoch: [108/1000] Step: [90 / 285] Batch Time: 0.1447 (0.1654) Data Time: 0.0114 (0.0316) Average Loss: 0.5503 (0.7581) Average CE Loss (Source):  0.5503 ( 0.7581) Learning Rate: 0.1000 (0.1000) Top1_base: 86.7188 (78.9844) Top1_base_per_class: 84.6605 (79.2975) 
Training Epoch: [108/1000] Step: [100 / 285] Batch Time: 0.1427 (0.1642) Data Time: 0.0119 (0.0306) Average Loss: 0.8397 (0.7608) Average CE Loss (Source):  0.8397 ( 0.7608) Learning Rate: 0.1000 (0.1000) Top1_base: 80.4688 (79.0156) Top1_base_per_class: 80.0298 (79.4158) 
Training Epoch: [108/1000] Step: [110 / 285] Batch Time: 0.1441 (0.1639) Data Time: 0.0113 (0.0305) Average Loss: 0.6779 (0.7572) Average CE Loss (Source):  0.6779 ( 0.7572) Learning Rate: 0.1000 (0.1000) Top1_base: 81.2500 (79.1122) Top1_base_per_class: 81.9215 (79.5082) 
Training Epoch: [108/1000] Step: [120 / 285] Batch Time: 0.1474 (0.1626) Data Time: 0.0119 (0.0293) Average Loss: 0.8564 (0.7586) Average CE Loss (Source):  0.8564 ( 0.7586) Learning Rate: 0.1000 (0.1000) Top1_base: 76.5625 (79.0560) Top1_base_per_class: 75.7326 (79.4323) 
Training Epoch: [108/1000] Step: [130 / 285] Batch Time: 0.1420 (0.1623) Data Time: 0.0107 (0.0289) Average Loss: 0.8504 (0.7636) Average CE Loss (Source):  0.8504 ( 0.7636) Learning Rate: 0.1000 (0.1000) Top1_base: 78.9062 (78.8822) Top1_base_per_class: 82.2113 (79.2283) 
Training Epoch: [108/1000] Step: [140 / 285] Batch Time: 0.1503 (0.1612) Data Time: 0.0149 (0.0278) Average Loss: 0.6514 (0.7652) Average CE Loss (Source):  0.6514 ( 0.7652) Learning Rate: 0.1000 (0.1000) Top1_base: 82.8125 (78.8170) Top1_base_per_class: 84.6552 (79.1424) 
Training Epoch: [108/1000] Step: [150 / 285] Batch Time: 0.1465 (0.1610) Data Time: 0.0133 (0.0278) Average Loss: 0.9067 (0.7669) Average CE Loss (Source):  0.9067 ( 0.7669) Learning Rate: 0.1000 (0.1000) Top1_base: 74.2188 (78.7448) Top1_base_per_class: 70.9877 (79.1149) 
Training Epoch: [108/1000] Step: [160 / 285] Batch Time: 0.1408 (0.1606) Data Time: 0.0106 (0.0274) Average Loss: 0.7016 (0.7682) Average CE Loss (Source):  0.7016 ( 0.7682) Learning Rate: 0.1000 (0.1000) Top1_base: 79.6875 (78.6572) Top1_base_per_class: 79.1071 (79.0682) 
Training Epoch: [108/1000] Step: [170 / 285] Batch Time: 0.1435 (0.1606) Data Time: 0.0116 (0.0275) Average Loss: 0.7769 (0.7673) Average CE Loss (Source):  0.7769 ( 0.7673) Learning Rate: 0.1000 (0.1000) Top1_base: 69.5312 (78.6259) Top1_base_per_class: 66.0734 (78.9928) 
Training Epoch: [108/1000] Step: [180 / 285] Batch Time: 0.1420 (0.1608) Data Time: 0.0115 (0.0278) Average Loss: 0.8055 (0.7670) Average CE Loss (Source):  0.8055 ( 0.7670) Learning Rate: 0.1000 (0.1000) Top1_base: 78.1250 (78.5938) Top1_base_per_class: 81.2500 (78.8966) 
Training Epoch: [108/1000] Step: [190 / 285] Batch Time: 0.1458 (0.1605) Data Time: 0.0130 (0.0275) Average Loss: 0.8079 (0.7710) Average CE Loss (Source):  0.8079 ( 0.7710) Learning Rate: 0.1000 (0.1000) Top1_base: 78.9062 (78.4786) Top1_base_per_class: 78.6782 (78.8576) 
Training Epoch: [108/1000] Step: [200 / 285] Batch Time: 0.1410 (0.1603) Data Time: 0.0107 (0.0274) Average Loss: 0.9624 (0.7740) Average CE Loss (Source):  0.9624 ( 0.7740) Learning Rate: 0.1000 (0.1000) Top1_base: 72.6562 (78.4453) Top1_base_per_class: 73.8182 (78.9039) 
Training Epoch: [108/1000] Step: [210 / 285] Batch Time: 0.1465 (0.1596) Data Time: 0.0120 (0.0268) Average Loss: 0.7770 (0.7770) Average CE Loss (Source):  0.7770 ( 0.7770) Learning Rate: 0.1000 (0.1000) Top1_base: 78.9062 (78.3371) Top1_base_per_class: 82.4107 (78.8581) 
Training Epoch: [108/1000] Step: [220 / 285] Batch Time: 0.1472 (0.1591) Data Time: 0.0122 (0.0262) Average Loss: 0.7650 (0.7793) Average CE Loss (Source):  0.7650 ( 0.7793) Learning Rate: 0.1000 (0.1000) Top1_base: 78.9062 (78.2635) Top1_base_per_class: 81.9497 (78.8042) 
Training Epoch: [108/1000] Step: [230 / 285] Batch Time: 0.1420 (0.1585) Data Time: 0.0102 (0.0256) Average Loss: 0.8864 (0.7817) Average CE Loss (Source):  0.8864 ( 0.7817) Learning Rate: 0.1000 (0.1000) Top1_base: 75.0000 (78.1420) Top1_base_per_class: 73.3333 (78.7263) 
Training Epoch: [108/1000] Step: [240 / 285] Batch Time: 0.1507 (0.1580) Data Time: 0.0159 (0.0251) Average Loss: 0.6574 (0.7818) Average CE Loss (Source):  0.6574 ( 0.7818) Learning Rate: 0.1000 (0.1000) Top1_base: 77.3438 (78.1217) Top1_base_per_class: 72.8363 (78.6353) 
Training Epoch: [108/1000] Step: [250 / 285] Batch Time: 0.1448 (0.1576) Data Time: 0.0130 (0.0246) Average Loss: 0.8476 (0.7819) Average CE Loss (Source):  0.8476 ( 0.7819) Learning Rate: 0.1000 (0.1000) Top1_base: 77.3438 (78.0906) Top1_base_per_class: 79.7879 (78.6184) 
Training Epoch: [108/1000] Step: [260 / 285] Batch Time: 0.1475 (0.1572) Data Time: 0.0137 (0.0243) Average Loss: 0.7988 (0.7828) Average CE Loss (Source):  0.7988 ( 0.7828) Learning Rate: 0.1000 (0.1000) Top1_base: 80.4688 (78.0649) Top1_base_per_class: 86.1494 (78.6710) 
Training Epoch: [108/1000] Step: [270 / 285] Batch Time: 0.1957 (0.1573) Data Time: 0.0645 (0.0243) Average Loss: 0.8639 (0.7837) Average CE Loss (Source):  0.8639 ( 0.7837) Learning Rate: 0.1000 (0.1000) Top1_base: 82.8125 (78.0845) Top1_base_per_class: 84.0517 (78.6935) 
Training Epoch: [108/1000] Step: [280 / 285] Batch Time: 0.1479 (0.1572) Data Time: 0.0120 (0.0242) Average Loss: 0.5613 (0.7833) Average CE Loss (Source):  0.5613 ( 0.7833) Learning Rate: 0.1000 (0.1000) Top1_base: 81.2500 (78.0831) Top1_base_per_class: 81.9591 (78.7216) 
Training Epoch: [109/1000] Step: [0] Batch Time: 0.1429 (0.1573) Data Time: 0.0111 (0.0244) Average Loss: 0.9506 (0.7836) Average CE Loss (Source):  0.9506 ( 0.7836) Learning Rate: 0.1000 (0.1000) Top1_base: 71.0938 (78.0647) Top1_base_per_class: 71.8983 (78.7045) 
Training Epoch: [109/1000] Step: [10 / 285] Batch Time: 0.1433 (0.2346) Data Time: 0.0115 (0.1023) Average Loss: 0.5939 (0.6758) Average CE Loss (Source):  0.5939 ( 0.6758) Learning Rate: 0.1000 (0.1000) Top1_base: 82.0312 (81.4062) Top1_base_per_class: 85.1170 (82.6378) 
Training Epoch: [109/1000] Step: [20 / 285] Batch Time: 0.1435 (0.1957) Data Time: 0.0117 (0.0633) Average Loss: 0.7423 (0.6713) Average CE Loss (Source):  0.7423 ( 0.6713) Learning Rate: 0.1000 (0.1000) Top1_base: 81.2500 (81.2500) Top1_base_per_class: 80.3509 (81.5973) 
Training Epoch: [109/1000] Step: [30 / 285] Batch Time: 0.1422 (0.1818) Data Time: 0.0119 (0.0496) Average Loss: 0.6486 (0.6832) Average CE Loss (Source):  0.6486 ( 0.6832) Learning Rate: 0.1000 (0.1000) Top1_base: 82.0312 (80.9375) Top1_base_per_class: 82.0303 (81.2750) 
Training Epoch: [109/1000] Step: [40 / 285] Batch Time: 0.1437 (0.1756) Data Time: 0.0122 (0.0434) Average Loss: 0.7679 (0.6941) Average CE Loss (Source):  0.7679 ( 0.6941) Learning Rate: 0.1000 (0.1000) Top1_base: 73.4375 (80.6641) Top1_base_per_class: 72.2070 (80.7986) 
Training Epoch: [109/1000] Step: [50 / 285] Batch Time: 0.1450 (0.1739) Data Time: 0.0106 (0.0416) Average Loss: 0.5635 (0.7110) Average CE Loss (Source):  0.5635 ( 0.7110) Learning Rate: 0.1000 (0.1000) Top1_base: 86.7188 (80.2344) Top1_base_per_class: 87.0402 (80.3477) 
Training Epoch: [109/1000] Step: [60 / 285] Batch Time: 0.1445 (0.1701) Data Time: 0.0142 (0.0378) Average Loss: 0.6867 (0.7200) Average CE Loss (Source):  0.6867 ( 0.7200) Learning Rate: 0.1000 (0.1000) Top1_base: 79.6875 (79.8568) Top1_base_per_class: 79.2588 (79.6808) 
Training Epoch: [109/1000] Step: [70 / 285] Batch Time: 0.1419 (0.1675) Data Time: 0.0119 (0.0352) Average Loss: 0.6094 (0.7260) Average CE Loss (Source):  0.6094 ( 0.7260) Learning Rate: 0.1000 (0.1000) Top1_base: 79.6875 (79.5312) Top1_base_per_class: 77.5617 (79.3820) 
Training Epoch: [109/1000] Step: [80 / 285] Batch Time: 0.1463 (0.1665) Data Time: 0.0150 (0.0342) Average Loss: 0.7331 (0.7312) Average CE Loss (Source):  0.7331 ( 0.7312) Learning Rate: 0.1000 (0.1000) Top1_base: 80.4688 (79.5312) Top1_base_per_class: 83.0994 (79.4491) 
Training Epoch: [109/1000] Step: [90 / 285] Batch Time: 0.1454 (0.1655) Data Time: 0.0104 (0.0331) Average Loss: 0.9129 (0.7402) Average CE Loss (Source):  0.9129 ( 0.7402) Learning Rate: 0.1000 (0.1000) Top1_base: 74.2188 (79.2188) Top1_base_per_class: 72.6023 (79.3309) 
Training Epoch: [109/1000] Step: [100 / 285] Batch Time: 0.1430 (0.1639) Data Time: 0.0123 (0.0315) Average Loss: 0.6353 (0.7434) Average CE Loss (Source):  0.6353 ( 0.7434) Learning Rate: 0.1000 (0.1000) Top1_base: 82.8125 (79.2031) Top1_base_per_class: 87.9560 (79.4534) 
Training Epoch: [109/1000] Step: [110 / 285] Batch Time: 0.1448 (0.1637) Data Time: 0.0106 (0.0314) Average Loss: 0.9572 (0.7444) Average CE Loss (Source):  0.9572 ( 0.7444) Learning Rate: 0.1000 (0.1000) Top1_base: 71.8750 (79.1619) Top1_base_per_class: 72.9598 (79.4910) 
Training Epoch: [109/1000] Step: [120 / 285] Batch Time: 0.1482 (0.1632) Data Time: 0.0153 (0.0308) Average Loss: 1.1289 (0.7466) Average CE Loss (Source):  1.1289 ( 0.7466) Learning Rate: 0.1000 (0.1000) Top1_base: 67.1875 (79.1081) Top1_base_per_class: 69.3030 (79.4533) 
Training Epoch: [109/1000] Step: [130 / 285] Batch Time: 0.1435 (0.1627) Data Time: 0.0104 (0.0302) Average Loss: 0.5798 (0.7485) Average CE Loss (Source):  0.5798 ( 0.7485) Learning Rate: 0.1000 (0.1000) Top1_base: 82.8125 (79.0745) Top1_base_per_class: 84.1026 (79.3615) 
Training Epoch: [109/1000] Step: [140 / 285] Batch Time: 0.1432 (0.1625) Data Time: 0.0122 (0.0300) Average Loss: 0.7827 (0.7547) Average CE Loss (Source):  0.7827 ( 0.7547) Learning Rate: 0.1000 (0.1000) Top1_base: 79.6875 (78.9509) Top1_base_per_class: 78.7273 (79.2344) 
Training Epoch: [109/1000] Step: [150 / 285] Batch Time: 0.1445 (0.1628) Data Time: 0.0104 (0.0303) Average Loss: 0.7504 (0.7552) Average CE Loss (Source):  0.7504 ( 0.7552) Learning Rate: 0.1000 (0.1000) Top1_base: 74.2188 (78.8490) Top1_base_per_class: 74.9685 (79.2548) 
Training Epoch: [109/1000] Step: [160 / 285] Batch Time: 0.1433 (0.1618) Data Time: 0.0114 (0.0293) Average Loss: 0.6393 (0.7592) Average CE Loss (Source):  0.6393 ( 0.7592) Learning Rate: 0.1000 (0.1000) Top1_base: 82.8125 (78.7402) Top1_base_per_class: 79.4277 (79.0823) 
Training Epoch: [109/1000] Step: [170 / 285] Batch Time: 0.1438 (0.1623) Data Time: 0.0102 (0.0298) Average Loss: 0.7500 (0.7600) Average CE Loss (Source):  0.7500 ( 0.7600) Learning Rate: 0.1000 (0.1000) Top1_base: 78.9062 (78.6489) Top1_base_per_class: 78.0952 (79.0612) 
Training Epoch: [109/1000] Step: [180 / 285] Batch Time: 0.1438 (0.1616) Data Time: 0.0117 (0.0290) Average Loss: 0.7446 (0.7637) Average CE Loss (Source):  0.7446 ( 0.7637) Learning Rate: 0.1000 (0.1000) Top1_base: 77.3438 (78.4549) Top1_base_per_class: 80.2614 (78.9484) 
Training Epoch: [109/1000] Step: [190 / 285] Batch Time: 0.1426 (0.1612) Data Time: 0.0114 (0.0287) Average Loss: 0.8921 (0.7693) Average CE Loss (Source):  0.8921 ( 0.7693) Learning Rate: 0.1000 (0.1000) Top1_base: 78.1250 (78.2936) Top1_base_per_class: 81.1310 (78.7884) 
Training Epoch: [109/1000] Step: [200 / 285] Batch Time: 0.1467 (0.1607) Data Time: 0.0118 (0.0281) Average Loss: 0.6287 (0.7719) Average CE Loss (Source):  0.6287 ( 0.7719) Learning Rate: 0.1000 (0.1000) Top1_base: 82.0312 (78.2539) Top1_base_per_class: 81.2028 (78.7231) 
Training Epoch: [109/1000] Step: [210 / 285] Batch Time: 0.1474 (0.1606) Data Time: 0.0102 (0.0280) Average Loss: 0.7969 (0.7748) Average CE Loss (Source):  0.7969 ( 0.7748) Learning Rate: 0.1000 (0.1000) Top1_base: 76.5625 (78.1920) Top1_base_per_class: 78.5758 (78.6454) 
Training Epoch: [109/1000] Step: [220 / 285] Batch Time: 0.1460 (0.1600) Data Time: 0.0126 (0.0273) Average Loss: 0.6565 (0.7743) Average CE Loss (Source):  0.6565 ( 0.7743) Learning Rate: 0.1000 (0.1000) Top1_base: 81.2500 (78.1889) Top1_base_per_class: 82.2727 (78.6616) 
Training Epoch: [109/1000] Step: [230 / 285] Batch Time: 0.1469 (0.1598) Data Time: 0.0105 (0.0270) Average Loss: 1.1687 (0.7758) Average CE Loss (Source):  1.1687 ( 0.7758) Learning Rate: 0.1000 (0.1000) Top1_base: 61.7188 (78.1352) Top1_base_per_class: 58.5849 (78.6057) 
Training Epoch: [109/1000] Step: [240 / 285] Batch Time: 0.1472 (0.1596) Data Time: 0.0122 (0.0267) Average Loss: 0.7932 (0.7792) Average CE Loss (Source):  0.7932 ( 0.7792) Learning Rate: 0.1000 (0.1000) Top1_base: 78.1250 (78.0566) Top1_base_per_class: 79.9415 (78.5461) 
Training Epoch: [109/1000] Step: [250 / 285] Batch Time: 0.1468 (0.1596) Data Time: 0.0102 (0.0266) Average Loss: 0.8772 (0.7815) Average CE Loss (Source):  0.8772 ( 0.7815) Learning Rate: 0.1000 (0.1000) Top1_base: 79.6875 (77.9750) Top1_base_per_class: 79.2121 (78.4473) 
Training Epoch: [109/1000] Step: [260 / 285] Batch Time: 0.1443 (0.1595) Data Time: 0.0107 (0.0265) Average Loss: 0.6797 (0.7818) Average CE Loss (Source):  0.6797 ( 0.7818) Learning Rate: 0.1000 (0.1000) Top1_base: 80.4688 (77.9657) Top1_base_per_class: 81.6964 (78.4163) 
Training Epoch: [109/1000] Step: [270 / 285] Batch Time: 0.1428 (0.1595) Data Time: 0.0111 (0.0265) Average Loss: 0.7158 (0.7830) Average CE Loss (Source):  0.7158 ( 0.7830) Learning Rate: 0.1000 (0.1000) Top1_base: 78.1250 (77.9427) Top1_base_per_class: 81.2893 (78.4222) 
Training Epoch: [109/1000] Step: [280 / 285] Batch Time: 0.1441 (0.1594) Data Time: 0.0115 (0.0264) Average Loss: 0.8243 (0.7846) Average CE Loss (Source):  0.8243 ( 0.7846) Learning Rate: 0.1000 (0.1000) Top1_base: 75.0000 (77.9018) Top1_base_per_class: 75.5556 (78.3525) 
Training Epoch: [110/1000] Step: [0] Batch Time: 0.1419 (0.1592) Data Time: 0.0127 (0.0262) Average Loss: 1.0183 (0.7850) Average CE Loss (Source):  1.0183 ( 0.7850) Learning Rate: 0.1000 (0.1000) Top1_base: 76.5625 (77.8920) Top1_base_per_class: 80.1775 (78.3648) 
 11%|█         | 110/1000 [1:26:00<11:32:00, 46.65s/it] 11%|█         | 111/1000 [1:26:45<11:24:22, 46.19s/it]Training Epoch: [110/1000] Step: [10 / 285] Batch Time: 0.1445 (0.2390) Data Time: 0.0106 (0.1062) Average Loss: 0.7771 (0.7928) Average CE Loss (Source):  0.7771 ( 0.7928) Learning Rate: 0.1000 (0.1000) Top1_base: 80.4688 (78.5156) Top1_base_per_class: 80.5316 (78.8350) 
Training Epoch: [110/1000] Step: [20 / 285] Batch Time: 0.1475 (0.1957) Data Time: 0.0144 (0.0629) Average Loss: 0.9205 (0.7880) Average CE Loss (Source):  0.9205 ( 0.7880) Learning Rate: 0.1000 (0.1000) Top1_base: 71.8750 (77.1875) Top1_base_per_class: 71.1207 (77.3328) 
Training Epoch: [110/1000] Step: [30 / 285] Batch Time: 0.1476 (0.1832) Data Time: 0.0129 (0.0503) Average Loss: 0.7403 (0.7697) Average CE Loss (Source):  0.7403 ( 0.7697) Learning Rate: 0.1000 (0.1000) Top1_base: 75.0000 (77.8906) Top1_base_per_class: 71.0758 (77.7605) 
Training Epoch: [110/1000] Step: [40 / 285] Batch Time: 0.1478 (0.1768) Data Time: 0.0149 (0.0437) Average Loss: 0.6223 (0.7589) Average CE Loss (Source):  0.6223 ( 0.7589) Learning Rate: 0.1000 (0.1000) Top1_base: 84.3750 (78.6523) Top1_base_per_class: 83.4211 (78.8445) 
Training Epoch: [110/1000] Step: [50 / 285] Batch Time: 0.1446 (0.1740) Data Time: 0.0103 (0.0408) Average Loss: 0.7180 (0.7581) Average CE Loss (Source):  0.7180 ( 0.7581) Learning Rate: 0.1000 (0.1000) Top1_base: 75.0000 (78.6250) Top1_base_per_class: 73.0556 (78.8491) 
Training Epoch: [110/1000] Step: [60 / 285] Batch Time: 0.1465 (0.1727) Data Time: 0.0111 (0.0395) Average Loss: 0.5532 (0.7556) Average CE Loss (Source):  0.5532 ( 0.7556) Learning Rate: 0.1000 (0.1000) Top1_base: 84.3750 (78.5807) Top1_base_per_class: 83.2768 (78.7287) 
Training Epoch: [110/1000] Step: [70 / 285] Batch Time: 0.1464 (0.1707) Data Time: 0.0105 (0.0374) Average Loss: 0.6272 (0.7445) Average CE Loss (Source):  0.6272 ( 0.7445) Learning Rate: 0.1000 (0.1000) Top1_base: 83.5938 (78.9621) Top1_base_per_class: 84.7321 (79.0983) 
Training Epoch: [110/1000] Step: [80 / 285] Batch Time: 0.1464 (0.1697) Data Time: 0.0133 (0.0364) Average Loss: 0.7309 (0.7436) Average CE Loss (Source):  0.7309 ( 0.7436) Learning Rate: 0.1000 (0.1000) Top1_base: 82.0312 (79.1504) Top1_base_per_class: 80.8908 (79.2095) 
Training Epoch: [110/1000] Step: [90 / 285] Batch Time: 0.1443 (0.1693) Data Time: 0.0105 (0.0360) Average Loss: 0.6631 (0.7443) Average CE Loss (Source):  0.6631 ( 0.7443) Learning Rate: 0.1000 (0.1000) Top1_base: 83.5938 (79.1840) Top1_base_per_class: 85.5644 (79.3907) 
Training Epoch: [110/1000] Step: [100 / 285] Batch Time: 0.1460 (0.1671) Data Time: 0.0134 (0.0338) Average Loss: 0.6923 (0.7471) Average CE Loss (Source):  0.6923 ( 0.7471) Learning Rate: 0.1000 (0.1000) Top1_base: 80.4688 (79.1797) Top1_base_per_class: 79.5455 (79.4176) 
Training Epoch: [110/1000] Step: [110 / 285] Batch Time: 0.1445 (0.1678) Data Time: 0.0121 (0.0345) Average Loss: 0.7534 (0.7459) Average CE Loss (Source):  0.7534 ( 0.7459) Learning Rate: 0.1000 (0.1000) Top1_base: 75.7812 (79.1832) Top1_base_per_class: 73.7427 (79.3623) 
Training Epoch: [110/1000] Step: [120 / 285] Batch Time: 0.1456 (0.1664) Data Time: 0.0124 (0.0331) Average Loss: 0.7142 (0.7492) Average CE Loss (Source):  0.7142 ( 0.7492) Learning Rate: 0.1000 (0.1000) Top1_base: 80.4688 (79.1602) Top1_base_per_class: 80.6378 (79.4421) 
Training Epoch: [110/1000] Step: [130 / 285] Batch Time: 0.1461 (0.1649) Data Time: 0.0122 (0.0316) Average Loss: 0.8992 (0.7535) Average CE Loss (Source):  0.8992 ( 0.7535) Learning Rate: 0.1000 (0.1000) Top1_base: 71.0938 (78.9724) Top1_base_per_class: 70.6244 (79.3135) 
Training Epoch: [110/1000] Step: [140 / 285] Batch Time: 0.1454 (0.1636) Data Time: 0.0124 (0.0304) Average Loss: 0.8977 (0.7574) Average CE Loss (Source):  0.8977 ( 0.7574) Learning Rate: 0.1000 (0.1000) Top1_base: 77.3438 (78.8616) Top1_base_per_class: 79.7531 (79.3318) 
Training Epoch: [110/1000] Step: [150 / 285] Batch Time: 0.1484 (0.1626) Data Time: 0.0135 (0.0293) Average Loss: 0.8119 (0.7566) Average CE Loss (Source):  0.8119 ( 0.7566) Learning Rate: 0.1000 (0.1000) Top1_base: 78.9062 (78.8750) Top1_base_per_class: 76.2727 (79.3730) 
Training Epoch: [110/1000] Step: [160 / 285] Batch Time: 0.1447 (0.1616) Data Time: 0.0133 (0.0283) Average Loss: 0.8158 (0.7562) Average CE Loss (Source):  0.8158 ( 0.7562) Learning Rate: 0.1000 (0.1000) Top1_base: 77.3438 (78.9258) Top1_base_per_class: 79.7273 (79.4285) 
Training Epoch: [110/1000] Step: [170 / 285] Batch Time: 0.1428 (0.1607) Data Time: 0.0120 (0.0275) Average Loss: 0.8265 (0.7563) Average CE Loss (Source):  0.8265 ( 0.7563) Learning Rate: 0.1000 (0.1000) Top1_base: 74.2188 (78.8465) Top1_base_per_class: 70.9477 (79.2805) 
Training Epoch: [110/1000] Step: [180 / 285] Batch Time: 0.1487 (0.1599) Data Time: 0.0159 (0.0267) Average Loss: 0.7290 (0.7610) Average CE Loss (Source):  0.7290 ( 0.7610) Learning Rate: 0.1000 (0.1000) Top1_base: 79.6875 (78.7760) Top1_base_per_class: 79.4335 (79.2486) 
Training Epoch: [110/1000] Step: [190 / 285] Batch Time: 0.1433 (0.1594) Data Time: 0.0104 (0.0263) Average Loss: 0.7000 (0.7614) Average CE Loss (Source):  0.7000 ( 0.7614) Learning Rate: 0.1000 (0.1000) Top1_base: 78.1250 (78.7952) Top1_base_per_class: 76.7241 (79.2882) 
Training Epoch: [110/1000] Step: [200 / 285] Batch Time: 0.1825 (0.1591) Data Time: 0.0481 (0.0259) Average Loss: 0.8130 (0.7625) Average CE Loss (Source):  0.8130 ( 0.7625) Learning Rate: 0.1000 (0.1000) Top1_base: 78.1250 (78.7617) Top1_base_per_class: 79.1212 (79.2707) 
Training Epoch: [110/1000] Step: [210 / 285] Batch Time: 0.1436 (0.1588) Data Time: 0.0119 (0.0256) Average Loss: 0.8997 (0.7657) Average CE Loss (Source):  0.8997 ( 0.7657) Learning Rate: 0.1000 (0.1000) Top1_base: 76.5625 (78.7202) Top1_base_per_class: 76.7544 (79.2547) 
Training Epoch: [110/1000] Step: [220 / 285] Batch Time: 0.1502 (0.1586) Data Time: 0.0170 (0.0255) Average Loss: 0.7693 (0.7673) Average CE Loss (Source):  0.7693 ( 0.7673) Learning Rate: 0.1000 (0.1000) Top1_base: 71.0938 (78.6186) Top1_base_per_class: 73.1035 (79.1969) 
Training Epoch: [110/1000] Step: [230 / 285] Batch Time: 0.1459 (0.1582) Data Time: 0.0122 (0.0251) Average Loss: 0.6799 (0.7684) Average CE Loss (Source):  0.6799 ( 0.7684) Learning Rate: 0.1000 (0.1000) Top1_base: 77.3438 (78.5292) Top1_base_per_class: 77.9598 (79.0864) 
Training Epoch: [110/1000] Step: [240 / 285] Batch Time: 0.1758 (0.1580) Data Time: 0.0443 (0.0248) Average Loss: 0.8703 (0.7694) Average CE Loss (Source):  0.8703 ( 0.7694) Learning Rate: 0.1000 (0.1000) Top1_base: 70.3125 (78.4570) Top1_base_per_class: 73.3621 (79.0087) 
Training Epoch: [110/1000] Step: [250 / 285] Batch Time: 0.1481 (0.1579) Data Time: 0.0140 (0.0248) Average Loss: 0.9965 (0.7719) Average CE Loss (Source):  0.9965 ( 0.7719) Learning Rate: 0.1000 (0.1000) Top1_base: 71.0938 (78.3844) Top1_base_per_class: 74.9191 (78.9601) 
Training Epoch: [110/1000] Step: [260 / 285] Batch Time: 0.1775 (0.1581) Data Time: 0.0466 (0.0250) Average Loss: 0.8442 (0.7729) Average CE Loss (Source):  0.8442 ( 0.7729) Learning Rate: 0.1000 (0.1000) Top1_base: 71.0938 (78.3594) Top1_base_per_class: 72.2531 (78.9010) 
Training Epoch: [110/1000] Step: [270 / 285] Batch Time: 0.1464 (0.1578) Data Time: 0.0119 (0.0247) Average Loss: 1.1296 (0.7762) Average CE Loss (Source):  1.1296 ( 0.7762) Learning Rate: 0.1000 (0.1000) Top1_base: 64.0625 (78.2668) Top1_base_per_class: 59.6676 (78.8107) 
Training Epoch: [110/1000] Step: [280 / 285] Batch Time: 0.2414 (0.1583) Data Time: 0.1082 (0.0251) Average Loss: 0.6475 (0.7768) Average CE Loss (Source):  0.6475 ( 0.7768) Learning Rate: 0.1000 (0.1000) Top1_base: 82.8125 (78.2812) Top1_base_per_class: 83.3046 (78.8360) 
Training Epoch: [111/1000] Step: [0] Batch Time: 0.1413 (0.1581) Data Time: 0.0099 (0.0250) Average Loss: 0.6560 (0.7772) Average CE Loss (Source):  0.6560 ( 0.7772) Learning Rate: 0.1000 (0.1000) Top1_base: 78.9062 (78.2484) Top1_base_per_class: 80.5032 (78.7721) 
Training Epoch: [111/1000] Step: [10 / 285] Batch Time: 0.1465 (0.2375) Data Time: 0.0148 (0.1044) Average Loss: 0.6542 (0.7604) Average CE Loss (Source):  0.6542 ( 0.7604) Learning Rate: 0.1000 (0.1000) Top1_base: 79.6875 (79.0625) Top1_base_per_class: 75.0847 (78.9065) 
Training Epoch: [111/1000] Step: [20 / 285] Batch Time: 0.1469 (0.1976) Data Time: 0.0129 (0.0645) Average Loss: 0.6895 (0.7762) Average CE Loss (Source):  0.6895 ( 0.7762) Learning Rate: 0.1000 (0.1000) Top1_base: 79.6875 (77.8906) Top1_base_per_class: 80.4598 (78.4538) 
Training Epoch: [111/1000] Step: [30 / 285] Batch Time: 0.1469 (0.1821) Data Time: 0.0152 (0.0489) Average Loss: 0.6917 (0.7651) Average CE Loss (Source):  0.6917 ( 0.7651) Learning Rate: 0.1000 (0.1000) Top1_base: 82.0312 (78.5156) Top1_base_per_class: 85.5172 (79.0598) 
Training Epoch: [111/1000] Step: [40 / 285] Batch Time: 0.1474 (0.1784) Data Time: 0.0131 (0.0450) Average Loss: 0.6354 (0.7461) Average CE Loss (Source):  0.6354 ( 0.7461) Learning Rate: 0.1000 (0.1000) Top1_base: 80.4688 (79.0039) Top1_base_per_class: 80.8974 (79.8350) 
Training Epoch: [111/1000] Step: [50 / 285] Batch Time: 0.1443 (0.1749) Data Time: 0.0133 (0.0415) Average Loss: 0.6971 (0.7446) Average CE Loss (Source):  0.6971 ( 0.7446) Learning Rate: 0.1000 (0.1000) Top1_base: 80.4688 (79.1719) Top1_base_per_class: 79.0179 (79.8278) 
Training Epoch: [111/1000] Step: [60 / 285] Batch Time: 0.1477 (0.1710) Data Time: 0.0122 (0.0375) Average Loss: 0.6819 (0.7478) Average CE Loss (Source):  0.6819 ( 0.7478) Learning Rate: 0.1000 (0.1000) Top1_base: 78.1250 (78.9714) Top1_base_per_class: 80.0000 (79.5791) 
Training Epoch: [111/1000] Step: [70 / 285] Batch Time: 0.1460 (0.1701) Data Time: 0.0125 (0.0366) Average Loss: 0.6838 (0.7484) Average CE Loss (Source):  0.6838 ( 0.7484) Learning Rate: 0.1000 (0.1000) Top1_base: 81.2500 (78.8728) Top1_base_per_class: 83.4795 (79.5055) 
Training Epoch: [111/1000] Step: [80 / 285] Batch Time: 0.1460 (0.1680) Data Time: 0.0130 (0.0346) Average Loss: 1.0935 (0.7672) Average CE Loss (Source):  1.0935 ( 0.7672) Learning Rate: 0.1000 (0.1000) Top1_base: 71.8750 (78.4082) Top1_base_per_class: 73.7356 (79.0965) 
Training Epoch: [111/1000] Step: [90 / 285] Batch Time: 0.1452 (0.1685) Data Time: 0.0108 (0.0350) Average Loss: 0.6009 (0.7668) Average CE Loss (Source):  0.6009 ( 0.7668) Learning Rate: 0.1000 (0.1000) Top1_base: 82.0312 (78.3681) Top1_base_per_class: 81.4881 (79.0680) 
Training Epoch: [111/1000] Step: [100 / 285] Batch Time: 0.1480 (0.1674) Data Time: 0.0124 (0.0339) Average Loss: 0.7451 (0.7626) Average CE Loss (Source):  0.7451 ( 0.7626) Learning Rate: 0.1000 (0.1000) Top1_base: 78.9062 (78.4141) Top1_base_per_class: 80.7759 (79.0733) 
Training Epoch: [111/1000] Step: [110 / 285] Batch Time: 0.1439 (0.1669) Data Time: 0.0114 (0.0333) Average Loss: 0.9280 (0.7648) Average CE Loss (Source):  0.9280 ( 0.7648) Learning Rate: 0.1000 (0.1000) Top1_base: 71.8750 (78.3381) Top1_base_per_class: 72.8274 (78.9139) 
Training Epoch: [111/1000] Step: [120 / 285] Batch Time: 0.1477 (0.1660) Data Time: 0.0135 (0.0325) Average Loss: 0.7526 (0.7645) Average CE Loss (Source):  0.7526 ( 0.7645) Learning Rate: 0.1000 (0.1000) Top1_base: 75.7812 (78.3724) Top1_base_per_class: 73.0226 (78.8643) 
Training Epoch: [111/1000] Step: [130 / 285] Batch Time: 0.1440 (0.1652) Data Time: 0.0121 (0.0316) Average Loss: 0.5886 (0.7611) Average CE Loss (Source):  0.5886 ( 0.7611) Learning Rate: 0.1000 (0.1000) Top1_base: 81.2500 (78.4435) Top1_base_per_class: 81.7500 (78.9842) 
Training Epoch: [111/1000] Step: [140 / 285] Batch Time: 0.1478 (0.1640) Data Time: 0.0121 (0.0305) Average Loss: 0.6961 (0.7651) Average CE Loss (Source):  0.6961 ( 0.7651) Learning Rate: 0.1000 (0.1000) Top1_base: 81.2500 (78.2812) Top1_base_per_class: 81.6667 (78.8441) 
Training Epoch: [111/1000] Step: [150 / 285] Batch Time: 0.1435 (0.1642) Data Time: 0.0118 (0.0307) Average Loss: 0.6747 (0.7657) Average CE Loss (Source):  0.6747 ( 0.7657) Learning Rate: 0.1000 (0.1000) Top1_base: 81.2500 (78.2969) Top1_base_per_class: 81.1703 (78.8893) 
Training Epoch: [111/1000] Step: [160 / 285] Batch Time: 0.1493 (0.1644) Data Time: 0.0159 (0.0309) Average Loss: 1.0047 (0.7674) Average CE Loss (Source):  1.0047 ( 0.7674) Learning Rate: 0.1000 (0.1000) Top1_base: 75.0000 (78.2910) Top1_base_per_class: 79.1049 (78.8800) 
Training Epoch: [111/1000] Step: [170 / 285] Batch Time: 0.1429 (0.1635) Data Time: 0.0110 (0.0301) Average Loss: 0.6460 (0.7655) Average CE Loss (Source):  0.6460 ( 0.7655) Learning Rate: 0.1000 (0.1000) Top1_base: 83.5938 (78.3915) Top1_base_per_class: 83.9308 (78.9737) 
Training Epoch: [111/1000] Step: [180 / 285] Batch Time: 0.1468 (0.1632) Data Time: 0.0143 (0.0298) Average Loss: 0.7015 (0.7650) Average CE Loss (Source):  0.7015 ( 0.7650) Learning Rate: 0.1000 (0.1000) Top1_base: 80.4688 (78.3507) Top1_base_per_class: 83.6859 (78.9406) 
Training Epoch: [111/1000] Step: [190 / 285] Batch Time: 0.1430 (0.1629) Data Time: 0.0111 (0.0295) Average Loss: 0.6327 (0.7653) Average CE Loss (Source):  0.6327 ( 0.7653) Learning Rate: 0.1000 (0.1000) Top1_base: 81.2500 (78.2812) Top1_base_per_class: 77.0755 (78.8831) 
Training Epoch: [111/1000] Step: [200 / 285] Batch Time: 0.1485 (0.1624) Data Time: 0.0140 (0.0289) Average Loss: 0.8463 (0.7716) Average CE Loss (Source):  0.8463 ( 0.7716) Learning Rate: 0.1000 (0.1000) Top1_base: 77.3438 (78.1172) Top1_base_per_class: 74.7273 (78.7271) 
Training Epoch: [111/1000] Step: [210 / 285] Batch Time: 0.1453 (0.1620) Data Time: 0.0127 (0.0285) Average Loss: 0.7448 (0.7761) Average CE Loss (Source):  0.7448 ( 0.7761) Learning Rate: 0.1000 (0.1000) Top1_base: 78.9062 (78.0171) Top1_base_per_class: 80.0575 (78.6052) 
Training Epoch: [111/1000] Step: [220 / 285] Batch Time: 0.1478 (0.1616) Data Time: 0.0136 (0.0280) Average Loss: 0.8932 (0.7775) Average CE Loss (Source):  0.8932 ( 0.7775) Learning Rate: 0.1000 (0.1000) Top1_base: 78.1250 (78.0504) Top1_base_per_class: 80.2299 (78.6586) 
Training Epoch: [111/1000] Step: [230 / 285] Batch Time: 0.1416 (0.1619) Data Time: 0.0110 (0.0284) Average Loss: 0.7900 (0.7765) Average CE Loss (Source):  0.7900 ( 0.7765) Learning Rate: 0.1000 (0.1000) Top1_base: 76.5625 (78.0639) Top1_base_per_class: 72.1605 (78.6166) 
Training Epoch: [111/1000] Step: [240 / 285] Batch Time: 0.1507 (0.1616) Data Time: 0.0145 (0.0281) Average Loss: 0.9537 (0.7764) Average CE Loss (Source):  0.9537 ( 0.7764) Learning Rate: 0.1000 (0.1000) Top1_base: 74.2188 (78.0957) Top1_base_per_class: 77.1930 (78.6055) 
Training Epoch: [111/1000] Step: [250 / 285] Batch Time: 0.1429 (0.1618) Data Time: 0.0106 (0.0282) Average Loss: 1.0881 (0.7789) Average CE Loss (Source):  1.0881 ( 0.7789) Learning Rate: 0.1000 (0.1000) Top1_base: 67.9688 (78.0281) Top1_base_per_class: 68.3036 (78.5520) 
Training Epoch: [111/1000] Step: [260 / 285] Batch Time: 0.1485 (0.1615) Data Time: 0.0144 (0.0279) Average Loss: 0.9727 (0.7796) Average CE Loss (Source):  0.9727 ( 0.7796) Learning Rate: 0.1000 (0.1000) Top1_base: 74.2188 (78.0168) Top1_base_per_class: 75.7759 (78.5322) 
Training Epoch: [111/1000] Step: [270 / 285] Batch Time: 0.1400 (0.1612) Data Time: 0.0100 (0.0277) Average Loss: 0.8133 (0.7799) Average CE Loss (Source):  0.8133 ( 0.7799) Learning Rate: 0.1000 (0.1000) Top1_base: 78.1250 (78.0816) Top1_base_per_class: 80.1307 (78.6388) 
Training Epoch: [111/1000] Step: [280 / 285] Batch Time: 0.1492 (0.1607) Data Time: 0.0148 (0.0272) Average Loss: 0.7829 (0.7799) Average CE Loss (Source):  0.7829 ( 0.7799) Learning Rate: 0.1000 (0.1000) Top1_base: 78.9062 (78.0859) Top1_base_per_class: 78.9697 (78.6178) 
Training Epoch: [112/1000] Step: [0] Batch Time: 0.1637 (0.1606) Data Time: 0.0336 (0.0271) Average Loss: 0.7652 (0.7800) Average CE Loss (Source):  0.7652 ( 0.7800) Learning Rate: 0.1000 (0.1000) Top1_base: 76.5625 (78.0565) Top1_base_per_class: 77.0075 (78.5968) 
 11%|█         | 112/1000 [1:27:33<11:33:51, 46.88s/it] 11%|█▏        | 113/1000 [1:28:18<11:23:23, 46.23s/it]Training Epoch: [112/1000] Step: [10 / 285] Batch Time: 0.1438 (0.2451) Data Time: 0.0103 (0.1128) Average Loss: 0.5054 (0.7155) Average CE Loss (Source):  0.5054 ( 0.7155) Learning Rate: 0.1000 (0.1000) Top1_base: 82.8125 (78.9844) Top1_base_per_class: 81.3506 (79.7483) 
Training Epoch: [112/1000] Step: [20 / 285] Batch Time: 0.1482 (0.2004) Data Time: 0.0137 (0.0679) Average Loss: 0.6864 (0.7234) Average CE Loss (Source):  0.6864 ( 0.7234) Learning Rate: 0.1000 (0.1000) Top1_base: 79.6875 (78.9062) Top1_base_per_class: 81.5033 (78.9438) 
Training Epoch: [112/1000] Step: [30 / 285] Batch Time: 0.1472 (0.1875) Data Time: 0.0107 (0.0539) Average Loss: 0.7620 (0.7318) Average CE Loss (Source):  0.7620 ( 0.7318) Learning Rate: 0.1000 (0.1000) Top1_base: 75.7812 (78.6719) Top1_base_per_class: 78.1173 (78.6563) 
Training Epoch: [112/1000] Step: [40 / 285] Batch Time: 0.1482 (0.1798) Data Time: 0.0144 (0.0463) Average Loss: 0.7465 (0.7524) Average CE Loss (Source):  0.7465 ( 0.7524) Learning Rate: 0.1000 (0.1000) Top1_base: 77.3438 (78.1836) Top1_base_per_class: 77.3446 (78.0102) 
Training Epoch: [112/1000] Step: [50 / 285] Batch Time: 0.1455 (0.1760) Data Time: 0.0114 (0.0426) Average Loss: 0.6008 (0.7496) Average CE Loss (Source):  0.6008 ( 0.7496) Learning Rate: 0.1000 (0.1000) Top1_base: 82.8125 (78.3125) Top1_base_per_class: 82.1264 (78.3205) 
Training Epoch: [112/1000] Step: [60 / 285] Batch Time: 0.1490 (0.1712) Data Time: 0.0169 (0.0378) Average Loss: 0.9834 (0.7541) Average CE Loss (Source):  0.9834 ( 0.7541) Learning Rate: 0.1000 (0.1000) Top1_base: 70.3125 (78.2161) Top1_base_per_class: 68.3333 (78.1792) 
Training Epoch: [112/1000] Step: [70 / 285] Batch Time: 0.1434 (0.1679) Data Time: 0.0108 (0.0347) Average Loss: 0.7705 (0.7489) Average CE Loss (Source):  0.7705 ( 0.7489) Learning Rate: 0.1000 (0.1000) Top1_base: 79.6875 (78.4152) Top1_base_per_class: 81.6624 (78.5660) 
Training Epoch: [112/1000] Step: [80 / 285] Batch Time: 0.1498 (0.1653) Data Time: 0.0165 (0.0321) Average Loss: 0.9840 (0.7523) Average CE Loss (Source):  0.9840 ( 0.7523) Learning Rate: 0.1000 (0.1000) Top1_base: 75.7812 (78.3887) Top1_base_per_class: 78.5000 (78.5939) 
Training Epoch: [112/1000] Step: [90 / 285] Batch Time: 0.1429 (0.1647) Data Time: 0.0110 (0.0316) Average Loss: 1.1929 (0.7642) Average CE Loss (Source):  1.1929 ( 0.7642) Learning Rate: 0.1000 (0.1000) Top1_base: 64.8438 (78.0990) Top1_base_per_class: 70.8491 (78.3723) 
Training Epoch: [112/1000] Step: [100 / 285] Batch Time: 0.2147 (0.1644) Data Time: 0.0804 (0.0311) Average Loss: 0.7024 (0.7672) Average CE Loss (Source):  0.7024 ( 0.7672) Learning Rate: 0.1000 (0.1000) Top1_base: 79.6875 (78.0781) Top1_base_per_class: 76.2147 (78.2671) 
Training Epoch: [112/1000] Step: [110 / 285] Batch Time: 0.1478 (0.1634) Data Time: 0.0119 (0.0299) Average Loss: 0.7323 (0.7700) Average CE Loss (Source):  0.7323 ( 0.7700) Learning Rate: 0.1000 (0.1000) Top1_base: 79.6875 (78.1179) Top1_base_per_class: 83.3036 (78.3320) 
Training Epoch: [112/1000] Step: [120 / 285] Batch Time: 0.1500 (0.1633) Data Time: 0.0159 (0.0297) Average Loss: 0.7689 (0.7699) Average CE Loss (Source):  0.7689 ( 0.7699) Learning Rate: 0.1000 (0.1000) Top1_base: 78.9062 (78.2096) Top1_base_per_class: 78.8690 (78.4954) 
Training Epoch: [112/1000] Step: [130 / 285] Batch Time: 0.1467 (0.1621) Data Time: 0.0110 (0.0283) Average Loss: 0.6342 (0.7707) Average CE Loss (Source):  0.6342 ( 0.7707) Learning Rate: 0.1000 (0.1000) Top1_base: 81.2500 (78.1911) Top1_base_per_class: 81.7816 (78.4786) 
Training Epoch: [112/1000] Step: [140 / 285] Batch Time: 0.1502 (0.1609) Data Time: 0.0154 (0.0273) Average Loss: 0.9676 (0.7686) Average CE Loss (Source):  0.9676 ( 0.7686) Learning Rate: 0.1000 (0.1000) Top1_base: 74.2188 (78.2422) Top1_base_per_class: 78.2748 (78.5749) 
Training Epoch: [112/1000] Step: [150 / 285] Batch Time: 0.1474 (0.1600) Data Time: 0.0110 (0.0263) Average Loss: 0.8898 (0.7688) Average CE Loss (Source):  0.8898 ( 0.7688) Learning Rate: 0.1000 (0.1000) Top1_base: 71.0938 (78.2188) Top1_base_per_class: 70.6816 (78.5651) 
Training Epoch: [112/1000] Step: [160 / 285] Batch Time: 0.1460 (0.1592) Data Time: 0.0133 (0.0255) Average Loss: 0.7440 (0.7655) Average CE Loss (Source):  0.7440 ( 0.7655) Learning Rate: 0.1000 (0.1000) Top1_base: 76.5625 (78.3496) Top1_base_per_class: 78.0189 (78.7121) 
Training Epoch: [112/1000] Step: [170 / 285] Batch Time: 0.1434 (0.1584) Data Time: 0.0116 (0.0247) Average Loss: 0.6905 (0.7647) Average CE Loss (Source):  0.6905 ( 0.7647) Learning Rate: 0.1000 (0.1000) Top1_base: 82.0312 (78.4467) Top1_base_per_class: 80.6790 (78.8516) 
Training Epoch: [112/1000] Step: [180 / 285] Batch Time: 0.1485 (0.1577) Data Time: 0.0143 (0.0241) Average Loss: 0.8479 (0.7650) Average CE Loss (Source):  0.8479 ( 0.7650) Learning Rate: 0.1000 (0.1000) Top1_base: 78.9062 (78.5113) Top1_base_per_class: 77.8491 (78.9269) 
Training Epoch: [112/1000] Step: [190 / 285] Batch Time: 0.1425 (0.1571) Data Time: 0.0116 (0.0236) Average Loss: 0.8529 (0.7678) Average CE Loss (Source):  0.8529 ( 0.7678) Learning Rate: 0.1000 (0.1000) Top1_base: 78.1250 (78.3882) Top1_base_per_class: 78.4481 (78.7967) 
Training Epoch: [112/1000] Step: [200 / 285] Batch Time: 0.1484 (0.1568) Data Time: 0.0158 (0.0232) Average Loss: 0.8428 (0.7700) Average CE Loss (Source):  0.8428 ( 0.7700) Learning Rate: 0.1000 (0.1000) Top1_base: 75.7812 (78.3750) Top1_base_per_class: 75.0000 (78.8016) 
Training Epoch: [112/1000] Step: [210 / 285] Batch Time: 0.1443 (0.1564) Data Time: 0.0107 (0.0229) Average Loss: 0.7811 (0.7688) Average CE Loss (Source):  0.7811 ( 0.7688) Learning Rate: 0.1000 (0.1000) Top1_base: 76.5625 (78.3891) Top1_base_per_class: 74.1228 (78.8391) 
Training Epoch: [112/1000] Step: [220 / 285] Batch Time: 0.1689 (0.1568) Data Time: 0.0367 (0.0233) Average Loss: 0.9150 (0.7686) Average CE Loss (Source):  0.9150 ( 0.7686) Learning Rate: 0.1000 (0.1000) Top1_base: 76.5625 (78.4517) Top1_base_per_class: 75.5357 (78.8866) 
Training Epoch: [112/1000] Step: [230 / 285] Batch Time: 0.1451 (0.1570) Data Time: 0.0109 (0.0234) Average Loss: 0.8982 (0.7689) Average CE Loss (Source):  0.8982 ( 0.7689) Learning Rate: 0.1000 (0.1000) Top1_base: 72.6562 (78.4273) Top1_base_per_class: 72.7678 (78.8464) 
Training Epoch: [112/1000] Step: [240 / 285] Batch Time: 0.1474 (0.1568) Data Time: 0.0164 (0.0233) Average Loss: 0.4974 (0.7679) Average CE Loss (Source):  0.4974 ( 0.7679) Learning Rate: 0.1000 (0.1000) Top1_base: 86.7188 (78.4505) Top1_base_per_class: 86.4583 (78.9034) 
Training Epoch: [112/1000] Step: [250 / 285] Batch Time: 0.1451 (0.1567) Data Time: 0.0130 (0.0232) Average Loss: 0.7356 (0.7687) Average CE Loss (Source):  0.7356 ( 0.7687) Learning Rate: 0.1000 (0.1000) Top1_base: 78.1250 (78.4219) Top1_base_per_class: 82.3117 (78.8859) 
Training Epoch: [112/1000] Step: [260 / 285] Batch Time: 0.2345 (0.1569) Data Time: 0.1037 (0.0234) Average Loss: 1.1787 (0.7736) Average CE Loss (Source):  1.1787 ( 0.7736) Learning Rate: 0.1000 (0.1000) Top1_base: 71.0938 (78.2632) Top1_base_per_class: 75.7304 (78.8010) 
Training Epoch: [112/1000] Step: [270 / 285] Batch Time: 0.1466 (0.1567) Data Time: 0.0113 (0.0233) Average Loss: 1.0701 (0.7756) Average CE Loss (Source):  1.0701 ( 0.7756) Learning Rate: 0.1000 (0.1000) Top1_base: 75.7812 (78.2089) Top1_base_per_class: 75.6845 (78.7514) 
Training Epoch: [112/1000] Step: [280 / 285] Batch Time: 0.2127 (0.1569) Data Time: 0.0804 (0.0235) Average Loss: 0.7606 (0.7762) Average CE Loss (Source):  0.7606 ( 0.7762) Learning Rate: 0.1000 (0.1000) Top1_base: 76.5625 (78.2059) Top1_base_per_class: 73.0503 (78.7176) 
Training Epoch: [113/1000] Step: [0] Batch Time: 0.1386 (0.1566) Data Time: 0.0095 (0.0232) Average Loss: 1.1159 (0.7765) Average CE Loss (Source):  1.1159 ( 0.7765) Learning Rate: 0.1000 (0.1000) Top1_base: 72.6562 (78.1826) Top1_base_per_class: 75.6725 (78.7193) 
Training Epoch: [113/1000] Step: [10 / 285] Batch Time: 0.1471 (0.2457) Data Time: 0.0104 (0.1098) Average Loss: 0.7363 (0.6946) Average CE Loss (Source):  0.7363 ( 0.6946) Learning Rate: 0.1000 (0.1000) Top1_base: 77.3438 (80.1562) Top1_base_per_class: 78.7202 (81.1813) 
Training Epoch: [113/1000] Step: [20 / 285] Batch Time: 0.1505 (0.2003) Data Time: 0.0136 (0.0645) Average Loss: 0.8310 (0.7481) Average CE Loss (Source):  0.8310 ( 0.7481) Learning Rate: 0.1000 (0.1000) Top1_base: 73.4375 (78.3594) Top1_base_per_class: 75.4938 (79.3880) 
Training Epoch: [113/1000] Step: [30 / 285] Batch Time: 0.1444 (0.1855) Data Time: 0.0102 (0.0499) Average Loss: 0.7416 (0.7298) Average CE Loss (Source):  0.7416 ( 0.7298) Learning Rate: 0.1000 (0.1000) Top1_base: 82.0312 (79.4531) Top1_base_per_class: 81.5455 (80.4247) 
Training Epoch: [113/1000] Step: [40 / 285] Batch Time: 0.1422 (0.1754) Data Time: 0.0116 (0.0406) Average Loss: 0.6145 (0.7289) Average CE Loss (Source):  0.6145 ( 0.7289) Learning Rate: 0.1000 (0.1000) Top1_base: 84.3750 (79.5898) Top1_base_per_class: 84.6825 (80.5578) 
Training Epoch: [113/1000] Step: [50 / 285] Batch Time: 0.1430 (0.1728) Data Time: 0.0109 (0.0384) Average Loss: 0.8300 (0.7279) Average CE Loss (Source):  0.8300 ( 0.7279) Learning Rate: 0.1000 (0.1000) Top1_base: 75.7812 (79.7812) Top1_base_per_class: 78.6000 (80.6969) 
Training Epoch: [113/1000] Step: [60 / 285] Batch Time: 0.1503 (0.1685) Data Time: 0.0157 (0.0342) Average Loss: 0.5244 (0.7286) Average CE Loss (Source):  0.5244 ( 0.7286) Learning Rate: 0.1000 (0.1000) Top1_base: 85.9375 (79.8047) Top1_base_per_class: 86.6092 (80.6350) 
Training Epoch: [113/1000] Step: [70 / 285] Batch Time: 0.1440 (0.1670) Data Time: 0.0114 (0.0329) Average Loss: 0.5567 (0.7322) Average CE Loss (Source):  0.5567 ( 0.7322) Learning Rate: 0.1000 (0.1000) Top1_base: 82.8125 (79.6987) Top1_base_per_class: 80.1852 (80.3881) 
Training Epoch: [113/1000] Step: [80 / 285] Batch Time: 0.1464 (0.1646) Data Time: 0.0131 (0.0307) Average Loss: 0.7361 (0.7363) Average CE Loss (Source):  0.7361 ( 0.7363) Learning Rate: 0.1000 (0.1000) Top1_base: 78.9062 (79.5215) Top1_base_per_class: 77.2701 (80.1144) 
Training Epoch: [113/1000] Step: [90 / 285] Batch Time: 0.1819 (0.1636) Data Time: 0.0493 (0.0299) Average Loss: 0.7500 (0.7408) Average CE Loss (Source):  0.7500 ( 0.7408) Learning Rate: 0.1000 (0.1000) Top1_base: 78.9062 (79.4444) Top1_base_per_class: 76.6964 (79.9684) 
Training Epoch: [113/1000] Step: [100 / 285] Batch Time: 0.1452 (0.1618) Data Time: 0.0128 (0.0282) Average Loss: 0.6820 (0.7430) Average CE Loss (Source):  0.6820 ( 0.7430) Learning Rate: 0.1000 (0.1000) Top1_base: 79.6875 (79.3516) Top1_base_per_class: 79.6296 (79.9013) 
Training Epoch: [113/1000] Step: [110 / 285] Batch Time: 0.1969 (0.1623) Data Time: 0.0638 (0.0287) Average Loss: 0.8347 (0.7420) Average CE Loss (Source):  0.8347 ( 0.7420) Learning Rate: 0.1000 (0.1000) Top1_base: 76.5625 (79.3679) Top1_base_per_class: 77.0370 (79.8273) 
Training Epoch: [113/1000] Step: [120 / 285] Batch Time: 0.1444 (0.1611) Data Time: 0.0107 (0.0276) Average Loss: 0.6578 (0.7391) Average CE Loss (Source):  0.6578 ( 0.7391) Learning Rate: 0.1000 (0.1000) Top1_base: 83.5938 (79.4336) Top1_base_per_class: 84.9371 (79.8537) 
Training Epoch: [113/1000] Step: [130 / 285] Batch Time: 0.1733 (0.1604) Data Time: 0.0420 (0.0269) Average Loss: 0.7825 (0.7369) Average CE Loss (Source):  0.7825 ( 0.7369) Learning Rate: 0.1000 (0.1000) Top1_base: 78.9062 (79.5312) Top1_base_per_class: 78.5876 (79.9444) 
Training Epoch: [113/1000] Step: [140 / 285] Batch Time: 0.1470 (0.1605) Data Time: 0.0126 (0.0270) Average Loss: 0.8727 (0.7380) Average CE Loss (Source):  0.8727 ( 0.7380) Learning Rate: 0.1000 (0.1000) Top1_base: 75.0000 (79.4754) Top1_base_per_class: 78.7922 (79.8918) 
Training Epoch: [113/1000] Step: [150 / 285] Batch Time: 0.1446 (0.1602) Data Time: 0.0139 (0.0268) Average Loss: 0.8923 (0.7433) Average CE Loss (Source):  0.8923 ( 0.7433) Learning Rate: 0.1000 (0.1000) Top1_base: 73.4375 (79.2812) Top1_base_per_class: 74.4136 (79.7155) 
Training Epoch: [113/1000] Step: [160 / 285] Batch Time: 0.1482 (0.1595) Data Time: 0.0137 (0.0261) Average Loss: 0.7551 (0.7437) Average CE Loss (Source):  0.7551 ( 0.7437) Learning Rate: 0.1000 (0.1000) Top1_base: 82.8125 (79.3066) Top1_base_per_class: 86.9224 (79.7258) 
Training Epoch: [113/1000] Step: [170 / 285] Batch Time: 0.1586 (0.1588) Data Time: 0.0252 (0.0254) Average Loss: 0.7640 (0.7441) Average CE Loss (Source):  0.7640 ( 0.7441) Learning Rate: 0.1000 (0.1000) Top1_base: 75.0000 (79.3015) Top1_base_per_class: 76.1864 (79.7384) 
Training Epoch: [113/1000] Step: [180 / 285] Batch Time: 0.1488 (0.1582) Data Time: 0.0128 (0.0248) Average Loss: 0.9016 (0.7474) Average CE Loss (Source):  0.9016 ( 0.7474) Learning Rate: 0.1000 (0.1000) Top1_base: 78.1250 (79.2405) Top1_base_per_class: 82.9235 (79.7089) 
Training Epoch: [113/1000] Step: [190 / 285] Batch Time: 0.1963 (0.1581) Data Time: 0.0650 (0.0247) Average Loss: 0.8140 (0.7501) Average CE Loss (Source):  0.8140 ( 0.7501) Learning Rate: 0.1000 (0.1000) Top1_base: 72.6562 (79.1612) Top1_base_per_class: 75.7228 (79.6409) 
Training Epoch: [113/1000] Step: [200 / 285] Batch Time: 0.1488 (0.1575) Data Time: 0.0150 (0.0241) Average Loss: 0.8257 (0.7515) Average CE Loss (Source):  0.8257 ( 0.7515) Learning Rate: 0.1000 (0.1000) Top1_base: 78.9062 (79.1523) Top1_base_per_class: 77.7083 (79.6516) 
Training Epoch: [113/1000] Step: [210 / 285] Batch Time: 0.1466 (0.1570) Data Time: 0.0136 (0.0237) Average Loss: 0.8492 (0.7563) Average CE Loss (Source):  0.8492 ( 0.7563) Learning Rate: 0.1000 (0.1000) Top1_base: 75.0000 (78.9695) Top1_base_per_class: 71.6384 (79.4631) 
Training Epoch: [113/1000] Step: [220 / 285] Batch Time: 0.1453 (0.1566) Data Time: 0.0111 (0.0232) Average Loss: 0.9225 (0.7591) Average CE Loss (Source):  0.9225 ( 0.7591) Learning Rate: 0.1000 (0.1000) Top1_base: 73.4375 (78.8778) Top1_base_per_class: 70.4023 (79.4195) 
Training Epoch: [113/1000] Step: [230 / 285] Batch Time: 0.1860 (0.1563) Data Time: 0.0541 (0.0229) Average Loss: 0.8125 (0.7586) Average CE Loss (Source):  0.8125 ( 0.7586) Learning Rate: 0.1000 (0.1000) Top1_base: 79.6875 (78.8859) Top1_base_per_class: 78.7945 (79.3949) 
Training Epoch: [113/1000] Step: [240 / 285] Batch Time: 0.1521 (0.1560) Data Time: 0.0135 (0.0225) Average Loss: 0.7907 (0.7578) Average CE Loss (Source):  0.7907 ( 0.7578) Learning Rate: 0.1000 (0.1000) Top1_base: 76.5625 (78.9583) Top1_base_per_class: 76.6667 (79.4605) 
Training Epoch: [113/1000] Step: [250 / 285] Batch Time: 0.1492 (0.1560) Data Time: 0.0157 (0.0225) Average Loss: 0.7523 (0.7591) Average CE Loss (Source):  0.7523 ( 0.7591) Learning Rate: 0.1000 (0.1000) Top1_base: 76.5625 (78.9031) Top1_base_per_class: 78.3626 (79.3914) 
Training Epoch: [113/1000] Step: [260 / 285] Batch Time: 0.1454 (0.1557) Data Time: 0.0126 (0.0222) Average Loss: 0.5966 (0.7612) Average CE Loss (Source):  0.5966 ( 0.7612) Learning Rate: 0.1000 (0.1000) Top1_base: 80.4688 (78.8161) Top1_base_per_class: 81.0256 (79.3218) 
Training Epoch: [113/1000] Step: [270 / 285] Batch Time: 0.2937 (0.1560) Data Time: 0.1592 (0.0225) Average Loss: 0.9650 (0.7642) Average CE Loss (Source):  0.9650 ( 0.7642) Learning Rate: 0.1000 (0.1000) Top1_base: 71.8750 (78.7240) Top1_base_per_class: 72.9697 (79.2370) 
Training Epoch: [113/1000] Step: [280 / 285] Batch Time: 0.1448 (0.1560) Data Time: 0.0104 (0.0225) Average Loss: 0.6185 (0.7648) Average CE Loss (Source):  0.6185 ( 0.7648) Learning Rate: 0.1000 (0.1000) Top1_base: 83.5938 (78.7193) Top1_base_per_class: 84.8634 (79.2354) 
Training Epoch: [114/1000] Step: [0] Batch Time: 0.1439 (0.1558) Data Time: 0.0115 (0.0223) Average Loss: 0.7118 (0.7646) Average CE Loss (Source):  0.7118 ( 0.7646) Learning Rate: 0.1000 (0.1000) Top1_base: 81.2500 (78.7582) Top1_base_per_class: 81.4620 (79.2716) 
 11%|█▏        | 114/1000 [1:29:05<11:27:04, 46.53s/it] 12%|█▏        | 115/1000 [1:29:51<11:21:16, 46.19s/it]Training Epoch: [114/1000] Step: [10 / 285] Batch Time: 0.1467 (0.2391) Data Time: 0.0149 (0.1065) Average Loss: 0.7304 (0.7102) Average CE Loss (Source):  0.7304 ( 0.7102) Learning Rate: 0.1000 (0.1000) Top1_base: 79.6875 (79.9219) Top1_base_per_class: 80.3216 (79.2421) 
Training Epoch: [114/1000] Step: [20 / 285] Batch Time: 0.1473 (0.1969) Data Time: 0.0109 (0.0645) Average Loss: 0.6316 (0.7055) Average CE Loss (Source):  0.6316 ( 0.7055) Learning Rate: 0.1000 (0.1000) Top1_base: 81.2500 (79.8828) Top1_base_per_class: 80.1887 (80.2702) 
Training Epoch: [114/1000] Step: [30 / 285] Batch Time: 0.1462 (0.1835) Data Time: 0.0125 (0.0511) Average Loss: 0.5491 (0.7210) Average CE Loss (Source):  0.5491 ( 0.7210) Learning Rate: 0.1000 (0.1000) Top1_base: 84.3750 (79.7917) Top1_base_per_class: 82.9532 (79.5572) 
Training Epoch: [114/1000] Step: [40 / 285] Batch Time: 0.1497 (0.1771) Data Time: 0.0143 (0.0444) Average Loss: 0.8096 (0.7276) Average CE Loss (Source):  0.8096 ( 0.7276) Learning Rate: 0.1000 (0.1000) Top1_base: 78.9062 (79.4336) Top1_base_per_class: 76.1782 (79.1255) 
Training Epoch: [114/1000] Step: [50 / 285] Batch Time: 0.2053 (0.1741) Data Time: 0.0740 (0.0413) Average Loss: 0.7391 (0.7427) Average CE Loss (Source):  0.7391 ( 0.7427) Learning Rate: 0.1000 (0.1000) Top1_base: 78.9062 (79.1719) Top1_base_per_class: 79.9038 (78.8059) 
Training Epoch: [114/1000] Step: [60 / 285] Batch Time: 0.1460 (0.1714) Data Time: 0.0113 (0.0385) Average Loss: 0.6758 (0.7401) Average CE Loss (Source):  0.6758 ( 0.7401) Learning Rate: 0.1000 (0.1000) Top1_base: 82.0312 (79.2839) Top1_base_per_class: 81.8644 (79.1248) 
Training Epoch: [114/1000] Step: [70 / 285] Batch Time: 0.1446 (0.1695) Data Time: 0.0134 (0.0366) Average Loss: 0.7752 (0.7353) Average CE Loss (Source):  0.7752 ( 0.7353) Learning Rate: 0.1000 (0.1000) Top1_base: 75.7812 (79.3415) Top1_base_per_class: 73.7879 (79.4642) 
Training Epoch: [114/1000] Step: [80 / 285] Batch Time: 0.1464 (0.1671) Data Time: 0.0128 (0.0343) Average Loss: 0.8444 (0.7353) Average CE Loss (Source):  0.8444 ( 0.7353) Learning Rate: 0.1000 (0.1000) Top1_base: 78.1250 (79.3945) Top1_base_per_class: 78.9881 (79.5368) 
Training Epoch: [114/1000] Step: [90 / 285] Batch Time: 0.2490 (0.1662) Data Time: 0.1173 (0.0334) Average Loss: 0.6645 (0.7347) Average CE Loss (Source):  0.6645 ( 0.7347) Learning Rate: 0.1000 (0.1000) Top1_base: 78.9062 (79.3924) Top1_base_per_class: 78.6568 (79.5897) 
Training Epoch: [114/1000] Step: [100 / 285] Batch Time: 0.1458 (0.1650) Data Time: 0.0113 (0.0321) Average Loss: 0.9113 (0.7389) Average CE Loss (Source):  0.9113 ( 0.7389) Learning Rate: 0.1000 (0.1000) Top1_base: 77.3438 (79.3672) Top1_base_per_class: 75.7471 (79.5530) 
Training Epoch: [114/1000] Step: [110 / 285] Batch Time: 0.1469 (0.1648) Data Time: 0.0159 (0.0319) Average Loss: 0.9495 (0.7428) Average CE Loss (Source):  0.9495 ( 0.7428) Learning Rate: 0.1000 (0.1000) Top1_base: 75.7812 (79.1406) Top1_base_per_class: 77.2711 (79.4102) 
Training Epoch: [114/1000] Step: [120 / 285] Batch Time: 0.1433 (0.1652) Data Time: 0.0101 (0.0323) Average Loss: 0.6133 (0.7455) Average CE Loss (Source):  0.6133 ( 0.7455) Learning Rate: 0.1000 (0.1000) Top1_base: 85.1562 (79.1341) Top1_base_per_class: 87.2222 (79.4171) 
Training Epoch: [114/1000] Step: [130 / 285] Batch Time: 0.1913 (0.1648) Data Time: 0.0573 (0.0318) Average Loss: 0.8192 (0.7426) Average CE Loss (Source):  0.8192 ( 0.7426) Learning Rate: 0.1000 (0.1000) Top1_base: 77.3438 (79.2428) Top1_base_per_class: 79.2121 (79.6076) 
Training Epoch: [114/1000] Step: [140 / 285] Batch Time: 0.1451 (0.1637) Data Time: 0.0111 (0.0308) Average Loss: 0.8554 (0.7444) Average CE Loss (Source):  0.8554 ( 0.7444) Learning Rate: 0.1000 (0.1000) Top1_base: 76.5625 (79.2076) Top1_base_per_class: 75.3983 (79.6216) 
Training Epoch: [114/1000] Step: [150 / 285] Batch Time: 0.1670 (0.1630) Data Time: 0.0358 (0.0300) Average Loss: 0.6633 (0.7475) Average CE Loss (Source):  0.6633 ( 0.7475) Learning Rate: 0.1000 (0.1000) Top1_base: 78.9062 (79.0833) Top1_base_per_class: 80.9319 (79.4982) 
Training Epoch: [114/1000] Step: [160 / 285] Batch Time: 0.1425 (0.1626) Data Time: 0.0113 (0.0297) Average Loss: 0.8341 (0.7487) Average CE Loss (Source):  0.8341 ( 0.7487) Learning Rate: 0.1000 (0.1000) Top1_base: 75.7812 (79.0283) Top1_base_per_class: 75.0000 (79.4699) 
Training Epoch: [114/1000] Step: [170 / 285] Batch Time: 0.1735 (0.1624) Data Time: 0.0424 (0.0294) Average Loss: 0.6279 (0.7467) Average CE Loss (Source):  0.6279 ( 0.7467) Learning Rate: 0.1000 (0.1000) Top1_base: 84.3750 (79.0441) Top1_base_per_class: 85.3274 (79.4923) 
Training Epoch: [114/1000] Step: [180 / 285] Batch Time: 0.1462 (0.1620) Data Time: 0.0120 (0.0291) Average Loss: 0.7133 (0.7469) Average CE Loss (Source):  0.7133 ( 0.7469) Learning Rate: 0.1000 (0.1000) Top1_base: 77.3438 (79.0104) Top1_base_per_class: 78.3918 (79.4683) 
Training Epoch: [114/1000] Step: [190 / 285] Batch Time: 0.1871 (0.1619) Data Time: 0.0560 (0.0290) Average Loss: 0.7690 (0.7480) Average CE Loss (Source):  0.7690 ( 0.7480) Learning Rate: 0.1000 (0.1000) Top1_base: 79.6875 (79.0049) Top1_base_per_class: 83.6728 (79.4575) 
Training Epoch: [114/1000] Step: [200 / 285] Batch Time: 0.1446 (0.1614) Data Time: 0.0113 (0.0285) Average Loss: 0.8835 (0.7495) Average CE Loss (Source):  0.8835 ( 0.7495) Learning Rate: 0.1000 (0.1000) Top1_base: 74.2188 (78.9727) Top1_base_per_class: 79.3678 (79.4507) 
Training Epoch: [114/1000] Step: [210 / 285] Batch Time: 0.1561 (0.1613) Data Time: 0.0249 (0.0285) Average Loss: 0.8609 (0.7505) Average CE Loss (Source):  0.8609 ( 0.7505) Learning Rate: 0.1000 (0.1000) Top1_base: 80.4688 (78.9435) Top1_base_per_class: 78.0357 (79.3902) 
Training Epoch: [114/1000] Step: [220 / 285] Batch Time: 0.1443 (0.1606) Data Time: 0.0118 (0.0279) Average Loss: 0.6495 (0.7531) Average CE Loss (Source):  0.6495 ( 0.7531) Learning Rate: 0.1000 (0.1000) Top1_base: 83.5938 (78.8530) Top1_base_per_class: 83.6364 (79.2568) 
Training Epoch: [114/1000] Step: [230 / 285] Batch Time: 0.2437 (0.1613) Data Time: 0.1106 (0.0285) Average Loss: 0.8042 (0.7553) Average CE Loss (Source):  0.8042 ( 0.7553) Learning Rate: 0.1000 (0.1000) Top1_base: 73.4375 (78.8010) Top1_base_per_class: 75.9942 (79.2454) 
Training Epoch: [114/1000] Step: [240 / 285] Batch Time: 0.1442 (0.1613) Data Time: 0.0116 (0.0285) Average Loss: 0.7075 (0.7555) Average CE Loss (Source):  0.7075 ( 0.7555) Learning Rate: 0.1000 (0.1000) Top1_base: 79.6875 (78.7402) Top1_base_per_class: 80.3672 (79.1814) 
Training Epoch: [114/1000] Step: [250 / 285] Batch Time: 0.1493 (0.1608) Data Time: 0.0172 (0.0280) Average Loss: 0.8604 (0.7594) Average CE Loss (Source):  0.8604 ( 0.7594) Learning Rate: 0.1000 (0.1000) Top1_base: 74.2188 (78.6500) Top1_base_per_class: 75.4402 (79.0604) 
Training Epoch: [114/1000] Step: [260 / 285] Batch Time: 0.1439 (0.1602) Data Time: 0.0131 (0.0274) Average Loss: 0.6640 (0.7610) Average CE Loss (Source):  0.6640 ( 0.7610) Learning Rate: 0.1000 (0.1000) Top1_base: 78.9062 (78.6148) Top1_base_per_class: 78.2716 (79.0126) 
Training Epoch: [114/1000] Step: [270 / 285] Batch Time: 0.1500 (0.1597) Data Time: 0.0170 (0.0269) Average Loss: 0.6761 (0.7601) Average CE Loss (Source):  0.6761 ( 0.7601) Learning Rate: 0.1000 (0.1000) Top1_base: 80.4688 (78.6458) Top1_base_per_class: 84.0606 (79.0481) 
Training Epoch: [114/1000] Step: [280 / 285] Batch Time: 0.1453 (0.1593) Data Time: 0.0127 (0.0265) Average Loss: 0.7665 (0.7633) Average CE Loss (Source):  0.7665 ( 0.7633) Learning Rate: 0.1000 (0.1000) Top1_base: 81.2500 (78.5519) Top1_base_per_class: 81.4327 (78.9626) 
Training Epoch: [115/1000] Step: [0] Batch Time: 0.1387 (0.1591) Data Time: 0.0099 (0.0262) Average Loss: 0.6981 (0.7622) Average CE Loss (Source):  0.6981 ( 0.7622) Learning Rate: 0.1000 (0.1000) Top1_base: 78.1250 (78.5910) Top1_base_per_class: 80.6790 (79.0132) 
Training Epoch: [115/1000] Step: [10 / 285] Batch Time: 0.1449 (0.2462) Data Time: 0.0136 (0.1134) Average Loss: 0.9172 (0.6923) Average CE Loss (Source):  0.9172 ( 0.6923) Learning Rate: 0.1000 (0.1000) Top1_base: 75.0000 (80.7031) Top1_base_per_class: 74.5536 (81.4294) 
Training Epoch: [115/1000] Step: [20 / 285] Batch Time: 0.1460 (0.2058) Data Time: 0.0123 (0.0732) Average Loss: 0.7412 (0.7160) Average CE Loss (Source):  0.7412 ( 0.7160) Learning Rate: 0.1000 (0.1000) Top1_base: 78.9062 (79.9609) Top1_base_per_class: 79.4152 (80.1440) 
Training Epoch: [115/1000] Step: [30 / 285] Batch Time: 0.1438 (0.1921) Data Time: 0.0108 (0.0592) Average Loss: 0.5675 (0.7097) Average CE Loss (Source):  0.5675 ( 0.7097) Learning Rate: 0.1000 (0.1000) Top1_base: 87.5000 (80.5208) Top1_base_per_class: 87.5786 (80.6521) 
Training Epoch: [115/1000] Step: [40 / 285] Batch Time: 0.1495 (0.1830) Data Time: 0.0140 (0.0497) Average Loss: 0.8943 (0.7172) Average CE Loss (Source):  0.8943 ( 0.7172) Learning Rate: 0.1000 (0.1000) Top1_base: 75.7812 (80.1172) Top1_base_per_class: 77.3457 (80.2278) 
Training Epoch: [115/1000] Step: [50 / 285] Batch Time: 0.1448 (0.1766) Data Time: 0.0118 (0.0434) Average Loss: 0.8400 (0.7265) Average CE Loss (Source):  0.8400 ( 0.7265) Learning Rate: 0.1000 (0.1000) Top1_base: 78.9062 (79.8750) Top1_base_per_class: 80.4321 (79.9819) 
Training Epoch: [115/1000] Step: [60 / 285] Batch Time: 0.1460 (0.1724) Data Time: 0.0124 (0.0392) Average Loss: 0.9392 (0.7336) Average CE Loss (Source):  0.9392 ( 0.7336) Learning Rate: 0.1000 (0.1000) Top1_base: 74.2188 (79.6224) Top1_base_per_class: 77.9938 (79.9214) 
Training Epoch: [115/1000] Step: [70 / 285] Batch Time: 0.1461 (0.1702) Data Time: 0.0119 (0.0370) Average Loss: 0.6886 (0.7346) Average CE Loss (Source):  0.6886 ( 0.7346) Learning Rate: 0.1000 (0.1000) Top1_base: 81.2500 (79.6205) Top1_base_per_class: 77.5731 (79.8974) 
Training Epoch: [115/1000] Step: [80 / 285] Batch Time: 0.1508 (0.1683) Data Time: 0.0153 (0.0352) Average Loss: 0.8525 (0.7335) Average CE Loss (Source):  0.8525 ( 0.7335) Learning Rate: 0.1000 (0.1000) Top1_base: 76.5625 (79.6289) Top1_base_per_class: 79.6364 (80.0435) 
Training Epoch: [115/1000] Step: [90 / 285] Batch Time: 0.1434 (0.1670) Data Time: 0.0114 (0.0339) Average Loss: 0.6441 (0.7336) Average CE Loss (Source):  0.6441 ( 0.7336) Learning Rate: 0.1000 (0.1000) Top1_base: 82.0312 (79.5573) Top1_base_per_class: 81.6082 (80.0021) 
Training Epoch: [115/1000] Step: [100 / 285] Batch Time: 0.1476 (0.1657) Data Time: 0.0134 (0.0325) Average Loss: 0.8219 (0.7340) Average CE Loss (Source):  0.8219 ( 0.7340) Learning Rate: 0.1000 (0.1000) Top1_base: 78.9062 (79.5312) Top1_base_per_class: 78.9583 (79.9272) 
Training Epoch: [115/1000] Step: [110 / 285] Batch Time: 0.1429 (0.1643) Data Time: 0.0111 (0.0311) Average Loss: 0.7827 (0.7359) Average CE Loss (Source):  0.7827 ( 0.7359) Learning Rate: 0.1000 (0.1000) Top1_base: 75.7812 (79.3253) Top1_base_per_class: 74.5536 (79.7269) 
Training Epoch: [115/1000] Step: [120 / 285] Batch Time: 0.1456 (0.1641) Data Time: 0.0123 (0.0308) Average Loss: 0.8686 (0.7376) Average CE Loss (Source):  0.8686 ( 0.7376) Learning Rate: 0.1000 (0.1000) Top1_base: 78.9062 (79.3229) Top1_base_per_class: 77.7679 (79.6799) 
Training Epoch: [115/1000] Step: [130 / 285] Batch Time: 0.1425 (0.1635) Data Time: 0.0117 (0.0302) Average Loss: 0.6207 (0.7390) Average CE Loss (Source):  0.6207 ( 0.7390) Learning Rate: 0.1000 (0.1000) Top1_base: 78.9062 (79.2608) Top1_base_per_class: 77.3214 (79.5348) 
Training Epoch: [115/1000] Step: [140 / 285] Batch Time: 0.1474 (0.1626) Data Time: 0.0140 (0.0293) Average Loss: 0.6833 (0.7388) Average CE Loss (Source):  0.6833 ( 0.7388) Learning Rate: 0.1000 (0.1000) Top1_base: 80.4688 (79.2411) Top1_base_per_class: 79.1005 (79.5352) 
Training Epoch: [115/1000] Step: [150 / 285] Batch Time: 0.1421 (0.1623) Data Time: 0.0112 (0.0290) Average Loss: 0.5921 (0.7389) Average CE Loss (Source):  0.5921 ( 0.7389) Learning Rate: 0.1000 (0.1000) Top1_base: 82.8125 (79.2448) Top1_base_per_class: 80.2469 (79.5199) 
Training Epoch: [115/1000] Step: [160 / 285] Batch Time: 0.1482 (0.1613) Data Time: 0.0139 (0.0280) Average Loss: 0.8440 (0.7406) Average CE Loss (Source):  0.8440 ( 0.7406) Learning Rate: 0.1000 (0.1000) Top1_base: 76.5625 (79.2188) Top1_base_per_class: 78.4877 (79.4993) 
Training Epoch: [115/1000] Step: [170 / 285] Batch Time: 0.1455 (0.1604) Data Time: 0.0117 (0.0271) Average Loss: 0.5986 (0.7415) Average CE Loss (Source):  0.5986 ( 0.7415) Learning Rate: 0.1000 (0.1000) Top1_base: 81.2500 (79.1774) Top1_base_per_class: 79.4789 (79.4568) 
Training Epoch: [115/1000] Step: [180 / 285] Batch Time: 0.1502 (0.1598) Data Time: 0.0154 (0.0265) Average Loss: 0.6684 (0.7453) Average CE Loss (Source):  0.6684 ( 0.7453) Learning Rate: 0.1000 (0.1000) Top1_base: 81.2500 (79.1146) Top1_base_per_class: 83.9286 (79.3748) 
Training Epoch: [115/1000] Step: [190 / 285] Batch Time: 0.1437 (0.1597) Data Time: 0.0116 (0.0265) Average Loss: 0.6728 (0.7458) Average CE Loss (Source):  0.6728 ( 0.7458) Learning Rate: 0.1000 (0.1000) Top1_base: 77.3438 (79.0543) Top1_base_per_class: 74.9691 (79.3205) 
Training Epoch: [115/1000] Step: [200 / 285] Batch Time: 0.1448 (0.1597) Data Time: 0.0118 (0.0264) Average Loss: 0.5274 (0.7486) Average CE Loss (Source):  0.5274 ( 0.7486) Learning Rate: 0.1000 (0.1000) Top1_base: 86.7188 (78.9883) Top1_base_per_class: 87.7586 (79.2936) 
Training Epoch: [115/1000] Step: [210 / 285] Batch Time: 0.1441 (0.1595) Data Time: 0.0120 (0.0262) Average Loss: 0.8164 (0.7499) Average CE Loss (Source):  0.8164 ( 0.7499) Learning Rate: 0.1000 (0.1000) Top1_base: 78.1250 (78.9249) Top1_base_per_class: 75.9322 (79.2773) 
Training Epoch: [115/1000] Step: [220 / 285] Batch Time: 0.1473 (0.1602) Data Time: 0.0126 (0.0270) Average Loss: 1.0885 (0.7558) Average CE Loss (Source):  1.0885 ( 0.7558) Learning Rate: 0.1000 (0.1000) Top1_base: 73.4375 (78.8104) Top1_base_per_class: 72.7679 (79.1994) 
Training Epoch: [115/1000] Step: [230 / 285] Batch Time: 0.1421 (0.1599) Data Time: 0.0117 (0.0267) Average Loss: 0.9011 (0.7584) Average CE Loss (Source):  0.9011 ( 0.7584) Learning Rate: 0.1000 (0.1000) Top1_base: 76.5625 (78.7874) Top1_base_per_class: 75.2381 (79.1913) 
Training Epoch: [115/1000] Step: [240 / 285] Batch Time: 0.1475 (0.1598) Data Time: 0.0140 (0.0266) Average Loss: 0.5955 (0.7605) Average CE Loss (Source):  0.5955 ( 0.7605) Learning Rate: 0.1000 (0.1000) Top1_base: 82.8125 (78.7467) Top1_base_per_class: 84.4048 (79.1486) 
Training Epoch: [115/1000] Step: [250 / 285] Batch Time: 0.1428 (0.1596) Data Time: 0.0116 (0.0264) Average Loss: 0.7915 (0.7608) Average CE Loss (Source):  0.7915 ( 0.7608) Learning Rate: 0.1000 (0.1000) Top1_base: 77.3438 (78.7625) Top1_base_per_class: 79.5198 (79.1328) 
Training Epoch: [115/1000] Step: [260 / 285] Batch Time: 0.1399 (0.1594) Data Time: 0.0107 (0.0262) Average Loss: 0.8156 (0.7615) Average CE Loss (Source):  0.8156 ( 0.7615) Learning Rate: 0.1000 (0.1000) Top1_base: 79.6875 (78.7470) Top1_base_per_class: 80.3395 (79.0628) 
Training Epoch: [115/1000] Step: [270 / 285] Batch Time: 0.1465 (0.1594) Data Time: 0.0124 (0.0263) Average Loss: 0.9386 (0.7628) Average CE Loss (Source):  0.9386 ( 0.7628) Learning Rate: 0.1000 (0.1000) Top1_base: 74.2188 (78.7037) Top1_base_per_class: 75.0617 (79.0097) 
Training Epoch: [115/1000] Step: [280 / 285] Batch Time: 0.1489 (0.1592) Data Time: 0.0147 (0.0261) Average Loss: 0.9749 (0.7634) Average CE Loss (Source):  0.9749 ( 0.7634) Learning Rate: 0.1000 (0.1000) Top1_base: 73.4375 (78.6775) Top1_base_per_class: 72.3214 (78.9302) 
Training Epoch: [116/1000] Step: [0] Batch Time: 0.2044 (0.1591) Data Time: 0.0724 (0.0261) Average Loss: 0.9707 (0.7647) Average CE Loss (Source):  0.9707 ( 0.7647) Learning Rate: 0.1000 (0.1000) Top1_base: 71.8750 (78.6349) Top1_base_per_class: 71.9697 (78.9016) 
 12%|█▏        | 116/1000 [1:30:39<11:29:35, 46.81s/it] 12%|█▏        | 117/1000 [1:31:23<11:17:53, 46.06s/it]Training Epoch: [116/1000] Step: [10 / 285] Batch Time: 0.1497 (0.2436) Data Time: 0.0129 (0.1102) Average Loss: 0.9090 (0.6935) Average CE Loss (Source):  0.9090 ( 0.6935) Learning Rate: 0.1000 (0.1000) Top1_base: 75.0000 (80.1562) Top1_base_per_class: 76.0417 (79.5908) 
Training Epoch: [116/1000] Step: [20 / 285] Batch Time: 0.1461 (0.1970) Data Time: 0.0149 (0.0641) Average Loss: 0.8283 (0.7052) Average CE Loss (Source):  0.8283 ( 0.7052) Learning Rate: 0.1000 (0.1000) Top1_base: 79.6875 (80.0391) Top1_base_per_class: 83.1356 (80.0165) 
Training Epoch: [116/1000] Step: [30 / 285] Batch Time: 0.1436 (0.1863) Data Time: 0.0103 (0.0536) Average Loss: 0.5118 (0.7085) Average CE Loss (Source):  0.5118 ( 0.7085) Learning Rate: 0.1000 (0.1000) Top1_base: 85.9375 (80.2083) Top1_base_per_class: 87.7222 (80.5730) 
Training Epoch: [116/1000] Step: [40 / 285] Batch Time: 0.1464 (0.1769) Data Time: 0.0136 (0.0441) Average Loss: 0.9210 (0.7223) Average CE Loss (Source):  0.9210 ( 0.7223) Learning Rate: 0.1000 (0.1000) Top1_base: 74.2188 (79.7852) Top1_base_per_class: 74.1964 (80.0420) 
Training Epoch: [116/1000] Step: [50 / 285] Batch Time: 0.1423 (0.1728) Data Time: 0.0119 (0.0401) Average Loss: 0.5336 (0.7229) Average CE Loss (Source):  0.5336 ( 0.7229) Learning Rate: 0.1000 (0.1000) Top1_base: 84.3750 (79.7969) Top1_base_per_class: 83.6552 (80.1057) 
Training Epoch: [116/1000] Step: [60 / 285] Batch Time: 0.1454 (0.1687) Data Time: 0.0106 (0.0361) Average Loss: 0.8010 (0.7262) Average CE Loss (Source):  0.8010 ( 0.7262) Learning Rate: 0.1000 (0.1000) Top1_base: 77.3438 (79.7135) Top1_base_per_class: 78.4795 (79.9926) 
Training Epoch: [116/1000] Step: [70 / 285] Batch Time: 0.1466 (0.1665) Data Time: 0.0105 (0.0337) Average Loss: 0.7402 (0.7278) Average CE Loss (Source):  0.7402 ( 0.7278) Learning Rate: 0.1000 (0.1000) Top1_base: 79.6875 (79.5759) Top1_base_per_class: 79.4000 (80.0097) 
Training Epoch: [116/1000] Step: [80 / 285] Batch Time: 0.1518 (0.1645) Data Time: 0.0167 (0.0313) Average Loss: 0.5616 (0.7322) Average CE Loss (Source):  0.5616 ( 0.7322) Learning Rate: 0.1000 (0.1000) Top1_base: 84.3750 (79.4629) Top1_base_per_class: 81.6061 (79.8708) 
Training Epoch: [116/1000] Step: [90 / 285] Batch Time: 0.1490 (0.1626) Data Time: 0.0173 (0.0293) Average Loss: 0.6921 (0.7366) Average CE Loss (Source):  0.6921 ( 0.7366) Learning Rate: 0.1000 (0.1000) Top1_base: 79.6875 (79.4097) Top1_base_per_class: 79.8104 (79.8508) 
Training Epoch: [116/1000] Step: [100 / 285] Batch Time: 0.1459 (0.1612) Data Time: 0.0143 (0.0279) Average Loss: 0.8737 (0.7386) Average CE Loss (Source):  0.8737 ( 0.7386) Learning Rate: 0.1000 (0.1000) Top1_base: 78.1250 (79.3750) Top1_base_per_class: 79.6970 (79.8319) 
Training Epoch: [116/1000] Step: [110 / 285] Batch Time: 0.1502 (0.1599) Data Time: 0.0175 (0.0266) Average Loss: 0.8064 (0.7405) Average CE Loss (Source):  0.8064 ( 0.7405) Learning Rate: 0.1000 (0.1000) Top1_base: 77.3438 (79.3963) Top1_base_per_class: 79.1346 (79.8994) 
Training Epoch: [116/1000] Step: [120 / 285] Batch Time: 0.1470 (0.1599) Data Time: 0.0144 (0.0266) Average Loss: 0.7213 (0.7435) Average CE Loss (Source):  0.7213 ( 0.7435) Learning Rate: 0.1000 (0.1000) Top1_base: 82.0312 (79.3490) Top1_base_per_class: 83.9655 (79.9386) 
Training Epoch: [116/1000] Step: [130 / 285] Batch Time: 0.1831 (0.1595) Data Time: 0.0526 (0.0262) Average Loss: 0.8840 (0.7466) Average CE Loss (Source):  0.8840 ( 0.7466) Learning Rate: 0.1000 (0.1000) Top1_base: 81.2500 (79.3209) Top1_base_per_class: 75.4464 (79.8256) 
Training Epoch: [116/1000] Step: [140 / 285] Batch Time: 0.1493 (0.1591) Data Time: 0.0137 (0.0256) Average Loss: 0.8516 (0.7511) Average CE Loss (Source):  0.8516 ( 0.7511) Learning Rate: 0.1000 (0.1000) Top1_base: 79.6875 (79.1574) Top1_base_per_class: 79.2767 (79.6027) 
Training Epoch: [116/1000] Step: [150 / 285] Batch Time: 0.1475 (0.1584) Data Time: 0.0114 (0.0249) Average Loss: 0.6958 (0.7535) Average CE Loss (Source):  0.6958 ( 0.7535) Learning Rate: 0.1000 (0.1000) Top1_base: 77.3438 (79.1146) Top1_base_per_class: 75.4088 (79.5654) 
Training Epoch: [116/1000] Step: [160 / 285] Batch Time: 0.1479 (0.1577) Data Time: 0.0135 (0.0241) Average Loss: 0.6880 (0.7581) Average CE Loss (Source):  0.6880 ( 0.7581) Learning Rate: 0.1000 (0.1000) Top1_base: 81.2500 (79.0137) Top1_base_per_class: 79.4770 (79.4412) 
Training Epoch: [116/1000] Step: [170 / 285] Batch Time: 0.2085 (0.1579) Data Time: 0.0739 (0.0244) Average Loss: 0.6975 (0.7609) Average CE Loss (Source):  0.6975 ( 0.7609) Learning Rate: 0.1000 (0.1000) Top1_base: 80.4688 (78.8879) Top1_base_per_class: 80.6851 (79.3261) 
Training Epoch: [116/1000] Step: [180 / 285] Batch Time: 0.1472 (0.1573) Data Time: 0.0150 (0.0238) Average Loss: 0.6568 (0.7613) Average CE Loss (Source):  0.6568 ( 0.7613) Learning Rate: 0.1000 (0.1000) Top1_base: 80.4688 (78.8411) Top1_base_per_class: 82.6235 (79.3171) 
Training Epoch: [116/1000] Step: [190 / 285] Batch Time: 0.1465 (0.1568) Data Time: 0.0125 (0.0233) Average Loss: 0.7744 (0.7616) Average CE Loss (Source):  0.7744 ( 0.7616) Learning Rate: 0.1000 (0.1000) Top1_base: 78.1250 (78.8775) Top1_base_per_class: 82.8616 (79.3798) 
Training Epoch: [116/1000] Step: [200 / 285] Batch Time: 0.1474 (0.1563) Data Time: 0.0152 (0.0228) Average Loss: 0.9487 (0.7652) Average CE Loss (Source):  0.9487 ( 0.7652) Learning Rate: 0.1000 (0.1000) Top1_base: 72.6562 (78.7656) Top1_base_per_class: 71.8452 (79.2622) 
Training Epoch: [116/1000] Step: [210 / 285] Batch Time: 0.1462 (0.1559) Data Time: 0.0116 (0.0224) Average Loss: 0.7466 (0.7656) Average CE Loss (Source):  0.7466 ( 0.7656) Learning Rate: 0.1000 (0.1000) Top1_base: 78.9062 (78.7054) Top1_base_per_class: 83.6420 (79.2339) 
Training Epoch: [116/1000] Step: [220 / 285] Batch Time: 0.1477 (0.1555) Data Time: 0.0135 (0.0220) Average Loss: 0.9589 (0.7673) Average CE Loss (Source):  0.9589 ( 0.7673) Learning Rate: 0.1000 (0.1000) Top1_base: 74.2188 (78.6648) Top1_base_per_class: 72.2619 (79.1472) 
Training Epoch: [116/1000] Step: [230 / 285] Batch Time: 0.1468 (0.1554) Data Time: 0.0106 (0.0218) Average Loss: 0.6610 (0.7673) Average CE Loss (Source):  0.6610 ( 0.7673) Learning Rate: 0.1000 (0.1000) Top1_base: 83.5938 (78.6957) Top1_base_per_class: 80.4848 (79.1811) 
Training Epoch: [116/1000] Step: [240 / 285] Batch Time: 0.1489 (0.1551) Data Time: 0.0145 (0.0215) Average Loss: 0.7233 (0.7656) Average CE Loss (Source):  0.7233 ( 0.7656) Learning Rate: 0.1000 (0.1000) Top1_base: 79.6875 (78.7142) Top1_base_per_class: 83.4619 (79.1981) 
Training Epoch: [116/1000] Step: [250 / 285] Batch Time: 0.1436 (0.1556) Data Time: 0.0120 (0.0219) Average Loss: 1.0660 (0.7676) Average CE Loss (Source):  1.0660 ( 0.7676) Learning Rate: 0.1000 (0.1000) Top1_base: 72.6562 (78.6344) Top1_base_per_class: 71.1111 (79.1144) 
Training Epoch: [116/1000] Step: [260 / 285] Batch Time: 0.1514 (0.1553) Data Time: 0.0166 (0.0215) Average Loss: 0.8629 (0.7694) Average CE Loss (Source):  0.8629 ( 0.7694) Learning Rate: 0.1000 (0.1000) Top1_base: 76.5625 (78.5577) Top1_base_per_class: 74.2816 (79.0420) 
Training Epoch: [116/1000] Step: [270 / 285] Batch Time: 0.1478 (0.1553) Data Time: 0.0107 (0.0215) Average Loss: 0.7502 (0.7718) Average CE Loss (Source):  0.7502 ( 0.7718) Learning Rate: 0.1000 (0.1000) Top1_base: 79.6875 (78.4954) Top1_base_per_class: 74.4570 (78.9764) 
Training Epoch: [116/1000] Step: [280 / 285] Batch Time: 0.1472 (0.1550) Data Time: 0.0147 (0.0212) Average Loss: 0.7430 (0.7707) Average CE Loss (Source):  0.7430 ( 0.7707) Learning Rate: 0.1000 (0.1000) Top1_base: 78.9062 (78.5017) Top1_base_per_class: 77.5758 (79.0041) 
Training Epoch: [117/1000] Step: [0] Batch Time: 0.1448 (0.1554) Data Time: 0.0142 (0.0216) Average Loss: 1.0037 (0.7719) Average CE Loss (Source):  1.0037 ( 0.7719) Learning Rate: 0.1000 (0.1000) Top1_base: 70.3125 (78.4978) Top1_base_per_class: 73.3626 (79.0144) 
Training Epoch: [117/1000] Step: [10 / 285] Batch Time: 0.1488 (0.2403) Data Time: 0.0123 (0.1052) Average Loss: 0.7611 (0.7230) Average CE Loss (Source):  0.7611 ( 0.7230) Learning Rate: 0.1000 (0.1000) Top1_base: 77.3438 (79.2188) Top1_base_per_class: 74.6795 (79.8708) 
Training Epoch: [117/1000] Step: [20 / 285] Batch Time: 0.1482 (0.1973) Data Time: 0.0132 (0.0618) Average Loss: 0.7547 (0.7354) Average CE Loss (Source):  0.7547 ( 0.7354) Learning Rate: 0.1000 (0.1000) Top1_base: 79.6875 (79.3750) Top1_base_per_class: 80.7345 (79.9289) 
Training Epoch: [117/1000] Step: [30 / 285] Batch Time: 0.1510 (0.1840) Data Time: 0.0118 (0.0482) Average Loss: 0.7451 (0.7224) Average CE Loss (Source):  0.7451 ( 0.7224) Learning Rate: 0.1000 (0.1000) Top1_base: 76.5625 (79.6094) Top1_base_per_class: 76.2424 (80.0484) 
Training Epoch: [117/1000] Step: [40 / 285] Batch Time: 0.1473 (0.1766) Data Time: 0.0122 (0.0409) Average Loss: 0.9163 (0.7281) Average CE Loss (Source):  0.9163 ( 0.7281) Learning Rate: 0.1000 (0.1000) Top1_base: 77.3438 (79.7070) Top1_base_per_class: 77.3392 (80.3167) 
Training Epoch: [117/1000] Step: [50 / 285] Batch Time: 0.1492 (0.1712) Data Time: 0.0136 (0.0356) Average Loss: 0.7941 (0.7269) Average CE Loss (Source):  0.7941 ( 0.7269) Learning Rate: 0.1000 (0.1000) Top1_base: 76.5625 (79.8125) Top1_base_per_class: 76.6061 (80.5388) 
Training Epoch: [117/1000] Step: [60 / 285] Batch Time: 0.1439 (0.1676) Data Time: 0.0123 (0.0323) Average Loss: 0.7217 (0.7268) Average CE Loss (Source):  0.7217 ( 0.7268) Learning Rate: 0.1000 (0.1000) Top1_base: 78.1250 (79.8438) Top1_base_per_class: 79.7076 (80.5452) 
Training Epoch: [117/1000] Step: [70 / 285] Batch Time: 0.1461 (0.1676) Data Time: 0.0129 (0.0325) Average Loss: 0.4791 (0.7121) Average CE Loss (Source):  0.4791 ( 0.7121) Learning Rate: 0.1000 (0.1000) Top1_base: 88.2812 (80.2009) Top1_base_per_class: 88.6792 (80.7522) 
Training Epoch: [117/1000] Step: [80 / 285] Batch Time: 0.1444 (0.1677) Data Time: 0.0118 (0.0328) Average Loss: 0.6940 (0.7160) Average CE Loss (Source):  0.6940 ( 0.7160) Learning Rate: 0.1000 (0.1000) Top1_base: 80.4688 (80.0195) Top1_base_per_class: 82.0175 (80.4482) 
Training Epoch: [117/1000] Step: [90 / 285] Batch Time: 0.1497 (0.1654) Data Time: 0.0125 (0.0307) Average Loss: 0.7437 (0.7235) Average CE Loss (Source):  0.7437 ( 0.7235) Learning Rate: 0.1000 (0.1000) Top1_base: 78.1250 (79.9132) Top1_base_per_class: 80.0641 (80.4107) 
Training Epoch: [117/1000] Step: [100 / 285] Batch Time: 0.1437 (0.1638) Data Time: 0.0110 (0.0290) Average Loss: 0.7172 (0.7297) Average CE Loss (Source):  0.7172 ( 0.7297) Learning Rate: 0.1000 (0.1000) Top1_base: 81.2500 (79.8750) Top1_base_per_class: 83.9937 (80.5025) 
Training Epoch: [117/1000] Step: [110 / 285] Batch Time: 0.1472 (0.1624) Data Time: 0.0129 (0.0277) Average Loss: 0.7983 (0.7364) Average CE Loss (Source):  0.7983 ( 0.7364) Learning Rate: 0.1000 (0.1000) Top1_base: 75.0000 (79.6591) Top1_base_per_class: 75.1258 (80.3429) 
Training Epoch: [117/1000] Step: [120 / 285] Batch Time: 0.1442 (0.1616) Data Time: 0.0106 (0.0270) Average Loss: 0.8035 (0.7286) Average CE Loss (Source):  0.8035 ( 0.7286) Learning Rate: 0.1000 (0.1000) Top1_base: 82.8125 (79.8958) Top1_base_per_class: 83.3631 (80.4553) 
Training Epoch: [117/1000] Step: [130 / 285] Batch Time: 0.1415 (0.1611) Data Time: 0.0106 (0.0265) Average Loss: 0.8037 (0.7301) Average CE Loss (Source):  0.8037 ( 0.7301) Learning Rate: 0.1000 (0.1000) Top1_base: 75.7812 (79.8678) Top1_base_per_class: 80.4396 (80.4769) 
Training Epoch: [117/1000] Step: [140 / 285] Batch Time: 0.1440 (0.1605) Data Time: 0.0119 (0.0259) Average Loss: 0.9141 (0.7320) Average CE Loss (Source):  0.9141 ( 0.7320) Learning Rate: 0.1000 (0.1000) Top1_base: 75.0000 (79.7768) Top1_base_per_class: 75.5229 (80.3327) 
Training Epoch: [117/1000] Step: [150 / 285] Batch Time: 0.1464 (0.1596) Data Time: 0.0145 (0.0251) Average Loss: 1.0304 (0.7363) Average CE Loss (Source):  1.0304 ( 0.7363) Learning Rate: 0.1000 (0.1000) Top1_base: 70.3125 (79.5833) Top1_base_per_class: 71.5786 (80.1273) 
Training Epoch: [117/1000] Step: [160 / 285] Batch Time: 0.1456 (0.1588) Data Time: 0.0119 (0.0243) Average Loss: 0.8189 (0.7416) Average CE Loss (Source):  0.8189 ( 0.7416) Learning Rate: 0.1000 (0.1000) Top1_base: 75.0000 (79.4580) Top1_base_per_class: 74.2949 (79.9676) 
Training Epoch: [117/1000] Step: [170 / 285] Batch Time: 0.1485 (0.1583) Data Time: 0.0122 (0.0237) Average Loss: 0.8994 (0.7450) Average CE Loss (Source):  0.8994 ( 0.7450) Learning Rate: 0.1000 (0.1000) Top1_base: 71.0938 (79.3244) Top1_base_per_class: 75.0298 (79.8104) 
Training Epoch: [117/1000] Step: [180 / 285] Batch Time: 0.1444 (0.1577) Data Time: 0.0120 (0.0232) Average Loss: 0.7311 (0.7459) Average CE Loss (Source):  0.7311 ( 0.7459) Learning Rate: 0.1000 (0.1000) Top1_base: 78.9062 (79.2535) Top1_base_per_class: 76.0842 (79.7725) 
Training Epoch: [117/1000] Step: [190 / 285] Batch Time: 0.1473 (0.1572) Data Time: 0.0120 (0.0227) Average Loss: 0.8122 (0.7509) Average CE Loss (Source):  0.8122 ( 0.7509) Learning Rate: 0.1000 (0.1000) Top1_base: 74.2188 (79.1530) Top1_base_per_class: 75.8796 (79.6231) 
Training Epoch: [117/1000] Step: [200 / 285] Batch Time: 0.1438 (0.1567) Data Time: 0.0121 (0.0222) Average Loss: 0.5188 (0.7498) Average CE Loss (Source):  0.5188 ( 0.7498) Learning Rate: 0.1000 (0.1000) Top1_base: 81.2500 (79.0781) Top1_base_per_class: 76.8182 (79.5363) 
Training Epoch: [117/1000] Step: [210 / 285] Batch Time: 0.1481 (0.1563) Data Time: 0.0123 (0.0219) Average Loss: 0.8884 (0.7496) Average CE Loss (Source):  0.8884 ( 0.7496) Learning Rate: 0.1000 (0.1000) Top1_base: 73.4375 (79.0811) Top1_base_per_class: 72.8788 (79.5117) 
Training Epoch: [117/1000] Step: [220 / 285] Batch Time: 0.1477 (0.1561) Data Time: 0.0154 (0.0216) Average Loss: 0.9355 (0.7521) Average CE Loss (Source):  0.9355 ( 0.7521) Learning Rate: 0.1000 (0.1000) Top1_base: 72.6562 (79.0021) Top1_base_per_class: 70.9965 (79.4893) 
Training Epoch: [117/1000] Step: [230 / 285] Batch Time: 0.1454 (0.1561) Data Time: 0.0110 (0.0217) Average Loss: 0.8197 (0.7547) Average CE Loss (Source):  0.8197 ( 0.7547) Learning Rate: 0.1000 (0.1000) Top1_base: 77.3438 (78.9368) Top1_base_per_class: 82.5844 (79.4445) 
Training Epoch: [117/1000] Step: [240 / 285] Batch Time: 0.1491 (0.1566) Data Time: 0.0120 (0.0222) Average Loss: 0.8418 (0.7550) Average CE Loss (Source):  0.8418 ( 0.7550) Learning Rate: 0.1000 (0.1000) Top1_base: 80.4688 (78.9486) Top1_base_per_class: 81.5152 (79.4425) 
Training Epoch: [117/1000] Step: [250 / 285] Batch Time: 0.1459 (0.1563) Data Time: 0.0102 (0.0219) Average Loss: 0.8311 (0.7586) Average CE Loss (Source):  0.8311 ( 0.7586) Learning Rate: 0.1000 (0.1000) Top1_base: 77.3438 (78.8563) Top1_base_per_class: 76.9841 (79.3360) 
Training Epoch: [117/1000] Step: [260 / 285] Batch Time: 0.1475 (0.1559) Data Time: 0.0126 (0.0216) Average Loss: 0.6417 (0.7625) Average CE Loss (Source):  0.6417 ( 0.7625) Learning Rate: 0.1000 (0.1000) Top1_base: 82.8125 (78.7200) Top1_base_per_class: 86.0345 (79.1828) 
Training Epoch: [117/1000] Step: [270 / 285] Batch Time: 0.1485 (0.1558) Data Time: 0.0111 (0.0215) Average Loss: 0.8385 (0.7654) Average CE Loss (Source):  0.8385 ( 0.7654) Learning Rate: 0.1000 (0.1000) Top1_base: 75.0000 (78.6400) Top1_base_per_class: 78.7909 (79.1154) 
Training Epoch: [117/1000] Step: [280 / 285] Batch Time: 0.1436 (0.1556) Data Time: 0.0106 (0.0212) Average Loss: 0.9059 (0.7668) Average CE Loss (Source):  0.9059 ( 0.7668) Learning Rate: 0.1000 (0.1000) Top1_base: 76.5625 (78.5938) Top1_base_per_class: 76.2429 (79.0710) 
Training Epoch: [118/1000] Step: [0] Batch Time: 0.1457 (0.1555) Data Time: 0.0131 (0.0211) Average Loss: 0.8726 (0.7696) Average CE Loss (Source):  0.8726 ( 0.7696) Learning Rate: 0.1000 (0.1000) Top1_base: 74.2188 (78.5471) Top1_base_per_class: 73.7826 (79.0065) 
 12%|█▏        | 118/1000 [1:32:10<11:22:18, 46.41s/it] 12%|█▏        | 119/1000 [1:32:55<11:11:47, 45.75s/it]Training Epoch: [118/1000] Step: [10 / 285] Batch Time: 0.1493 (0.2376) Data Time: 0.0122 (0.1042) Average Loss: 0.9013 (0.6841) Average CE Loss (Source):  0.9013 ( 0.6841) Learning Rate: 0.1000 (0.1000) Top1_base: 75.0000 (80.0000) Top1_base_per_class: 74.0136 (79.6338) 
Training Epoch: [118/1000] Step: [20 / 285] Batch Time: 0.1422 (0.1921) Data Time: 0.0106 (0.0590) Average Loss: 0.8252 (0.7061) Average CE Loss (Source):  0.8252 ( 0.7061) Learning Rate: 0.1000 (0.1000) Top1_base: 76.5625 (80.3516) Top1_base_per_class: 77.8161 (80.2558) 
Training Epoch: [118/1000] Step: [30 / 285] Batch Time: 0.1849 (0.1808) Data Time: 0.0501 (0.0475) Average Loss: 0.7663 (0.7081) Average CE Loss (Source):  0.7663 ( 0.7081) Learning Rate: 0.1000 (0.1000) Top1_base: 75.7812 (80.4167) Top1_base_per_class: 78.5028 (80.3936) 
Training Epoch: [118/1000] Step: [40 / 285] Batch Time: 0.1450 (0.1738) Data Time: 0.0133 (0.0403) Average Loss: 0.5455 (0.7120) Average CE Loss (Source):  0.5455 ( 0.7120) Learning Rate: 0.1000 (0.1000) Top1_base: 83.5938 (80.1562) Top1_base_per_class: 86.2208 (80.2551) 
Training Epoch: [118/1000] Step: [50 / 285] Batch Time: 0.1497 (0.1713) Data Time: 0.0153 (0.0379) Average Loss: 0.7009 (0.7285) Average CE Loss (Source):  0.7009 ( 0.7285) Learning Rate: 0.1000 (0.1000) Top1_base: 81.2500 (79.7500) Top1_base_per_class: 80.3526 (80.0273) 
Training Epoch: [118/1000] Step: [60 / 285] Batch Time: 0.1425 (0.1699) Data Time: 0.0110 (0.0366) Average Loss: 0.8294 (0.7408) Average CE Loss (Source):  0.8294 ( 0.7408) Learning Rate: 0.1000 (0.1000) Top1_base: 74.2188 (79.2839) Top1_base_per_class: 76.1212 (79.5041) 
Training Epoch: [118/1000] Step: [70 / 285] Batch Time: 0.1492 (0.1672) Data Time: 0.0158 (0.0339) Average Loss: 0.6562 (0.7380) Average CE Loss (Source):  0.6562 ( 0.7380) Learning Rate: 0.1000 (0.1000) Top1_base: 82.0312 (79.0848) Top1_base_per_class: 81.1905 (79.3227) 
Training Epoch: [118/1000] Step: [80 / 285] Batch Time: 0.1449 (0.1661) Data Time: 0.0110 (0.0328) Average Loss: 0.6406 (0.7503) Average CE Loss (Source):  0.6406 ( 0.7503) Learning Rate: 0.1000 (0.1000) Top1_base: 84.3750 (78.7500) Top1_base_per_class: 84.0351 (78.9145) 
Training Epoch: [118/1000] Step: [90 / 285] Batch Time: 0.1510 (0.1648) Data Time: 0.0146 (0.0313) Average Loss: 0.8629 (0.7552) Average CE Loss (Source):  0.8629 ( 0.7552) Learning Rate: 0.1000 (0.1000) Top1_base: 78.9062 (78.7240) Top1_base_per_class: 81.4583 (78.8079) 
Training Epoch: [118/1000] Step: [100 / 285] Batch Time: 0.1451 (0.1631) Data Time: 0.0121 (0.0296) Average Loss: 0.7258 (0.7569) Average CE Loss (Source):  0.7258 ( 0.7569) Learning Rate: 0.1000 (0.1000) Top1_base: 76.5625 (78.6328) Top1_base_per_class: 77.6231 (78.7538) 
Training Epoch: [118/1000] Step: [110 / 285] Batch Time: 0.1502 (0.1616) Data Time: 0.0145 (0.0281) Average Loss: 0.7041 (0.7544) Average CE Loss (Source):  0.7041 ( 0.7544) Learning Rate: 0.1000 (0.1000) Top1_base: 78.1250 (78.6293) Top1_base_per_class: 76.2202 (78.8170) 
Training Epoch: [118/1000] Step: [120 / 285] Batch Time: 0.1430 (0.1603) Data Time: 0.0102 (0.0269) Average Loss: 0.8159 (0.7556) Average CE Loss (Source):  0.8159 ( 0.7556) Learning Rate: 0.1000 (0.1000) Top1_base: 78.1250 (78.6654) Top1_base_per_class: 77.8947 (78.9276) 
Training Epoch: [118/1000] Step: [130 / 285] Batch Time: 0.1545 (0.1593) Data Time: 0.0187 (0.0259) Average Loss: 0.8204 (0.7511) Average CE Loss (Source):  0.8204 ( 0.7511) Learning Rate: 0.1000 (0.1000) Top1_base: 75.7812 (78.7620) Top1_base_per_class: 79.2424 (79.0765) 
Training Epoch: [118/1000] Step: [140 / 285] Batch Time: 0.1443 (0.1585) Data Time: 0.0111 (0.0250) Average Loss: 0.7778 (0.7537) Average CE Loss (Source):  0.7778 ( 0.7537) Learning Rate: 0.1000 (0.1000) Top1_base: 77.3438 (78.7165) Top1_base_per_class: 78.6225 (79.0635) 
Training Epoch: [118/1000] Step: [150 / 285] Batch Time: 0.1482 (0.1584) Data Time: 0.0141 (0.0250) Average Loss: 0.9239 (0.7553) Average CE Loss (Source):  0.9239 ( 0.7553) Learning Rate: 0.1000 (0.1000) Top1_base: 69.5312 (78.7344) Top1_base_per_class: 74.7835 (79.1681) 
Training Epoch: [118/1000] Step: [160 / 285] Batch Time: 0.1474 (0.1576) Data Time: 0.0156 (0.0243) Average Loss: 0.6253 (0.7575) Average CE Loss (Source):  0.6253 ( 0.7575) Learning Rate: 0.1000 (0.1000) Top1_base: 84.3750 (78.7158) Top1_base_per_class: 84.6364 (79.1268) 
Training Epoch: [118/1000] Step: [170 / 285] Batch Time: 0.1500 (0.1571) Data Time: 0.0155 (0.0238) Average Loss: 0.7723 (0.7601) Average CE Loss (Source):  0.7723 ( 0.7601) Learning Rate: 0.1000 (0.1000) Top1_base: 75.7812 (78.6535) Top1_base_per_class: 77.0909 (79.1334) 
Training Epoch: [118/1000] Step: [180 / 285] Batch Time: 0.1454 (0.1566) Data Time: 0.0134 (0.0233) Average Loss: 0.9060 (0.7614) Average CE Loss (Source):  0.9060 ( 0.7614) Learning Rate: 0.1000 (0.1000) Top1_base: 75.0000 (78.6024) Top1_base_per_class: 71.2264 (79.0806) 
Training Epoch: [118/1000] Step: [190 / 285] Batch Time: 0.1488 (0.1563) Data Time: 0.0138 (0.0230) Average Loss: 0.7790 (0.7646) Average CE Loss (Source):  0.7790 ( 0.7646) Learning Rate: 0.1000 (0.1000) Top1_base: 77.3438 (78.5773) Top1_base_per_class: 78.9286 (79.0447) 
Training Epoch: [118/1000] Step: [200 / 285] Batch Time: 0.1437 (0.1560) Data Time: 0.0121 (0.0227) Average Loss: 0.7668 (0.7645) Average CE Loss (Source):  0.7668 ( 0.7645) Learning Rate: 0.1000 (0.1000) Top1_base: 76.5625 (78.5547) Top1_base_per_class: 77.9719 (79.0430) 
Training Epoch: [118/1000] Step: [210 / 285] Batch Time: 0.1491 (0.1556) Data Time: 0.0141 (0.0223) Average Loss: 0.5255 (0.7639) Average CE Loss (Source):  0.5255 ( 0.7639) Learning Rate: 0.1000 (0.1000) Top1_base: 85.9375 (78.5603) Top1_base_per_class: 85.2976 (79.0622) 
Training Epoch: [118/1000] Step: [220 / 285] Batch Time: 0.1457 (0.1553) Data Time: 0.0140 (0.0220) Average Loss: 0.6476 (0.7640) Average CE Loss (Source):  0.6476 ( 0.7640) Learning Rate: 0.1000 (0.1000) Top1_base: 84.3750 (78.6009) Top1_base_per_class: 81.3889 (79.1241) 
Training Epoch: [118/1000] Step: [230 / 285] Batch Time: 0.1510 (0.1553) Data Time: 0.0146 (0.0219) Average Loss: 0.8099 (0.7655) Average CE Loss (Source):  0.8099 ( 0.7655) Learning Rate: 0.1000 (0.1000) Top1_base: 78.9062 (78.5258) Top1_base_per_class: 75.5975 (79.0278) 
Training Epoch: [118/1000] Step: [240 / 285] Batch Time: 0.1463 (0.1554) Data Time: 0.0125 (0.0220) Average Loss: 0.5875 (0.7658) Average CE Loss (Source):  0.5875 ( 0.7658) Learning Rate: 0.1000 (0.1000) Top1_base: 85.1562 (78.5482) Top1_base_per_class: 83.7135 (79.0099) 
Training Epoch: [118/1000] Step: [250 / 285] Batch Time: 0.1501 (0.1551) Data Time: 0.0139 (0.0216) Average Loss: 0.9901 (0.7661) Average CE Loss (Source):  0.9901 ( 0.7661) Learning Rate: 0.1000 (0.1000) Top1_base: 73.4375 (78.5906) Top1_base_per_class: 72.7932 (79.0588) 
Training Epoch: [118/1000] Step: [260 / 285] Batch Time: 0.1474 (0.1552) Data Time: 0.0133 (0.0217) Average Loss: 0.7367 (0.7659) Average CE Loss (Source):  0.7367 ( 0.7659) Learning Rate: 0.1000 (0.1000) Top1_base: 75.7812 (78.5877) Top1_base_per_class: 74.6491 (79.0553) 
Training Epoch: [118/1000] Step: [270 / 285] Batch Time: 0.1484 (0.1552) Data Time: 0.0135 (0.0216) Average Loss: 0.7883 (0.7638) Average CE Loss (Source):  0.7883 ( 0.7638) Learning Rate: 0.1000 (0.1000) Top1_base: 78.9062 (78.6632) Top1_base_per_class: 78.9076 (79.1568) 
Training Epoch: [118/1000] Step: [280 / 285] Batch Time: 0.1472 (0.1549) Data Time: 0.0135 (0.0213) Average Loss: 0.7091 (0.7685) Average CE Loss (Source):  0.7091 ( 0.7685) Learning Rate: 0.1000 (0.1000) Top1_base: 82.0312 (78.5296) Top1_base_per_class: 79.8851 (79.0310) 
Training Epoch: [119/1000] Step: [0] Batch Time: 0.1447 (0.1549) Data Time: 0.0093 (0.0213) Average Loss: 0.6812 (0.7685) Average CE Loss (Source):  0.6812 ( 0.7685) Learning Rate: 0.1000 (0.1000) Top1_base: 77.3438 (78.5060) Top1_base_per_class: 76.4935 (79.0256) 
Training Epoch: [119/1000] Step: [10 / 285] Batch Time: 0.1445 (0.2397) Data Time: 0.0106 (0.1067) Average Loss: 0.7511 (0.6853) Average CE Loss (Source):  0.7511 ( 0.6853) Learning Rate: 0.1000 (0.1000) Top1_base: 76.5625 (81.0156) Top1_base_per_class: 75.9226 (81.8893) 
Training Epoch: [119/1000] Step: [20 / 285] Batch Time: 0.1458 (0.2063) Data Time: 0.0153 (0.0735) Average Loss: 0.6762 (0.6985) Average CE Loss (Source):  0.6762 ( 0.6985) Learning Rate: 0.1000 (0.1000) Top1_base: 82.8125 (80.7812) Top1_base_per_class: 85.1462 (81.4349) 
Training Epoch: [119/1000] Step: [30 / 285] Batch Time: 0.1435 (0.1894) Data Time: 0.0105 (0.0567) Average Loss: 0.6225 (0.6898) Average CE Loss (Source):  0.6225 ( 0.6898) Learning Rate: 0.1000 (0.1000) Top1_base: 80.4688 (80.7812) Top1_base_per_class: 82.2881 (81.1082) 
Training Epoch: [119/1000] Step: [40 / 285] Batch Time: 0.1434 (0.1856) Data Time: 0.0120 (0.0528) Average Loss: 0.6885 (0.6926) Average CE Loss (Source):  0.6885 ( 0.6926) Learning Rate: 0.1000 (0.1000) Top1_base: 82.8125 (80.5273) Top1_base_per_class: 82.0238 (80.8546) 
Training Epoch: [119/1000] Step: [50 / 285] Batch Time: 0.1426 (0.1798) Data Time: 0.0116 (0.0472) Average Loss: 0.7634 (0.7016) Average CE Loss (Source):  0.7634 ( 0.7016) Learning Rate: 0.1000 (0.1000) Top1_base: 80.4688 (80.4688) Top1_base_per_class: 77.9091 (80.9413) 
Training Epoch: [119/1000] Step: [60 / 285] Batch Time: 0.1479 (0.1758) Data Time: 0.0116 (0.0426) Average Loss: 0.9720 (0.7085) Average CE Loss (Source):  0.9720 ( 0.7085) Learning Rate: 0.1000 (0.1000) Top1_base: 69.5312 (80.1823) Top1_base_per_class: 70.3801 (80.7520) 
Training Epoch: [119/1000] Step: [70 / 285] Batch Time: 0.1480 (0.1736) Data Time: 0.0104 (0.0401) Average Loss: 0.7208 (0.7177) Average CE Loss (Source):  0.7208 ( 0.7177) Learning Rate: 0.1000 (0.1000) Top1_base: 82.8125 (79.9888) Top1_base_per_class: 86.2654 (80.6221) 
Training Epoch: [119/1000] Step: [80 / 285] Batch Time: 0.1468 (0.1715) Data Time: 0.0117 (0.0377) Average Loss: 0.7633 (0.7270) Average CE Loss (Source):  0.7633 ( 0.7270) Learning Rate: 0.1000 (0.1000) Top1_base: 78.1250 (79.6875) Top1_base_per_class: 77.3810 (80.4449) 
Training Epoch: [119/1000] Step: [90 / 285] Batch Time: 0.1493 (0.1691) Data Time: 0.0150 (0.0352) Average Loss: 0.7353 (0.7265) Average CE Loss (Source):  0.7353 ( 0.7265) Learning Rate: 0.1000 (0.1000) Top1_base: 79.6875 (79.6267) Top1_base_per_class: 82.8846 (80.4294) 
Training Epoch: [119/1000] Step: [100 / 285] Batch Time: 0.1468 (0.1672) Data Time: 0.0149 (0.0332) Average Loss: 0.7512 (0.7321) Average CE Loss (Source):  0.7512 ( 0.7321) Learning Rate: 0.1000 (0.1000) Top1_base: 81.2500 (79.4609) Top1_base_per_class: 87.6415 (80.3591) 
Training Epoch: [119/1000] Step: [110 / 285] Batch Time: 0.1479 (0.1669) Data Time: 0.0146 (0.0328) Average Loss: 0.9113 (0.7392) Average CE Loss (Source):  0.9113 ( 0.7392) Learning Rate: 0.1000 (0.1000) Top1_base: 79.6875 (79.3821) Top1_base_per_class: 80.6364 (80.2236) 
Training Epoch: [119/1000] Step: [120 / 285] Batch Time: 0.1462 (0.1653) Data Time: 0.0120 (0.0313) Average Loss: 0.7530 (0.7393) Average CE Loss (Source):  0.7530 ( 0.7393) Learning Rate: 0.1000 (0.1000) Top1_base: 80.4688 (79.4466) Top1_base_per_class: 79.6491 (80.2876) 
Training Epoch: [119/1000] Step: [130 / 285] Batch Time: 0.1520 (0.1652) Data Time: 0.0131 (0.0311) Average Loss: 0.8376 (0.7399) Average CE Loss (Source):  0.8376 ( 0.7399) Learning Rate: 0.1000 (0.1000) Top1_base: 78.9062 (79.4231) Top1_base_per_class: 77.9592 (80.2505) 
Training Epoch: [119/1000] Step: [140 / 285] Batch Time: 0.1478 (0.1646) Data Time: 0.0150 (0.0305) Average Loss: 0.8015 (0.7462) Average CE Loss (Source):  0.8015 ( 0.7462) Learning Rate: 0.1000 (0.1000) Top1_base: 77.3438 (79.1908) Top1_base_per_class: 76.3636 (80.0424) 
Training Epoch: [119/1000] Step: [150 / 285] Batch Time: 0.1443 (0.1636) Data Time: 0.0107 (0.0296) Average Loss: 0.7659 (0.7475) Average CE Loss (Source):  0.7659 ( 0.7475) Learning Rate: 0.1000 (0.1000) Top1_base: 78.1250 (79.1562) Top1_base_per_class: 78.1173 (79.9503) 
Training Epoch: [119/1000] Step: [160 / 285] Batch Time: 0.1479 (0.1632) Data Time: 0.0118 (0.0292) Average Loss: 0.5771 (0.7492) Average CE Loss (Source):  0.5771 ( 0.7492) Learning Rate: 0.1000 (0.1000) Top1_base: 85.1562 (79.1699) Top1_base_per_class: 85.1437 (79.9289) 
Training Epoch: [119/1000] Step: [170 / 285] Batch Time: 0.1466 (0.1630) Data Time: 0.0103 (0.0291) Average Loss: 0.6219 (0.7484) Average CE Loss (Source):  0.6219 ( 0.7484) Learning Rate: 0.1000 (0.1000) Top1_base: 83.5938 (79.1314) Top1_base_per_class: 85.1695 (79.8733) 
Training Epoch: [119/1000] Step: [180 / 285] Batch Time: 0.1437 (0.1626) Data Time: 0.0111 (0.0287) Average Loss: 0.6007 (0.7476) Average CE Loss (Source):  0.6007 ( 0.7476) Learning Rate: 0.1000 (0.1000) Top1_base: 81.2500 (79.1016) Top1_base_per_class: 83.8788 (79.7942) 
Training Epoch: [119/1000] Step: [190 / 285] Batch Time: 0.1458 (0.1622) Data Time: 0.0104 (0.0283) Average Loss: 0.8781 (0.7495) Average CE Loss (Source):  0.8781 ( 0.7495) Learning Rate: 0.1000 (0.1000) Top1_base: 78.1250 (79.0748) Top1_base_per_class: 76.2654 (79.7186) 
Training Epoch: [119/1000] Step: [200 / 285] Batch Time: 0.1468 (0.1623) Data Time: 0.0121 (0.0283) Average Loss: 0.8661 (0.7503) Average CE Loss (Source):  0.8661 ( 0.7503) Learning Rate: 0.1000 (0.1000) Top1_base: 73.4375 (79.0352) Top1_base_per_class: 74.6552 (79.7220) 
Training Epoch: [119/1000] Step: [210 / 285] Batch Time: 0.1481 (0.1624) Data Time: 0.0112 (0.0283) Average Loss: 0.6849 (0.7534) Average CE Loss (Source):  0.6849 ( 0.7534) Learning Rate: 0.1000 (0.1000) Top1_base: 81.2500 (78.9583) Top1_base_per_class: 83.4259 (79.5866) 
Training Epoch: [119/1000] Step: [220 / 285] Batch Time: 0.1478 (0.1618) Data Time: 0.0124 (0.0276) Average Loss: 0.6315 (0.7547) Average CE Loss (Source):  0.6315 ( 0.7547) Learning Rate: 0.1000 (0.1000) Top1_base: 80.4688 (78.9240) Top1_base_per_class: 80.9877 (79.5570) 
Training Epoch: [119/1000] Step: [230 / 285] Batch Time: 0.1483 (0.1613) Data Time: 0.0108 (0.0271) Average Loss: 1.0412 (0.7555) Average CE Loss (Source):  1.0412 ( 0.7555) Learning Rate: 0.1000 (0.1000) Top1_base: 67.9688 (78.9062) Top1_base_per_class: 64.9415 (79.5240) 
Training Epoch: [119/1000] Step: [240 / 285] Batch Time: 0.1455 (0.1608) Data Time: 0.0126 (0.0266) Average Loss: 0.7515 (0.7563) Average CE Loss (Source):  0.7515 ( 0.7563) Learning Rate: 0.1000 (0.1000) Top1_base: 79.6875 (78.8997) Top1_base_per_class: 75.5357 (79.5122) 
Training Epoch: [119/1000] Step: [250 / 285] Batch Time: 0.1440 (0.1614) Data Time: 0.0104 (0.0273) Average Loss: 0.5983 (0.7564) Average CE Loss (Source):  0.5983 ( 0.7564) Learning Rate: 0.1000 (0.1000) Top1_base: 82.0312 (78.8875) Top1_base_per_class: 83.8988 (79.5237) 
Training Epoch: [119/1000] Step: [260 / 285] Batch Time: 0.1435 (0.1613) Data Time: 0.0121 (0.0272) Average Loss: 0.7969 (0.7562) Average CE Loss (Source):  0.7969 ( 0.7562) Learning Rate: 0.1000 (0.1000) Top1_base: 81.2500 (78.9002) Top1_base_per_class: 84.5597 (79.5232) 
Training Epoch: [119/1000] Step: [270 / 285] Batch Time: 0.1455 (0.1615) Data Time: 0.0108 (0.0274) Average Loss: 0.7959 (0.7557) Average CE Loss (Source):  0.7959 ( 0.7557) Learning Rate: 0.1000 (0.1000) Top1_base: 74.2188 (78.8513) Top1_base_per_class: 70.2830 (79.4676) 
Training Epoch: [119/1000] Step: [280 / 285] Batch Time: 0.1451 (0.1611) Data Time: 0.0109 (0.0271) Average Loss: 0.9130 (0.7563) Average CE Loss (Source):  0.9130 ( 0.7563) Learning Rate: 0.1000 (0.1000) Top1_base: 72.6562 (78.8393) Top1_base_per_class: 72.9762 (79.4537) 
Training Epoch: [120/1000] Step: [0] Batch Time: 0.1608 (0.1611) Data Time: 0.0266 (0.0271) Average Loss: 1.1666 (0.7583) Average CE Loss (Source):  1.1666 ( 0.7583) Learning Rate: 0.1000 (0.1000) Top1_base: 67.9688 (78.7993) Top1_base_per_class: 74.4444 (79.4491) 
 12%|█▏        | 120/1000 [1:33:43<11:24:00, 46.64s/it] 12%|█▏        | 121/1000 [1:34:28<11:16:57, 46.21s/it]Training Epoch: [120/1000] Step: [10 / 285] Batch Time: 0.1432 (0.2323) Data Time: 0.0114 (0.0992) Average Loss: 0.7496 (0.7816) Average CE Loss (Source):  0.7496 ( 0.7816) Learning Rate: 0.1000 (0.1000) Top1_base: 75.7812 (79.1406) Top1_base_per_class: 78.1322 (80.2445) 
Training Epoch: [120/1000] Step: [20 / 285] Batch Time: 0.1460 (0.1956) Data Time: 0.0136 (0.0624) Average Loss: 0.7707 (0.7601) Average CE Loss (Source):  0.7707 ( 0.7601) Learning Rate: 0.1000 (0.1000) Top1_base: 81.2500 (78.7500) Top1_base_per_class: 83.3939 (80.2791) 
Training Epoch: [120/1000] Step: [30 / 285] Batch Time: 0.1434 (0.1820) Data Time: 0.0105 (0.0489) Average Loss: 0.7400 (0.7443) Average CE Loss (Source):  0.7400 ( 0.7443) Learning Rate: 0.1000 (0.1000) Top1_base: 78.1250 (78.9583) Top1_base_per_class: 80.3390 (80.3433) 
Training Epoch: [120/1000] Step: [40 / 285] Batch Time: 0.1470 (0.1746) Data Time: 0.0135 (0.0415) Average Loss: 0.6075 (0.7404) Average CE Loss (Source):  0.6075 ( 0.7404) Learning Rate: 0.1000 (0.1000) Top1_base: 79.6875 (79.1602) Top1_base_per_class: 79.2593 (80.4515) 
Training Epoch: [120/1000] Step: [50 / 285] Batch Time: 0.1450 (0.1708) Data Time: 0.0120 (0.0377) Average Loss: 0.8354 (0.7376) Average CE Loss (Source):  0.8354 ( 0.7376) Learning Rate: 0.1000 (0.1000) Top1_base: 75.7812 (79.2969) Top1_base_per_class: 75.5357 (80.4817) 
Training Epoch: [120/1000] Step: [60 / 285] Batch Time: 0.1503 (0.1687) Data Time: 0.0137 (0.0354) Average Loss: 0.6519 (0.7411) Average CE Loss (Source):  0.6519 ( 0.7411) Learning Rate: 0.1000 (0.1000) Top1_base: 81.2500 (79.3359) Top1_base_per_class: 81.3988 (80.4389) 
Training Epoch: [120/1000] Step: [70 / 285] Batch Time: 0.1449 (0.1667) Data Time: 0.0131 (0.0334) Average Loss: 0.9167 (0.7401) Average CE Loss (Source):  0.9167 ( 0.7401) Learning Rate: 0.1000 (0.1000) Top1_base: 78.9062 (79.3750) Top1_base_per_class: 79.1228 (80.3667) 
Training Epoch: [120/1000] Step: [80 / 285] Batch Time: 0.1419 (0.1653) Data Time: 0.0111 (0.0321) Average Loss: 0.8474 (0.7394) Average CE Loss (Source):  0.8474 ( 0.7394) Learning Rate: 0.1000 (0.1000) Top1_base: 77.3438 (79.4043) Top1_base_per_class: 76.7593 (80.4202) 
Training Epoch: [120/1000] Step: [90 / 285] Batch Time: 0.1467 (0.1657) Data Time: 0.0119 (0.0325) Average Loss: 0.7347 (0.7328) Average CE Loss (Source):  0.7347 ( 0.7328) Learning Rate: 0.1000 (0.1000) Top1_base: 77.3438 (79.5312) Top1_base_per_class: 76.2848 (80.4350) 
Training Epoch: [120/1000] Step: [100 / 285] Batch Time: 0.1436 (0.1643) Data Time: 0.0120 (0.0312) Average Loss: 0.8261 (0.7296) Average CE Loss (Source):  0.8261 ( 0.7296) Learning Rate: 0.1000 (0.1000) Top1_base: 73.4375 (79.4766) Top1_base_per_class: 71.8926 (80.3370) 
Training Epoch: [120/1000] Step: [110 / 285] Batch Time: 0.1460 (0.1628) Data Time: 0.0115 (0.0297) Average Loss: 0.8735 (0.7310) Average CE Loss (Source):  0.8735 ( 0.7310) Learning Rate: 0.1000 (0.1000) Top1_base: 70.3125 (79.3892) Top1_base_per_class: 75.3953 (80.3200) 
Training Epoch: [120/1000] Step: [120 / 285] Batch Time: 0.1454 (0.1631) Data Time: 0.0119 (0.0300) Average Loss: 0.8811 (0.7370) Average CE Loss (Source):  0.8811 ( 0.7370) Learning Rate: 0.1000 (0.1000) Top1_base: 77.3438 (79.3034) Top1_base_per_class: 78.4056 (80.1133) 
Training Epoch: [120/1000] Step: [130 / 285] Batch Time: 0.1495 (0.1624) Data Time: 0.0156 (0.0293) Average Loss: 0.7806 (0.7376) Average CE Loss (Source):  0.7806 ( 0.7376) Learning Rate: 0.1000 (0.1000) Top1_base: 78.1250 (79.2428) Top1_base_per_class: 80.5747 (79.9921) 
Training Epoch: [120/1000] Step: [140 / 285] Batch Time: 0.1437 (0.1620) Data Time: 0.0115 (0.0288) Average Loss: 0.6057 (0.7380) Average CE Loss (Source):  0.6057 ( 0.7380) Learning Rate: 0.1000 (0.1000) Top1_base: 82.8125 (79.2355) Top1_base_per_class: 81.7251 (79.9364) 
Training Epoch: [120/1000] Step: [150 / 285] Batch Time: 0.1438 (0.1620) Data Time: 0.0112 (0.0289) Average Loss: 0.9107 (0.7381) Average CE Loss (Source):  0.9107 ( 0.7381) Learning Rate: 0.1000 (0.1000) Top1_base: 73.4375 (79.2344) Top1_base_per_class: 73.5000 (79.9080) 
Training Epoch: [120/1000] Step: [160 / 285] Batch Time: 0.1466 (0.1626) Data Time: 0.0132 (0.0294) Average Loss: 0.7648 (0.7356) Average CE Loss (Source):  0.7648 ( 0.7356) Learning Rate: 0.1000 (0.1000) Top1_base: 77.3438 (79.3408) Top1_base_per_class: 78.8393 (80.0595) 
Training Epoch: [120/1000] Step: [170 / 285] Batch Time: 0.1441 (0.1625) Data Time: 0.0118 (0.0292) Average Loss: 0.8506 (0.7414) Average CE Loss (Source):  0.8506 ( 0.7414) Learning Rate: 0.1000 (0.1000) Top1_base: 76.5625 (79.2371) Top1_base_per_class: 77.0988 (79.9248) 
Training Epoch: [120/1000] Step: [180 / 285] Batch Time: 0.1445 (0.1618) Data Time: 0.0119 (0.0285) Average Loss: 0.9858 (0.7453) Average CE Loss (Source):  0.9858 ( 0.7453) Learning Rate: 0.1000 (0.1000) Top1_base: 71.8750 (79.1189) Top1_base_per_class: 73.0864 (79.7818) 
Training Epoch: [120/1000] Step: [190 / 285] Batch Time: 0.1451 (0.1614) Data Time: 0.0124 (0.0281) Average Loss: 0.6837 (0.7480) Average CE Loss (Source):  0.6837 ( 0.7480) Learning Rate: 0.1000 (0.1000) Top1_base: 78.9062 (79.0461) Top1_base_per_class: 82.1726 (79.7438) 
Training Epoch: [120/1000] Step: [200 / 285] Batch Time: 0.1451 (0.1609) Data Time: 0.0117 (0.0276) Average Loss: 0.7606 (0.7503) Average CE Loss (Source):  0.7606 ( 0.7503) Learning Rate: 0.1000 (0.1000) Top1_base: 80.4688 (78.9414) Top1_base_per_class: 80.0000 (79.6586) 
Training Epoch: [120/1000] Step: [210 / 285] Batch Time: 0.1444 (0.1608) Data Time: 0.0118 (0.0275) Average Loss: 0.6752 (0.7492) Average CE Loss (Source):  0.6752 ( 0.7492) Learning Rate: 0.1000 (0.1000) Top1_base: 80.4688 (78.9583) Top1_base_per_class: 85.1818 (79.7096) 
Training Epoch: [120/1000] Step: [220 / 285] Batch Time: 0.1486 (0.1603) Data Time: 0.0145 (0.0271) Average Loss: 0.7460 (0.7530) Average CE Loss (Source):  0.7460 ( 0.7530) Learning Rate: 0.1000 (0.1000) Top1_base: 81.2500 (78.8849) Top1_base_per_class: 80.6061 (79.6270) 
Training Epoch: [120/1000] Step: [230 / 285] Batch Time: 0.1460 (0.1599) Data Time: 0.0115 (0.0265) Average Loss: 0.9211 (0.7551) Average CE Loss (Source):  0.9211 ( 0.7551) Learning Rate: 0.1000 (0.1000) Top1_base: 76.5625 (78.7772) Top1_base_per_class: 80.9697 (79.5570) 
Training Epoch: [120/1000] Step: [240 / 285] Batch Time: 0.1409 (0.1598) Data Time: 0.0105 (0.0264) Average Loss: 0.8520 (0.7568) Average CE Loss (Source):  0.8520 ( 0.7568) Learning Rate: 0.1000 (0.1000) Top1_base: 76.5625 (78.7500) Top1_base_per_class: 77.4510 (79.5559) 
Training Epoch: [120/1000] Step: [250 / 285] Batch Time: 0.1488 (0.1598) Data Time: 0.0162 (0.0264) Average Loss: 0.7065 (0.7604) Average CE Loss (Source):  0.7065 ( 0.7604) Learning Rate: 0.1000 (0.1000) Top1_base: 79.6875 (78.6531) Top1_base_per_class: 82.3100 (79.4488) 
Training Epoch: [120/1000] Step: [260 / 285] Batch Time: 0.1433 (0.1593) Data Time: 0.0119 (0.0260) Average Loss: 0.7571 (0.7616) Average CE Loss (Source):  0.7571 ( 0.7616) Learning Rate: 0.1000 (0.1000) Top1_base: 79.6875 (78.6088) Top1_base_per_class: 80.3801 (79.3545) 
Training Epoch: [120/1000] Step: [270 / 285] Batch Time: 0.1465 (0.1589) Data Time: 0.0124 (0.0256) Average Loss: 0.6543 (0.7600) Average CE Loss (Source):  0.6543 ( 0.7600) Learning Rate: 0.1000 (0.1000) Top1_base: 83.5938 (78.6661) Top1_base_per_class: 83.1140 (79.4103) 
Training Epoch: [120/1000] Step: [280 / 285] Batch Time: 0.1467 (0.1585) Data Time: 0.0137 (0.0252) Average Loss: 0.7248 (0.7599) Average CE Loss (Source):  0.7248 ( 0.7599) Learning Rate: 0.1000 (0.1000) Top1_base: 80.4688 (78.6858) Top1_base_per_class: 81.4151 (79.4267) 
Training Epoch: [121/1000] Step: [0] Batch Time: 0.1598 (0.1584) Data Time: 0.0267 (0.0251) Average Loss: 0.8525 (0.7609) Average CE Loss (Source):  0.8525 ( 0.7609) Learning Rate: 0.1000 (0.1000) Top1_base: 79.6875 (78.6595) Top1_base_per_class: 82.1751 (79.4087) 
Training Epoch: [121/1000] Step: [10 / 285] Batch Time: 0.1462 (0.2355) Data Time: 0.0125 (0.1029) Average Loss: 0.8924 (0.6866) Average CE Loss (Source):  0.8924 ( 0.6866) Learning Rate: 0.1000 (0.1000) Top1_base: 75.7812 (81.3281) Top1_base_per_class: 77.4011 (81.2989) 
Training Epoch: [121/1000] Step: [20 / 285] Batch Time: 0.1468 (0.1981) Data Time: 0.0147 (0.0651) Average Loss: 0.6578 (0.6970) Average CE Loss (Source):  0.6578 ( 0.6970) Learning Rate: 0.1000 (0.1000) Top1_base: 84.3750 (81.0938) Top1_base_per_class: 82.8997 (81.0213) 
Training Epoch: [121/1000] Step: [30 / 285] Batch Time: 0.1422 (0.1872) Data Time: 0.0111 (0.0546) Average Loss: 0.8199 (0.7237) Average CE Loss (Source):  0.8199 ( 0.7237) Learning Rate: 0.1000 (0.1000) Top1_base: 76.5625 (80.3906) Top1_base_per_class: 75.6973 (80.0288) 
Training Epoch: [121/1000] Step: [40 / 285] Batch Time: 0.1448 (0.1778) Data Time: 0.0125 (0.0454) Average Loss: 0.7063 (0.7067) Average CE Loss (Source):  0.7063 ( 0.7067) Learning Rate: 0.1000 (0.1000) Top1_base: 78.1250 (80.6641) Top1_base_per_class: 79.9713 (80.5350) 
Training Epoch: [121/1000] Step: [50 / 285] Batch Time: 0.1432 (0.1723) Data Time: 0.0116 (0.0400) Average Loss: 0.7871 (0.7260) Average CE Loss (Source):  0.7871 ( 0.7260) Learning Rate: 0.1000 (0.1000) Top1_base: 75.7812 (79.8594) Top1_base_per_class: 75.0287 (79.7830) 
Training Epoch: [121/1000] Step: [60 / 285] Batch Time: 0.1492 (0.1679) Data Time: 0.0139 (0.0355) Average Loss: 0.6321 (0.7165) Average CE Loss (Source):  0.6321 ( 0.7165) Learning Rate: 0.1000 (0.1000) Top1_base: 81.2500 (80.1562) Top1_base_per_class: 84.1228 (80.0790) 
Training Epoch: [121/1000] Step: [70 / 285] Batch Time: 0.1498 (0.1664) Data Time: 0.0121 (0.0337) Average Loss: 0.8492 (0.7187) Average CE Loss (Source):  0.8492 ( 0.7187) Learning Rate: 0.1000 (0.1000) Top1_base: 76.5625 (79.9888) Top1_base_per_class: 82.0440 (80.0837) 
Training Epoch: [121/1000] Step: [80 / 285] Batch Time: 0.1483 (0.1650) Data Time: 0.0137 (0.0319) Average Loss: 0.6659 (0.7176) Average CE Loss (Source):  0.6659 ( 0.7176) Learning Rate: 0.1000 (0.1000) Top1_base: 81.2500 (79.9219) Top1_base_per_class: 80.9604 (80.0977) 
Training Epoch: [121/1000] Step: [90 / 285] Batch Time: 0.1455 (0.1632) Data Time: 0.0147 (0.0299) Average Loss: 0.6546 (0.7246) Average CE Loss (Source):  0.6546 ( 0.7246) Learning Rate: 0.1000 (0.1000) Top1_base: 82.8125 (79.6441) Top1_base_per_class: 84.8830 (79.7878) 
Training Epoch: [121/1000] Step: [100 / 285] Batch Time: 0.1480 (0.1625) Data Time: 0.0134 (0.0290) Average Loss: 0.6855 (0.7230) Average CE Loss (Source):  0.6855 ( 0.7230) Learning Rate: 0.1000 (0.1000) Top1_base: 80.4688 (79.7031) Top1_base_per_class: 80.0877 (79.8338) 
Training Epoch: [121/1000] Step: [110 / 285] Batch Time: 0.1483 (0.1619) Data Time: 0.0142 (0.0284) Average Loss: 0.6884 (0.7222) Average CE Loss (Source):  0.6884 ( 0.7222) Learning Rate: 0.1000 (0.1000) Top1_base: 79.6875 (79.8011) Top1_base_per_class: 78.6310 (79.9694) 
Training Epoch: [121/1000] Step: [120 / 285] Batch Time: 0.2162 (0.1621) Data Time: 0.0842 (0.0284) Average Loss: 0.7978 (0.7248) Average CE Loss (Source):  0.7978 ( 0.7248) Learning Rate: 0.1000 (0.1000) Top1_base: 78.9062 (79.7135) Top1_base_per_class: 78.1746 (79.8431) 
Training Epoch: [121/1000] Step: [130 / 285] Batch Time: 0.1486 (0.1611) Data Time: 0.0149 (0.0273) Average Loss: 0.7342 (0.7271) Average CE Loss (Source):  0.7342 ( 0.7271) Learning Rate: 0.1000 (0.1000) Top1_base: 77.3438 (79.6755) Top1_base_per_class: 78.1212 (79.8598) 
Training Epoch: [121/1000] Step: [140 / 285] Batch Time: 0.1671 (0.1605) Data Time: 0.0360 (0.0268) Average Loss: 0.7124 (0.7252) Average CE Loss (Source):  0.7124 ( 0.7252) Learning Rate: 0.1000 (0.1000) Top1_base: 78.1250 (79.6317) Top1_base_per_class: 78.3333 (79.8366) 
Training Epoch: [121/1000] Step: [150 / 285] Batch Time: 0.1500 (0.1596) Data Time: 0.0135 (0.0259) Average Loss: 0.7941 (0.7234) Average CE Loss (Source):  0.7941 ( 0.7234) Learning Rate: 0.1000 (0.1000) Top1_base: 74.2188 (79.6667) Top1_base_per_class: 75.8479 (79.8605) 
Training Epoch: [121/1000] Step: [160 / 285] Batch Time: 0.1631 (0.1593) Data Time: 0.0325 (0.0256) Average Loss: 0.8619 (0.7266) Average CE Loss (Source):  0.8619 ( 0.7266) Learning Rate: 0.1000 (0.1000) Top1_base: 75.0000 (79.5410) Top1_base_per_class: 77.2840 (79.7461) 
Training Epoch: [121/1000] Step: [170 / 285] Batch Time: 0.1475 (0.1586) Data Time: 0.0132 (0.0249) Average Loss: 0.6759 (0.7288) Average CE Loss (Source):  0.6759 ( 0.7288) Learning Rate: 0.1000 (0.1000) Top1_base: 82.0312 (79.5129) Top1_base_per_class: 79.0741 (79.6766) 
Training Epoch: [121/1000] Step: [180 / 285] Batch Time: 0.2694 (0.1587) Data Time: 0.1342 (0.0249) Average Loss: 0.7905 (0.7285) Average CE Loss (Source):  0.7905 ( 0.7285) Learning Rate: 0.1000 (0.1000) Top1_base: 75.0000 (79.5312) Top1_base_per_class: 73.7006 (79.6919) 
Training Epoch: [121/1000] Step: [190 / 285] Batch Time: 0.1519 (0.1583) Data Time: 0.0154 (0.0244) Average Loss: 0.7634 (0.7331) Average CE Loss (Source):  0.7634 ( 0.7331) Learning Rate: 0.1000 (0.1000) Top1_base: 81.2500 (79.4161) Top1_base_per_class: 81.8210 (79.5808) 
Training Epoch: [121/1000] Step: [200 / 285] Batch Time: 0.1508 (0.1577) Data Time: 0.0182 (0.0239) Average Loss: 0.8373 (0.7337) Average CE Loss (Source):  0.8373 ( 0.7337) Learning Rate: 0.1000 (0.1000) Top1_base: 74.2188 (79.3789) Top1_base_per_class: 79.7024 (79.5685) 
Training Epoch: [121/1000] Step: [210 / 285] Batch Time: 0.1480 (0.1572) Data Time: 0.0123 (0.0234) Average Loss: 0.7506 (0.7383) Average CE Loss (Source):  0.7506 ( 0.7383) Learning Rate: 0.1000 (0.1000) Top1_base: 78.1250 (79.2299) Top1_base_per_class: 75.8176 (79.4817) 
Training Epoch: [121/1000] Step: [220 / 285] Batch Time: 0.1524 (0.1568) Data Time: 0.0185 (0.0230) Average Loss: 0.7986 (0.7430) Average CE Loss (Source):  0.7986 ( 0.7430) Learning Rate: 0.1000 (0.1000) Top1_base: 75.7812 (79.1335) Top1_base_per_class: 75.3395 (79.3926) 
Training Epoch: [121/1000] Step: [230 / 285] Batch Time: 0.1424 (0.1568) Data Time: 0.0113 (0.0231) Average Loss: 0.7622 (0.7455) Average CE Loss (Source):  0.7622 ( 0.7455) Learning Rate: 0.1000 (0.1000) Top1_base: 81.2500 (79.0625) Top1_base_per_class: 81.2987 (79.3135) 
Training Epoch: [121/1000] Step: [240 / 285] Batch Time: 0.1541 (0.1565) Data Time: 0.0177 (0.0227) Average Loss: 0.9001 (0.7488) Average CE Loss (Source):  0.9001 ( 0.7488) Learning Rate: 0.1000 (0.1000) Top1_base: 78.9062 (78.9648) Top1_base_per_class: 75.8187 (79.2306) 
Training Epoch: [121/1000] Step: [250 / 285] Batch Time: 0.1503 (0.1562) Data Time: 0.0148 (0.0224) Average Loss: 0.7081 (0.7517) Average CE Loss (Source):  0.7081 ( 0.7517) Learning Rate: 0.1000 (0.1000) Top1_base: 79.6875 (78.8563) Top1_base_per_class: 82.8104 (79.1258) 
Training Epoch: [121/1000] Step: [260 / 285] Batch Time: 0.1468 (0.1559) Data Time: 0.0144 (0.0220) Average Loss: 1.0708 (0.7553) Average CE Loss (Source):  1.0708 ( 0.7553) Learning Rate: 0.1000 (0.1000) Top1_base: 72.6562 (78.7650) Top1_base_per_class: 73.6667 (79.0507) 
Training Epoch: [121/1000] Step: [270 / 285] Batch Time: 0.1449 (0.1555) Data Time: 0.0107 (0.0217) Average Loss: 0.8939 (0.7578) Average CE Loss (Source):  0.8939 ( 0.7578) Learning Rate: 0.1000 (0.1000) Top1_base: 74.2188 (78.6950) Top1_base_per_class: 72.6023 (79.0048) 
Training Epoch: [121/1000] Step: [280 / 285] Batch Time: 0.1486 (0.1554) Data Time: 0.0165 (0.0216) Average Loss: 0.8363 (0.7590) Average CE Loss (Source):  0.8363 ( 0.7590) Learning Rate: 0.1000 (0.1000) Top1_base: 74.2188 (78.6244) Top1_base_per_class: 73.7654 (78.9435) 
Training Epoch: [122/1000] Step: [0] Batch Time: 0.1408 (0.1552) Data Time: 0.0106 (0.0215) Average Loss: 0.8387 (0.7592) Average CE Loss (Source):  0.8387 ( 0.7592) Learning Rate: 0.1000 (0.1000) Top1_base: 78.9062 (78.6102) Top1_base_per_class: 82.4138 (78.9535) 
 12%|█▏        | 122/1000 [1:35:15<11:19:43, 46.45s/it] 12%|█▏        | 123/1000 [1:36:00<11:09:55, 45.83s/it]Training Epoch: [122/1000] Step: [10 / 285] Batch Time: 0.1451 (0.2341) Data Time: 0.0103 (0.0999) Average Loss: 0.7534 (0.8284) Average CE Loss (Source):  0.7534 ( 0.8284) Learning Rate: 0.1000 (0.1000) Top1_base: 78.1250 (76.7969) Top1_base_per_class: 82.0426 (78.5425) 
Training Epoch: [122/1000] Step: [20 / 285] Batch Time: 0.1443 (0.1954) Data Time: 0.0108 (0.0624) Average Loss: 0.7329 (0.8137) Average CE Loss (Source):  0.7329 ( 0.8137) Learning Rate: 0.1000 (0.1000) Top1_base: 80.4688 (76.8750) Top1_base_per_class: 79.1327 (77.7710) 
Training Epoch: [122/1000] Step: [30 / 285] Batch Time: 0.1463 (0.1818) Data Time: 0.0105 (0.0487) Average Loss: 0.7959 (0.8087) Average CE Loss (Source):  0.7959 ( 0.8087) Learning Rate: 0.1000 (0.1000) Top1_base: 82.0312 (77.1875) Top1_base_per_class: 83.2672 (77.9369) 
Training Epoch: [122/1000] Step: [40 / 285] Batch Time: 0.1459 (0.1746) Data Time: 0.0115 (0.0415) Average Loss: 0.6947 (0.7945) Average CE Loss (Source):  0.6947 ( 0.7945) Learning Rate: 0.1000 (0.1000) Top1_base: 83.5938 (77.6562) Top1_base_per_class: 84.1029 (78.1813) 
Training Epoch: [122/1000] Step: [50 / 285] Batch Time: 0.1541 (0.1696) Data Time: 0.0161 (0.0360) Average Loss: 0.6492 (0.7885) Average CE Loss (Source):  0.6492 ( 0.7885) Learning Rate: 0.1000 (0.1000) Top1_base: 81.2500 (77.7344) Top1_base_per_class: 79.7663 (78.1922) 
Training Epoch: [122/1000] Step: [60 / 285] Batch Time: 0.1476 (0.1661) Data Time: 0.0101 (0.0322) Average Loss: 0.7403 (0.7846) Average CE Loss (Source):  0.7403 ( 0.7846) Learning Rate: 0.1000 (0.1000) Top1_base: 78.9062 (77.8385) Top1_base_per_class: 78.5632 (78.2202) 
Training Epoch: [122/1000] Step: [70 / 285] Batch Time: 0.1498 (0.1641) Data Time: 0.0127 (0.0301) Average Loss: 0.8175 (0.7776) Average CE Loss (Source):  0.8175 ( 0.7776) Learning Rate: 0.1000 (0.1000) Top1_base: 76.5625 (78.0692) Top1_base_per_class: 79.3082 (78.5614) 
Training Epoch: [122/1000] Step: [80 / 285] Batch Time: 0.1486 (0.1623) Data Time: 0.0113 (0.0280) Average Loss: 0.7373 (0.7747) Average CE Loss (Source):  0.7373 ( 0.7747) Learning Rate: 0.1000 (0.1000) Top1_base: 78.9062 (78.1836) Top1_base_per_class: 81.8590 (78.7423) 
Training Epoch: [122/1000] Step: [90 / 285] Batch Time: 0.1431 (0.1619) Data Time: 0.0129 (0.0277) Average Loss: 0.8643 (0.7721) Average CE Loss (Source):  0.8643 ( 0.7721) Learning Rate: 0.1000 (0.1000) Top1_base: 75.7812 (78.2378) Top1_base_per_class: 76.9841 (78.7838) 
Training Epoch: [122/1000] Step: [100 / 285] Batch Time: 0.1480 (0.1607) Data Time: 0.0113 (0.0264) Average Loss: 0.6729 (0.7743) Average CE Loss (Source):  0.6729 ( 0.7743) Learning Rate: 0.1000 (0.1000) Top1_base: 80.4688 (78.1484) Top1_base_per_class: 82.7576 (78.6992) 
Training Epoch: [122/1000] Step: [110 / 285] Batch Time: 0.1496 (0.1598) Data Time: 0.0128 (0.0254) Average Loss: 0.7988 (0.7829) Average CE Loss (Source):  0.7988 ( 0.7829) Learning Rate: 0.1000 (0.1000) Top1_base: 75.7812 (77.8338) Top1_base_per_class: 77.6970 (78.5004) 
Training Epoch: [122/1000] Step: [120 / 285] Batch Time: 0.1491 (0.1596) Data Time: 0.0114 (0.0252) Average Loss: 0.6310 (0.7815) Average CE Loss (Source):  0.6310 ( 0.7815) Learning Rate: 0.1000 (0.1000) Top1_base: 78.9062 (77.8516) Top1_base_per_class: 79.4940 (78.5107) 
Training Epoch: [122/1000] Step: [130 / 285] Batch Time: 0.1476 (0.1589) Data Time: 0.0112 (0.0244) Average Loss: 0.7758 (0.7822) Average CE Loss (Source):  0.7758 ( 0.7822) Learning Rate: 0.1000 (0.1000) Top1_base: 74.2188 (77.8185) Top1_base_per_class: 70.9641 (78.4153) 
Training Epoch: [122/1000] Step: [140 / 285] Batch Time: 0.1471 (0.1581) Data Time: 0.0109 (0.0236) Average Loss: 0.7473 (0.7832) Average CE Loss (Source):  0.7473 ( 0.7832) Learning Rate: 0.1000 (0.1000) Top1_base: 80.4688 (77.8013) Top1_base_per_class: 80.1235 (78.4335) 
Training Epoch: [122/1000] Step: [150 / 285] Batch Time: 0.1471 (0.1582) Data Time: 0.0110 (0.0236) Average Loss: 0.8942 (0.7867) Average CE Loss (Source):  0.8942 ( 0.7867) Learning Rate: 0.1000 (0.1000) Top1_base: 78.1250 (77.6823) Top1_base_per_class: 82.5000 (78.4447) 
Training Epoch: [122/1000] Step: [160 / 285] Batch Time: 0.1454 (0.1577) Data Time: 0.0102 (0.0231) Average Loss: 0.7352 (0.7876) Average CE Loss (Source):  0.7352 ( 0.7876) Learning Rate: 0.1000 (0.1000) Top1_base: 80.4688 (77.6660) Top1_base_per_class: 80.3736 (78.3873) 
Training Epoch: [122/1000] Step: [170 / 285] Batch Time: 0.1470 (0.1574) Data Time: 0.0112 (0.0228) Average Loss: 0.7156 (0.7878) Average CE Loss (Source):  0.7156 ( 0.7878) Learning Rate: 0.1000 (0.1000) Top1_base: 78.9062 (77.6838) Top1_base_per_class: 80.5247 (78.4154) 
Training Epoch: [122/1000] Step: [180 / 285] Batch Time: 0.1491 (0.1573) Data Time: 0.0108 (0.0227) Average Loss: 0.8984 (0.7908) Average CE Loss (Source):  0.8984 ( 0.7908) Learning Rate: 0.1000 (0.1000) Top1_base: 74.2188 (77.5694) Top1_base_per_class: 76.6667 (78.2935) 
Training Epoch: [122/1000] Step: [190 / 285] Batch Time: 0.1516 (0.1568) Data Time: 0.0142 (0.0222) Average Loss: 0.7356 (0.7904) Average CE Loss (Source):  0.7356 ( 0.7904) Learning Rate: 0.1000 (0.1000) Top1_base: 78.9062 (77.5493) Top1_base_per_class: 80.9770 (78.2343) 
Training Epoch: [122/1000] Step: [200 / 285] Batch Time: 0.1429 (0.1562) Data Time: 0.0121 (0.0218) Average Loss: 1.0006 (0.7893) Average CE Loss (Source):  1.0006 ( 0.7893) Learning Rate: 0.1000 (0.1000) Top1_base: 70.3125 (77.6133) Top1_base_per_class: 73.0747 (78.3109) 
Training Epoch: [122/1000] Step: [210 / 285] Batch Time: 0.1446 (0.1560) Data Time: 0.0127 (0.0217) Average Loss: 0.6336 (0.7881) Average CE Loss (Source):  0.6336 ( 0.7881) Learning Rate: 0.1000 (0.1000) Top1_base: 81.2500 (77.5930) Top1_base_per_class: 81.4912 (78.3159) 
Training Epoch: [122/1000] Step: [220 / 285] Batch Time: 0.1443 (0.1557) Data Time: 0.0119 (0.0214) Average Loss: 0.7764 (0.7898) Average CE Loss (Source):  0.7764 ( 0.7898) Learning Rate: 0.1000 (0.1000) Top1_base: 76.5625 (77.5462) Top1_base_per_class: 72.5758 (78.1809) 
Training Epoch: [122/1000] Step: [230 / 285] Batch Time: 0.1441 (0.1556) Data Time: 0.0126 (0.0214) Average Loss: 0.6130 (0.7866) Average CE Loss (Source):  0.6130 ( 0.7866) Learning Rate: 0.1000 (0.1000) Top1_base: 82.0312 (77.6732) Top1_base_per_class: 83.3636 (78.3407) 
Training Epoch: [122/1000] Step: [240 / 285] Batch Time: 0.1483 (0.1556) Data Time: 0.0109 (0.0213) Average Loss: 0.6852 (0.7834) Average CE Loss (Source):  0.6852 ( 0.7834) Learning Rate: 0.1000 (0.1000) Top1_base: 78.9062 (77.7474) Top1_base_per_class: 79.2138 (78.4296) 
Training Epoch: [122/1000] Step: [250 / 285] Batch Time: 0.1427 (0.1558) Data Time: 0.0120 (0.0216) Average Loss: 0.7057 (0.7829) Average CE Loss (Source):  0.7057 ( 0.7829) Learning Rate: 0.1000 (0.1000) Top1_base: 80.4688 (77.7625) Top1_base_per_class: 81.4972 (78.4432) 
Training Epoch: [122/1000] Step: [260 / 285] Batch Time: 0.1495 (0.1556) Data Time: 0.0125 (0.0214) Average Loss: 0.7080 (0.7823) Average CE Loss (Source):  0.7080 ( 0.7823) Learning Rate: 0.1000 (0.1000) Top1_base: 81.2500 (77.7915) Top1_base_per_class: 77.7976 (78.4570) 
Training Epoch: [122/1000] Step: [270 / 285] Batch Time: 0.1488 (0.1556) Data Time: 0.0109 (0.0214) Average Loss: 0.8749 (0.7857) Average CE Loss (Source):  0.8749 ( 0.7857) Learning Rate: 0.1000 (0.1000) Top1_base: 73.4375 (77.7054) Top1_base_per_class: 72.8526 (78.3561) 
Training Epoch: [122/1000] Step: [280 / 285] Batch Time: 0.1465 (0.1556) Data Time: 0.0104 (0.0213) Average Loss: 0.6142 (0.7866) Average CE Loss (Source):  0.6142 ( 0.7866) Learning Rate: 0.1000 (0.1000) Top1_base: 79.6875 (77.6507) Top1_base_per_class: 79.5330 (78.3369) 
Training Epoch: [123/1000] Step: [0] Batch Time: 0.1604 (0.1555) Data Time: 0.0276 (0.0212) Average Loss: 0.8803 (0.7866) Average CE Loss (Source):  0.8803 ( 0.7866) Learning Rate: 0.1000 (0.1000) Top1_base: 74.2188 (77.6206) Top1_base_per_class: 75.0877 (78.3010) 
Training Epoch: [123/1000] Step: [10 / 285] Batch Time: 0.1426 (0.2270) Data Time: 0.0121 (0.0947) Average Loss: 0.6884 (0.7101) Average CE Loss (Source):  0.6884 ( 0.7101) Learning Rate: 0.1000 (0.1000) Top1_base: 78.9062 (79.1406) Top1_base_per_class: 79.2560 (80.2247) 
Training Epoch: [123/1000] Step: [20 / 285] Batch Time: 0.1443 (0.1896) Data Time: 0.0119 (0.0573) Average Loss: 0.9583 (0.7664) Average CE Loss (Source):  0.9583 ( 0.7664) Learning Rate: 0.1000 (0.1000) Top1_base: 75.7812 (78.5938) Top1_base_per_class: 77.5000 (79.5790) 
Training Epoch: [123/1000] Step: [30 / 285] Batch Time: 0.1460 (0.1793) Data Time: 0.0142 (0.0469) Average Loss: 0.6974 (0.7430) Average CE Loss (Source):  0.6974 ( 0.7430) Learning Rate: 0.1000 (0.1000) Top1_base: 78.1250 (79.2969) Top1_base_per_class: 72.4150 (79.7393) 
Training Epoch: [123/1000] Step: [40 / 285] Batch Time: 0.1453 (0.1748) Data Time: 0.0116 (0.0425) Average Loss: 0.8594 (0.7401) Average CE Loss (Source):  0.8594 ( 0.7401) Learning Rate: 0.1000 (0.1000) Top1_base: 77.3438 (79.2773) Top1_base_per_class: 77.1212 (79.7448) 
Training Epoch: [123/1000] Step: [50 / 285] Batch Time: 0.1475 (0.1706) Data Time: 0.0146 (0.0382) Average Loss: 0.7884 (0.7428) Average CE Loss (Source):  0.7884 ( 0.7428) Learning Rate: 0.1000 (0.1000) Top1_base: 75.0000 (79.0938) Top1_base_per_class: 73.3169 (79.5217) 
Training Epoch: [123/1000] Step: [60 / 285] Batch Time: 0.1443 (0.1694) Data Time: 0.0102 (0.0370) Average Loss: 0.7880 (0.7396) Average CE Loss (Source):  0.7880 ( 0.7396) Learning Rate: 0.1000 (0.1000) Top1_base: 80.4688 (79.2448) Top1_base_per_class: 83.6970 (79.8157) 
Training Epoch: [123/1000] Step: [70 / 285] Batch Time: 0.1494 (0.1674) Data Time: 0.0136 (0.0348) Average Loss: 0.6766 (0.7380) Average CE Loss (Source):  0.6766 ( 0.7380) Learning Rate: 0.1000 (0.1000) Top1_base: 82.8125 (79.2299) Top1_base_per_class: 83.9947 (79.7281) 
Training Epoch: [123/1000] Step: [80 / 285] Batch Time: 0.1435 (0.1670) Data Time: 0.0114 (0.0343) Average Loss: 0.7912 (0.7443) Average CE Loss (Source):  0.7912 ( 0.7443) Learning Rate: 0.1000 (0.1000) Top1_base: 77.3438 (79.0723) Top1_base_per_class: 77.9697 (79.5805) 
Training Epoch: [123/1000] Step: [90 / 285] Batch Time: 0.1431 (0.1650) Data Time: 0.0117 (0.0324) Average Loss: 0.5356 (0.7390) Average CE Loss (Source):  0.5356 ( 0.7390) Learning Rate: 0.1000 (0.1000) Top1_base: 88.2812 (79.2274) Top1_base_per_class: 86.9345 (79.6361) 
Training Epoch: [123/1000] Step: [100 / 285] Batch Time: 0.1487 (0.1645) Data Time: 0.0143 (0.0320) Average Loss: 0.5795 (0.7391) Average CE Loss (Source):  0.5795 ( 0.7391) Learning Rate: 0.1000 (0.1000) Top1_base: 85.1562 (79.1328) Top1_base_per_class: 84.6111 (79.3532) 
Training Epoch: [123/1000] Step: [110 / 285] Batch Time: 0.1464 (0.1636) Data Time: 0.0128 (0.0310) Average Loss: 0.7506 (0.7439) Average CE Loss (Source):  0.7506 ( 0.7439) Learning Rate: 0.1000 (0.1000) Top1_base: 80.4688 (79.1122) Top1_base_per_class: 81.6883 (79.4650) 
Training Epoch: [123/1000] Step: [120 / 285] Batch Time: 0.1427 (0.1627) Data Time: 0.0116 (0.0301) Average Loss: 0.6918 (0.7440) Average CE Loss (Source):  0.6918 ( 0.7440) Learning Rate: 0.1000 (0.1000) Top1_base: 78.9062 (79.0820) Top1_base_per_class: 78.4432 (79.4175) 
Training Epoch: [123/1000] Step: [130 / 285] Batch Time: 0.1467 (0.1623) Data Time: 0.0132 (0.0296) Average Loss: 0.8004 (0.7441) Average CE Loss (Source):  0.8004 ( 0.7441) Learning Rate: 0.1000 (0.1000) Top1_base: 75.7812 (79.1226) Top1_base_per_class: 78.6310 (79.4650) 
Training Epoch: [123/1000] Step: [140 / 285] Batch Time: 0.1433 (0.1622) Data Time: 0.0117 (0.0295) Average Loss: 0.5092 (0.7437) Average CE Loss (Source):  0.5092 ( 0.7437) Learning Rate: 0.1000 (0.1000) Top1_base: 86.7188 (79.1406) Top1_base_per_class: 87.2068 (79.5130) 
Training Epoch: [123/1000] Step: [150 / 285] Batch Time: 0.1463 (0.1621) Data Time: 0.0129 (0.0294) Average Loss: 0.7413 (0.7486) Average CE Loss (Source):  0.7413 ( 0.7486) Learning Rate: 0.1000 (0.1000) Top1_base: 77.3438 (79.0469) Top1_base_per_class: 75.8485 (79.4674) 
Training Epoch: [123/1000] Step: [160 / 285] Batch Time: 0.1472 (0.1620) Data Time: 0.0133 (0.0293) Average Loss: 0.6002 (0.7519) Average CE Loss (Source):  0.6002 ( 0.7519) Learning Rate: 0.1000 (0.1000) Top1_base: 87.5000 (78.9551) Top1_base_per_class: 88.6905 (79.4522) 
Training Epoch: [123/1000] Step: [170 / 285] Batch Time: 0.1426 (0.1616) Data Time: 0.0119 (0.0289) Average Loss: 1.0431 (0.7559) Average CE Loss (Source):  1.0431 ( 0.7559) Learning Rate: 0.1000 (0.1000) Top1_base: 69.5312 (78.8327) Top1_base_per_class: 62.7381 (79.3005) 
Training Epoch: [123/1000] Step: [180 / 285] Batch Time: 0.1463 (0.1618) Data Time: 0.0136 (0.0291) Average Loss: 0.8545 (0.7585) Average CE Loss (Source):  0.8545 ( 0.7585) Learning Rate: 0.1000 (0.1000) Top1_base: 71.8750 (78.7543) Top1_base_per_class: 70.8333 (79.2436) 
Training Epoch: [123/1000] Step: [190 / 285] Batch Time: 0.1429 (0.1615) Data Time: 0.0105 (0.0288) Average Loss: 0.7902 (0.7614) Average CE Loss (Source):  0.7902 ( 0.7614) Learning Rate: 0.1000 (0.1000) Top1_base: 77.3438 (78.6554) Top1_base_per_class: 78.4463 (79.1817) 
Training Epoch: [123/1000] Step: [200 / 285] Batch Time: 0.1454 (0.1615) Data Time: 0.0117 (0.0288) Average Loss: 0.7931 (0.7693) Average CE Loss (Source):  0.7931 ( 0.7693) Learning Rate: 0.1000 (0.1000) Top1_base: 75.7812 (78.4219) Top1_base_per_class: 76.4327 (78.9373) 
Training Epoch: [123/1000] Step: [210 / 285] Batch Time: 0.1420 (0.1610) Data Time: 0.0109 (0.0284) Average Loss: 0.9637 (0.7725) Average CE Loss (Source):  0.9637 ( 0.7725) Learning Rate: 0.1000 (0.1000) Top1_base: 75.7812 (78.3780) Top1_base_per_class: 77.3148 (78.9202) 
Training Epoch: [123/1000] Step: [220 / 285] Batch Time: 0.1433 (0.1605) Data Time: 0.0105 (0.0279) Average Loss: 0.7504 (0.7710) Average CE Loss (Source):  0.7504 ( 0.7710) Learning Rate: 0.1000 (0.1000) Top1_base: 79.6875 (78.4624) Top1_base_per_class: 79.3210 (78.9785) 
Training Epoch: [123/1000] Step: [230 / 285] Batch Time: 0.1422 (0.1604) Data Time: 0.0105 (0.0278) Average Loss: 0.8915 (0.7736) Average CE Loss (Source):  0.8915 ( 0.7736) Learning Rate: 0.1000 (0.1000) Top1_base: 75.7812 (78.3798) Top1_base_per_class: 78.4524 (78.9469) 
Training Epoch: [123/1000] Step: [240 / 285] Batch Time: 0.1445 (0.1608) Data Time: 0.0116 (0.0281) Average Loss: 0.7927 (0.7729) Average CE Loss (Source):  0.7927 ( 0.7729) Learning Rate: 0.1000 (0.1000) Top1_base: 82.0312 (78.4180) Top1_base_per_class: 83.3041 (79.0031) 
Training Epoch: [123/1000] Step: [250 / 285] Batch Time: 0.1427 (0.1603) Data Time: 0.0112 (0.0276) Average Loss: 0.8850 (0.7728) Average CE Loss (Source):  0.8850 ( 0.7728) Learning Rate: 0.1000 (0.1000) Top1_base: 79.6875 (78.4500) Top1_base_per_class: 81.8210 (79.0199) 
Training Epoch: [123/1000] Step: [260 / 285] Batch Time: 0.1434 (0.1599) Data Time: 0.0122 (0.0272) Average Loss: 0.9003 (0.7735) Average CE Loss (Source):  0.9003 ( 0.7735) Learning Rate: 0.1000 (0.1000) Top1_base: 75.0000 (78.3924) Top1_base_per_class: 74.8830 (78.9596) 
Training Epoch: [123/1000] Step: [270 / 285] Batch Time: 0.1431 (0.1599) Data Time: 0.0116 (0.0272) Average Loss: 0.8729 (0.7732) Average CE Loss (Source):  0.8729 ( 0.7732) Learning Rate: 0.1000 (0.1000) Top1_base: 70.3125 (78.3796) Top1_base_per_class: 65.1818 (78.9042) 
Training Epoch: [123/1000] Step: [280 / 285] Batch Time: 0.1423 (0.1596) Data Time: 0.0104 (0.0269) Average Loss: 0.6666 (0.7731) Average CE Loss (Source):  0.6666 ( 0.7731) Learning Rate: 0.1000 (0.1000) Top1_base: 78.9062 (78.3622) Top1_base_per_class: 76.7262 (78.8825) 
Training Epoch: [124/1000] Step: [0] Batch Time: 0.1421 (0.1595) Data Time: 0.0094 (0.0268) Average Loss: 0.7717 (0.7718) Average CE Loss (Source):  0.7717 ( 0.7718) Learning Rate: 0.1000 (0.1000) Top1_base: 80.4688 (78.3964) Top1_base_per_class: 81.9753 (78.9090) 
 12%|█▏        | 124/1000 [1:36:48<11:19:46, 46.56s/it] 12%|█▎        | 125/1000 [1:37:33<11:10:44, 45.99s/it]Training Epoch: [124/1000] Step: [10 / 285] Batch Time: 0.1438 (0.2297) Data Time: 0.0103 (0.0976) Average Loss: 0.6252 (0.6841) Average CE Loss (Source):  0.6252 ( 0.6841) Learning Rate: 0.1000 (0.1000) Top1_base: 80.4688 (80.0000) Top1_base_per_class: 78.2341 (80.8865) 
Training Epoch: [124/1000] Step: [20 / 285] Batch Time: 0.1476 (0.1909) Data Time: 0.0124 (0.0584) Average Loss: 0.6076 (0.7005) Average CE Loss (Source):  0.6076 ( 0.7005) Learning Rate: 0.1000 (0.1000) Top1_base: 86.7188 (79.8047) Top1_base_per_class: 85.9524 (80.1498) 
Training Epoch: [124/1000] Step: [30 / 285] Batch Time: 0.1486 (0.1784) Data Time: 0.0148 (0.0456) Average Loss: 0.6667 (0.7069) Average CE Loss (Source):  0.6667 ( 0.7069) Learning Rate: 0.1000 (0.1000) Top1_base: 81.2500 (79.4792) Top1_base_per_class: 82.0621 (80.0569) 
Training Epoch: [124/1000] Step: [40 / 285] Batch Time: 0.1573 (0.1745) Data Time: 0.0250 (0.0413) Average Loss: 0.8815 (0.7212) Average CE Loss (Source):  0.8815 ( 0.7212) Learning Rate: 0.1000 (0.1000) Top1_base: 73.4375 (79.2578) Top1_base_per_class: 70.2866 (80.0125) 
Training Epoch: [124/1000] Step: [50 / 285] Batch Time: 0.1473 (0.1707) Data Time: 0.0143 (0.0375) Average Loss: 0.7884 (0.7360) Average CE Loss (Source):  0.7884 ( 0.7360) Learning Rate: 0.1000 (0.1000) Top1_base: 81.2500 (78.9531) Top1_base_per_class: 80.2469 (79.5809) 
Training Epoch: [124/1000] Step: [60 / 285] Batch Time: 0.1501 (0.1679) Data Time: 0.0150 (0.0349) Average Loss: 0.6065 (0.7412) Average CE Loss (Source):  0.6065 ( 0.7412) Learning Rate: 0.1000 (0.1000) Top1_base: 82.0312 (78.8151) Top1_base_per_class: 81.5123 (79.3398) 
Training Epoch: [124/1000] Step: [70 / 285] Batch Time: 0.1478 (0.1665) Data Time: 0.0137 (0.0334) Average Loss: 1.0644 (0.7451) Average CE Loss (Source):  1.0644 ( 0.7451) Learning Rate: 0.1000 (0.1000) Top1_base: 71.0938 (78.7277) Top1_base_per_class: 75.5403 (79.3258) 
Training Epoch: [124/1000] Step: [80 / 285] Batch Time: 0.1482 (0.1646) Data Time: 0.0153 (0.0314) Average Loss: 0.9015 (0.7508) Average CE Loss (Source):  0.9015 ( 0.7508) Learning Rate: 0.1000 (0.1000) Top1_base: 75.7812 (78.6914) Top1_base_per_class: 79.1667 (79.2144) 
Training Epoch: [124/1000] Step: [90 / 285] Batch Time: 0.1472 (0.1630) Data Time: 0.0143 (0.0297) Average Loss: 0.8125 (0.7534) Average CE Loss (Source):  0.8125 ( 0.7534) Learning Rate: 0.1000 (0.1000) Top1_base: 75.7812 (78.4722) Top1_base_per_class: 76.3158 (78.8917) 
Training Epoch: [124/1000] Step: [100 / 285] Batch Time: 0.1476 (0.1614) Data Time: 0.0146 (0.0281) Average Loss: 0.4942 (0.7513) Average CE Loss (Source):  0.4942 ( 0.7513) Learning Rate: 0.1000 (0.1000) Top1_base: 85.1562 (78.5625) Top1_base_per_class: 85.8918 (79.0103) 
Training Epoch: [124/1000] Step: [110 / 285] Batch Time: 0.1468 (0.1606) Data Time: 0.0141 (0.0272) Average Loss: 0.6122 (0.7489) Average CE Loss (Source):  0.6122 ( 0.7489) Learning Rate: 0.1000 (0.1000) Top1_base: 83.5938 (78.6293) Top1_base_per_class: 83.6163 (79.0343) 
Training Epoch: [124/1000] Step: [120 / 285] Batch Time: 0.1827 (0.1604) Data Time: 0.0486 (0.0271) Average Loss: 0.8704 (0.7483) Average CE Loss (Source):  0.8704 ( 0.7483) Learning Rate: 0.1000 (0.1000) Top1_base: 75.0000 (78.6784) Top1_base_per_class: 78.7037 (79.1378) 
Training Epoch: [124/1000] Step: [130 / 285] Batch Time: 0.1480 (0.1597) Data Time: 0.0133 (0.0264) Average Loss: 0.7404 (0.7512) Average CE Loss (Source):  0.7404 ( 0.7512) Learning Rate: 0.1000 (0.1000) Top1_base: 78.1250 (78.6538) Top1_base_per_class: 79.8538 (79.1578) 
Training Epoch: [124/1000] Step: [140 / 285] Batch Time: 0.1729 (0.1595) Data Time: 0.0386 (0.0263) Average Loss: 0.6624 (0.7500) Average CE Loss (Source):  0.6624 ( 0.7500) Learning Rate: 0.1000 (0.1000) Top1_base: 82.0312 (78.7388) Top1_base_per_class: 79.3636 (79.2347) 
Training Epoch: [124/1000] Step: [150 / 285] Batch Time: 0.1481 (0.1592) Data Time: 0.0156 (0.0260) Average Loss: 0.6769 (0.7510) Average CE Loss (Source):  0.6769 ( 0.7510) Learning Rate: 0.1000 (0.1000) Top1_base: 81.2500 (78.6667) Top1_base_per_class: 81.0234 (79.1538) 
Training Epoch: [124/1000] Step: [160 / 285] Batch Time: 0.1594 (0.1593) Data Time: 0.0288 (0.0261) Average Loss: 0.6569 (0.7513) Average CE Loss (Source):  0.6569 ( 0.7513) Learning Rate: 0.1000 (0.1000) Top1_base: 84.3750 (78.6768) Top1_base_per_class: 84.4136 (79.2450) 
Training Epoch: [124/1000] Step: [170 / 285] Batch Time: 0.1487 (0.1595) Data Time: 0.0123 (0.0263) Average Loss: 0.8847 (0.7511) Average CE Loss (Source):  0.8847 ( 0.7511) Learning Rate: 0.1000 (0.1000) Top1_base: 77.3438 (78.7086) Top1_base_per_class: 75.8621 (79.2500) 
Training Epoch: [124/1000] Step: [180 / 285] Batch Time: 0.1560 (0.1594) Data Time: 0.0202 (0.0261) Average Loss: 0.8990 (0.7522) Average CE Loss (Source):  0.8990 ( 0.7522) Learning Rate: 0.1000 (0.1000) Top1_base: 76.5625 (78.6589) Top1_base_per_class: 75.4802 (79.1633) 
Training Epoch: [124/1000] Step: [190 / 285] Batch Time: 0.1430 (0.1595) Data Time: 0.0110 (0.0262) Average Loss: 0.6078 (0.7522) Average CE Loss (Source):  0.6078 ( 0.7522) Learning Rate: 0.1000 (0.1000) Top1_base: 79.6875 (78.6390) Top1_base_per_class: 78.5494 (79.1515) 
Training Epoch: [124/1000] Step: [200 / 285] Batch Time: 0.1482 (0.1588) Data Time: 0.0166 (0.0256) Average Loss: 0.7149 (0.7525) Average CE Loss (Source):  0.7149 ( 0.7525) Learning Rate: 0.1000 (0.1000) Top1_base: 78.1250 (78.6211) Top1_base_per_class: 77.8086 (79.1485) 
Training Epoch: [124/1000] Step: [210 / 285] Batch Time: 0.1475 (0.1583) Data Time: 0.0113 (0.0251) Average Loss: 0.7912 (0.7552) Average CE Loss (Source):  0.7912 ( 0.7552) Learning Rate: 0.1000 (0.1000) Top1_base: 78.9062 (78.5826) Top1_base_per_class: 82.6488 (79.1387) 
Training Epoch: [124/1000] Step: [220 / 285] Batch Time: 0.1505 (0.1579) Data Time: 0.0169 (0.0246) Average Loss: 0.7658 (0.7574) Average CE Loss (Source):  0.7658 ( 0.7574) Learning Rate: 0.1000 (0.1000) Top1_base: 79.6875 (78.5476) Top1_base_per_class: 77.8736 (79.1110) 
Training Epoch: [124/1000] Step: [230 / 285] Batch Time: 0.1446 (0.1574) Data Time: 0.0119 (0.0242) Average Loss: 0.9322 (0.7599) Average CE Loss (Source):  0.9322 ( 0.7599) Learning Rate: 0.1000 (0.1000) Top1_base: 75.0000 (78.4613) Top1_base_per_class: 74.8788 (79.0171) 
Training Epoch: [124/1000] Step: [240 / 285] Batch Time: 0.1593 (0.1570) Data Time: 0.0265 (0.0238) Average Loss: 0.8231 (0.7610) Average CE Loss (Source):  0.8231 ( 0.7610) Learning Rate: 0.1000 (0.1000) Top1_base: 76.5625 (78.4473) Top1_base_per_class: 76.3842 (78.9909) 
Training Epoch: [124/1000] Step: [250 / 285] Batch Time: 0.1473 (0.1567) Data Time: 0.0116 (0.0235) Average Loss: 0.8290 (0.7585) Average CE Loss (Source):  0.8290 ( 0.7585) Learning Rate: 0.1000 (0.1000) Top1_base: 76.5625 (78.5094) Top1_base_per_class: 78.3333 (79.0258) 
Training Epoch: [124/1000] Step: [260 / 285] Batch Time: 0.1515 (0.1567) Data Time: 0.0178 (0.0234) Average Loss: 0.7181 (0.7577) Average CE Loss (Source):  0.7181 ( 0.7577) Learning Rate: 0.1000 (0.1000) Top1_base: 80.4688 (78.5126) Top1_base_per_class: 81.0833 (79.0452) 
Training Epoch: [124/1000] Step: [270 / 285] Batch Time: 0.1447 (0.1564) Data Time: 0.0132 (0.0231) Average Loss: 0.7609 (0.7578) Average CE Loss (Source):  0.7609 ( 0.7578) Learning Rate: 0.1000 (0.1000) Top1_base: 77.3438 (78.5243) Top1_base_per_class: 80.9434 (79.0684) 
Training Epoch: [124/1000] Step: [280 / 285] Batch Time: 0.1930 (0.1564) Data Time: 0.0616 (0.0232) Average Loss: 0.7628 (0.7586) Average CE Loss (Source):  0.7628 ( 0.7586) Learning Rate: 0.1000 (0.1000) Top1_base: 82.8125 (78.5519) Top1_base_per_class: 83.9744 (79.0443) 
Training Epoch: [125/1000] Step: [0] Batch Time: 0.1474 (0.1565) Data Time: 0.0131 (0.0232) Average Loss: 0.8069 (0.7598) Average CE Loss (Source):  0.8069 ( 0.7598) Learning Rate: 0.1000 (0.1000) Top1_base: 75.7812 (78.5444) Top1_base_per_class: 78.8218 (79.0414) 
Training Epoch: [125/1000] Step: [10 / 285] Batch Time: 0.1453 (0.2326) Data Time: 0.0144 (0.1006) Average Loss: 0.8758 (0.7479) Average CE Loss (Source):  0.8758 ( 0.7479) Learning Rate: 0.1000 (0.1000) Top1_base: 79.6875 (78.9062) Top1_base_per_class: 76.8827 (80.2206) 
Training Epoch: [125/1000] Step: [20 / 285] Batch Time: 0.1428 (0.1935) Data Time: 0.0115 (0.0615) Average Loss: 0.7943 (0.7602) Average CE Loss (Source):  0.7943 ( 0.7602) Learning Rate: 0.1000 (0.1000) Top1_base: 78.1250 (78.6719) Top1_base_per_class: 78.7576 (79.1673) 
Training Epoch: [125/1000] Step: [30 / 285] Batch Time: 0.1486 (0.1789) Data Time: 0.0126 (0.0464) Average Loss: 0.7099 (0.7413) Average CE Loss (Source):  0.7099 ( 0.7413) Learning Rate: 0.1000 (0.1000) Top1_base: 80.4688 (79.2188) Top1_base_per_class: 81.3158 (79.4590) 
Training Epoch: [125/1000] Step: [40 / 285] Batch Time: 0.1455 (0.1731) Data Time: 0.0111 (0.0403) Average Loss: 0.9161 (0.7278) Average CE Loss (Source):  0.9161 ( 0.7278) Learning Rate: 0.1000 (0.1000) Top1_base: 79.6875 (79.6875) Top1_base_per_class: 81.5774 (79.8691) 
Training Epoch: [125/1000] Step: [50 / 285] Batch Time: 0.1429 (0.1716) Data Time: 0.0126 (0.0389) Average Loss: 0.4545 (0.7144) Average CE Loss (Source):  0.4545 ( 0.7144) Learning Rate: 0.1000 (0.1000) Top1_base: 88.2812 (79.9531) Top1_base_per_class: 91.9883 (80.2390) 
Training Epoch: [125/1000] Step: [60 / 285] Batch Time: 0.1420 (0.1699) Data Time: 0.0105 (0.0373) Average Loss: 0.7174 (0.7192) Average CE Loss (Source):  0.7174 ( 0.7192) Learning Rate: 0.1000 (0.1000) Top1_base: 82.0312 (79.8047) Top1_base_per_class: 83.4277 (80.3597) 
Training Epoch: [125/1000] Step: [70 / 285] Batch Time: 0.1447 (0.1679) Data Time: 0.0134 (0.0354) Average Loss: 0.6196 (0.7184) Average CE Loss (Source):  0.6196 ( 0.7184) Learning Rate: 0.1000 (0.1000) Top1_base: 83.5938 (79.7991) Top1_base_per_class: 82.8182 (80.4516) 
Training Epoch: [125/1000] Step: [80 / 285] Batch Time: 0.1448 (0.1656) Data Time: 0.0109 (0.0330) Average Loss: 0.8425 (0.7220) Average CE Loss (Source):  0.8425 ( 0.7220) Learning Rate: 0.1000 (0.1000) Top1_base: 73.4375 (79.8145) Top1_base_per_class: 76.3030 (80.4325) 
Training Epoch: [125/1000] Step: [90 / 285] Batch Time: 0.1439 (0.1645) Data Time: 0.0139 (0.0319) Average Loss: 0.8872 (0.7235) Average CE Loss (Source):  0.8872 ( 0.7235) Learning Rate: 0.1000 (0.1000) Top1_base: 74.2188 (79.7917) Top1_base_per_class: 74.3210 (80.2621) 
Training Epoch: [125/1000] Step: [100 / 285] Batch Time: 0.1426 (0.1627) Data Time: 0.0124 (0.0302) Average Loss: 0.8836 (0.7279) Average CE Loss (Source):  0.8836 ( 0.7279) Learning Rate: 0.1000 (0.1000) Top1_base: 75.7812 (79.5469) Top1_base_per_class: 75.4935 (79.9290) 
Training Epoch: [125/1000] Step: [110 / 285] Batch Time: 0.1484 (0.1614) Data Time: 0.0108 (0.0287) Average Loss: 0.9191 (0.7324) Average CE Loss (Source):  0.9191 ( 0.7324) Learning Rate: 0.1000 (0.1000) Top1_base: 73.4375 (79.4247) Top1_base_per_class: 74.7879 (79.7671) 
Training Epoch: [125/1000] Step: [120 / 285] Batch Time: 0.1452 (0.1602) Data Time: 0.0107 (0.0274) Average Loss: 0.8836 (0.7376) Average CE Loss (Source):  0.8836 ( 0.7376) Learning Rate: 0.1000 (0.1000) Top1_base: 70.3125 (79.2057) Top1_base_per_class: 69.4182 (79.5058) 
Training Epoch: [125/1000] Step: [130 / 285] Batch Time: 0.1451 (0.1592) Data Time: 0.0108 (0.0263) Average Loss: 0.7296 (0.7367) Average CE Loss (Source):  0.7296 ( 0.7367) Learning Rate: 0.1000 (0.1000) Top1_base: 79.6875 (79.3269) Top1_base_per_class: 79.4722 (79.6616) 
Training Epoch: [125/1000] Step: [140 / 285] Batch Time: 0.1430 (0.1582) Data Time: 0.0120 (0.0254) Average Loss: 0.4531 (0.7385) Average CE Loss (Source):  0.4531 ( 0.7385) Learning Rate: 0.1000 (0.1000) Top1_base: 88.2812 (79.2188) Top1_base_per_class: 90.7602 (79.5281) 
Training Epoch: [125/1000] Step: [150 / 285] Batch Time: 0.1508 (0.1576) Data Time: 0.0119 (0.0246) Average Loss: 0.5265 (0.7380) Average CE Loss (Source):  0.5265 ( 0.7380) Learning Rate: 0.1000 (0.1000) Top1_base: 85.9375 (79.2552) Top1_base_per_class: 86.7647 (79.6137) 
Training Epoch: [125/1000] Step: [160 / 285] Batch Time: 0.1467 (0.1571) Data Time: 0.0112 (0.0239) Average Loss: 0.7121 (0.7382) Average CE Loss (Source):  0.7121 ( 0.7382) Learning Rate: 0.1000 (0.1000) Top1_base: 78.1250 (79.1602) Top1_base_per_class: 76.9497 (79.4824) 
Training Epoch: [125/1000] Step: [170 / 285] Batch Time: 0.1498 (0.1568) Data Time: 0.0121 (0.0236) Average Loss: 0.5983 (0.7385) Average CE Loss (Source):  0.5983 ( 0.7385) Learning Rate: 0.1000 (0.1000) Top1_base: 81.2500 (79.0763) Top1_base_per_class: 81.6369 (79.3565) 
Training Epoch: [125/1000] Step: [180 / 285] Batch Time: 0.1472 (0.1564) Data Time: 0.0113 (0.0230) Average Loss: 0.8868 (0.7402) Average CE Loss (Source):  0.8868 ( 0.7402) Learning Rate: 0.1000 (0.1000) Top1_base: 80.4688 (79.1016) Top1_base_per_class: 85.4402 (79.4027) 
Training Epoch: [125/1000] Step: [190 / 285] Batch Time: 0.1418 (0.1559) Data Time: 0.0125 (0.0226) Average Loss: 0.9750 (0.7413) Average CE Loss (Source):  0.9750 ( 0.7413) Learning Rate: 0.1000 (0.1000) Top1_base: 75.0000 (79.0995) Top1_base_per_class: 76.3782 (79.4111) 
Training Epoch: [125/1000] Step: [200 / 285] Batch Time: 0.1439 (0.1562) Data Time: 0.0115 (0.0230) Average Loss: 0.8406 (0.7433) Average CE Loss (Source):  0.8406 ( 0.7433) Learning Rate: 0.1000 (0.1000) Top1_base: 78.1250 (79.0586) Top1_base_per_class: 82.2917 (79.3830) 
Training Epoch: [125/1000] Step: [210 / 285] Batch Time: 0.1436 (0.1569) Data Time: 0.0123 (0.0238) Average Loss: 0.8505 (0.7458) Average CE Loss (Source):  0.8505 ( 0.7458) Learning Rate: 0.1000 (0.1000) Top1_base: 71.8750 (78.9435) Top1_base_per_class: 74.5322 (79.3095) 
Training Epoch: [125/1000] Step: [220 / 285] Batch Time: 0.1414 (0.1570) Data Time: 0.0110 (0.0240) Average Loss: 0.6538 (0.7492) Average CE Loss (Source):  0.6538 ( 0.7492) Learning Rate: 0.1000 (0.1000) Top1_base: 83.5938 (78.8743) Top1_base_per_class: 84.6131 (79.2524) 
Training Epoch: [125/1000] Step: [230 / 285] Batch Time: 0.1441 (0.1574) Data Time: 0.0102 (0.0244) Average Loss: 0.7693 (0.7527) Average CE Loss (Source):  0.7693 ( 0.7527) Learning Rate: 0.1000 (0.1000) Top1_base: 75.7812 (78.8553) Top1_base_per_class: 72.2727 (79.1908) 
Training Epoch: [125/1000] Step: [240 / 285] Batch Time: 0.1460 (0.1576) Data Time: 0.0118 (0.0246) Average Loss: 0.8132 (0.7552) Average CE Loss (Source):  0.8132 ( 0.7552) Learning Rate: 0.1000 (0.1000) Top1_base: 77.3438 (78.7826) Top1_base_per_class: 80.8642 (79.1276) 
Training Epoch: [125/1000] Step: [250 / 285] Batch Time: 0.1465 (0.1581) Data Time: 0.0104 (0.0251) Average Loss: 0.7552 (0.7552) Average CE Loss (Source):  0.7552 ( 0.7552) Learning Rate: 0.1000 (0.1000) Top1_base: 75.0000 (78.7906) Top1_base_per_class: 74.4152 (79.1285) 
Training Epoch: [125/1000] Step: [260 / 285] Batch Time: 0.1464 (0.1581) Data Time: 0.0113 (0.0251) Average Loss: 0.7071 (0.7531) Average CE Loss (Source):  0.7071 ( 0.7531) Learning Rate: 0.1000 (0.1000) Top1_base: 80.4688 (78.8492) Top1_base_per_class: 77.3148 (79.2048) 
Training Epoch: [125/1000] Step: [270 / 285] Batch Time: 0.1465 (0.1586) Data Time: 0.0107 (0.0255) Average Loss: 0.8629 (0.7531) Average CE Loss (Source):  0.8629 ( 0.7531) Learning Rate: 0.1000 (0.1000) Top1_base: 75.7812 (78.8455) Top1_base_per_class: 77.2807 (79.2494) 
Training Epoch: [125/1000] Step: [280 / 285] Batch Time: 0.1427 (0.1585) Data Time: 0.0103 (0.0254) Average Loss: 0.7859 (0.7540) Average CE Loss (Source):  0.7859 ( 0.7540) Learning Rate: 0.1000 (0.1000) Top1_base: 74.2188 (78.8309) Top1_base_per_class: 72.2619 (79.2705) 
Training Epoch: [126/1000] Step: [0] Batch Time: 0.1565 (0.1583) Data Time: 0.0281 (0.0252) Average Loss: 0.7386 (0.7551) Average CE Loss (Source):  0.7386 ( 0.7551) Learning Rate: 0.1000 (0.1000) Top1_base: 82.0312 (78.8240) Top1_base_per_class: 83.6735 (79.2684) 
 13%|█▎        | 126/1000 [1:38:21<11:18:29, 46.58s/it] 13%|█▎        | 127/1000 [1:39:05<11:09:07, 45.99s/it]Training Epoch: [126/1000] Step: [10 / 285] Batch Time: 0.1509 (0.2294) Data Time: 0.0154 (0.0951) Average Loss: 0.7726 (0.7856) Average CE Loss (Source):  0.7726 ( 0.7856) Learning Rate: 0.1000 (0.1000) Top1_base: 79.6875 (78.2812) Top1_base_per_class: 80.8772 (78.5415) 
Training Epoch: [126/1000] Step: [20 / 285] Batch Time: 0.1486 (0.1894) Data Time: 0.0130 (0.0544) Average Loss: 0.7729 (0.7481) Average CE Loss (Source):  0.7729 ( 0.7481) Learning Rate: 0.1000 (0.1000) Top1_base: 78.1250 (79.4922) Top1_base_per_class: 76.3580 (79.5056) 
Training Epoch: [126/1000] Step: [30 / 285] Batch Time: 0.1471 (0.1797) Data Time: 0.0130 (0.0448) Average Loss: 0.7015 (0.7389) Average CE Loss (Source):  0.7015 ( 0.7389) Learning Rate: 0.1000 (0.1000) Top1_base: 82.8125 (79.8698) Top1_base_per_class: 84.3333 (80.0486) 
Training Epoch: [126/1000] Step: [40 / 285] Batch Time: 0.1448 (0.1764) Data Time: 0.0133 (0.0415) Average Loss: 0.7098 (0.7389) Average CE Loss (Source):  0.7098 ( 0.7389) Learning Rate: 0.1000 (0.1000) Top1_base: 80.4688 (79.7461) Top1_base_per_class: 81.2579 (80.1341) 
Training Epoch: [126/1000] Step: [50 / 285] Batch Time: 0.1574 (0.1723) Data Time: 0.0224 (0.0376) Average Loss: 0.7199 (0.7269) Average CE Loss (Source):  0.7199 ( 0.7269) Learning Rate: 0.1000 (0.1000) Top1_base: 81.2500 (80.2344) Top1_base_per_class: 80.4248 (80.5020) 
Training Epoch: [126/1000] Step: [60 / 285] Batch Time: 0.1474 (0.1711) Data Time: 0.0122 (0.0363) Average Loss: 0.7074 (0.7294) Average CE Loss (Source):  0.7074 ( 0.7294) Learning Rate: 0.1000 (0.1000) Top1_base: 82.0312 (80.1042) Top1_base_per_class: 79.6199 (80.4139) 
Training Epoch: [126/1000] Step: [70 / 285] Batch Time: 0.1515 (0.1681) Data Time: 0.0155 (0.0332) Average Loss: 0.5551 (0.7251) Average CE Loss (Source):  0.5551 ( 0.7251) Learning Rate: 0.1000 (0.1000) Top1_base: 85.9375 (80.1562) Top1_base_per_class: 85.5681 (80.5197) 
Training Epoch: [126/1000] Step: [80 / 285] Batch Time: 0.1442 (0.1673) Data Time: 0.0111 (0.0323) Average Loss: 0.5689 (0.7190) Average CE Loss (Source):  0.5689 ( 0.7190) Learning Rate: 0.1000 (0.1000) Top1_base: 82.8125 (80.2344) Top1_base_per_class: 80.0893 (80.5429) 
Training Epoch: [126/1000] Step: [90 / 285] Batch Time: 0.1485 (0.1652) Data Time: 0.0150 (0.0302) Average Loss: 0.6591 (0.7178) Average CE Loss (Source):  0.6591 ( 0.7178) Learning Rate: 0.1000 (0.1000) Top1_base: 75.7812 (80.1389) Top1_base_per_class: 78.4210 (80.5971) 
Training Epoch: [126/1000] Step: [100 / 285] Batch Time: 0.1450 (0.1634) Data Time: 0.0115 (0.0286) Average Loss: 0.9994 (0.7197) Average CE Loss (Source):  0.9994 ( 0.7197) Learning Rate: 0.1000 (0.1000) Top1_base: 71.8750 (80.0234) Top1_base_per_class: 71.3244 (80.4326) 
Training Epoch: [126/1000] Step: [110 / 285] Batch Time: 0.1483 (0.1628) Data Time: 0.0137 (0.0283) Average Loss: 0.7576 (0.7240) Average CE Loss (Source):  0.7576 ( 0.7240) Learning Rate: 0.1000 (0.1000) Top1_base: 79.6875 (79.8935) Top1_base_per_class: 81.5455 (80.3469) 
Training Epoch: [126/1000] Step: [120 / 285] Batch Time: 0.1422 (0.1633) Data Time: 0.0108 (0.0289) Average Loss: 0.6462 (0.7247) Average CE Loss (Source):  0.6462 ( 0.7247) Learning Rate: 0.1000 (0.1000) Top1_base: 80.4688 (79.7266) Top1_base_per_class: 81.0185 (80.1163) 
Training Epoch: [126/1000] Step: [130 / 285] Batch Time: 0.1472 (0.1621) Data Time: 0.0131 (0.0278) Average Loss: 0.7202 (0.7228) Average CE Loss (Source):  0.7202 ( 0.7228) Learning Rate: 0.1000 (0.1000) Top1_base: 77.3438 (79.6454) Top1_base_per_class: 78.5494 (80.0635) 
Training Epoch: [126/1000] Step: [140 / 285] Batch Time: 0.1451 (0.1619) Data Time: 0.0114 (0.0277) Average Loss: 0.6891 (0.7218) Average CE Loss (Source):  0.6891 ( 0.7218) Learning Rate: 0.1000 (0.1000) Top1_base: 79.6875 (79.6429) Top1_base_per_class: 78.4226 (80.0168) 
Training Epoch: [126/1000] Step: [150 / 285] Batch Time: 0.1482 (0.1614) Data Time: 0.0134 (0.0273) Average Loss: 0.9197 (0.7272) Average CE Loss (Source):  0.9197 ( 0.7272) Learning Rate: 0.1000 (0.1000) Top1_base: 71.8750 (79.5781) Top1_base_per_class: 69.2857 (79.9756) 
Training Epoch: [126/1000] Step: [160 / 285] Batch Time: 0.1434 (0.1611) Data Time: 0.0104 (0.0270) Average Loss: 0.8500 (0.7280) Average CE Loss (Source):  0.8500 ( 0.7280) Learning Rate: 0.1000 (0.1000) Top1_base: 81.2500 (79.6143) Top1_base_per_class: 80.9483 (80.0234) 
Training Epoch: [126/1000] Step: [170 / 285] Batch Time: 0.1457 (0.1604) Data Time: 0.0131 (0.0264) Average Loss: 0.7414 (0.7301) Average CE Loss (Source):  0.7414 ( 0.7301) Learning Rate: 0.1000 (0.1000) Top1_base: 79.6875 (79.6048) Top1_base_per_class: 82.0008 (79.9923) 
Training Epoch: [126/1000] Step: [180 / 285] Batch Time: 0.1432 (0.1597) Data Time: 0.0106 (0.0258) Average Loss: 0.7643 (0.7346) Average CE Loss (Source):  0.7643 ( 0.7346) Learning Rate: 0.1000 (0.1000) Top1_base: 75.0000 (79.4618) Top1_base_per_class: 78.2471 (79.8603) 
Training Epoch: [126/1000] Step: [190 / 285] Batch Time: 0.1434 (0.1591) Data Time: 0.0123 (0.0253) Average Loss: 0.7881 (0.7366) Average CE Loss (Source):  0.7881 ( 0.7366) Learning Rate: 0.1000 (0.1000) Top1_base: 80.4688 (79.4449) Top1_base_per_class: 78.7427 (79.8095) 
Training Epoch: [126/1000] Step: [200 / 285] Batch Time: 0.1442 (0.1589) Data Time: 0.0113 (0.0251) Average Loss: 0.9545 (0.7418) Average CE Loss (Source):  0.9545 ( 0.7418) Learning Rate: 0.1000 (0.1000) Top1_base: 76.5625 (79.3164) Top1_base_per_class: 77.3457 (79.6557) 
Training Epoch: [126/1000] Step: [210 / 285] Batch Time: 0.1445 (0.1588) Data Time: 0.0124 (0.0250) Average Loss: 0.8489 (0.7455) Average CE Loss (Source):  0.8489 ( 0.7455) Learning Rate: 0.1000 (0.1000) Top1_base: 79.6875 (79.2485) Top1_base_per_class: 79.3464 (79.4982) 
Training Epoch: [126/1000] Step: [220 / 285] Batch Time: 0.1414 (0.1587) Data Time: 0.0116 (0.0250) Average Loss: 0.5058 (0.7450) Average CE Loss (Source):  0.5058 ( 0.7450) Learning Rate: 0.1000 (0.1000) Top1_base: 85.9375 (79.2685) Top1_base_per_class: 85.4464 (79.5141) 
Training Epoch: [126/1000] Step: [230 / 285] Batch Time: 0.1467 (0.1585) Data Time: 0.0120 (0.0248) Average Loss: 0.6516 (0.7463) Average CE Loss (Source):  0.6516 ( 0.7463) Learning Rate: 0.1000 (0.1000) Top1_base: 80.4688 (79.2459) Top1_base_per_class: 82.2443 (79.5516) 
Training Epoch: [126/1000] Step: [240 / 285] Batch Time: 0.1459 (0.1583) Data Time: 0.0137 (0.0246) Average Loss: 0.9041 (0.7482) Average CE Loss (Source):  0.9041 ( 0.7482) Learning Rate: 0.1000 (0.1000) Top1_base: 73.4375 (79.1764) Top1_base_per_class: 74.6619 (79.5212) 
Training Epoch: [126/1000] Step: [250 / 285] Batch Time: 0.1429 (0.1577) Data Time: 0.0113 (0.0242) Average Loss: 0.6801 (0.7472) Average CE Loss (Source):  0.6801 ( 0.7472) Learning Rate: 0.1000 (0.1000) Top1_base: 78.1250 (79.1906) Top1_base_per_class: 80.6845 (79.5403) 
Training Epoch: [126/1000] Step: [260 / 285] Batch Time: 0.1448 (0.1573) Data Time: 0.0102 (0.0237) Average Loss: 0.6096 (0.7498) Average CE Loss (Source):  0.6096 ( 0.7498) Learning Rate: 0.1000 (0.1000) Top1_base: 83.5938 (79.1196) Top1_base_per_class: 81.6369 (79.4624) 
Training Epoch: [126/1000] Step: [270 / 285] Batch Time: 0.1438 (0.1569) Data Time: 0.0119 (0.0234) Average Loss: 0.6220 (0.7516) Average CE Loss (Source):  0.6220 ( 0.7516) Learning Rate: 0.1000 (0.1000) Top1_base: 78.9062 (79.0220) Top1_base_per_class: 80.3216 (79.3681) 
Training Epoch: [126/1000] Step: [280 / 285] Batch Time: 0.1439 (0.1565) Data Time: 0.0122 (0.0230) Average Loss: 0.8224 (0.7515) Average CE Loss (Source):  0.8224 ( 0.7515) Learning Rate: 0.1000 (0.1000) Top1_base: 79.6875 (79.0458) Top1_base_per_class: 80.7440 (79.3902) 
Training Epoch: [127/1000] Step: [0] Batch Time: 0.1449 (0.1563) Data Time: 0.0110 (0.0228) Average Loss: 0.9295 (0.7525) Average CE Loss (Source):  0.9295 ( 0.7525) Learning Rate: 0.1000 (0.1000) Top1_base: 75.7812 (79.0351) Top1_base_per_class: 78.2692 (79.3837) 
Training Epoch: [127/1000] Step: [10 / 285] Batch Time: 0.1430 (0.2330) Data Time: 0.0114 (0.1007) Average Loss: 0.7400 (0.7803) Average CE Loss (Source):  0.7400 ( 0.7803) Learning Rate: 0.1000 (0.1000) Top1_base: 78.9062 (78.1250) Top1_base_per_class: 77.1962 (77.8252) 
Training Epoch: [127/1000] Step: [20 / 285] Batch Time: 0.1483 (0.1965) Data Time: 0.0141 (0.0636) Average Loss: 0.8705 (0.7623) Average CE Loss (Source):  0.8705 ( 0.7623) Learning Rate: 0.1000 (0.1000) Top1_base: 75.7812 (78.4375) Top1_base_per_class: 77.5128 (78.9860) 
Training Epoch: [127/1000] Step: [30 / 285] Batch Time: 0.1440 (0.1847) Data Time: 0.0129 (0.0518) Average Loss: 0.8808 (0.7507) Average CE Loss (Source):  0.8808 ( 0.7507) Learning Rate: 0.1000 (0.1000) Top1_base: 78.1250 (78.8542) Top1_base_per_class: 80.0000 (79.2269) 
Training Epoch: [127/1000] Step: [40 / 285] Batch Time: 0.1482 (0.1771) Data Time: 0.0145 (0.0441) Average Loss: 0.8139 (0.7461) Average CE Loss (Source):  0.8139 ( 0.7461) Learning Rate: 0.1000 (0.1000) Top1_base: 79.6875 (78.6719) Top1_base_per_class: 79.6364 (78.9257) 
Training Epoch: [127/1000] Step: [50 / 285] Batch Time: 0.1454 (0.1732) Data Time: 0.0114 (0.0402) Average Loss: 0.5864 (0.7301) Average CE Loss (Source):  0.5864 ( 0.7301) Learning Rate: 0.1000 (0.1000) Top1_base: 82.0312 (79.1719) Top1_base_per_class: 79.4540 (79.0869) 
Training Epoch: [127/1000] Step: [60 / 285] Batch Time: 0.1502 (0.1697) Data Time: 0.0174 (0.0366) Average Loss: 0.5718 (0.7312) Average CE Loss (Source):  0.5718 ( 0.7312) Learning Rate: 0.1000 (0.1000) Top1_base: 81.2500 (79.3620) Top1_base_per_class: 78.9548 (79.2227) 
Training Epoch: [127/1000] Step: [70 / 285] Batch Time: 0.1430 (0.1679) Data Time: 0.0105 (0.0348) Average Loss: 0.8924 (0.7322) Average CE Loss (Source):  0.8924 ( 0.7322) Learning Rate: 0.1000 (0.1000) Top1_base: 76.5625 (79.5089) Top1_base_per_class: 78.9091 (79.4803) 
Training Epoch: [127/1000] Step: [80 / 285] Batch Time: 0.1478 (0.1652) Data Time: 0.0127 (0.0322) Average Loss: 0.6589 (0.7314) Average CE Loss (Source):  0.6589 ( 0.7314) Learning Rate: 0.1000 (0.1000) Top1_base: 82.0312 (79.3457) Top1_base_per_class: 80.2586 (79.3708) 
Training Epoch: [127/1000] Step: [90 / 285] Batch Time: 0.1434 (0.1656) Data Time: 0.0110 (0.0326) Average Loss: 0.6622 (0.7287) Average CE Loss (Source):  0.6622 ( 0.7287) Learning Rate: 0.1000 (0.1000) Top1_base: 81.2500 (79.5486) Top1_base_per_class: 80.1852 (79.5895) 
Training Epoch: [127/1000] Step: [100 / 285] Batch Time: 0.1439 (0.1639) Data Time: 0.0121 (0.0310) Average Loss: 0.6181 (0.7296) Average CE Loss (Source):  0.6181 ( 0.7296) Learning Rate: 0.1000 (0.1000) Top1_base: 83.5938 (79.5469) Top1_base_per_class: 84.6970 (79.5687) 
Training Epoch: [127/1000] Step: [110 / 285] Batch Time: 0.1463 (0.1628) Data Time: 0.0111 (0.0298) Average Loss: 0.6242 (0.7283) Average CE Loss (Source):  0.6242 ( 0.7283) Learning Rate: 0.1000 (0.1000) Top1_base: 82.8125 (79.6378) Top1_base_per_class: 81.9394 (79.7233) 
Training Epoch: [127/1000] Step: [120 / 285] Batch Time: 0.1507 (0.1617) Data Time: 0.0136 (0.0285) Average Loss: 0.5142 (0.7262) Average CE Loss (Source):  0.5142 ( 0.7262) Learning Rate: 0.1000 (0.1000) Top1_base: 86.7188 (79.7135) Top1_base_per_class: 88.2839 (79.8565) 
Training Epoch: [127/1000] Step: [130 / 285] Batch Time: 0.1434 (0.1609) Data Time: 0.0107 (0.0275) Average Loss: 0.6896 (0.7324) Average CE Loss (Source):  0.6896 ( 0.7324) Learning Rate: 0.1000 (0.1000) Top1_base: 76.5625 (79.4531) Top1_base_per_class: 76.6583 (79.5922) 
Training Epoch: [127/1000] Step: [140 / 285] Batch Time: 0.1489 (0.1607) Data Time: 0.0133 (0.0273) Average Loss: 0.8337 (0.7382) Average CE Loss (Source):  0.8337 ( 0.7382) Learning Rate: 0.1000 (0.1000) Top1_base: 75.0000 (79.3248) Top1_base_per_class: 79.5029 (79.5616) 
Training Epoch: [127/1000] Step: [150 / 285] Batch Time: 0.1456 (0.1598) Data Time: 0.0125 (0.0266) Average Loss: 0.8439 (0.7405) Average CE Loss (Source):  0.8439 ( 0.7405) Learning Rate: 0.1000 (0.1000) Top1_base: 79.6875 (79.3646) Top1_base_per_class: 77.3851 (79.5546) 
Training Epoch: [127/1000] Step: [160 / 285] Batch Time: 0.1507 (0.1592) Data Time: 0.0135 (0.0259) Average Loss: 0.8004 (0.7412) Average CE Loss (Source):  0.8004 ( 0.7412) Learning Rate: 0.1000 (0.1000) Top1_base: 76.5625 (79.3701) Top1_base_per_class: 77.3810 (79.5539) 
Training Epoch: [127/1000] Step: [170 / 285] Batch Time: 0.1453 (0.1595) Data Time: 0.0112 (0.0261) Average Loss: 0.7877 (0.7450) Average CE Loss (Source):  0.7877 ( 0.7450) Learning Rate: 0.1000 (0.1000) Top1_base: 79.6875 (79.2555) Top1_base_per_class: 76.6082 (79.4457) 
Training Epoch: [127/1000] Step: [180 / 285] Batch Time: 0.1498 (0.1590) Data Time: 0.0130 (0.0255) Average Loss: 0.7464 (0.7451) Average CE Loss (Source):  0.7464 ( 0.7451) Learning Rate: 0.1000 (0.1000) Top1_base: 79.6875 (79.2882) Top1_base_per_class: 81.0417 (79.4929) 
Training Epoch: [127/1000] Step: [190 / 285] Batch Time: 0.1457 (0.1584) Data Time: 0.0125 (0.0248) Average Loss: 0.8622 (0.7464) Average CE Loss (Source):  0.8622 ( 0.7464) Learning Rate: 0.1000 (0.1000) Top1_base: 71.8750 (79.1735) Top1_base_per_class: 71.2346 (79.3660) 
Training Epoch: [127/1000] Step: [200 / 285] Batch Time: 0.1498 (0.1578) Data Time: 0.0143 (0.0242) Average Loss: 0.6465 (0.7501) Average CE Loss (Source):  0.6465 ( 0.7501) Learning Rate: 0.1000 (0.1000) Top1_base: 78.1250 (79.0156) Top1_base_per_class: 80.7099 (79.2176) 
Training Epoch: [127/1000] Step: [210 / 285] Batch Time: 0.1438 (0.1574) Data Time: 0.0103 (0.0237) Average Loss: 0.8124 (0.7517) Average CE Loss (Source):  0.8124 ( 0.7517) Learning Rate: 0.1000 (0.1000) Top1_base: 82.8125 (78.9844) Top1_base_per_class: 81.7924 (79.2294) 
Training Epoch: [127/1000] Step: [220 / 285] Batch Time: 0.1454 (0.1569) Data Time: 0.0139 (0.0232) Average Loss: 0.6048 (0.7501) Average CE Loss (Source):  0.6048 ( 0.7501) Learning Rate: 0.1000 (0.1000) Top1_base: 86.7188 (79.0447) Top1_base_per_class: 88.8506 (79.2517) 
Training Epoch: [127/1000] Step: [230 / 285] Batch Time: 0.1482 (0.1565) Data Time: 0.0132 (0.0228) Average Loss: 0.7957 (0.7517) Average CE Loss (Source):  0.7957 ( 0.7517) Learning Rate: 0.1000 (0.1000) Top1_base: 75.7812 (78.9436) Top1_base_per_class: 78.1944 (79.1790) 
Training Epoch: [127/1000] Step: [240 / 285] Batch Time: 0.1585 (0.1564) Data Time: 0.0277 (0.0227) Average Loss: 0.8075 (0.7529) Average CE Loss (Source):  0.8075 ( 0.7529) Learning Rate: 0.1000 (0.1000) Top1_base: 77.3438 (78.9258) Top1_base_per_class: 76.0433 (79.1754) 
Training Epoch: [127/1000] Step: [250 / 285] Batch Time: 0.1449 (0.1564) Data Time: 0.0123 (0.0227) Average Loss: 0.7225 (0.7518) Average CE Loss (Source):  0.7225 ( 0.7518) Learning Rate: 0.1000 (0.1000) Top1_base: 78.9062 (78.9406) Top1_base_per_class: 76.4744 (79.1840) 
Training Epoch: [127/1000] Step: [260 / 285] Batch Time: 0.1531 (0.1565) Data Time: 0.0171 (0.0228) Average Loss: 0.7643 (0.7551) Average CE Loss (Source):  0.7643 ( 0.7551) Learning Rate: 0.1000 (0.1000) Top1_base: 77.3438 (78.8191) Top1_base_per_class: 76.8868 (79.0704) 
Training Epoch: [127/1000] Step: [270 / 285] Batch Time: 0.1456 (0.1561) Data Time: 0.0117 (0.0224) Average Loss: 0.9676 (0.7558) Average CE Loss (Source):  0.9676 ( 0.7558) Learning Rate: 0.1000 (0.1000) Top1_base: 71.8750 (78.8050) Top1_base_per_class: 72.3457 (79.0546) 
Training Epoch: [127/1000] Step: [280 / 285] Batch Time: 0.1534 (0.1561) Data Time: 0.0168 (0.0224) Average Loss: 0.6246 (0.7556) Average CE Loss (Source):  0.6246 ( 0.7556) Learning Rate: 0.1000 (0.1000) Top1_base: 82.8125 (78.7863) Top1_base_per_class: 79.7839 (78.9973) 
Training Epoch: [128/1000] Step: [0] Batch Time: 0.1456 (0.1560) Data Time: 0.0114 (0.0222) Average Loss: 0.9407 (0.7570) Average CE Loss (Source):  0.9407 ( 0.7570) Learning Rate: 0.1000 (0.1000) Top1_base: 71.8750 (78.7390) Top1_base_per_class: 71.5205 (78.9638) 
 13%|█▎        | 128/1000 [1:39:53<11:14:11, 46.39s/it] 13%|█▎        | 129/1000 [1:40:39<11:12:13, 46.31s/it]Training Epoch: [128/1000] Step: [10 / 285] Batch Time: 0.1413 (0.2302) Data Time: 0.0106 (0.0979) Average Loss: 0.7829 (0.7267) Average CE Loss (Source):  0.7829 ( 0.7267) Learning Rate: 0.1000 (0.1000) Top1_base: 78.9062 (79.6094) Top1_base_per_class: 80.3161 (80.1016) 
Training Epoch: [128/1000] Step: [20 / 285] Batch Time: 0.1460 (0.1939) Data Time: 0.0108 (0.0617) Average Loss: 0.5454 (0.7048) Average CE Loss (Source):  0.5454 ( 0.7048) Learning Rate: 0.1000 (0.1000) Top1_base: 83.5938 (80.2344) Top1_base_per_class: 85.5367 (80.9400) 
Training Epoch: [128/1000] Step: [30 / 285] Batch Time: 0.1487 (0.1838) Data Time: 0.0143 (0.0514) Average Loss: 1.0309 (0.6997) Average CE Loss (Source):  1.0309 ( 0.6997) Learning Rate: 0.1000 (0.1000) Top1_base: 70.3125 (80.2604) Top1_base_per_class: 72.2327 (80.7921) 
Training Epoch: [128/1000] Step: [40 / 285] Batch Time: 0.1473 (0.1770) Data Time: 0.0121 (0.0445) Average Loss: 0.7975 (0.7065) Average CE Loss (Source):  0.7975 ( 0.7065) Learning Rate: 0.1000 (0.1000) Top1_base: 78.9062 (79.8633) Top1_base_per_class: 81.0632 (80.5052) 
Training Epoch: [128/1000] Step: [50 / 285] Batch Time: 0.1612 (0.1727) Data Time: 0.0269 (0.0400) Average Loss: 0.6457 (0.7093) Average CE Loss (Source):  0.6457 ( 0.7093) Learning Rate: 0.1000 (0.1000) Top1_base: 83.5938 (79.7812) Top1_base_per_class: 81.5901 (80.4583) 
Training Epoch: [128/1000] Step: [60 / 285] Batch Time: 0.1468 (0.1703) Data Time: 0.0116 (0.0374) Average Loss: 0.8796 (0.7156) Average CE Loss (Source):  0.8796 ( 0.7156) Learning Rate: 0.1000 (0.1000) Top1_base: 74.2188 (79.6745) Top1_base_per_class: 72.8736 (80.4924) 
Training Epoch: [128/1000] Step: [70 / 285] Batch Time: 0.2897 (0.1706) Data Time: 0.1568 (0.0375) Average Loss: 0.7958 (0.7128) Average CE Loss (Source):  0.7958 ( 0.7128) Learning Rate: 0.1000 (0.1000) Top1_base: 78.9062 (79.8326) Top1_base_per_class: 77.1914 (80.5348) 
Training Epoch: [128/1000] Step: [80 / 285] Batch Time: 0.1445 (0.1692) Data Time: 0.0112 (0.0361) Average Loss: 0.8176 (0.7099) Average CE Loss (Source):  0.8176 ( 0.7099) Learning Rate: 0.1000 (0.1000) Top1_base: 75.0000 (79.8242) Top1_base_per_class: 72.9091 (80.2546) 
Training Epoch: [128/1000] Step: [90 / 285] Batch Time: 0.4136 (0.1707) Data Time: 0.2818 (0.0376) Average Loss: 0.7970 (0.7192) Average CE Loss (Source):  0.7970 ( 0.7192) Learning Rate: 0.1000 (0.1000) Top1_base: 78.1250 (79.5747) Top1_base_per_class: 79.4091 (80.0525) 
Training Epoch: [128/1000] Step: [100 / 285] Batch Time: 0.1439 (0.1693) Data Time: 0.0105 (0.0362) Average Loss: 0.7890 (0.7230) Average CE Loss (Source):  0.7890 ( 0.7230) Learning Rate: 0.1000 (0.1000) Top1_base: 78.1250 (79.4531) Top1_base_per_class: 81.3444 (80.0321) 
Training Epoch: [128/1000] Step: [110 / 285] Batch Time: 0.2277 (0.1702) Data Time: 0.0946 (0.0372) Average Loss: 0.8135 (0.7262) Average CE Loss (Source):  0.8135 ( 0.7262) Learning Rate: 0.1000 (0.1000) Top1_base: 78.9062 (79.3608) Top1_base_per_class: 79.7917 (79.8760) 
Training Epoch: [128/1000] Step: [120 / 285] Batch Time: 0.1457 (0.1694) Data Time: 0.0103 (0.0363) Average Loss: 0.7887 (0.7293) Average CE Loss (Source):  0.7887 ( 0.7293) Learning Rate: 0.1000 (0.1000) Top1_base: 75.0000 (79.2188) Top1_base_per_class: 73.6450 (79.6764) 
Training Epoch: [128/1000] Step: [130 / 285] Batch Time: 0.1609 (0.1691) Data Time: 0.0265 (0.0360) Average Loss: 0.6167 (0.7328) Average CE Loss (Source):  0.6167 ( 0.7328) Learning Rate: 0.1000 (0.1000) Top1_base: 82.0312 (79.1947) Top1_base_per_class: 81.7390 (79.7273) 
Training Epoch: [128/1000] Step: [140 / 285] Batch Time: 0.1447 (0.1678) Data Time: 0.0104 (0.0348) Average Loss: 0.7358 (0.7367) Average CE Loss (Source):  0.7358 ( 0.7367) Learning Rate: 0.1000 (0.1000) Top1_base: 76.5625 (79.1071) Top1_base_per_class: 73.6364 (79.6896) 
Training Epoch: [128/1000] Step: [150 / 285] Batch Time: 0.2077 (0.1681) Data Time: 0.0746 (0.0351) Average Loss: 0.8038 (0.7383) Average CE Loss (Source):  0.8038 ( 0.7383) Learning Rate: 0.1000 (0.1000) Top1_base: 75.0000 (79.0365) Top1_base_per_class: 74.9702 (79.6141) 
Training Epoch: [128/1000] Step: [160 / 285] Batch Time: 0.1476 (0.1670) Data Time: 0.0106 (0.0339) Average Loss: 0.7329 (0.7409) Average CE Loss (Source):  0.7329 ( 0.7409) Learning Rate: 0.1000 (0.1000) Top1_base: 79.6875 (79.0430) Top1_base_per_class: 78.7556 (79.6770) 
Training Epoch: [128/1000] Step: [170 / 285] Batch Time: 0.2450 (0.1664) Data Time: 0.1143 (0.0334) Average Loss: 0.6019 (0.7390) Average CE Loss (Source):  0.6019 ( 0.7390) Learning Rate: 0.1000 (0.1000) Top1_base: 84.3750 (79.1268) Top1_base_per_class: 84.9717 (79.7967) 
Training Epoch: [128/1000] Step: [180 / 285] Batch Time: 0.1459 (0.1661) Data Time: 0.0103 (0.0330) Average Loss: 0.7088 (0.7396) Average CE Loss (Source):  0.7088 ( 0.7396) Learning Rate: 0.1000 (0.1000) Top1_base: 79.6875 (79.1406) Top1_base_per_class: 80.6667 (79.7644) 
Training Epoch: [128/1000] Step: [190 / 285] Batch Time: 0.1603 (0.1655) Data Time: 0.0278 (0.0324) Average Loss: 0.6276 (0.7408) Average CE Loss (Source):  0.6276 ( 0.7408) Learning Rate: 0.1000 (0.1000) Top1_base: 81.2500 (79.0214) Top1_base_per_class: 83.7798 (79.6472) 
Training Epoch: [128/1000] Step: [200 / 285] Batch Time: 0.1421 (0.1650) Data Time: 0.0111 (0.0319) Average Loss: 0.6478 (0.7445) Average CE Loss (Source):  0.6478 ( 0.7445) Learning Rate: 0.1000 (0.1000) Top1_base: 82.0312 (78.9531) Top1_base_per_class: 84.1521 (79.6397) 
Training Epoch: [128/1000] Step: [210 / 285] Batch Time: 0.1492 (0.1640) Data Time: 0.0162 (0.0310) Average Loss: 0.8227 (0.7417) Average CE Loss (Source):  0.8227 ( 0.7417) Learning Rate: 0.1000 (0.1000) Top1_base: 75.0000 (79.0253) Top1_base_per_class: 78.2407 (79.7365) 
Training Epoch: [128/1000] Step: [220 / 285] Batch Time: 0.1466 (0.1635) Data Time: 0.0106 (0.0304) Average Loss: 0.6830 (0.7409) Average CE Loss (Source):  0.6830 ( 0.7409) Learning Rate: 0.1000 (0.1000) Top1_base: 80.4688 (79.0696) Top1_base_per_class: 78.9048 (79.7885) 
Training Epoch: [128/1000] Step: [230 / 285] Batch Time: 0.1509 (0.1631) Data Time: 0.0183 (0.0299) Average Loss: 0.7139 (0.7430) Average CE Loss (Source):  0.7139 ( 0.7430) Learning Rate: 0.1000 (0.1000) Top1_base: 79.6875 (79.0455) Top1_base_per_class: 81.4052 (79.7391) 
Training Epoch: [128/1000] Step: [240 / 285] Batch Time: 0.1425 (0.1624) Data Time: 0.0116 (0.0292) Average Loss: 0.7931 (0.7429) Average CE Loss (Source):  0.7931 ( 0.7429) Learning Rate: 0.1000 (0.1000) Top1_base: 80.4688 (79.0137) Top1_base_per_class: 75.0411 (79.6980) 
Training Epoch: [128/1000] Step: [250 / 285] Batch Time: 0.2001 (0.1624) Data Time: 0.0647 (0.0291) Average Loss: 0.7825 (0.7464) Average CE Loss (Source):  0.7825 ( 0.7464) Learning Rate: 0.1000 (0.1000) Top1_base: 78.1250 (78.9500) Top1_base_per_class: 76.6959 (79.5764) 
Training Epoch: [128/1000] Step: [260 / 285] Batch Time: 0.1488 (0.1620) Data Time: 0.0115 (0.0286) Average Loss: 0.9463 (0.7467) Average CE Loss (Source):  0.9463 ( 0.7467) Learning Rate: 0.1000 (0.1000) Top1_base: 71.8750 (78.9273) Top1_base_per_class: 73.1250 (79.5715) 
Training Epoch: [128/1000] Step: [270 / 285] Batch Time: 0.2280 (0.1619) Data Time: 0.0931 (0.0284) Average Loss: 0.8741 (0.7507) Average CE Loss (Source):  0.8741 ( 0.7507) Learning Rate: 0.1000 (0.1000) Top1_base: 76.5625 (78.8252) Top1_base_per_class: 80.5455 (79.4702) 
Training Epoch: [128/1000] Step: [280 / 285] Batch Time: 0.1454 (0.1616) Data Time: 0.0097 (0.0281) Average Loss: 0.9023 (0.7524) Average CE Loss (Source):  0.9023 ( 0.7524) Learning Rate: 0.1000 (0.1000) Top1_base: 75.7812 (78.7723) Top1_base_per_class: 74.6784 (79.4411) 
Training Epoch: [129/1000] Step: [0] Batch Time: 0.1468 (0.1616) Data Time: 0.0126 (0.0280) Average Loss: 0.7547 (0.7528) Average CE Loss (Source):  0.7547 ( 0.7528) Learning Rate: 0.1000 (0.1000) Top1_base: 78.9062 (78.7719) Top1_base_per_class: 77.0690 (79.4282) 
Training Epoch: [129/1000] Step: [10 / 285] Batch Time: 0.1451 (0.2318) Data Time: 0.0121 (0.0988) Average Loss: 0.8174 (0.7877) Average CE Loss (Source):  0.8174 ( 0.7877) Learning Rate: 0.1000 (0.1000) Top1_base: 79.6875 (78.9844) Top1_base_per_class: 77.0621 (79.8485) 
Training Epoch: [129/1000] Step: [20 / 285] Batch Time: 0.1445 (0.1887) Data Time: 0.0120 (0.0558) Average Loss: 0.6496 (0.7811) Average CE Loss (Source):  0.6496 ( 0.7811) Learning Rate: 0.1000 (0.1000) Top1_base: 82.8125 (78.9844) Top1_base_per_class: 80.0833 (79.5006) 
Training Epoch: [129/1000] Step: [30 / 285] Batch Time: 0.1495 (0.1773) Data Time: 0.0151 (0.0445) Average Loss: 0.6166 (0.7667) Average CE Loss (Source):  0.6166 ( 0.7667) Learning Rate: 0.1000 (0.1000) Top1_base: 82.8125 (78.8281) Top1_base_per_class: 84.0936 (79.7346) 
Training Epoch: [129/1000] Step: [40 / 285] Batch Time: 0.1421 (0.1724) Data Time: 0.0117 (0.0396) Average Loss: 0.6419 (0.7504) Average CE Loss (Source):  0.6419 ( 0.7504) Learning Rate: 0.1000 (0.1000) Top1_base: 75.7812 (78.9648) Top1_base_per_class: 76.0332 (79.6733) 
Training Epoch: [129/1000] Step: [50 / 285] Batch Time: 0.1480 (0.1671) Data Time: 0.0149 (0.0343) Average Loss: 0.7373 (0.7558) Average CE Loss (Source):  0.7373 ( 0.7558) Learning Rate: 0.1000 (0.1000) Top1_base: 80.4688 (78.9688) Top1_base_per_class: 81.6952 (79.6916) 
Training Epoch: [129/1000] Step: [60 / 285] Batch Time: 0.1480 (0.1667) Data Time: 0.0164 (0.0338) Average Loss: 0.7059 (0.7480) Average CE Loss (Source):  0.7059 ( 0.7480) Learning Rate: 0.1000 (0.1000) Top1_base: 80.4688 (79.1146) Top1_base_per_class: 84.7273 (79.8997) 
Training Epoch: [129/1000] Step: [70 / 285] Batch Time: 0.1475 (0.1647) Data Time: 0.0133 (0.0319) Average Loss: 0.7141 (0.7480) Average CE Loss (Source):  0.7141 ( 0.7480) Learning Rate: 0.1000 (0.1000) Top1_base: 77.3438 (79.0737) Top1_base_per_class: 79.2529 (79.7659) 
Training Epoch: [129/1000] Step: [80 / 285] Batch Time: 0.1430 (0.1633) Data Time: 0.0123 (0.0306) Average Loss: 0.8256 (0.7493) Average CE Loss (Source):  0.8256 ( 0.7493) Learning Rate: 0.1000 (0.1000) Top1_base: 78.1250 (79.0723) Top1_base_per_class: 80.2244 (79.6807) 
Training Epoch: [129/1000] Step: [90 / 285] Batch Time: 0.1474 (0.1615) Data Time: 0.0134 (0.0288) Average Loss: 0.9286 (0.7475) Average CE Loss (Source):  0.9286 ( 0.7475) Learning Rate: 0.1000 (0.1000) Top1_base: 71.0938 (79.0017) Top1_base_per_class: 73.1845 (79.5083) 
Training Epoch: [129/1000] Step: [100 / 285] Batch Time: 0.2211 (0.1625) Data Time: 0.0895 (0.0298) Average Loss: 0.4953 (0.7487) Average CE Loss (Source):  0.4953 ( 0.7487) Learning Rate: 0.1000 (0.1000) Top1_base: 86.7188 (79.0703) Top1_base_per_class: 83.8182 (79.5747) 
Training Epoch: [129/1000] Step: [110 / 285] Batch Time: 0.1463 (0.1614) Data Time: 0.0119 (0.0288) Average Loss: 0.6492 (0.7430) Average CE Loss (Source):  0.6492 ( 0.7430) Learning Rate: 0.1000 (0.1000) Top1_base: 80.4688 (79.2259) Top1_base_per_class: 80.7547 (79.7360) 
Training Epoch: [129/1000] Step: [120 / 285] Batch Time: 0.1537 (0.1603) Data Time: 0.0226 (0.0276) Average Loss: 0.8415 (0.7413) Average CE Loss (Source):  0.8415 ( 0.7413) Learning Rate: 0.1000 (0.1000) Top1_base: 76.5625 (79.1927) Top1_base_per_class: 73.5417 (79.6457) 
Training Epoch: [129/1000] Step: [130 / 285] Batch Time: 0.1461 (0.1598) Data Time: 0.0119 (0.0271) Average Loss: 0.6448 (0.7381) Average CE Loss (Source):  0.6448 ( 0.7381) Learning Rate: 0.1000 (0.1000) Top1_base: 84.3750 (79.3810) Top1_base_per_class: 84.7531 (79.8963) 
Training Epoch: [129/1000] Step: [140 / 285] Batch Time: 0.2062 (0.1594) Data Time: 0.0751 (0.0268) Average Loss: 0.6560 (0.7334) Average CE Loss (Source):  0.6560 ( 0.7334) Learning Rate: 0.1000 (0.1000) Top1_base: 81.2500 (79.5647) Top1_base_per_class: 80.8422 (79.9724) 
Training Epoch: [129/1000] Step: [150 / 285] Batch Time: 0.1411 (0.1589) Data Time: 0.0105 (0.0263) Average Loss: 0.7715 (0.7318) Average CE Loss (Source):  0.7715 ( 0.7318) Learning Rate: 0.1000 (0.1000) Top1_base: 77.3438 (79.5729) Top1_base_per_class: 79.0230 (80.0351) 
Training Epoch: [129/1000] Step: [160 / 285] Batch Time: 0.1964 (0.1588) Data Time: 0.0643 (0.0263) Average Loss: 0.8023 (0.7337) Average CE Loss (Source):  0.8023 ( 0.7337) Learning Rate: 0.1000 (0.1000) Top1_base: 79.6875 (79.5410) Top1_base_per_class: 79.1818 (79.9783) 
Training Epoch: [129/1000] Step: [170 / 285] Batch Time: 0.1409 (0.1584) Data Time: 0.0106 (0.0260) Average Loss: 0.7435 (0.7340) Average CE Loss (Source):  0.7435 ( 0.7340) Learning Rate: 0.1000 (0.1000) Top1_base: 77.3438 (79.5129) Top1_base_per_class: 78.2749 (79.9970) 
Training Epoch: [129/1000] Step: [180 / 285] Batch Time: 0.2386 (0.1587) Data Time: 0.1056 (0.0263) Average Loss: 0.6734 (0.7344) Average CE Loss (Source):  0.6734 ( 0.7344) Learning Rate: 0.1000 (0.1000) Top1_base: 79.6875 (79.4705) Top1_base_per_class: 79.1515 (79.9559) 
Training Epoch: [129/1000] Step: [190 / 285] Batch Time: 0.1465 (0.1579) Data Time: 0.0124 (0.0256) Average Loss: 0.6978 (0.7342) Average CE Loss (Source):  0.6978 ( 0.7342) Learning Rate: 0.1000 (0.1000) Top1_base: 75.7812 (79.4449) Top1_base_per_class: 76.6667 (79.9821) 
Training Epoch: [129/1000] Step: [200 / 285] Batch Time: 0.1638 (0.1578) Data Time: 0.0311 (0.0254) Average Loss: 0.9180 (0.7370) Average CE Loss (Source):  0.9180 ( 0.7370) Learning Rate: 0.1000 (0.1000) Top1_base: 75.0000 (79.3711) Top1_base_per_class: 72.7299 (79.8138) 
Training Epoch: [129/1000] Step: [210 / 285] Batch Time: 0.1477 (0.1572) Data Time: 0.0122 (0.0248) Average Loss: 0.6136 (0.7393) Average CE Loss (Source):  0.6136 ( 0.7393) Learning Rate: 0.1000 (0.1000) Top1_base: 81.2500 (79.3378) Top1_base_per_class: 78.2554 (79.7589) 
Training Epoch: [129/1000] Step: [220 / 285] Batch Time: 0.1585 (0.1570) Data Time: 0.0281 (0.0247) Average Loss: 0.6049 (0.7416) Average CE Loss (Source):  0.6049 ( 0.7416) Learning Rate: 0.1000 (0.1000) Top1_base: 86.7188 (79.3643) Top1_base_per_class: 86.3580 (79.8292) 
Training Epoch: [129/1000] Step: [230 / 285] Batch Time: 0.1470 (0.1574) Data Time: 0.0135 (0.0251) Average Loss: 0.7351 (0.7427) Average CE Loss (Source):  0.7351 ( 0.7427) Learning Rate: 0.1000 (0.1000) Top1_base: 78.1250 (79.3037) Top1_base_per_class: 78.7069 (79.8200) 
Training Epoch: [129/1000] Step: [240 / 285] Batch Time: 0.1590 (0.1575) Data Time: 0.0291 (0.0252) Average Loss: 1.0463 (0.7452) Average CE Loss (Source):  1.0463 ( 0.7452) Learning Rate: 0.1000 (0.1000) Top1_base: 70.3125 (79.2513) Top1_base_per_class: 75.0809 (79.7775) 
Training Epoch: [129/1000] Step: [250 / 285] Batch Time: 0.1446 (0.1572) Data Time: 0.0123 (0.0248) Average Loss: 0.7689 (0.7477) Average CE Loss (Source):  0.7689 ( 0.7477) Learning Rate: 0.1000 (0.1000) Top1_base: 78.9062 (79.1469) Top1_base_per_class: 76.3272 (79.6695) 
Training Epoch: [129/1000] Step: [260 / 285] Batch Time: 0.2038 (0.1573) Data Time: 0.0737 (0.0249) Average Loss: 0.8105 (0.7501) Average CE Loss (Source):  0.8105 ( 0.7501) Learning Rate: 0.1000 (0.1000) Top1_base: 77.3438 (79.0715) Top1_base_per_class: 77.8931 (79.5671) 
Training Epoch: [129/1000] Step: [270 / 285] Batch Time: 0.1459 (0.1570) Data Time: 0.0128 (0.0247) Average Loss: 0.6773 (0.7523) Average CE Loss (Source):  0.6773 ( 0.7523) Learning Rate: 0.1000 (0.1000) Top1_base: 82.0312 (78.9931) Top1_base_per_class: 82.0833 (79.4929) 
Training Epoch: [129/1000] Step: [280 / 285] Batch Time: 0.1804 (0.1571) Data Time: 0.0505 (0.0248) Average Loss: 0.8596 (0.7532) Average CE Loss (Source):  0.8596 ( 0.7532) Learning Rate: 0.1000 (0.1000) Top1_base: 72.6562 (78.9342) Top1_base_per_class: 73.8135 (79.4443) 
Training Epoch: [130/1000] Step: [0] Batch Time: 0.1408 (0.1568) Data Time: 0.0109 (0.0245) Average Loss: 0.7129 (0.7540) Average CE Loss (Source):  0.7129 ( 0.7540) Learning Rate: 0.1000 (0.1000) Top1_base: 77.3438 (78.9200) Top1_base_per_class: 78.1579 (79.3991) 
 13%|█▎        | 130/1000 [1:41:26<11:16:43, 46.67s/it] 13%|█▎        | 131/1000 [1:42:11<11:05:34, 45.95s/it]Training Epoch: [130/1000] Step: [10 / 285] Batch Time: 0.1469 (0.2270) Data Time: 0.0129 (0.0938) Average Loss: 0.6903 (0.7328) Average CE Loss (Source):  0.6903 ( 0.7328) Learning Rate: 0.1000 (0.1000) Top1_base: 82.0312 (79.5312) Top1_base_per_class: 83.8988 (80.2651) 
Training Epoch: [130/1000] Step: [20 / 285] Batch Time: 0.1474 (0.1920) Data Time: 0.0147 (0.0588) Average Loss: 0.6047 (0.7606) Average CE Loss (Source):  0.6047 ( 0.7606) Learning Rate: 0.1000 (0.1000) Top1_base: 82.0312 (78.6328) Top1_base_per_class: 84.8164 (79.3740) 
Training Epoch: [130/1000] Step: [30 / 285] Batch Time: 0.1487 (0.1806) Data Time: 0.0131 (0.0471) Average Loss: 0.6043 (0.7439) Average CE Loss (Source):  0.6043 ( 0.7439) Learning Rate: 0.1000 (0.1000) Top1_base: 82.0312 (78.9583) Top1_base_per_class: 84.7953 (79.4356) 
Training Epoch: [130/1000] Step: [40 / 285] Batch Time: 0.1464 (0.1756) Data Time: 0.0124 (0.0417) Average Loss: 0.7582 (0.7430) Average CE Loss (Source):  0.7582 ( 0.7430) Learning Rate: 0.1000 (0.1000) Top1_base: 75.0000 (78.6719) Top1_base_per_class: 69.9435 (79.1902) 
Training Epoch: [130/1000] Step: [50 / 285] Batch Time: 0.1477 (0.1700) Data Time: 0.0120 (0.0362) Average Loss: 0.8125 (0.7374) Average CE Loss (Source):  0.8125 ( 0.7374) Learning Rate: 0.1000 (0.1000) Top1_base: 75.7812 (79.0156) Top1_base_per_class: 75.0000 (79.6758) 
Training Epoch: [130/1000] Step: [60 / 285] Batch Time: 0.2026 (0.1680) Data Time: 0.0695 (0.0343) Average Loss: 0.7058 (0.7360) Average CE Loss (Source):  0.7058 ( 0.7360) Learning Rate: 0.1000 (0.1000) Top1_base: 84.3750 (79.3359) Top1_base_per_class: 84.1987 (79.9146) 
Training Epoch: [130/1000] Step: [70 / 285] Batch Time: 0.1443 (0.1662) Data Time: 0.0121 (0.0327) Average Loss: 0.8012 (0.7397) Average CE Loss (Source):  0.8012 ( 0.7397) Learning Rate: 0.1000 (0.1000) Top1_base: 79.6875 (79.2746) Top1_base_per_class: 79.1941 (79.6624) 
Training Epoch: [130/1000] Step: [80 / 285] Batch Time: 0.1480 (0.1640) Data Time: 0.0133 (0.0306) Average Loss: 0.8729 (0.7417) Average CE Loss (Source):  0.8729 ( 0.7417) Learning Rate: 0.1000 (0.1000) Top1_base: 75.0000 (79.2285) Top1_base_per_class: 73.4295 (79.4366) 
Training Epoch: [130/1000] Step: [90 / 285] Batch Time: 0.1432 (0.1632) Data Time: 0.0101 (0.0299) Average Loss: 0.7384 (0.7442) Average CE Loss (Source):  0.7384 ( 0.7442) Learning Rate: 0.1000 (0.1000) Top1_base: 78.9062 (79.1059) Top1_base_per_class: 80.7353 (79.4495) 
Training Epoch: [130/1000] Step: [100 / 285] Batch Time: 0.1461 (0.1616) Data Time: 0.0117 (0.0284) Average Loss: 0.6839 (0.7453) Average CE Loss (Source):  0.6839 ( 0.7453) Learning Rate: 0.1000 (0.1000) Top1_base: 80.4688 (79.0703) Top1_base_per_class: 81.4327 (79.4080) 
Training Epoch: [130/1000] Step: [110 / 285] Batch Time: 0.1427 (0.1609) Data Time: 0.0120 (0.0278) Average Loss: 0.5517 (0.7448) Average CE Loss (Source):  0.5517 ( 0.7448) Learning Rate: 0.1000 (0.1000) Top1_base: 83.5938 (79.1619) Top1_base_per_class: 85.6387 (79.5257) 
Training Epoch: [130/1000] Step: [120 / 285] Batch Time: 0.1454 (0.1602) Data Time: 0.0125 (0.0273) Average Loss: 0.8548 (0.7471) Average CE Loss (Source):  0.8548 ( 0.7471) Learning Rate: 0.1000 (0.1000) Top1_base: 74.2188 (78.9193) Top1_base_per_class: 74.2308 (79.3793) 
Training Epoch: [130/1000] Step: [130 / 285] Batch Time: 0.1495 (0.1591) Data Time: 0.0121 (0.0262) Average Loss: 0.8237 (0.7493) Average CE Loss (Source):  0.8237 ( 0.7493) Learning Rate: 0.1000 (0.1000) Top1_base: 77.3438 (78.8582) Top1_base_per_class: 76.9091 (79.3634) 
Training Epoch: [130/1000] Step: [140 / 285] Batch Time: 0.1454 (0.1582) Data Time: 0.0122 (0.0253) Average Loss: 0.7241 (0.7494) Average CE Loss (Source):  0.7241 ( 0.7494) Learning Rate: 0.1000 (0.1000) Top1_base: 75.0000 (78.9621) Top1_base_per_class: 75.8176 (79.4682) 
Training Epoch: [130/1000] Step: [150 / 285] Batch Time: 0.1490 (0.1580) Data Time: 0.0120 (0.0250) Average Loss: 0.7905 (0.7527) Average CE Loss (Source):  0.7905 ( 0.7527) Learning Rate: 0.1000 (0.1000) Top1_base: 78.9062 (78.8750) Top1_base_per_class: 76.6369 (79.3506) 
Training Epoch: [130/1000] Step: [160 / 285] Batch Time: 0.1463 (0.1575) Data Time: 0.0128 (0.0244) Average Loss: 0.7752 (0.7529) Average CE Loss (Source):  0.7752 ( 0.7529) Learning Rate: 0.1000 (0.1000) Top1_base: 77.3438 (78.8379) Top1_base_per_class: 78.7963 (79.3588) 
Training Epoch: [130/1000] Step: [170 / 285] Batch Time: 0.1450 (0.1571) Data Time: 0.0127 (0.0240) Average Loss: 0.6865 (0.7533) Average CE Loss (Source):  0.6865 ( 0.7533) Learning Rate: 0.1000 (0.1000) Top1_base: 79.6875 (78.8281) Top1_base_per_class: 81.2121 (79.3681) 
Training Epoch: [130/1000] Step: [180 / 285] Batch Time: 0.1467 (0.1568) Data Time: 0.0144 (0.0237) Average Loss: 0.7651 (0.7576) Average CE Loss (Source):  0.7651 ( 0.7576) Learning Rate: 0.1000 (0.1000) Top1_base: 78.9062 (78.7196) Top1_base_per_class: 79.1667 (79.2422) 
Training Epoch: [130/1000] Step: [190 / 285] Batch Time: 0.1470 (0.1562) Data Time: 0.0124 (0.0232) Average Loss: 0.7624 (0.7563) Average CE Loss (Source):  0.7624 ( 0.7563) Learning Rate: 0.1000 (0.1000) Top1_base: 78.1250 (78.7829) Top1_base_per_class: 80.0000 (79.3537) 
Training Epoch: [130/1000] Step: [200 / 285] Batch Time: 0.1487 (0.1562) Data Time: 0.0128 (0.0231) Average Loss: 0.6588 (0.7559) Average CE Loss (Source):  0.6588 ( 0.7559) Learning Rate: 0.1000 (0.1000) Top1_base: 81.2500 (78.7344) Top1_base_per_class: 83.6728 (79.3024) 
Training Epoch: [130/1000] Step: [210 / 285] Batch Time: 0.1487 (0.1564) Data Time: 0.0139 (0.0234) Average Loss: 0.6823 (0.7556) Average CE Loss (Source):  0.6823 ( 0.7556) Learning Rate: 0.1000 (0.1000) Top1_base: 83.5938 (78.7202) Top1_base_per_class: 84.9384 (79.2683) 
Training Epoch: [130/1000] Step: [220 / 285] Batch Time: 0.1443 (0.1560) Data Time: 0.0106 (0.0230) Average Loss: 0.5856 (0.7575) Average CE Loss (Source):  0.5856 ( 0.7575) Learning Rate: 0.1000 (0.1000) Top1_base: 85.1562 (78.6648) Top1_base_per_class: 84.9697 (79.1892) 
Training Epoch: [130/1000] Step: [230 / 285] Batch Time: 0.1437 (0.1561) Data Time: 0.0119 (0.0231) Average Loss: 0.6239 (0.7567) Average CE Loss (Source):  0.6239 ( 0.7567) Learning Rate: 0.1000 (0.1000) Top1_base: 79.6875 (78.6481) Top1_base_per_class: 78.6970 (79.1572) 
Training Epoch: [130/1000] Step: [240 / 285] Batch Time: 0.1496 (0.1559) Data Time: 0.0139 (0.0228) Average Loss: 0.7897 (0.7562) Average CE Loss (Source):  0.7897 ( 0.7562) Learning Rate: 0.1000 (0.1000) Top1_base: 77.3438 (78.6426) Top1_base_per_class: 76.1310 (79.1324) 
Training Epoch: [130/1000] Step: [250 / 285] Batch Time: 0.1493 (0.1557) Data Time: 0.0136 (0.0225) Average Loss: 0.8706 (0.7566) Average CE Loss (Source):  0.8706 ( 0.7566) Learning Rate: 0.1000 (0.1000) Top1_base: 76.5625 (78.6312) Top1_base_per_class: 76.1576 (79.1450) 
Training Epoch: [130/1000] Step: [260 / 285] Batch Time: 0.1443 (0.1554) Data Time: 0.0121 (0.0222) Average Loss: 0.7897 (0.7578) Average CE Loss (Source):  0.7897 ( 0.7578) Learning Rate: 0.1000 (0.1000) Top1_base: 75.7812 (78.5457) Top1_base_per_class: 74.9718 (79.0317) 
Training Epoch: [130/1000] Step: [270 / 285] Batch Time: 0.1495 (0.1555) Data Time: 0.0113 (0.0223) Average Loss: 0.9192 (0.7592) Average CE Loss (Source):  0.9192 ( 0.7592) Learning Rate: 0.1000 (0.1000) Top1_base: 79.6875 (78.4925) Top1_base_per_class: 78.3121 (78.9228) 
Training Epoch: [130/1000] Step: [280 / 285] Batch Time: 0.1420 (0.1553) Data Time: 0.0104 (0.0220) Average Loss: 0.6406 (0.7610) Average CE Loss (Source):  0.6406 ( 0.7610) Learning Rate: 0.1000 (0.1000) Top1_base: 82.0312 (78.4682) Top1_base_per_class: 81.4881 (78.8791) 
Training Epoch: [131/1000] Step: [0] Batch Time: 0.1526 (0.1552) Data Time: 0.0209 (0.0219) Average Loss: 0.7622 (0.7609) Average CE Loss (Source):  0.7622 ( 0.7609) Learning Rate: 0.1000 (0.1000) Top1_base: 78.1250 (78.4512) Top1_base_per_class: 79.3966 (78.8499) 
Training Epoch: [131/1000] Step: [10 / 285] Batch Time: 0.1425 (0.2402) Data Time: 0.0105 (0.1076) Average Loss: 0.7810 (0.6974) Average CE Loss (Source):  0.7810 ( 0.6974) Learning Rate: 0.1000 (0.1000) Top1_base: 78.9062 (80.1562) Top1_base_per_class: 78.3929 (80.2490) 
Training Epoch: [131/1000] Step: [20 / 285] Batch Time: 0.1484 (0.2011) Data Time: 0.0142 (0.0685) Average Loss: 1.0169 (0.7154) Average CE Loss (Source):  1.0169 ( 0.7154) Learning Rate: 0.1000 (0.1000) Top1_base: 75.7812 (79.6875) Top1_base_per_class: 74.4600 (79.9534) 
Training Epoch: [131/1000] Step: [30 / 285] Batch Time: 0.1418 (0.1859) Data Time: 0.0104 (0.0534) Average Loss: 0.7350 (0.6995) Average CE Loss (Source):  0.7350 ( 0.6995) Learning Rate: 0.1000 (0.1000) Top1_base: 80.4688 (80.0781) Top1_base_per_class: 78.9506 (80.5485) 
Training Epoch: [131/1000] Step: [40 / 285] Batch Time: 0.1489 (0.1778) Data Time: 0.0139 (0.0451) Average Loss: 0.6230 (0.7036) Average CE Loss (Source):  0.6230 ( 0.7036) Learning Rate: 0.1000 (0.1000) Top1_base: 85.1562 (80.0391) Top1_base_per_class: 85.2924 (80.4631) 
Training Epoch: [131/1000] Step: [50 / 285] Batch Time: 0.1431 (0.1739) Data Time: 0.0103 (0.0411) Average Loss: 0.4861 (0.7077) Average CE Loss (Source):  0.4861 ( 0.7077) Learning Rate: 0.1000 (0.1000) Top1_base: 87.5000 (80.0469) Top1_base_per_class: 85.2339 (80.5364) 
Training Epoch: [131/1000] Step: [60 / 285] Batch Time: 0.1493 (0.1711) Data Time: 0.0129 (0.0378) Average Loss: 0.6338 (0.7057) Average CE Loss (Source):  0.6338 ( 0.7057) Learning Rate: 0.1000 (0.1000) Top1_base: 82.0312 (80.0911) Top1_base_per_class: 80.8621 (80.4902) 
Training Epoch: [131/1000] Step: [70 / 285] Batch Time: 0.1456 (0.1683) Data Time: 0.0105 (0.0348) Average Loss: 0.6315 (0.7073) Average CE Loss (Source):  0.6315 ( 0.7073) Learning Rate: 0.1000 (0.1000) Top1_base: 84.3750 (80.2344) Top1_base_per_class: 84.1667 (80.6344) 
Training Epoch: [131/1000] Step: [80 / 285] Batch Time: 0.1432 (0.1657) Data Time: 0.0112 (0.0322) Average Loss: 0.7430 (0.7076) Average CE Loss (Source):  0.7430 ( 0.7076) Learning Rate: 0.1000 (0.1000) Top1_base: 76.5625 (80.1562) Top1_base_per_class: 78.6970 (80.5797) 
Training Epoch: [131/1000] Step: [90 / 285] Batch Time: 0.1443 (0.1637) Data Time: 0.0103 (0.0301) Average Loss: 0.7079 (0.7157) Average CE Loss (Source):  0.7079 ( 0.7157) Learning Rate: 0.1000 (0.1000) Top1_base: 81.2500 (80.0521) Top1_base_per_class: 80.6364 (80.4171) 
Training Epoch: [131/1000] Step: [100 / 285] Batch Time: 0.1466 (0.1622) Data Time: 0.0104 (0.0284) Average Loss: 0.6434 (0.7209) Average CE Loss (Source):  0.6434 ( 0.7209) Learning Rate: 0.1000 (0.1000) Top1_base: 84.3750 (80.0156) Top1_base_per_class: 85.0314 (80.2915) 
Training Epoch: [131/1000] Step: [110 / 285] Batch Time: 0.1453 (0.1614) Data Time: 0.0109 (0.0275) Average Loss: 0.5572 (0.7177) Average CE Loss (Source):  0.5572 ( 0.7177) Learning Rate: 0.1000 (0.1000) Top1_base: 84.3750 (79.9787) Top1_base_per_class: 84.4827 (80.2896) 
Training Epoch: [131/1000] Step: [120 / 285] Batch Time: 0.1498 (0.1603) Data Time: 0.0131 (0.0264) Average Loss: 0.8791 (0.7138) Average CE Loss (Source):  0.8791 ( 0.7138) Learning Rate: 0.1000 (0.1000) Top1_base: 71.0938 (80.0391) Top1_base_per_class: 71.3988 (80.2906) 
Training Epoch: [131/1000] Step: [130 / 285] Batch Time: 0.1416 (0.1596) Data Time: 0.0103 (0.0258) Average Loss: 0.7459 (0.7142) Average CE Loss (Source):  0.7459 ( 0.7142) Learning Rate: 0.1000 (0.1000) Top1_base: 78.9062 (80.0240) Top1_base_per_class: 76.6624 (80.2817) 
Training Epoch: [131/1000] Step: [140 / 285] Batch Time: 0.1486 (0.1588) Data Time: 0.0146 (0.0249) Average Loss: 1.0359 (0.7181) Average CE Loss (Source):  1.0359 ( 0.7181) Learning Rate: 0.1000 (0.1000) Top1_base: 70.3125 (79.8996) Top1_base_per_class: 71.8590 (80.0887) 
Training Epoch: [131/1000] Step: [150 / 285] Batch Time: 0.1452 (0.1582) Data Time: 0.0122 (0.0244) Average Loss: 0.8002 (0.7248) Average CE Loss (Source):  0.8002 ( 0.7248) Learning Rate: 0.1000 (0.1000) Top1_base: 75.0000 (79.7292) Top1_base_per_class: 76.0626 (79.9163) 
Training Epoch: [131/1000] Step: [160 / 285] Batch Time: 0.1498 (0.1582) Data Time: 0.0136 (0.0244) Average Loss: 0.6783 (0.7284) Average CE Loss (Source):  0.6783 ( 0.7284) Learning Rate: 0.1000 (0.1000) Top1_base: 81.2500 (79.6289) Top1_base_per_class: 81.3399 (79.8699) 
Training Epoch: [131/1000] Step: [170 / 285] Batch Time: 0.1425 (0.1580) Data Time: 0.0110 (0.0241) Average Loss: 0.7957 (0.7287) Average CE Loss (Source):  0.7957 ( 0.7287) Learning Rate: 0.1000 (0.1000) Top1_base: 73.4375 (79.5726) Top1_base_per_class: 75.4386 (79.8984) 
Training Epoch: [131/1000] Step: [180 / 285] Batch Time: 0.1497 (0.1574) Data Time: 0.0132 (0.0235) Average Loss: 0.6817 (0.7309) Average CE Loss (Source):  0.6817 ( 0.7309) Learning Rate: 0.1000 (0.1000) Top1_base: 82.8125 (79.5703) Top1_base_per_class: 83.5494 (79.8914) 
Training Epoch: [131/1000] Step: [190 / 285] Batch Time: 0.1455 (0.1569) Data Time: 0.0120 (0.0231) Average Loss: 0.7480 (0.7355) Average CE Loss (Source):  0.7480 ( 0.7355) Learning Rate: 0.1000 (0.1000) Top1_base: 75.7812 (79.4038) Top1_base_per_class: 76.9028 (79.6958) 
Training Epoch: [131/1000] Step: [200 / 285] Batch Time: 0.1474 (0.1565) Data Time: 0.0120 (0.0226) Average Loss: 0.8496 (0.7362) Average CE Loss (Source):  0.8496 ( 0.7362) Learning Rate: 0.1000 (0.1000) Top1_base: 77.3438 (79.3945) Top1_base_per_class: 80.9434 (79.7558) 
Training Epoch: [131/1000] Step: [210 / 285] Batch Time: 0.1438 (0.1568) Data Time: 0.0111 (0.0230) Average Loss: 0.6831 (0.7362) Average CE Loss (Source):  0.6831 ( 0.7362) Learning Rate: 0.1000 (0.1000) Top1_base: 79.6875 (79.3824) Top1_base_per_class: 76.6071 (79.7398) 
Training Epoch: [131/1000] Step: [220 / 285] Batch Time: 0.1533 (0.1566) Data Time: 0.0166 (0.0227) Average Loss: 0.9035 (0.7382) Average CE Loss (Source):  0.9035 ( 0.7382) Learning Rate: 0.1000 (0.1000) Top1_base: 75.7812 (79.3501) Top1_base_per_class: 75.1515 (79.6622) 
Training Epoch: [131/1000] Step: [230 / 285] Batch Time: 0.1425 (0.1563) Data Time: 0.0104 (0.0224) Average Loss: 0.7604 (0.7403) Average CE Loss (Source):  0.7604 ( 0.7403) Learning Rate: 0.1000 (0.1000) Top1_base: 79.6875 (79.2935) Top1_base_per_class: 78.2738 (79.5969) 
Training Epoch: [131/1000] Step: [240 / 285] Batch Time: 0.1449 (0.1563) Data Time: 0.0134 (0.0224) Average Loss: 0.7761 (0.7427) Average CE Loss (Source):  0.7761 ( 0.7427) Learning Rate: 0.1000 (0.1000) Top1_base: 78.9062 (79.2090) Top1_base_per_class: 77.9321 (79.5099) 
Training Epoch: [131/1000] Step: [250 / 285] Batch Time: 0.1454 (0.1559) Data Time: 0.0140 (0.0220) Average Loss: 0.9505 (0.7478) Average CE Loss (Source):  0.9505 ( 0.7478) Learning Rate: 0.1000 (0.1000) Top1_base: 75.7812 (79.1125) Top1_base_per_class: 78.9942 (79.4282) 
Training Epoch: [131/1000] Step: [260 / 285] Batch Time: 0.1496 (0.1556) Data Time: 0.0136 (0.0217) Average Loss: 0.7585 (0.7484) Average CE Loss (Source):  0.7585 ( 0.7484) Learning Rate: 0.1000 (0.1000) Top1_base: 76.5625 (79.0685) Top1_base_per_class: 76.1696 (79.3928) 
Training Epoch: [131/1000] Step: [270 / 285] Batch Time: 0.1952 (0.1555) Data Time: 0.0630 (0.0217) Average Loss: 0.7124 (0.7492) Average CE Loss (Source):  0.7124 ( 0.7492) Learning Rate: 0.1000 (0.1000) Top1_base: 82.8125 (79.0046) Top1_base_per_class: 83.2562 (79.2989) 
Training Epoch: [131/1000] Step: [280 / 285] Batch Time: 0.1489 (0.1556) Data Time: 0.0139 (0.0218) Average Loss: 0.7082 (0.7493) Average CE Loss (Source):  0.7082 ( 0.7493) Learning Rate: 0.1000 (0.1000) Top1_base: 80.4688 (79.0067) Top1_base_per_class: 82.3810 (79.3276) 
Training Epoch: [132/1000] Step: [0] Batch Time: 0.1435 (0.1556) Data Time: 0.0112 (0.0218) Average Loss: 0.8330 (0.7511) Average CE Loss (Source):  0.8330 ( 0.7511) Learning Rate: 0.1000 (0.1000) Top1_base: 75.0000 (78.9693) Top1_base_per_class: 73.5623 (79.2865) 
 13%|█▎        | 132/1000 [1:42:58<11:10:24, 46.34s/it] 13%|█▎        | 133/1000 [1:43:42<11:01:39, 45.79s/it]Training Epoch: [132/1000] Step: [10 / 285] Batch Time: 0.1455 (0.2362) Data Time: 0.0114 (0.1037) Average Loss: 0.5325 (0.6755) Average CE Loss (Source):  0.5325 ( 0.6755) Learning Rate: 0.1000 (0.1000) Top1_base: 82.0312 (81.1719) Top1_base_per_class: 79.8457 (81.6961) 
Training Epoch: [132/1000] Step: [20 / 285] Batch Time: 0.1527 (0.1938) Data Time: 0.0118 (0.0608) Average Loss: 0.5731 (0.7116) Average CE Loss (Source):  0.5731 ( 0.7116) Learning Rate: 0.1000 (0.1000) Top1_base: 80.4688 (79.1797) Top1_base_per_class: 80.9936 (79.6214) 
Training Epoch: [132/1000] Step: [30 / 285] Batch Time: 0.1476 (0.1794) Data Time: 0.0157 (0.0465) Average Loss: 0.7727 (0.7263) Average CE Loss (Source):  0.7727 ( 0.7263) Learning Rate: 0.1000 (0.1000) Top1_base: 75.0000 (79.1146) Top1_base_per_class: 73.6970 (79.4245) 
Training Epoch: [132/1000] Step: [40 / 285] Batch Time: 0.1473 (0.1724) Data Time: 0.0122 (0.0393) Average Loss: 0.6721 (0.7016) Average CE Loss (Source):  0.6721 ( 0.7016) Learning Rate: 0.1000 (0.1000) Top1_base: 81.2500 (80.0195) Top1_base_per_class: 81.7576 (80.2443) 
Training Epoch: [132/1000] Step: [50 / 285] Batch Time: 0.1670 (0.1683) Data Time: 0.0338 (0.0350) Average Loss: 0.8408 (0.6974) Average CE Loss (Source):  0.8408 ( 0.6974) Learning Rate: 0.1000 (0.1000) Top1_base: 71.8750 (80.1875) Top1_base_per_class: 71.4368 (80.2926) 
Training Epoch: [132/1000] Step: [60 / 285] Batch Time: 0.1483 (0.1647) Data Time: 0.0130 (0.0314) Average Loss: 0.8513 (0.7020) Average CE Loss (Source):  0.8513 ( 0.7020) Learning Rate: 0.1000 (0.1000) Top1_base: 78.1250 (80.2344) Top1_base_per_class: 78.6550 (80.3153) 
Training Epoch: [132/1000] Step: [70 / 285] Batch Time: 0.2192 (0.1643) Data Time: 0.0886 (0.0310) Average Loss: 0.8947 (0.7076) Average CE Loss (Source):  0.8947 ( 0.7076) Learning Rate: 0.1000 (0.1000) Top1_base: 73.4375 (79.9442) Top1_base_per_class: 73.3745 (80.0880) 
Training Epoch: [132/1000] Step: [80 / 285] Batch Time: 0.1447 (0.1630) Data Time: 0.0107 (0.0298) Average Loss: 0.4996 (0.7050) Average CE Loss (Source):  0.4996 ( 0.7050) Learning Rate: 0.1000 (0.1000) Top1_base: 87.5000 (80.0488) Top1_base_per_class: 88.4700 (80.2651) 
Training Epoch: [132/1000] Step: [90 / 285] Batch Time: 0.2523 (0.1628) Data Time: 0.1200 (0.0296) Average Loss: 0.7482 (0.7152) Average CE Loss (Source):  0.7482 ( 0.7152) Learning Rate: 0.1000 (0.1000) Top1_base: 82.8125 (79.7743) Top1_base_per_class: 82.3333 (80.0391) 
Training Epoch: [132/1000] Step: [100 / 285] Batch Time: 0.1440 (0.1615) Data Time: 0.0109 (0.0284) Average Loss: 1.0003 (0.7208) Average CE Loss (Source):  1.0003 ( 0.7208) Learning Rate: 0.1000 (0.1000) Top1_base: 72.6562 (79.6562) Top1_base_per_class: 72.0194 (80.0059) 
Training Epoch: [132/1000] Step: [110 / 285] Batch Time: 0.1647 (0.1603) Data Time: 0.0328 (0.0272) Average Loss: 0.6340 (0.7227) Average CE Loss (Source):  0.6340 ( 0.7227) Learning Rate: 0.1000 (0.1000) Top1_base: 82.0312 (79.5668) Top1_base_per_class: 83.3626 (79.8202) 
Training Epoch: [132/1000] Step: [120 / 285] Batch Time: 0.1435 (0.1591) Data Time: 0.0125 (0.0262) Average Loss: 0.5856 (0.7211) Average CE Loss (Source):  0.5856 ( 0.7211) Learning Rate: 0.1000 (0.1000) Top1_base: 84.3750 (79.6159) Top1_base_per_class: 82.8788 (79.8482) 
Training Epoch: [132/1000] Step: [130 / 285] Batch Time: 0.1485 (0.1584) Data Time: 0.0173 (0.0255) Average Loss: 0.7236 (0.7172) Average CE Loss (Source):  0.7236 ( 0.7172) Learning Rate: 0.1000 (0.1000) Top1_base: 78.1250 (79.6094) Top1_base_per_class: 80.0412 (79.9146) 
Training Epoch: [132/1000] Step: [140 / 285] Batch Time: 0.1445 (0.1580) Data Time: 0.0108 (0.0251) Average Loss: 0.9385 (0.7250) Average CE Loss (Source):  0.9385 ( 0.7250) Learning Rate: 0.1000 (0.1000) Top1_base: 78.1250 (79.3806) Top1_base_per_class: 79.3396 (79.7236) 
Training Epoch: [132/1000] Step: [150 / 285] Batch Time: 0.2537 (0.1585) Data Time: 0.1222 (0.0257) Average Loss: 0.7056 (0.7275) Average CE Loss (Source):  0.7056 ( 0.7275) Learning Rate: 0.1000 (0.1000) Top1_base: 81.2500 (79.3750) Top1_base_per_class: 82.6554 (79.7727) 
Training Epoch: [132/1000] Step: [160 / 285] Batch Time: 0.1441 (0.1586) Data Time: 0.0125 (0.0258) Average Loss: 0.5784 (0.7252) Average CE Loss (Source):  0.5784 ( 0.7252) Learning Rate: 0.1000 (0.1000) Top1_base: 84.3750 (79.4678) Top1_base_per_class: 83.1212 (79.8098) 
Training Epoch: [132/1000] Step: [170 / 285] Batch Time: 0.1663 (0.1586) Data Time: 0.0321 (0.0259) Average Loss: 0.7946 (0.7283) Average CE Loss (Source):  0.7946 ( 0.7283) Learning Rate: 0.1000 (0.1000) Top1_base: 75.7812 (79.3336) Top1_base_per_class: 72.3684 (79.7036) 
Training Epoch: [132/1000] Step: [180 / 285] Batch Time: 0.1433 (0.1583) Data Time: 0.0102 (0.0256) Average Loss: 0.7217 (0.7310) Average CE Loss (Source):  0.7217 ( 0.7310) Learning Rate: 0.1000 (0.1000) Top1_base: 77.3438 (79.2405) Top1_base_per_class: 79.2398 (79.6110) 
Training Epoch: [132/1000] Step: [190 / 285] Batch Time: 0.1556 (0.1578) Data Time: 0.0243 (0.0251) Average Loss: 0.8122 (0.7345) Average CE Loss (Source):  0.8122 ( 0.7345) Learning Rate: 0.1000 (0.1000) Top1_base: 77.3438 (79.1283) Top1_base_per_class: 78.7202 (79.4811) 
Training Epoch: [132/1000] Step: [200 / 285] Batch Time: 0.1457 (0.1578) Data Time: 0.0129 (0.0251) Average Loss: 0.8110 (0.7360) Average CE Loss (Source):  0.8110 ( 0.7360) Learning Rate: 0.1000 (0.1000) Top1_base: 77.3438 (79.1055) Top1_base_per_class: 79.4474 (79.4842) 
Training Epoch: [132/1000] Step: [210 / 285] Batch Time: 0.2018 (0.1583) Data Time: 0.0675 (0.0256) Average Loss: 0.8615 (0.7420) Average CE Loss (Source):  0.8615 ( 0.7420) Learning Rate: 0.1000 (0.1000) Top1_base: 73.4375 (78.8876) Top1_base_per_class: 74.0000 (79.2454) 
Training Epoch: [132/1000] Step: [220 / 285] Batch Time: 0.1433 (0.1577) Data Time: 0.0116 (0.0251) Average Loss: 0.7630 (0.7430) Average CE Loss (Source):  0.7630 ( 0.7430) Learning Rate: 0.1000 (0.1000) Top1_base: 78.1250 (78.8920) Top1_base_per_class: 78.7346 (79.1925) 
Training Epoch: [132/1000] Step: [230 / 285] Batch Time: 0.1621 (0.1573) Data Time: 0.0284 (0.0246) Average Loss: 0.8861 (0.7434) Average CE Loss (Source):  0.8861 ( 0.7434) Learning Rate: 0.1000 (0.1000) Top1_base: 75.7812 (78.8485) Top1_base_per_class: 75.9259 (79.1496) 
Training Epoch: [132/1000] Step: [240 / 285] Batch Time: 0.1467 (0.1573) Data Time: 0.0107 (0.0245) Average Loss: 0.6885 (0.7414) Average CE Loss (Source):  0.6885 ( 0.7414) Learning Rate: 0.1000 (0.1000) Top1_base: 77.3438 (78.8867) Top1_base_per_class: 74.5614 (79.1961) 
Training Epoch: [132/1000] Step: [250 / 285] Batch Time: 0.1498 (0.1573) Data Time: 0.0161 (0.0244) Average Loss: 0.9278 (0.7438) Average CE Loss (Source):  0.9278 ( 0.7438) Learning Rate: 0.1000 (0.1000) Top1_base: 75.0000 (78.8281) Top1_base_per_class: 83.2185 (79.1780) 
Training Epoch: [132/1000] Step: [260 / 285] Batch Time: 0.1486 (0.1570) Data Time: 0.0116 (0.0241) Average Loss: 0.7038 (0.7472) Average CE Loss (Source):  0.7038 ( 0.7472) Learning Rate: 0.1000 (0.1000) Top1_base: 81.2500 (78.7470) Top1_base_per_class: 82.9023 (79.1797) 
Training Epoch: [132/1000] Step: [270 / 285] Batch Time: 0.1470 (0.1566) Data Time: 0.0154 (0.0237) Average Loss: 0.7756 (0.7471) Average CE Loss (Source):  0.7756 ( 0.7471) Learning Rate: 0.1000 (0.1000) Top1_base: 75.7812 (78.7297) Top1_base_per_class: 73.5494 (79.1481) 
Training Epoch: [132/1000] Step: [280 / 285] Batch Time: 0.1434 (0.1562) Data Time: 0.0128 (0.0233) Average Loss: 0.6772 (0.7496) Average CE Loss (Source):  0.6772 ( 0.7496) Learning Rate: 0.1000 (0.1000) Top1_base: 82.8125 (78.7081) Top1_base_per_class: 85.2299 (79.1353) 
Training Epoch: [133/1000] Step: [0] Batch Time: 0.1412 (0.1559) Data Time: 0.0107 (0.0231) Average Loss: 0.8807 (0.7512) Average CE Loss (Source):  0.8807 ( 0.7512) Learning Rate: 0.1000 (0.1000) Top1_base: 78.9062 (78.6623) Top1_base_per_class: 79.2241 (79.0848) 
Training Epoch: [133/1000] Step: [10 / 285] Batch Time: 0.2395 (0.2384) Data Time: 0.1080 (0.1066) Average Loss: 0.6594 (0.7348) Average CE Loss (Source):  0.6594 ( 0.7348) Learning Rate: 0.1000 (0.1000) Top1_base: 82.8125 (80.3125) Top1_base_per_class: 83.0065 (80.0285) 
Training Epoch: [133/1000] Step: [20 / 285] Batch Time: 0.1407 (0.1931) Data Time: 0.0109 (0.0614) Average Loss: 0.5652 (0.7059) Average CE Loss (Source):  0.5652 ( 0.7059) Learning Rate: 0.1000 (0.1000) Top1_base: 81.2500 (80.8594) Top1_base_per_class: 83.4277 (81.5283) 
Training Epoch: [133/1000] Step: [30 / 285] Batch Time: 0.1469 (0.1827) Data Time: 0.0141 (0.0505) Average Loss: 0.6536 (0.6962) Average CE Loss (Source):  0.6536 ( 0.6962) Learning Rate: 0.1000 (0.1000) Top1_base: 83.5938 (81.0417) Top1_base_per_class: 84.9107 (81.5504) 
Training Epoch: [133/1000] Step: [40 / 285] Batch Time: 0.1420 (0.1734) Data Time: 0.0115 (0.0411) Average Loss: 0.6835 (0.7042) Average CE Loss (Source):  0.6835 ( 0.7042) Learning Rate: 0.1000 (0.1000) Top1_base: 80.4688 (80.5664) Top1_base_per_class: 82.2727 (81.0464) 
Training Epoch: [133/1000] Step: [50 / 285] Batch Time: 0.1438 (0.1691) Data Time: 0.0124 (0.0370) Average Loss: 0.6529 (0.7080) Average CE Loss (Source):  0.6529 ( 0.7080) Learning Rate: 0.1000 (0.1000) Top1_base: 83.5938 (80.4219) Top1_base_per_class: 83.9957 (80.9939) 
Training Epoch: [133/1000] Step: [60 / 285] Batch Time: 0.1479 (0.1661) Data Time: 0.0133 (0.0338) Average Loss: 0.5814 (0.7130) Average CE Loss (Source):  0.5814 ( 0.7130) Learning Rate: 0.1000 (0.1000) Top1_base: 84.3750 (80.3646) Top1_base_per_class: 85.2299 (80.9032) 
Training Epoch: [133/1000] Step: [70 / 285] Batch Time: 0.1441 (0.1645) Data Time: 0.0129 (0.0321) Average Loss: 0.6754 (0.7093) Average CE Loss (Source):  0.6754 ( 0.7093) Learning Rate: 0.1000 (0.1000) Top1_base: 79.6875 (80.4799) Top1_base_per_class: 80.8036 (81.0797) 
Training Epoch: [133/1000] Step: [80 / 285] Batch Time: 0.1486 (0.1632) Data Time: 0.0145 (0.0308) Average Loss: 0.4571 (0.7060) Average CE Loss (Source):  0.4571 ( 0.7060) Learning Rate: 0.1000 (0.1000) Top1_base: 85.1562 (80.4980) Top1_base_per_class: 85.1235 (81.0636) 
Training Epoch: [133/1000] Step: [90 / 285] Batch Time: 0.1438 (0.1622) Data Time: 0.0108 (0.0298) Average Loss: 0.7200 (0.7078) Average CE Loss (Source):  0.7200 ( 0.7078) Learning Rate: 0.1000 (0.1000) Top1_base: 77.3438 (80.3819) Top1_base_per_class: 81.9136 (80.8231) 
Training Epoch: [133/1000] Step: [100 / 285] Batch Time: 0.1478 (0.1608) Data Time: 0.0140 (0.0281) Average Loss: 0.7347 (0.7059) Average CE Loss (Source):  0.7347 ( 0.7059) Learning Rate: 0.1000 (0.1000) Top1_base: 78.1250 (80.3672) Top1_base_per_class: 78.8580 (80.7788) 
Training Epoch: [133/1000] Step: [110 / 285] Batch Time: 0.1423 (0.1604) Data Time: 0.0105 (0.0277) Average Loss: 0.6963 (0.7096) Average CE Loss (Source):  0.6963 ( 0.7096) Learning Rate: 0.1000 (0.1000) Top1_base: 77.3438 (80.2770) Top1_base_per_class: 75.4146 (80.6351) 
Training Epoch: [133/1000] Step: [120 / 285] Batch Time: 0.1415 (0.1591) Data Time: 0.0114 (0.0264) Average Loss: 0.8277 (0.7200) Average CE Loss (Source):  0.8277 ( 0.7200) Learning Rate: 0.1000 (0.1000) Top1_base: 75.7812 (80.0260) Top1_base_per_class: 78.0189 (80.3596) 
Training Epoch: [133/1000] Step: [130 / 285] Batch Time: 0.1544 (0.1582) Data Time: 0.0226 (0.0255) Average Loss: 0.7442 (0.7253) Average CE Loss (Source):  0.7442 ( 0.7253) Learning Rate: 0.1000 (0.1000) Top1_base: 76.5625 (79.7656) Top1_base_per_class: 77.0115 (80.1425) 
Training Epoch: [133/1000] Step: [140 / 285] Batch Time: 0.1490 (0.1579) Data Time: 0.0135 (0.0253) Average Loss: 0.7464 (0.7266) Average CE Loss (Source):  0.7464 ( 0.7266) Learning Rate: 0.1000 (0.1000) Top1_base: 80.4688 (79.6763) Top1_base_per_class: 80.3889 (80.0249) 
Training Epoch: [133/1000] Step: [150 / 285] Batch Time: 0.1571 (0.1579) Data Time: 0.0228 (0.0252) Average Loss: 0.9362 (0.7287) Average CE Loss (Source):  0.9362 ( 0.7287) Learning Rate: 0.1000 (0.1000) Top1_base: 75.7812 (79.6510) Top1_base_per_class: 75.6863 (79.9563) 
Training Epoch: [133/1000] Step: [160 / 285] Batch Time: 0.1445 (0.1576) Data Time: 0.0123 (0.0250) Average Loss: 0.6127 (0.7295) Average CE Loss (Source):  0.6127 ( 0.7295) Learning Rate: 0.1000 (0.1000) Top1_base: 85.9375 (79.6289) Top1_base_per_class: 85.5454 (79.8625) 
Training Epoch: [133/1000] Step: [170 / 285] Batch Time: 0.1541 (0.1571) Data Time: 0.0235 (0.0245) Average Loss: 0.9800 (0.7329) Average CE Loss (Source):  0.9800 ( 0.7329) Learning Rate: 0.1000 (0.1000) Top1_base: 74.2188 (79.5267) Top1_base_per_class: 73.1762 (79.7411) 
Training Epoch: [133/1000] Step: [180 / 285] Batch Time: 0.1425 (0.1569) Data Time: 0.0114 (0.0243) Average Loss: 0.9156 (0.7348) Average CE Loss (Source):  0.9156 ( 0.7348) Learning Rate: 0.1000 (0.1000) Top1_base: 75.7812 (79.5269) Top1_base_per_class: 77.8736 (79.7708) 
Training Epoch: [133/1000] Step: [190 / 285] Batch Time: 0.1456 (0.1566) Data Time: 0.0141 (0.0240) Average Loss: 0.9056 (0.7384) Average CE Loss (Source):  0.9056 ( 0.7384) Learning Rate: 0.1000 (0.1000) Top1_base: 74.2188 (79.4367) Top1_base_per_class: 74.8148 (79.7036) 
Training Epoch: [133/1000] Step: [200 / 285] Batch Time: 0.1431 (0.1566) Data Time: 0.0112 (0.0239) Average Loss: 0.6487 (0.7362) Average CE Loss (Source):  0.6487 ( 0.7362) Learning Rate: 0.1000 (0.1000) Top1_base: 82.0312 (79.4766) Top1_base_per_class: 82.5220 (79.7437) 
Training Epoch: [133/1000] Step: [210 / 285] Batch Time: 0.1598 (0.1563) Data Time: 0.0287 (0.0237) Average Loss: 0.6354 (0.7357) Average CE Loss (Source):  0.6354 ( 0.7357) Learning Rate: 0.1000 (0.1000) Top1_base: 82.0312 (79.5201) Top1_base_per_class: 83.8182 (79.7952) 
Training Epoch: [133/1000] Step: [220 / 285] Batch Time: 0.1441 (0.1560) Data Time: 0.0126 (0.0233) Average Loss: 0.8079 (0.7359) Average CE Loss (Source):  0.8079 ( 0.7359) Learning Rate: 0.1000 (0.1000) Top1_base: 76.5625 (79.4709) Top1_base_per_class: 77.5298 (79.7777) 
Training Epoch: [133/1000] Step: [230 / 285] Batch Time: 0.1719 (0.1557) Data Time: 0.0401 (0.0231) Average Loss: 0.8972 (0.7408) Average CE Loss (Source):  0.8972 ( 0.7408) Learning Rate: 0.1000 (0.1000) Top1_base: 77.3438 (79.4090) Top1_base_per_class: 73.2562 (79.7233) 
Training Epoch: [133/1000] Step: [240 / 285] Batch Time: 0.1425 (0.1555) Data Time: 0.0111 (0.0229) Average Loss: 0.7360 (0.7412) Average CE Loss (Source):  0.7360 ( 0.7412) Learning Rate: 0.1000 (0.1000) Top1_base: 75.7812 (79.3945) Top1_base_per_class: 78.1897 (79.7124) 
Training Epoch: [133/1000] Step: [250 / 285] Batch Time: 0.1542 (0.1553) Data Time: 0.0227 (0.0227) Average Loss: 0.8037 (0.7416) Average CE Loss (Source):  0.8037 ( 0.7416) Learning Rate: 0.1000 (0.1000) Top1_base: 77.3438 (79.3688) Top1_base_per_class: 81.3409 (79.7305) 
Training Epoch: [133/1000] Step: [260 / 285] Batch Time: 0.1481 (0.1550) Data Time: 0.0145 (0.0224) Average Loss: 0.7169 (0.7447) Average CE Loss (Source):  0.7169 ( 0.7447) Learning Rate: 0.1000 (0.1000) Top1_base: 78.1250 (79.2969) Top1_base_per_class: 77.4702 (79.6705) 
Training Epoch: [133/1000] Step: [270 / 285] Batch Time: 0.1476 (0.1549) Data Time: 0.0160 (0.0223) Average Loss: 0.7138 (0.7436) Average CE Loss (Source):  0.7138 ( 0.7436) Learning Rate: 0.1000 (0.1000) Top1_base: 81.2500 (79.3113) Top1_base_per_class: 83.1790 (79.7031) 
Training Epoch: [133/1000] Step: [280 / 285] Batch Time: 0.1455 (0.1548) Data Time: 0.0132 (0.0223) Average Loss: 0.8653 (0.7449) Average CE Loss (Source):  0.8653 ( 0.7449) Learning Rate: 0.1000 (0.1000) Top1_base: 77.3438 (79.2913) Top1_base_per_class: 79.9951 (79.7284) 
Training Epoch: [134/1000] Step: [0] Batch Time: 0.1418 (0.1547) Data Time: 0.0115 (0.0222) Average Loss: 0.7345 (0.7479) Average CE Loss (Source):  0.7345 ( 0.7479) Learning Rate: 0.1000 (0.1000) Top1_base: 78.9062 (79.2215) Top1_base_per_class: 77.2988 (79.6741) 
 13%|█▎        | 134/1000 [1:44:29<11:05:41, 46.12s/it] 14%|█▎        | 135/1000 [1:45:14<10:58:20, 45.67s/it]Training Epoch: [134/1000] Step: [10 / 285] Batch Time: 0.1460 (0.2215) Data Time: 0.0137 (0.0889) Average Loss: 0.6606 (0.7020) Average CE Loss (Source):  0.6606 ( 0.7020) Learning Rate: 0.1000 (0.1000) Top1_base: 81.2500 (80.6250) Top1_base_per_class: 82.3636 (81.3236) 
Training Epoch: [134/1000] Step: [20 / 285] Batch Time: 0.1427 (0.1945) Data Time: 0.0109 (0.0623) Average Loss: 0.6293 (0.7114) Average CE Loss (Source):  0.6293 ( 0.7114) Learning Rate: 0.1000 (0.1000) Top1_base: 82.0312 (80.5469) Top1_base_per_class: 83.0994 (81.0783) 
Training Epoch: [134/1000] Step: [30 / 285] Batch Time: 0.1454 (0.1796) Data Time: 0.0114 (0.0472) Average Loss: 0.5031 (0.7451) Average CE Loss (Source):  0.5031 ( 0.7451) Learning Rate: 0.1000 (0.1000) Top1_base: 87.5000 (79.1927) Top1_base_per_class: 88.0601 (79.5649) 
Training Epoch: [134/1000] Step: [40 / 285] Batch Time: 0.1448 (0.1729) Data Time: 0.0114 (0.0404) Average Loss: 0.5536 (0.7398) Average CE Loss (Source):  0.5536 ( 0.7398) Learning Rate: 0.1000 (0.1000) Top1_base: 82.0312 (79.3750) Top1_base_per_class: 85.9656 (79.8702) 
Training Epoch: [134/1000] Step: [50 / 285] Batch Time: 0.1449 (0.1703) Data Time: 0.0135 (0.0377) Average Loss: 0.6636 (0.7274) Average CE Loss (Source):  0.6636 ( 0.7274) Learning Rate: 0.1000 (0.1000) Top1_base: 78.9062 (79.6406) Top1_base_per_class: 78.2738 (80.1311) 
Training Epoch: [134/1000] Step: [60 / 285] Batch Time: 0.1487 (0.1668) Data Time: 0.0126 (0.0340) Average Loss: 0.7498 (0.7252) Average CE Loss (Source):  0.7498 ( 0.7252) Learning Rate: 0.1000 (0.1000) Top1_base: 80.4688 (79.6745) Top1_base_per_class: 78.9583 (79.9771) 
Training Epoch: [134/1000] Step: [70 / 285] Batch Time: 0.1763 (0.1662) Data Time: 0.0431 (0.0333) Average Loss: 0.8290 (0.7212) Average CE Loss (Source):  0.8290 ( 0.7212) Learning Rate: 0.1000 (0.1000) Top1_base: 76.5625 (79.8214) Top1_base_per_class: 78.2424 (80.1847) 
Training Epoch: [134/1000] Step: [80 / 285] Batch Time: 0.1510 (0.1649) Data Time: 0.0158 (0.0319) Average Loss: 0.7857 (0.7237) Average CE Loss (Source):  0.7857 ( 0.7237) Learning Rate: 0.1000 (0.1000) Top1_base: 78.9062 (79.8438) Top1_base_per_class: 80.0309 (80.1398) 
Training Epoch: [134/1000] Step: [90 / 285] Batch Time: 0.1453 (0.1632) Data Time: 0.0139 (0.0302) Average Loss: 0.7186 (0.7234) Average CE Loss (Source):  0.7186 ( 0.7234) Learning Rate: 0.1000 (0.1000) Top1_base: 80.4688 (79.9306) Top1_base_per_class: 83.4181 (80.2934) 
Training Epoch: [134/1000] Step: [100 / 285] Batch Time: 0.1477 (0.1630) Data Time: 0.0121 (0.0300) Average Loss: 0.9798 (0.7269) Average CE Loss (Source):  0.9798 ( 0.7269) Learning Rate: 0.1000 (0.1000) Top1_base: 68.7500 (79.6484) Top1_base_per_class: 71.0000 (80.0777) 
Training Epoch: [134/1000] Step: [110 / 285] Batch Time: 0.1536 (0.1623) Data Time: 0.0234 (0.0293) Average Loss: 0.7608 (0.7262) Average CE Loss (Source):  0.7608 ( 0.7262) Learning Rate: 0.1000 (0.1000) Top1_base: 78.9062 (79.6520) Top1_base_per_class: 79.3000 (80.0104) 
Training Epoch: [134/1000] Step: [120 / 285] Batch Time: 0.1427 (0.1622) Data Time: 0.0120 (0.0292) Average Loss: 0.8505 (0.7321) Average CE Loss (Source):  0.8505 ( 0.7321) Learning Rate: 0.1000 (0.1000) Top1_base: 77.3438 (79.5052) Top1_base_per_class: 77.7879 (79.8957) 
Training Epoch: [134/1000] Step: [130 / 285] Batch Time: 0.1597 (0.1616) Data Time: 0.0270 (0.0286) Average Loss: 0.6698 (0.7351) Average CE Loss (Source):  0.6698 ( 0.7351) Learning Rate: 0.1000 (0.1000) Top1_base: 80.4688 (79.5192) Top1_base_per_class: 80.2632 (79.9062) 
Training Epoch: [134/1000] Step: [140 / 285] Batch Time: 0.1431 (0.1604) Data Time: 0.0110 (0.0275) Average Loss: 0.6911 (0.7335) Average CE Loss (Source):  0.6911 ( 0.7335) Learning Rate: 0.1000 (0.1000) Top1_base: 82.0312 (79.4754) Top1_base_per_class: 80.6212 (79.8755) 
Training Epoch: [134/1000] Step: [150 / 285] Batch Time: 0.1648 (0.1599) Data Time: 0.0336 (0.0270) Average Loss: 0.8335 (0.7352) Average CE Loss (Source):  0.8335 ( 0.7352) Learning Rate: 0.1000 (0.1000) Top1_base: 77.3438 (79.4844) Top1_base_per_class: 77.3810 (79.8605) 
Training Epoch: [134/1000] Step: [160 / 285] Batch Time: 0.1419 (0.1591) Data Time: 0.0107 (0.0262) Average Loss: 0.7439 (0.7405) Average CE Loss (Source):  0.7439 ( 0.7405) Learning Rate: 0.1000 (0.1000) Top1_base: 78.9062 (79.3115) Top1_base_per_class: 76.8644 (79.6458) 
Training Epoch: [134/1000] Step: [170 / 285] Batch Time: 0.1897 (0.1587) Data Time: 0.0592 (0.0259) Average Loss: 0.7289 (0.7437) Average CE Loss (Source):  0.7289 ( 0.7437) Learning Rate: 0.1000 (0.1000) Top1_base: 81.2500 (79.2693) Top1_base_per_class: 78.6927 (79.6081) 
Training Epoch: [134/1000] Step: [180 / 285] Batch Time: 0.1474 (0.1584) Data Time: 0.0136 (0.0255) Average Loss: 0.8361 (0.7471) Average CE Loss (Source):  0.8361 ( 0.7471) Learning Rate: 0.1000 (0.1000) Top1_base: 76.5625 (79.1363) Top1_base_per_class: 80.8019 (79.5798) 
Training Epoch: [134/1000] Step: [190 / 285] Batch Time: 0.1515 (0.1584) Data Time: 0.0206 (0.0256) Average Loss: 1.0897 (0.7527) Average CE Loss (Source):  1.0897 ( 0.7527) Learning Rate: 0.1000 (0.1000) Top1_base: 71.8750 (78.9638) Top1_base_per_class: 71.6174 (79.4317) 
Training Epoch: [134/1000] Step: [200 / 285] Batch Time: 0.1442 (0.1580) Data Time: 0.0116 (0.0252) Average Loss: 0.9324 (0.7547) Average CE Loss (Source):  0.9324 ( 0.7547) Learning Rate: 0.1000 (0.1000) Top1_base: 71.8750 (78.8594) Top1_base_per_class: 73.1548 (79.2767) 
Training Epoch: [134/1000] Step: [210 / 285] Batch Time: 0.1630 (0.1575) Data Time: 0.0319 (0.0248) Average Loss: 0.7620 (0.7549) Average CE Loss (Source):  0.7620 ( 0.7549) Learning Rate: 0.1000 (0.1000) Top1_base: 82.0312 (78.8021) Top1_base_per_class: 81.4815 (79.2272) 
Training Epoch: [134/1000] Step: [220 / 285] Batch Time: 0.1464 (0.1577) Data Time: 0.0123 (0.0249) Average Loss: 0.9771 (0.7559) Average CE Loss (Source):  0.9771 ( 0.7559) Learning Rate: 0.1000 (0.1000) Top1_base: 72.6562 (78.8210) Top1_base_per_class: 73.9308 (79.2715) 
Training Epoch: [134/1000] Step: [230 / 285] Batch Time: 0.1482 (0.1575) Data Time: 0.0172 (0.0247) Average Loss: 0.7226 (0.7577) Average CE Loss (Source):  0.7226 ( 0.7577) Learning Rate: 0.1000 (0.1000) Top1_base: 81.2500 (78.7840) Top1_base_per_class: 81.2500 (79.2700) 
Training Epoch: [134/1000] Step: [240 / 285] Batch Time: 0.1466 (0.1571) Data Time: 0.0118 (0.0242) Average Loss: 0.7243 (0.7575) Average CE Loss (Source):  0.7243 ( 0.7575) Learning Rate: 0.1000 (0.1000) Top1_base: 76.5625 (78.7988) Top1_base_per_class: 75.8491 (79.3151) 
Training Epoch: [134/1000] Step: [250 / 285] Batch Time: 0.2278 (0.1572) Data Time: 0.0957 (0.0243) Average Loss: 0.6530 (0.7557) Average CE Loss (Source):  0.6530 ( 0.7557) Learning Rate: 0.1000 (0.1000) Top1_base: 81.2500 (78.8187) Top1_base_per_class: 79.5635 (79.3369) 
Training Epoch: [134/1000] Step: [260 / 285] Batch Time: 0.1466 (0.1569) Data Time: 0.0118 (0.0240) Average Loss: 0.7248 (0.7565) Average CE Loss (Source):  0.7248 ( 0.7565) Learning Rate: 0.1000 (0.1000) Top1_base: 82.0312 (78.7981) Top1_base_per_class: 82.9532 (79.3435) 
Training Epoch: [134/1000] Step: [270 / 285] Batch Time: 0.1464 (0.1569) Data Time: 0.0154 (0.0240) Average Loss: 0.7407 (0.7573) Average CE Loss (Source):  0.7407 ( 0.7573) Learning Rate: 0.1000 (0.1000) Top1_base: 82.0312 (78.7963) Top1_base_per_class: 81.4536 (79.3395) 
Training Epoch: [134/1000] Step: [280 / 285] Batch Time: 0.1436 (0.1565) Data Time: 0.0115 (0.0236) Average Loss: 0.7857 (0.7572) Average CE Loss (Source):  0.7857 ( 0.7572) Learning Rate: 0.1000 (0.1000) Top1_base: 78.9062 (78.8086) Top1_base_per_class: 78.0994 (79.3291) 
Training Epoch: [135/1000] Step: [0] Batch Time: 0.1400 (0.1563) Data Time: 0.0106 (0.0234) Average Loss: 0.7145 (0.7563) Average CE Loss (Source):  0.7145 ( 0.7563) Learning Rate: 0.1000 (0.1000) Top1_base: 81.2500 (78.8432) Top1_base_per_class: 81.4151 (79.3699) 
Training Epoch: [135/1000] Step: [10 / 285] Batch Time: 0.1417 (0.2416) Data Time: 0.0100 (0.1088) Average Loss: 0.7369 (0.7350) Average CE Loss (Source):  0.7369 ( 0.7350) Learning Rate: 0.1000 (0.1000) Top1_base: 79.6875 (79.4531) Top1_base_per_class: 79.7170 (80.1083) 
Training Epoch: [135/1000] Step: [20 / 285] Batch Time: 0.1455 (0.2016) Data Time: 0.0115 (0.0684) Average Loss: 0.7582 (0.7083) Average CE Loss (Source):  0.7582 ( 0.7083) Learning Rate: 0.1000 (0.1000) Top1_base: 81.2500 (79.9609) Top1_base_per_class: 80.8667 (81.1648) 
Training Epoch: [135/1000] Step: [30 / 285] Batch Time: 0.1465 (0.1844) Data Time: 0.0115 (0.0509) Average Loss: 0.7069 (0.7087) Average CE Loss (Source):  0.7069 ( 0.7087) Learning Rate: 0.1000 (0.1000) Top1_base: 78.1250 (79.6875) Top1_base_per_class: 82.6191 (80.5231) 
Training Epoch: [135/1000] Step: [40 / 285] Batch Time: 0.1450 (0.1759) Data Time: 0.0112 (0.0426) Average Loss: 0.6090 (0.7134) Average CE Loss (Source):  0.6090 ( 0.7134) Learning Rate: 0.1000 (0.1000) Top1_base: 82.8125 (79.7266) Top1_base_per_class: 81.8713 (80.5828) 
Training Epoch: [135/1000] Step: [50 / 285] Batch Time: 0.1440 (0.1710) Data Time: 0.0129 (0.0377) Average Loss: 0.6982 (0.7075) Average CE Loss (Source):  0.6982 ( 0.7075) Learning Rate: 0.1000 (0.1000) Top1_base: 78.1250 (79.9219) Top1_base_per_class: 80.4575 (80.9403) 
Training Epoch: [135/1000] Step: [60 / 285] Batch Time: 0.1487 (0.1678) Data Time: 0.0133 (0.0347) Average Loss: 0.6076 (0.7116) Average CE Loss (Source):  0.6076 ( 0.7116) Learning Rate: 0.1000 (0.1000) Top1_base: 83.5938 (79.8307) Top1_base_per_class: 84.1049 (80.5473) 
Training Epoch: [135/1000] Step: [70 / 285] Batch Time: 0.1425 (0.1657) Data Time: 0.0103 (0.0326) Average Loss: 0.8090 (0.7114) Average CE Loss (Source):  0.8090 ( 0.7114) Learning Rate: 0.1000 (0.1000) Top1_base: 77.3438 (79.8438) Top1_base_per_class: 77.7485 (80.5714) 
Training Epoch: [135/1000] Step: [80 / 285] Batch Time: 0.1456 (0.1660) Data Time: 0.0113 (0.0328) Average Loss: 0.6741 (0.7106) Average CE Loss (Source):  0.6741 ( 0.7106) Learning Rate: 0.1000 (0.1000) Top1_base: 80.4688 (79.7656) Top1_base_per_class: 79.0113 (80.5573) 
Training Epoch: [135/1000] Step: [90 / 285] Batch Time: 0.1454 (0.1649) Data Time: 0.0129 (0.0318) Average Loss: 0.9208 (0.7116) Average CE Loss (Source):  0.9208 ( 0.7116) Learning Rate: 0.1000 (0.1000) Top1_base: 75.7812 (79.7830) Top1_base_per_class: 78.5593 (80.5863) 
Training Epoch: [135/1000] Step: [100 / 285] Batch Time: 0.1453 (0.1642) Data Time: 0.0106 (0.0310) Average Loss: 0.7825 (0.7163) Average CE Loss (Source):  0.7825 ( 0.7163) Learning Rate: 0.1000 (0.1000) Top1_base: 74.2188 (79.7422) Top1_base_per_class: 73.8095 (80.4667) 
Training Epoch: [135/1000] Step: [110 / 285] Batch Time: 0.1454 (0.1631) Data Time: 0.0142 (0.0300) Average Loss: 0.8108 (0.7209) Average CE Loss (Source):  0.8108 ( 0.7209) Learning Rate: 0.1000 (0.1000) Top1_base: 74.2188 (79.6094) Top1_base_per_class: 76.8182 (80.3744) 
Training Epoch: [135/1000] Step: [120 / 285] Batch Time: 0.1428 (0.1627) Data Time: 0.0118 (0.0296) Average Loss: 0.6291 (0.7252) Average CE Loss (Source):  0.6291 ( 0.7252) Learning Rate: 0.1000 (0.1000) Top1_base: 83.5938 (79.5182) Top1_base_per_class: 83.6111 (80.3166) 
Training Epoch: [135/1000] Step: [130 / 285] Batch Time: 0.1455 (0.1621) Data Time: 0.0116 (0.0290) Average Loss: 0.8533 (0.7304) Average CE Loss (Source):  0.8533 ( 0.7304) Learning Rate: 0.1000 (0.1000) Top1_base: 75.7812 (79.4171) Top1_base_per_class: 80.1634 (80.2288) 
Training Epoch: [135/1000] Step: [140 / 285] Batch Time: 0.1476 (0.1625) Data Time: 0.0113 (0.0293) Average Loss: 0.9479 (0.7345) Average CE Loss (Source):  0.9479 ( 0.7345) Learning Rate: 0.1000 (0.1000) Top1_base: 74.2188 (79.2467) Top1_base_per_class: 79.1156 (80.1291) 
Training Epoch: [135/1000] Step: [150 / 285] Batch Time: 0.1428 (0.1622) Data Time: 0.0114 (0.0290) Average Loss: 0.6792 (0.7382) Average CE Loss (Source):  0.6792 ( 0.7382) Learning Rate: 0.1000 (0.1000) Top1_base: 80.4688 (79.1979) Top1_base_per_class: 78.7963 (80.0247) 
Training Epoch: [135/1000] Step: [160 / 285] Batch Time: 0.1444 (0.1621) Data Time: 0.0109 (0.0290) Average Loss: 0.6675 (0.7412) Average CE Loss (Source):  0.6675 ( 0.7412) Learning Rate: 0.1000 (0.1000) Top1_base: 81.2500 (79.1553) Top1_base_per_class: 75.8929 (79.9492) 
Training Epoch: [135/1000] Step: [170 / 285] Batch Time: 0.1471 (0.1619) Data Time: 0.0117 (0.0287) Average Loss: 0.6131 (0.7401) Average CE Loss (Source):  0.6131 ( 0.7401) Learning Rate: 0.1000 (0.1000) Top1_base: 79.6875 (79.1912) Top1_base_per_class: 77.0000 (79.8915) 
Training Epoch: [135/1000] Step: [180 / 285] Batch Time: 0.1468 (0.1613) Data Time: 0.0116 (0.0281) Average Loss: 0.7386 (0.7396) Average CE Loss (Source):  0.7386 ( 0.7396) Learning Rate: 0.1000 (0.1000) Top1_base: 82.0312 (79.2405) Top1_base_per_class: 82.7273 (79.8974) 
Training Epoch: [135/1000] Step: [190 / 285] Batch Time: 0.1458 (0.1607) Data Time: 0.0107 (0.0274) Average Loss: 0.5607 (0.7392) Average CE Loss (Source):  0.5607 ( 0.7392) Learning Rate: 0.1000 (0.1000) Top1_base: 84.3750 (79.2393) Top1_base_per_class: 84.4048 (79.8665) 
Training Epoch: [135/1000] Step: [200 / 285] Batch Time: 0.1427 (0.1605) Data Time: 0.0112 (0.0273) Average Loss: 0.7091 (0.7374) Average CE Loss (Source):  0.7091 ( 0.7374) Learning Rate: 0.1000 (0.1000) Top1_base: 80.4688 (79.2812) Top1_base_per_class: 81.1696 (79.8779) 
Training Epoch: [135/1000] Step: [210 / 285] Batch Time: 0.1440 (0.1601) Data Time: 0.0128 (0.0269) Average Loss: 0.6548 (0.7385) Average CE Loss (Source):  0.6548 ( 0.7385) Learning Rate: 0.1000 (0.1000) Top1_base: 79.6875 (79.2299) Top1_base_per_class: 78.8050 (79.8019) 
Training Epoch: [135/1000] Step: [220 / 285] Batch Time: 0.1447 (0.1596) Data Time: 0.0124 (0.0265) Average Loss: 0.6800 (0.7377) Average CE Loss (Source):  0.6800 ( 0.7377) Learning Rate: 0.1000 (0.1000) Top1_base: 82.0312 (79.2188) Top1_base_per_class: 83.2407 (79.7556) 
Training Epoch: [135/1000] Step: [230 / 285] Batch Time: 0.1493 (0.1592) Data Time: 0.0131 (0.0261) Average Loss: 0.9055 (0.7382) Average CE Loss (Source):  0.9055 ( 0.7382) Learning Rate: 0.1000 (0.1000) Top1_base: 72.6562 (79.1576) Top1_base_per_class: 73.1761 (79.7174) 
Training Epoch: [135/1000] Step: [240 / 285] Batch Time: 0.1416 (0.1591) Data Time: 0.0116 (0.0259) Average Loss: 0.6950 (0.7357) Average CE Loss (Source):  0.6950 ( 0.7357) Learning Rate: 0.1000 (0.1000) Top1_base: 75.0000 (79.2090) Top1_base_per_class: 71.4465 (79.7338) 
Training Epoch: [135/1000] Step: [250 / 285] Batch Time: 0.1495 (0.1588) Data Time: 0.0120 (0.0256) Average Loss: 0.6402 (0.7349) Average CE Loss (Source):  0.6402 ( 0.7349) Learning Rate: 0.1000 (0.1000) Top1_base: 82.0312 (79.2062) Top1_base_per_class: 81.2121 (79.7193) 
Training Epoch: [135/1000] Step: [260 / 285] Batch Time: 0.1421 (0.1583) Data Time: 0.0127 (0.0251) Average Loss: 0.9863 (0.7357) Average CE Loss (Source):  0.9863 ( 0.7357) Learning Rate: 0.1000 (0.1000) Top1_base: 78.1250 (79.2218) Top1_base_per_class: 79.3711 (79.7206) 
Training Epoch: [135/1000] Step: [270 / 285] Batch Time: 0.1493 (0.1579) Data Time: 0.0111 (0.0248) Average Loss: 0.7413 (0.7367) Average CE Loss (Source):  0.7413 ( 0.7367) Learning Rate: 0.1000 (0.1000) Top1_base: 77.3438 (79.1898) Top1_base_per_class: 72.6488 (79.6783) 
Training Epoch: [135/1000] Step: [280 / 285] Batch Time: 0.2529 (0.1579) Data Time: 0.1178 (0.0248) Average Loss: 0.7527 (0.7402) Average CE Loss (Source):  0.7527 ( 0.7402) Learning Rate: 0.1000 (0.1000) Top1_base: 79.6875 (79.1099) Top1_base_per_class: 77.2381 (79.6169) 
Training Epoch: [136/1000] Step: [0] Batch Time: 0.1460 (0.1578) Data Time: 0.0130 (0.0246) Average Loss: 0.7683 (0.7410) Average CE Loss (Source):  0.7683 ( 0.7410) Learning Rate: 0.1000 (0.1000) Top1_base: 75.7812 (79.0789) Top1_base_per_class: 79.2228 (79.5827) 
 14%|█▎        | 136/1000 [1:46:02<11:06:34, 46.29s/it] 14%|█▎        | 137/1000 [1:46:46<10:58:15, 45.77s/it]Training Epoch: [136/1000] Step: [10 / 285] Batch Time: 0.1433 (0.2274) Data Time: 0.0118 (0.0952) Average Loss: 0.6242 (0.6884) Average CE Loss (Source):  0.6242 ( 0.6884) Learning Rate: 0.1000 (0.1000) Top1_base: 81.2500 (80.4688) Top1_base_per_class: 82.6333 (81.1038) 
Training Epoch: [136/1000] Step: [20 / 285] Batch Time: 0.1535 (0.1939) Data Time: 0.0177 (0.0607) Average Loss: 0.4954 (0.6954) Average CE Loss (Source):  0.4954 ( 0.6954) Learning Rate: 0.1000 (0.1000) Top1_base: 84.3750 (80.7422) Top1_base_per_class: 84.2105 (81.5379) 
Training Epoch: [136/1000] Step: [30 / 285] Batch Time: 0.1493 (0.1817) Data Time: 0.0155 (0.0480) Average Loss: 0.7770 (0.7093) Average CE Loss (Source):  0.7770 ( 0.7093) Learning Rate: 0.1000 (0.1000) Top1_base: 77.3438 (80.6510) Top1_base_per_class: 77.8105 (81.1930) 
Training Epoch: [136/1000] Step: [40 / 285] Batch Time: 0.1476 (0.1776) Data Time: 0.0134 (0.0432) Average Loss: 0.5849 (0.7184) Average CE Loss (Source):  0.5849 ( 0.7184) Learning Rate: 0.1000 (0.1000) Top1_base: 79.6875 (80.0195) Top1_base_per_class: 78.9071 (80.1508) 
Training Epoch: [136/1000] Step: [50 / 285] Batch Time: 0.1443 (0.1737) Data Time: 0.0124 (0.0395) Average Loss: 0.6844 (0.7163) Average CE Loss (Source):  0.6844 ( 0.7163) Learning Rate: 0.1000 (0.1000) Top1_base: 79.6875 (80.1250) Top1_base_per_class: 83.1845 (80.1902) 
Training Epoch: [136/1000] Step: [60 / 285] Batch Time: 0.1477 (0.1699) Data Time: 0.0150 (0.0357) Average Loss: 0.8164 (0.7182) Average CE Loss (Source):  0.8164 ( 0.7182) Learning Rate: 0.1000 (0.1000) Top1_base: 74.2188 (79.9609) Top1_base_per_class: 75.8036 (79.8928) 
Training Epoch: [136/1000] Step: [70 / 285] Batch Time: 0.1455 (0.1667) Data Time: 0.0145 (0.0326) Average Loss: 0.8730 (0.7159) Average CE Loss (Source):  0.8730 ( 0.7159) Learning Rate: 0.1000 (0.1000) Top1_base: 77.3438 (79.9107) Top1_base_per_class: 74.8742 (79.8993) 
Training Epoch: [136/1000] Step: [80 / 285] Batch Time: 0.1436 (0.1641) Data Time: 0.0119 (0.0301) Average Loss: 0.9506 (0.7180) Average CE Loss (Source):  0.9506 ( 0.7180) Learning Rate: 0.1000 (0.1000) Top1_base: 73.4375 (79.8340) Top1_base_per_class: 75.3395 (79.9208) 
Training Epoch: [136/1000] Step: [90 / 285] Batch Time: 0.1450 (0.1633) Data Time: 0.0143 (0.0294) Average Loss: 0.6892 (0.7266) Average CE Loss (Source):  0.6892 ( 0.7266) Learning Rate: 0.1000 (0.1000) Top1_base: 79.6875 (79.6354) Top1_base_per_class: 80.1515 (79.8930) 
Training Epoch: [136/1000] Step: [100 / 285] Batch Time: 0.1478 (0.1628) Data Time: 0.0147 (0.0289) Average Loss: 0.5570 (0.7279) Average CE Loss (Source):  0.5570 ( 0.7279) Learning Rate: 0.1000 (0.1000) Top1_base: 85.1562 (79.5547) Top1_base_per_class: 84.5238 (79.7009) 
Training Epoch: [136/1000] Step: [110 / 285] Batch Time: 0.1449 (0.1626) Data Time: 0.0127 (0.0288) Average Loss: 0.8591 (0.7324) Average CE Loss (Source):  0.8591 ( 0.7324) Learning Rate: 0.1000 (0.1000) Top1_base: 76.5625 (79.4389) Top1_base_per_class: 78.3333 (79.6445) 
Training Epoch: [136/1000] Step: [120 / 285] Batch Time: 0.1461 (0.1619) Data Time: 0.0137 (0.0281) Average Loss: 0.5108 (0.7336) Average CE Loss (Source):  0.5108 ( 0.7336) Learning Rate: 0.1000 (0.1000) Top1_base: 83.5938 (79.5117) Top1_base_per_class: 83.3631 (79.7451) 
Training Epoch: [136/1000] Step: [130 / 285] Batch Time: 0.1467 (0.1613) Data Time: 0.0137 (0.0275) Average Loss: 0.9997 (0.7375) Average CE Loss (Source):  0.9997 ( 0.7375) Learning Rate: 0.1000 (0.1000) Top1_base: 75.0000 (79.3570) Top1_base_per_class: 75.7440 (79.5577) 
Training Epoch: [136/1000] Step: [140 / 285] Batch Time: 0.1460 (0.1605) Data Time: 0.0141 (0.0268) Average Loss: 0.8414 (0.7384) Average CE Loss (Source):  0.8414 ( 0.7384) Learning Rate: 0.1000 (0.1000) Top1_base: 74.2188 (79.3248) Top1_base_per_class: 78.0864 (79.6112) 
Training Epoch: [136/1000] Step: [150 / 285] Batch Time: 0.1452 (0.1598) Data Time: 0.0136 (0.0261) Average Loss: 0.7784 (0.7434) Average CE Loss (Source):  0.7784 ( 0.7434) Learning Rate: 0.1000 (0.1000) Top1_base: 75.7812 (79.2135) Top1_base_per_class: 78.6728 (79.5574) 
Training Epoch: [136/1000] Step: [160 / 285] Batch Time: 0.1453 (0.1593) Data Time: 0.0119 (0.0256) Average Loss: 0.8359 (0.7440) Average CE Loss (Source):  0.8359 ( 0.7440) Learning Rate: 0.1000 (0.1000) Top1_base: 75.7812 (79.1895) Top1_base_per_class: 75.7273 (79.4994) 
Training Epoch: [136/1000] Step: [170 / 285] Batch Time: 0.1490 (0.1588) Data Time: 0.0134 (0.0251) Average Loss: 0.8334 (0.7431) Average CE Loss (Source):  0.8334 ( 0.7431) Learning Rate: 0.1000 (0.1000) Top1_base: 77.3438 (79.1636) Top1_base_per_class: 75.2469 (79.4941) 
Training Epoch: [136/1000] Step: [180 / 285] Batch Time: 0.1452 (0.1586) Data Time: 0.0124 (0.0248) Average Loss: 0.6976 (0.7437) Average CE Loss (Source):  0.6976 ( 0.7437) Learning Rate: 0.1000 (0.1000) Top1_base: 81.2500 (79.1753) Top1_base_per_class: 82.2013 (79.5103) 
Training Epoch: [136/1000] Step: [190 / 285] Batch Time: 0.1479 (0.1591) Data Time: 0.0135 (0.0253) Average Loss: 0.6960 (0.7425) Average CE Loss (Source):  0.6960 ( 0.7425) Learning Rate: 0.1000 (0.1000) Top1_base: 82.0312 (79.2229) Top1_base_per_class: 82.6316 (79.5944) 
Training Epoch: [136/1000] Step: [200 / 285] Batch Time: 0.1467 (0.1587) Data Time: 0.0134 (0.0248) Average Loss: 0.6460 (0.7448) Average CE Loss (Source):  0.6460 ( 0.7448) Learning Rate: 0.1000 (0.1000) Top1_base: 85.9375 (79.1758) Top1_base_per_class: 86.6667 (79.6073) 
Training Epoch: [136/1000] Step: [210 / 285] Batch Time: 0.1475 (0.1583) Data Time: 0.0130 (0.0242) Average Loss: 1.0190 (0.7478) Average CE Loss (Source):  1.0190 ( 0.7478) Learning Rate: 0.1000 (0.1000) Top1_base: 71.8750 (79.1257) Top1_base_per_class: 74.1667 (79.5582) 
Training Epoch: [136/1000] Step: [220 / 285] Batch Time: 0.1456 (0.1578) Data Time: 0.0122 (0.0238) Average Loss: 0.7088 (0.7490) Average CE Loss (Source):  0.7088 ( 0.7490) Learning Rate: 0.1000 (0.1000) Top1_base: 82.8125 (79.1584) Top1_base_per_class: 82.9023 (79.6165) 
Training Epoch: [136/1000] Step: [230 / 285] Batch Time: 0.1483 (0.1574) Data Time: 0.0131 (0.0233) Average Loss: 0.6401 (0.7495) Average CE Loss (Source):  0.6401 ( 0.7495) Learning Rate: 0.1000 (0.1000) Top1_base: 78.9062 (79.0353) Top1_base_per_class: 78.0769 (79.4744) 
Training Epoch: [136/1000] Step: [240 / 285] Batch Time: 0.1495 (0.1570) Data Time: 0.0159 (0.0230) Average Loss: 0.7450 (0.7497) Average CE Loss (Source):  0.7450 ( 0.7497) Learning Rate: 0.1000 (0.1000) Top1_base: 80.4688 (79.0072) Top1_base_per_class: 80.2976 (79.4266) 
Training Epoch: [136/1000] Step: [250 / 285] Batch Time: 0.1466 (0.1567) Data Time: 0.0116 (0.0226) Average Loss: 0.5493 (0.7495) Average CE Loss (Source):  0.5493 ( 0.7495) Learning Rate: 0.1000 (0.1000) Top1_base: 82.0312 (79.0031) Top1_base_per_class: 82.1069 (79.4189) 
Training Epoch: [136/1000] Step: [260 / 285] Batch Time: 0.1479 (0.1563) Data Time: 0.0167 (0.0223) Average Loss: 0.5327 (0.7510) Average CE Loss (Source):  0.5327 ( 0.7510) Learning Rate: 0.1000 (0.1000) Top1_base: 85.1562 (78.9874) Top1_base_per_class: 82.5298 (79.4101) 
Training Epoch: [136/1000] Step: [270 / 285] Batch Time: 0.1434 (0.1562) Data Time: 0.0122 (0.0222) Average Loss: 0.8826 (0.7509) Average CE Loss (Source):  0.8826 ( 0.7509) Learning Rate: 0.1000 (0.1000) Top1_base: 74.2188 (78.9207) Top1_base_per_class: 70.5152 (79.3355) 
Training Epoch: [136/1000] Step: [280 / 285] Batch Time: 0.1479 (0.1562) Data Time: 0.0144 (0.0222) Average Loss: 0.8886 (0.7529) Average CE Loss (Source):  0.8886 ( 0.7529) Learning Rate: 0.1000 (0.1000) Top1_base: 73.4375 (78.8477) Top1_base_per_class: 71.5009 (79.2402) 
Training Epoch: [137/1000] Step: [0] Batch Time: 0.1547 (0.1561) Data Time: 0.0184 (0.0221) Average Loss: 0.6429 (0.7540) Average CE Loss (Source):  0.6429 ( 0.7540) Learning Rate: 0.1000 (0.1000) Top1_base: 81.2500 (78.8158) Top1_base_per_class: 80.4945 (79.2163) 
Training Epoch: [137/1000] Step: [10 / 285] Batch Time: 0.1452 (0.2350) Data Time: 0.0116 (0.1022) Average Loss: 0.6915 (0.7086) Average CE Loss (Source):  0.6915 ( 0.7086) Learning Rate: 0.1000 (0.1000) Top1_base: 82.8125 (80.0781) Top1_base_per_class: 86.6364 (80.4730) 
Training Epoch: [137/1000] Step: [20 / 285] Batch Time: 0.1466 (0.2034) Data Time: 0.0142 (0.0705) Average Loss: 0.6846 (0.7009) Average CE Loss (Source):  0.6846 ( 0.7009) Learning Rate: 0.1000 (0.1000) Top1_base: 82.0312 (80.4297) Top1_base_per_class: 81.7232 (81.2584) 
Training Epoch: [137/1000] Step: [30 / 285] Batch Time: 0.1421 (0.1897) Data Time: 0.0110 (0.0572) Average Loss: 0.6583 (0.7085) Average CE Loss (Source):  0.6583 ( 0.7085) Learning Rate: 0.1000 (0.1000) Top1_base: 76.5625 (80.3646) Top1_base_per_class: 78.6352 (81.2387) 
Training Epoch: [137/1000] Step: [40 / 285] Batch Time: 0.1468 (0.1787) Data Time: 0.0152 (0.0462) Average Loss: 0.7557 (0.7027) Average CE Loss (Source):  0.7557 ( 0.7027) Learning Rate: 0.1000 (0.1000) Top1_base: 76.5625 (80.1562) Top1_base_per_class: 76.1494 (80.9884) 
Training Epoch: [137/1000] Step: [50 / 285] Batch Time: 0.1415 (0.1734) Data Time: 0.0111 (0.0411) Average Loss: 0.7591 (0.7100) Average CE Loss (Source):  0.7591 ( 0.7100) Learning Rate: 0.1000 (0.1000) Top1_base: 78.9062 (79.9844) Top1_base_per_class: 80.6450 (80.7945) 
Training Epoch: [137/1000] Step: [60 / 285] Batch Time: 0.1441 (0.1699) Data Time: 0.0114 (0.0377) Average Loss: 0.8015 (0.7201) Average CE Loss (Source):  0.8015 ( 0.7201) Learning Rate: 0.1000 (0.1000) Top1_base: 75.7812 (79.4792) Top1_base_per_class: 74.8889 (80.3149) 
Training Epoch: [137/1000] Step: [70 / 285] Batch Time: 0.1434 (0.1671) Data Time: 0.0130 (0.0349) Average Loss: 0.4789 (0.7161) Average CE Loss (Source):  0.4789 ( 0.7161) Learning Rate: 0.1000 (0.1000) Top1_base: 82.8125 (79.5536) Top1_base_per_class: 82.2424 (80.2313) 
Training Epoch: [137/1000] Step: [80 / 285] Batch Time: 0.1433 (0.1647) Data Time: 0.0110 (0.0326) Average Loss: 0.5882 (0.7124) Average CE Loss (Source):  0.5882 ( 0.7124) Learning Rate: 0.1000 (0.1000) Top1_base: 83.5938 (79.7070) Top1_base_per_class: 83.9286 (80.3732) 
Training Epoch: [137/1000] Step: [90 / 285] Batch Time: 0.1438 (0.1629) Data Time: 0.0131 (0.0309) Average Loss: 0.7895 (0.7110) Average CE Loss (Source):  0.7895 ( 0.7110) Learning Rate: 0.1000 (0.1000) Top1_base: 75.7812 (79.7569) Top1_base_per_class: 78.3046 (80.3903) 
Training Epoch: [137/1000] Step: [100 / 285] Batch Time: 0.1432 (0.1629) Data Time: 0.0117 (0.0310) Average Loss: 0.6619 (0.7185) Average CE Loss (Source):  0.6619 ( 0.7185) Learning Rate: 0.1000 (0.1000) Top1_base: 82.8125 (79.6094) Top1_base_per_class: 82.6023 (80.2546) 
Training Epoch: [137/1000] Step: [110 / 285] Batch Time: 0.1437 (0.1631) Data Time: 0.0100 (0.0312) Average Loss: 0.7369 (0.7216) Average CE Loss (Source):  0.7369 ( 0.7216) Learning Rate: 0.1000 (0.1000) Top1_base: 82.0312 (79.5952) Top1_base_per_class: 84.8512 (80.1799) 
Training Epoch: [137/1000] Step: [120 / 285] Batch Time: 0.1446 (0.1617) Data Time: 0.0112 (0.0297) Average Loss: 0.6333 (0.7263) Average CE Loss (Source):  0.6333 ( 0.7263) Learning Rate: 0.1000 (0.1000) Top1_base: 82.0312 (79.4531) Top1_base_per_class: 83.9511 (80.1665) 
Training Epoch: [137/1000] Step: [130 / 285] Batch Time: 0.1445 (0.1606) Data Time: 0.0105 (0.0286) Average Loss: 0.6670 (0.7290) Average CE Loss (Source):  0.6670 ( 0.7290) Learning Rate: 0.1000 (0.1000) Top1_base: 77.3438 (79.4231) Top1_base_per_class: 77.1515 (80.0845) 
Training Epoch: [137/1000] Step: [140 / 285] Batch Time: 0.1443 (0.1596) Data Time: 0.0139 (0.0275) Average Loss: 0.7889 (0.7237) Average CE Loss (Source):  0.7889 ( 0.7237) Learning Rate: 0.1000 (0.1000) Top1_base: 77.3438 (79.5647) Top1_base_per_class: 76.8868 (80.1678) 
Training Epoch: [137/1000] Step: [150 / 285] Batch Time: 0.1445 (0.1593) Data Time: 0.0107 (0.0272) Average Loss: 0.8298 (0.7234) Average CE Loss (Source):  0.8298 ( 0.7234) Learning Rate: 0.1000 (0.1000) Top1_base: 75.7812 (79.6406) Top1_base_per_class: 76.9492 (80.1792) 
Training Epoch: [137/1000] Step: [160 / 285] Batch Time: 0.1485 (0.1585) Data Time: 0.0150 (0.0264) Average Loss: 0.7076 (0.7265) Average CE Loss (Source):  0.7076 ( 0.7265) Learning Rate: 0.1000 (0.1000) Top1_base: 82.0312 (79.5312) Top1_base_per_class: 81.6092 (80.0114) 
Training Epoch: [137/1000] Step: [170 / 285] Batch Time: 0.1476 (0.1581) Data Time: 0.0120 (0.0259) Average Loss: 1.0493 (0.7271) Average CE Loss (Source):  1.0493 ( 0.7271) Learning Rate: 0.1000 (0.1000) Top1_base: 72.6562 (79.5037) Top1_base_per_class: 75.1572 (79.9941) 
Training Epoch: [137/1000] Step: [180 / 285] Batch Time: 0.1479 (0.1575) Data Time: 0.0138 (0.0252) Average Loss: 0.8000 (0.7306) Average CE Loss (Source):  0.8000 ( 0.7306) Learning Rate: 0.1000 (0.1000) Top1_base: 80.4688 (79.4314) Top1_base_per_class: 82.8947 (79.9018) 
Training Epoch: [137/1000] Step: [190 / 285] Batch Time: 0.1491 (0.1569) Data Time: 0.0120 (0.0245) Average Loss: 0.6265 (0.7319) Average CE Loss (Source):  0.6265 ( 0.7319) Learning Rate: 0.1000 (0.1000) Top1_base: 78.1250 (79.3873) Top1_base_per_class: 81.6964 (79.8186) 
Training Epoch: [137/1000] Step: [200 / 285] Batch Time: 0.1467 (0.1565) Data Time: 0.0136 (0.0240) Average Loss: 0.8014 (0.7303) Average CE Loss (Source):  0.8014 ( 0.7303) Learning Rate: 0.1000 (0.1000) Top1_base: 77.3438 (79.3828) Top1_base_per_class: 77.6667 (79.8382) 
Training Epoch: [137/1000] Step: [210 / 285] Batch Time: 0.1460 (0.1565) Data Time: 0.0102 (0.0238) Average Loss: 0.6463 (0.7294) Average CE Loss (Source):  0.6463 ( 0.7294) Learning Rate: 0.1000 (0.1000) Top1_base: 78.9062 (79.4122) Top1_base_per_class: 80.0265 (79.8793) 
Training Epoch: [137/1000] Step: [220 / 285] Batch Time: 0.1481 (0.1561) Data Time: 0.0144 (0.0233) Average Loss: 0.6775 (0.7331) Average CE Loss (Source):  0.6775 ( 0.7331) Learning Rate: 0.1000 (0.1000) Top1_base: 81.2500 (79.2898) Top1_base_per_class: 81.2264 (79.6764) 
Training Epoch: [137/1000] Step: [230 / 285] Batch Time: 0.1464 (0.1558) Data Time: 0.0103 (0.0230) Average Loss: 0.9731 (0.7335) Average CE Loss (Source):  0.9731 ( 0.7335) Learning Rate: 0.1000 (0.1000) Top1_base: 72.6562 (79.2731) Top1_base_per_class: 73.5920 (79.7073) 
Training Epoch: [137/1000] Step: [240 / 285] Batch Time: 0.1470 (0.1555) Data Time: 0.0136 (0.0226) Average Loss: 0.6737 (0.7368) Average CE Loss (Source):  0.6737 ( 0.7368) Learning Rate: 0.1000 (0.1000) Top1_base: 81.2500 (79.1927) Top1_base_per_class: 81.2821 (79.6138) 
Training Epoch: [137/1000] Step: [250 / 285] Batch Time: 0.1466 (0.1552) Data Time: 0.0102 (0.0222) Average Loss: 0.7894 (0.7371) Average CE Loss (Source):  0.7894 ( 0.7371) Learning Rate: 0.1000 (0.1000) Top1_base: 76.5625 (79.1937) Top1_base_per_class: 80.3509 (79.6054) 
Training Epoch: [137/1000] Step: [260 / 285] Batch Time: 0.1525 (0.1552) Data Time: 0.0155 (0.0221) Average Loss: 0.7166 (0.7403) Average CE Loss (Source):  0.7166 ( 0.7403) Learning Rate: 0.1000 (0.1000) Top1_base: 82.0312 (79.0956) Top1_base_per_class: 83.9506 (79.5141) 
Training Epoch: [137/1000] Step: [270 / 285] Batch Time: 0.1441 (0.1549) Data Time: 0.0102 (0.0217) Average Loss: 0.7866 (0.7418) Average CE Loss (Source):  0.7866 ( 0.7418) Learning Rate: 0.1000 (0.1000) Top1_base: 78.9062 (79.0885) Top1_base_per_class: 79.6855 (79.5394) 
Training Epoch: [137/1000] Step: [280 / 285] Batch Time: 0.1451 (0.1546) Data Time: 0.0119 (0.0214) Average Loss: 0.6486 (0.7445) Average CE Loss (Source):  0.6486 ( 0.7445) Learning Rate: 0.1000 (0.1000) Top1_base: 82.0312 (79.0402) Top1_base_per_class: 83.7273 (79.4723) 
Training Epoch: [138/1000] Step: [0] Batch Time: 0.1415 (0.1545) Data Time: 0.0126 (0.0214) Average Loss: 0.6741 (0.7459) Average CE Loss (Source):  0.6741 ( 0.7459) Learning Rate: 0.1000 (0.1000) Top1_base: 80.4688 (79.0104) Top1_base_per_class: 80.5975 (79.4602) 
 14%|█▍        | 138/1000 [1:47:33<11:02:26, 46.11s/it] 14%|█▍        | 139/1000 [1:48:17<10:53:07, 45.51s/it]Training Epoch: [138/1000] Step: [10 / 285] Batch Time: 0.1438 (0.2381) Data Time: 0.0104 (0.1034) Average Loss: 0.7760 (0.6838) Average CE Loss (Source):  0.7760 ( 0.6838) Learning Rate: 0.1000 (0.1000) Top1_base: 75.0000 (81.4844) Top1_base_per_class: 79.4444 (82.6920) 
Training Epoch: [138/1000] Step: [20 / 285] Batch Time: 0.1472 (0.1923) Data Time: 0.0128 (0.0585) Average Loss: 0.5408 (0.6883) Average CE Loss (Source):  0.5408 ( 0.6883) Learning Rate: 0.1000 (0.1000) Top1_base: 85.1562 (81.2109) Top1_base_per_class: 78.3626 (81.8461) 
Training Epoch: [138/1000] Step: [30 / 285] Batch Time: 0.1428 (0.1795) Data Time: 0.0123 (0.0461) Average Loss: 1.0135 (0.7218) Average CE Loss (Source):  1.0135 ( 0.7218) Learning Rate: 0.1000 (0.1000) Top1_base: 71.0938 (80.0000) Top1_base_per_class: 67.8333 (80.1121) 
Training Epoch: [138/1000] Step: [40 / 285] Batch Time: 0.1491 (0.1720) Data Time: 0.0162 (0.0388) Average Loss: 0.7065 (0.7061) Average CE Loss (Source):  0.7065 ( 0.7061) Learning Rate: 0.1000 (0.1000) Top1_base: 82.8125 (80.4688) Top1_base_per_class: 82.6608 (80.6146) 
Training Epoch: [138/1000] Step: [50 / 285] Batch Time: 0.1451 (0.1690) Data Time: 0.0138 (0.0359) Average Loss: 0.7722 (0.7085) Average CE Loss (Source):  0.7722 ( 0.7085) Learning Rate: 0.1000 (0.1000) Top1_base: 83.5938 (80.6250) Top1_base_per_class: 84.1379 (80.6592) 
Training Epoch: [138/1000] Step: [60 / 285] Batch Time: 0.1449 (0.1665) Data Time: 0.0136 (0.0335) Average Loss: 0.7069 (0.7091) Average CE Loss (Source):  0.7069 ( 0.7091) Learning Rate: 0.1000 (0.1000) Top1_base: 81.2500 (80.8333) Top1_base_per_class: 79.6364 (80.8727) 
Training Epoch: [138/1000] Step: [70 / 285] Batch Time: 0.1467 (0.1638) Data Time: 0.0153 (0.0308) Average Loss: 0.6914 (0.7160) Average CE Loss (Source):  0.6914 ( 0.7160) Learning Rate: 0.1000 (0.1000) Top1_base: 81.2500 (80.6585) Top1_base_per_class: 81.7857 (80.7128) 
Training Epoch: [138/1000] Step: [80 / 285] Batch Time: 0.1486 (0.1616) Data Time: 0.0143 (0.0287) Average Loss: 0.6358 (0.7104) Average CE Loss (Source):  0.6358 ( 0.7104) Learning Rate: 0.1000 (0.1000) Top1_base: 82.8125 (80.7715) Top1_base_per_class: 82.5617 (80.9161) 
Training Epoch: [138/1000] Step: [90 / 285] Batch Time: 0.1643 (0.1620) Data Time: 0.0342 (0.0293) Average Loss: 0.7744 (0.7122) Average CE Loss (Source):  0.7744 ( 0.7122) Learning Rate: 0.1000 (0.1000) Top1_base: 79.6875 (80.5903) Top1_base_per_class: 78.7963 (80.6878) 
Training Epoch: [138/1000] Step: [100 / 285] Batch Time: 0.1460 (0.1606) Data Time: 0.0124 (0.0279) Average Loss: 0.5601 (0.7098) Average CE Loss (Source):  0.5601 ( 0.7098) Learning Rate: 0.1000 (0.1000) Top1_base: 80.4688 (80.6172) Top1_base_per_class: 79.4737 (80.8461) 
Training Epoch: [138/1000] Step: [110 / 285] Batch Time: 0.1465 (0.1605) Data Time: 0.0144 (0.0277) Average Loss: 0.7124 (0.7062) Average CE Loss (Source):  0.7124 ( 0.7062) Learning Rate: 0.1000 (0.1000) Top1_base: 78.9062 (80.6108) Top1_base_per_class: 82.6608 (80.9706) 
Training Epoch: [138/1000] Step: [120 / 285] Batch Time: 0.1514 (0.1594) Data Time: 0.0128 (0.0265) Average Loss: 0.9251 (0.7081) Average CE Loss (Source):  0.9251 ( 0.7081) Learning Rate: 0.1000 (0.1000) Top1_base: 71.8750 (80.4883) Top1_base_per_class: 71.5054 (80.8529) 
Training Epoch: [138/1000] Step: [130 / 285] Batch Time: 0.1500 (0.1585) Data Time: 0.0171 (0.0255) Average Loss: 0.7417 (0.7154) Average CE Loss (Source):  0.7417 ( 0.7154) Learning Rate: 0.1000 (0.1000) Top1_base: 80.4688 (80.3546) Top1_base_per_class: 81.8750 (80.7327) 
Training Epoch: [138/1000] Step: [140 / 285] Batch Time: 0.1440 (0.1575) Data Time: 0.0112 (0.0246) Average Loss: 0.7697 (0.7158) Average CE Loss (Source):  0.7697 ( 0.7158) Learning Rate: 0.1000 (0.1000) Top1_base: 78.1250 (80.3683) Top1_base_per_class: 76.4744 (80.7105) 
Training Epoch: [138/1000] Step: [150 / 285] Batch Time: 0.1479 (0.1569) Data Time: 0.0152 (0.0239) Average Loss: 0.9345 (0.7218) Average CE Loss (Source):  0.9345 ( 0.7218) Learning Rate: 0.1000 (0.1000) Top1_base: 78.1250 (80.1406) Top1_base_per_class: 79.5751 (80.4051) 
Training Epoch: [138/1000] Step: [160 / 285] Batch Time: 0.1431 (0.1563) Data Time: 0.0117 (0.0232) Average Loss: 0.7803 (0.7180) Average CE Loss (Source):  0.7803 ( 0.7180) Learning Rate: 0.1000 (0.1000) Top1_base: 75.7812 (80.2832) Top1_base_per_class: 75.6173 (80.5208) 
Training Epoch: [138/1000] Step: [170 / 285] Batch Time: 0.1486 (0.1558) Data Time: 0.0152 (0.0227) Average Loss: 0.5640 (0.7194) Average CE Loss (Source):  0.5640 ( 0.7194) Learning Rate: 0.1000 (0.1000) Top1_base: 87.5000 (80.2711) Top1_base_per_class: 87.8758 (80.5247) 
Training Epoch: [138/1000] Step: [180 / 285] Batch Time: 0.1519 (0.1555) Data Time: 0.0137 (0.0222) Average Loss: 1.1164 (0.7232) Average CE Loss (Source):  1.1164 ( 0.7232) Learning Rate: 0.1000 (0.1000) Top1_base: 71.8750 (80.1259) Top1_base_per_class: 71.4703 (80.3747) 
Training Epoch: [138/1000] Step: [190 / 285] Batch Time: 0.1448 (0.1552) Data Time: 0.0128 (0.0218) Average Loss: 0.8239 (0.7238) Average CE Loss (Source):  0.8239 ( 0.7238) Learning Rate: 0.1000 (0.1000) Top1_base: 76.5625 (80.1069) Top1_base_per_class: 76.5205 (80.3458) 
Training Epoch: [138/1000] Step: [200 / 285] Batch Time: 0.1496 (0.1548) Data Time: 0.0121 (0.0213) Average Loss: 0.5820 (0.7268) Average CE Loss (Source):  0.5820 ( 0.7268) Learning Rate: 0.1000 (0.1000) Top1_base: 85.1562 (80.0703) Top1_base_per_class: 83.6552 (80.3433) 
Training Epoch: [138/1000] Step: [210 / 285] Batch Time: 0.1456 (0.1547) Data Time: 0.0124 (0.0211) Average Loss: 0.8312 (0.7272) Average CE Loss (Source):  0.8312 ( 0.7272) Learning Rate: 0.1000 (0.1000) Top1_base: 76.5625 (80.0446) Top1_base_per_class: 76.6970 (80.3476) 
Training Epoch: [138/1000] Step: [220 / 285] Batch Time: 0.1426 (0.1543) Data Time: 0.0113 (0.0208) Average Loss: 0.7404 (0.7302) Average CE Loss (Source):  0.7404 ( 0.7302) Learning Rate: 0.1000 (0.1000) Top1_base: 82.0312 (79.9822) Top1_base_per_class: 81.0692 (80.3154) 
Training Epoch: [138/1000] Step: [230 / 285] Batch Time: 0.1441 (0.1540) Data Time: 0.0123 (0.0205) Average Loss: 0.7038 (0.7304) Average CE Loss (Source):  0.7038 ( 0.7304) Learning Rate: 0.1000 (0.1000) Top1_base: 80.4688 (79.9626) Top1_base_per_class: 83.3333 (80.3273) 
Training Epoch: [138/1000] Step: [240 / 285] Batch Time: 0.1496 (0.1544) Data Time: 0.0119 (0.0209) Average Loss: 0.5583 (0.7333) Average CE Loss (Source):  0.5583 ( 0.7333) Learning Rate: 0.1000 (0.1000) Top1_base: 85.1562 (79.8633) Top1_base_per_class: 84.3567 (80.2491) 
Training Epoch: [138/1000] Step: [250 / 285] Batch Time: 0.1447 (0.1548) Data Time: 0.0106 (0.0212) Average Loss: 0.7734 (0.7337) Average CE Loss (Source):  0.7734 ( 0.7337) Learning Rate: 0.1000 (0.1000) Top1_base: 77.3438 (79.8156) Top1_base_per_class: 79.2341 (80.1851) 
Training Epoch: [138/1000] Step: [260 / 285] Batch Time: 0.1489 (0.1552) Data Time: 0.0134 (0.0215) Average Loss: 0.8699 (0.7344) Average CE Loss (Source):  0.8699 ( 0.7344) Learning Rate: 0.1000 (0.1000) Top1_base: 78.9062 (79.8047) Top1_base_per_class: 76.3636 (80.1080) 
Training Epoch: [138/1000] Step: [270 / 285] Batch Time: 0.1466 (0.1549) Data Time: 0.0127 (0.0213) Average Loss: 0.8453 (0.7346) Average CE Loss (Source):  0.8453 ( 0.7346) Learning Rate: 0.1000 (0.1000) Top1_base: 76.5625 (79.7888) Top1_base_per_class: 79.1358 (80.1134) 
Training Epoch: [138/1000] Step: [280 / 285] Batch Time: 0.1481 (0.1548) Data Time: 0.0132 (0.0211) Average Loss: 0.6953 (0.7357) Average CE Loss (Source):  0.6953 ( 0.7357) Learning Rate: 0.1000 (0.1000) Top1_base: 81.2500 (79.7377) Top1_base_per_class: 83.6257 (80.0775) 
Training Epoch: [139/1000] Step: [0] Batch Time: 0.1416 (0.1546) Data Time: 0.0104 (0.0209) Average Loss: 0.6547 (0.7377) Average CE Loss (Source):  0.6547 ( 0.7377) Learning Rate: 0.1000 (0.1000) Top1_base: 79.6875 (79.6930) Top1_base_per_class: 73.8304 (80.0378) 
Training Epoch: [139/1000] Step: [10 / 285] Batch Time: 0.1451 (0.2192) Data Time: 0.0133 (0.0862) Average Loss: 0.6476 (0.7113) Average CE Loss (Source):  0.6476 ( 0.7113) Learning Rate: 0.1000 (0.1000) Top1_base: 83.5938 (80.0781) Top1_base_per_class: 84.0774 (81.5782) 
Training Epoch: [139/1000] Step: [20 / 285] Batch Time: 0.1474 (0.1843) Data Time: 0.0121 (0.0514) Average Loss: 0.6078 (0.7056) Average CE Loss (Source):  0.6078 ( 0.7056) Learning Rate: 0.1000 (0.1000) Top1_base: 80.4688 (80.4688) Top1_base_per_class: 83.1667 (81.2677) 
Training Epoch: [139/1000] Step: [30 / 285] Batch Time: 0.1455 (0.1730) Data Time: 0.0137 (0.0400) Average Loss: 0.6328 (0.7052) Average CE Loss (Source):  0.6328 ( 0.7052) Learning Rate: 0.1000 (0.1000) Top1_base: 83.5938 (80.2865) Top1_base_per_class: 84.6667 (81.3527) 
Training Epoch: [139/1000] Step: [40 / 285] Batch Time: 0.1420 (0.1687) Data Time: 0.0119 (0.0361) Average Loss: 0.5872 (0.7055) Average CE Loss (Source):  0.5872 ( 0.7055) Learning Rate: 0.1000 (0.1000) Top1_base: 83.5938 (80.2539) Top1_base_per_class: 84.9394 (81.1700) 
Training Epoch: [139/1000] Step: [50 / 285] Batch Time: 0.1406 (0.1684) Data Time: 0.0102 (0.0360) Average Loss: 0.7195 (0.7247) Average CE Loss (Source):  0.7195 ( 0.7247) Learning Rate: 0.1000 (0.1000) Top1_base: 79.6875 (79.6406) Top1_base_per_class: 82.4074 (80.3948) 
Training Epoch: [139/1000] Step: [60 / 285] Batch Time: 0.1471 (0.1653) Data Time: 0.0136 (0.0329) Average Loss: 0.7831 (0.7273) Average CE Loss (Source):  0.7831 ( 0.7273) Learning Rate: 0.1000 (0.1000) Top1_base: 76.5625 (79.6094) Top1_base_per_class: 73.4795 (80.3738) 
Training Epoch: [139/1000] Step: [70 / 285] Batch Time: 0.1429 (0.1643) Data Time: 0.0106 (0.0319) Average Loss: 0.7283 (0.7220) Average CE Loss (Source):  0.7283 ( 0.7220) Learning Rate: 0.1000 (0.1000) Top1_base: 83.5938 (80.1004) Top1_base_per_class: 87.3030 (80.7031) 
Training Epoch: [139/1000] Step: [80 / 285] Batch Time: 0.1460 (0.1638) Data Time: 0.0116 (0.0313) Average Loss: 0.3543 (0.7220) Average CE Loss (Source):  0.3543 ( 0.7220) Learning Rate: 0.1000 (0.1000) Top1_base: 91.4062 (80.1465) Top1_base_per_class: 91.9492 (80.7581) 
Training Epoch: [139/1000] Step: [90 / 285] Batch Time: 0.1420 (0.1645) Data Time: 0.0102 (0.0320) Average Loss: 0.7303 (0.7180) Average CE Loss (Source):  0.7303 ( 0.7180) Learning Rate: 0.1000 (0.1000) Top1_base: 80.4688 (80.2604) Top1_base_per_class: 76.5497 (80.8406) 
Training Epoch: [139/1000] Step: [100 / 285] Batch Time: 0.1449 (0.1636) Data Time: 0.0121 (0.0312) Average Loss: 0.6808 (0.7154) Average CE Loss (Source):  0.6808 ( 0.7154) Learning Rate: 0.1000 (0.1000) Top1_base: 75.7812 (80.2422) Top1_base_per_class: 77.8655 (80.8213) 
Training Epoch: [139/1000] Step: [110 / 285] Batch Time: 0.1407 (0.1631) Data Time: 0.0105 (0.0307) Average Loss: 0.7652 (0.7161) Average CE Loss (Source):  0.7652 ( 0.7161) Learning Rate: 0.1000 (0.1000) Top1_base: 79.6875 (80.1634) Top1_base_per_class: 79.7531 (80.6847) 
Training Epoch: [139/1000] Step: [120 / 285] Batch Time: 0.1416 (0.1626) Data Time: 0.0111 (0.0303) Average Loss: 0.5473 (0.7127) Average CE Loss (Source):  0.5473 ( 0.7127) Learning Rate: 0.1000 (0.1000) Top1_base: 83.5938 (80.1953) Top1_base_per_class: 83.8889 (80.6932) 
Training Epoch: [139/1000] Step: [130 / 285] Batch Time: 0.1444 (0.1635) Data Time: 0.0116 (0.0311) Average Loss: 0.6551 (0.7109) Average CE Loss (Source):  0.6551 ( 0.7109) Learning Rate: 0.1000 (0.1000) Top1_base: 78.9062 (80.2043) Top1_base_per_class: 77.2126 (80.6982) 
Training Epoch: [139/1000] Step: [140 / 285] Batch Time: 0.1481 (0.1628) Data Time: 0.0136 (0.0305) Average Loss: 0.7692 (0.7130) Average CE Loss (Source):  0.7692 ( 0.7130) Learning Rate: 0.1000 (0.1000) Top1_base: 76.5625 (80.1562) Top1_base_per_class: 75.0909 (80.5909) 
Training Epoch: [139/1000] Step: [150 / 285] Batch Time: 0.1442 (0.1624) Data Time: 0.0123 (0.0300) Average Loss: 0.8053 (0.7160) Average CE Loss (Source):  0.8053 ( 0.7160) Learning Rate: 0.1000 (0.1000) Top1_base: 79.6875 (80.0208) Top1_base_per_class: 85.1690 (80.4973) 
Training Epoch: [139/1000] Step: [160 / 285] Batch Time: 0.1410 (0.1618) Data Time: 0.0107 (0.0295) Average Loss: 0.8400 (0.7170) Average CE Loss (Source):  0.8400 ( 0.7170) Learning Rate: 0.1000 (0.1000) Top1_base: 76.5625 (79.9316) Top1_base_per_class: 77.9654 (80.4100) 
Training Epoch: [139/1000] Step: [170 / 285] Batch Time: 0.1429 (0.1614) Data Time: 0.0112 (0.0291) Average Loss: 0.8502 (0.7198) Average CE Loss (Source):  0.8502 ( 0.7198) Learning Rate: 0.1000 (0.1000) Top1_base: 75.0000 (79.7978) Top1_base_per_class: 76.6667 (80.2723) 
Training Epoch: [139/1000] Step: [180 / 285] Batch Time: 0.1475 (0.1605) Data Time: 0.0124 (0.0282) Average Loss: 0.7355 (0.7236) Average CE Loss (Source):  0.7355 ( 0.7236) Learning Rate: 0.1000 (0.1000) Top1_base: 81.2500 (79.7439) Top1_base_per_class: 82.4830 (80.2263) 
Training Epoch: [139/1000] Step: [190 / 285] Batch Time: 0.1438 (0.1598) Data Time: 0.0116 (0.0275) Average Loss: 0.6906 (0.7258) Average CE Loss (Source):  0.6906 ( 0.7258) Learning Rate: 0.1000 (0.1000) Top1_base: 78.9062 (79.7574) Top1_base_per_class: 76.9345 (80.1883) 
Training Epoch: [139/1000] Step: [200 / 285] Batch Time: 0.1503 (0.1591) Data Time: 0.0136 (0.0267) Average Loss: 0.7986 (0.7277) Average CE Loss (Source):  0.7986 ( 0.7277) Learning Rate: 0.1000 (0.1000) Top1_base: 75.7812 (79.7031) Top1_base_per_class: 75.1818 (80.2112) 
Training Epoch: [139/1000] Step: [210 / 285] Batch Time: 0.1428 (0.1589) Data Time: 0.0117 (0.0265) Average Loss: 0.8804 (0.7296) Average CE Loss (Source):  0.8804 ( 0.7296) Learning Rate: 0.1000 (0.1000) Top1_base: 74.2188 (79.6168) Top1_base_per_class: 72.1333 (80.1067) 
Training Epoch: [139/1000] Step: [220 / 285] Batch Time: 0.1488 (0.1584) Data Time: 0.0140 (0.0259) Average Loss: 0.8190 (0.7323) Average CE Loss (Source):  0.8190 ( 0.7323) Learning Rate: 0.1000 (0.1000) Top1_base: 74.2188 (79.5455) Top1_base_per_class: 69.6429 (79.9536) 
Training Epoch: [139/1000] Step: [230 / 285] Batch Time: 0.1415 (0.1579) Data Time: 0.0104 (0.0255) Average Loss: 0.8229 (0.7325) Average CE Loss (Source):  0.8229 ( 0.7325) Learning Rate: 0.1000 (0.1000) Top1_base: 73.4375 (79.4803) Top1_base_per_class: 74.8299 (79.9294) 
Training Epoch: [139/1000] Step: [240 / 285] Batch Time: 0.1428 (0.1575) Data Time: 0.0126 (0.0251) Average Loss: 0.7273 (0.7357) Average CE Loss (Source):  0.7273 ( 0.7357) Learning Rate: 0.1000 (0.1000) Top1_base: 79.6875 (79.4271) Top1_base_per_class: 75.0862 (79.8585) 
Training Epoch: [139/1000] Step: [250 / 285] Batch Time: 0.1437 (0.1572) Data Time: 0.0116 (0.0248) Average Loss: 0.9419 (0.7389) Average CE Loss (Source):  0.9419 ( 0.7389) Learning Rate: 0.1000 (0.1000) Top1_base: 78.9062 (79.3000) Top1_base_per_class: 80.2727 (79.7001) 
Training Epoch: [139/1000] Step: [260 / 285] Batch Time: 0.1480 (0.1568) Data Time: 0.0141 (0.0244) Average Loss: 0.8449 (0.7387) Average CE Loss (Source):  0.8449 ( 0.7387) Learning Rate: 0.1000 (0.1000) Top1_base: 77.3438 (79.2939) Top1_base_per_class: 78.3041 (79.6452) 
Training Epoch: [139/1000] Step: [270 / 285] Batch Time: 0.1431 (0.1569) Data Time: 0.0112 (0.0245) Average Loss: 0.6679 (0.7401) Average CE Loss (Source):  0.6679 ( 0.7401) Learning Rate: 0.1000 (0.1000) Top1_base: 80.4688 (79.2535) Top1_base_per_class: 83.2738 (79.6200) 
Training Epoch: [139/1000] Step: [280 / 285] Batch Time: 0.1479 (0.1568) Data Time: 0.0125 (0.0244) Average Loss: 0.8324 (0.7402) Average CE Loss (Source):  0.8324 ( 0.7402) Learning Rate: 0.1000 (0.1000) Top1_base: 79.6875 (79.2467) Top1_base_per_class: 79.1975 (79.5824) 
Training Epoch: [140/1000] Step: [0] Batch Time: 0.1863 (0.1569) Data Time: 0.0566 (0.0245) Average Loss: 0.8392 (0.7412) Average CE Loss (Source):  0.8392 ( 0.7412) Learning Rate: 0.1000 (0.1000) Top1_base: 75.7812 (79.2105) Top1_base_per_class: 76.0606 (79.5685) 
 14%|█▍        | 140/1000 [1:49:05<11:01:00, 46.12s/it] 14%|█▍        | 141/1000 [1:49:49<10:53:22, 45.64s/it]Training Epoch: [140/1000] Step: [10 / 285] Batch Time: 0.1435 (0.2320) Data Time: 0.0108 (0.0997) Average Loss: 0.7119 (0.7135) Average CE Loss (Source):  0.7119 ( 0.7135) Learning Rate: 0.1000 (0.1000) Top1_base: 81.2500 (80.2344) Top1_base_per_class: 83.0791 (81.0183) 
Training Epoch: [140/1000] Step: [20 / 285] Batch Time: 0.1464 (0.1956) Data Time: 0.0129 (0.0633) Average Loss: 0.7637 (0.6962) Average CE Loss (Source):  0.7637 ( 0.6962) Learning Rate: 0.1000 (0.1000) Top1_base: 79.6875 (80.4297) Top1_base_per_class: 81.6379 (81.2143) 
Training Epoch: [140/1000] Step: [30 / 285] Batch Time: 0.1411 (0.1842) Data Time: 0.0106 (0.0523) Average Loss: 0.9980 (0.6899) Average CE Loss (Source):  0.9980 ( 0.6899) Learning Rate: 0.1000 (0.1000) Top1_base: 71.0938 (80.5729) Top1_base_per_class: 67.7778 (81.0157) 
Training Epoch: [140/1000] Step: [40 / 285] Batch Time: 0.1437 (0.1789) Data Time: 0.0117 (0.0467) Average Loss: 0.8278 (0.6950) Average CE Loss (Source):  0.8278 ( 0.6950) Learning Rate: 0.1000 (0.1000) Top1_base: 75.0000 (80.7031) Top1_base_per_class: 79.6684 (81.4127) 
Training Epoch: [140/1000] Step: [50 / 285] Batch Time: 0.1456 (0.1774) Data Time: 0.0142 (0.0451) Average Loss: 0.4505 (0.6848) Average CE Loss (Source):  0.4505 ( 0.6848) Learning Rate: 0.1000 (0.1000) Top1_base: 87.5000 (81.0000) Top1_base_per_class: 89.5278 (81.4949) 
Training Epoch: [140/1000] Step: [60 / 285] Batch Time: 0.1449 (0.1730) Data Time: 0.0109 (0.0408) Average Loss: 0.5822 (0.6928) Average CE Loss (Source):  0.5822 ( 0.6928) Learning Rate: 0.1000 (0.1000) Top1_base: 82.0312 (80.7552) Top1_base_per_class: 83.2058 (81.3633) 
Training Epoch: [140/1000] Step: [70 / 285] Batch Time: 0.1441 (0.1708) Data Time: 0.0124 (0.0386) Average Loss: 0.6989 (0.6938) Average CE Loss (Source):  0.6989 ( 0.6938) Learning Rate: 0.1000 (0.1000) Top1_base: 82.8125 (80.5915) Top1_base_per_class: 84.2816 (81.2458) 
Training Epoch: [140/1000] Step: [80 / 285] Batch Time: 0.1443 (0.1683) Data Time: 0.0112 (0.0361) Average Loss: 0.6112 (0.7007) Average CE Loss (Source):  0.6112 ( 0.7007) Learning Rate: 0.1000 (0.1000) Top1_base: 79.6875 (80.2734) Top1_base_per_class: 79.1975 (80.9164) 
Training Epoch: [140/1000] Step: [90 / 285] Batch Time: 0.1457 (0.1664) Data Time: 0.0120 (0.0342) Average Loss: 0.7010 (0.7003) Average CE Loss (Source):  0.7010 ( 0.7003) Learning Rate: 0.1000 (0.1000) Top1_base: 83.5938 (80.4340) Top1_base_per_class: 80.7310 (80.8808) 
Training Epoch: [140/1000] Step: [100 / 285] Batch Time: 0.1470 (0.1645) Data Time: 0.0128 (0.0322) Average Loss: 1.0098 (0.7045) Average CE Loss (Source):  1.0098 ( 0.7045) Learning Rate: 0.1000 (0.1000) Top1_base: 71.0938 (80.3516) Top1_base_per_class: 71.1207 (80.8207) 
Training Epoch: [140/1000] Step: [110 / 285] Batch Time: 0.1439 (0.1635) Data Time: 0.0112 (0.0311) Average Loss: 1.0214 (0.7101) Average CE Loss (Source):  1.0214 ( 0.7101) Learning Rate: 0.1000 (0.1000) Top1_base: 75.0000 (80.3196) Top1_base_per_class: 75.7738 (80.8483) 
Training Epoch: [140/1000] Step: [120 / 285] Batch Time: 0.1440 (0.1629) Data Time: 0.0111 (0.0306) Average Loss: 0.7165 (0.7105) Average CE Loss (Source):  0.7165 ( 0.7105) Learning Rate: 0.1000 (0.1000) Top1_base: 81.2500 (80.3971) Top1_base_per_class: 82.3148 (80.9301) 
Training Epoch: [140/1000] Step: [130 / 285] Batch Time: 0.1482 (0.1618) Data Time: 0.0143 (0.0292) Average Loss: 0.8266 (0.7118) Average CE Loss (Source):  0.8266 ( 0.7118) Learning Rate: 0.1000 (0.1000) Top1_base: 78.9062 (80.3486) Top1_base_per_class: 75.4546 (80.7868) 
Training Epoch: [140/1000] Step: [140 / 285] Batch Time: 0.1450 (0.1606) Data Time: 0.0116 (0.0280) Average Loss: 0.7207 (0.7102) Average CE Loss (Source):  0.7207 ( 0.7102) Learning Rate: 0.1000 (0.1000) Top1_base: 80.4688 (80.3460) Top1_base_per_class: 81.6358 (80.7272) 
Training Epoch: [140/1000] Step: [150 / 285] Batch Time: 0.1438 (0.1602) Data Time: 0.0120 (0.0277) Average Loss: 0.6757 (0.7173) Average CE Loss (Source):  0.6757 ( 0.7173) Learning Rate: 0.1000 (0.1000) Top1_base: 78.9062 (80.1198) Top1_base_per_class: 81.5152 (80.4511) 
Training Epoch: [140/1000] Step: [160 / 285] Batch Time: 0.1472 (0.1598) Data Time: 0.0125 (0.0272) Average Loss: 0.9949 (0.7198) Average CE Loss (Source):  0.9949 ( 0.7198) Learning Rate: 0.1000 (0.1000) Top1_base: 68.7500 (79.9658) Top1_base_per_class: 68.2471 (80.2791) 
Training Epoch: [140/1000] Step: [170 / 285] Batch Time: 0.1428 (0.1598) Data Time: 0.0109 (0.0271) Average Loss: 1.0086 (0.7245) Average CE Loss (Source):  1.0086 ( 0.7245) Learning Rate: 0.1000 (0.1000) Top1_base: 72.6562 (79.7978) Top1_base_per_class: 75.4678 (80.1396) 
Training Epoch: [140/1000] Step: [180 / 285] Batch Time: 0.1452 (0.1590) Data Time: 0.0112 (0.0264) Average Loss: 0.7499 (0.7246) Average CE Loss (Source):  0.7499 ( 0.7246) Learning Rate: 0.1000 (0.1000) Top1_base: 76.5625 (79.7700) Top1_base_per_class: 75.4409 (80.1005) 
Training Epoch: [140/1000] Step: [190 / 285] Batch Time: 0.1435 (0.1584) Data Time: 0.0109 (0.0258) Average Loss: 0.7860 (0.7251) Average CE Loss (Source):  0.7860 ( 0.7251) Learning Rate: 0.1000 (0.1000) Top1_base: 77.3438 (79.7574) Top1_base_per_class: 75.1111 (80.0352) 
Training Epoch: [140/1000] Step: [200 / 285] Batch Time: 0.1473 (0.1584) Data Time: 0.0128 (0.0257) Average Loss: 0.8974 (0.7269) Average CE Loss (Source):  0.8974 ( 0.7269) Learning Rate: 0.1000 (0.1000) Top1_base: 76.5625 (79.6680) Top1_base_per_class: 77.1930 (79.9233) 
Training Epoch: [140/1000] Step: [210 / 285] Batch Time: 0.1472 (0.1580) Data Time: 0.0123 (0.0252) Average Loss: 0.7150 (0.7291) Average CE Loss (Source):  0.7150 ( 0.7291) Learning Rate: 0.1000 (0.1000) Top1_base: 84.3750 (79.7098) Top1_base_per_class: 84.2816 (80.0273) 
Training Epoch: [140/1000] Step: [220 / 285] Batch Time: 0.1481 (0.1576) Data Time: 0.0141 (0.0247) Average Loss: 0.7834 (0.7316) Average CE Loss (Source):  0.7834 ( 0.7316) Learning Rate: 0.1000 (0.1000) Top1_base: 78.9062 (79.6555) Top1_base_per_class: 80.8025 (80.0410) 
Training Epoch: [140/1000] Step: [230 / 285] Batch Time: 0.1507 (0.1572) Data Time: 0.0161 (0.0243) Average Loss: 0.7083 (0.7341) Average CE Loss (Source):  0.7083 ( 0.7341) Learning Rate: 0.1000 (0.1000) Top1_base: 79.6875 (79.6162) Top1_base_per_class: 81.4972 (80.0515) 
Training Epoch: [140/1000] Step: [240 / 285] Batch Time: 0.1435 (0.1568) Data Time: 0.0106 (0.0239) Average Loss: 0.9937 (0.7376) Average CE Loss (Source):  0.9937 ( 0.7376) Learning Rate: 0.1000 (0.1000) Top1_base: 73.4375 (79.5247) Top1_base_per_class: 72.2956 (79.9556) 
Training Epoch: [140/1000] Step: [250 / 285] Batch Time: 0.1491 (0.1566) Data Time: 0.0143 (0.0236) Average Loss: 0.8883 (0.7385) Average CE Loss (Source):  0.8883 ( 0.7385) Learning Rate: 0.1000 (0.1000) Top1_base: 76.5625 (79.5219) Top1_base_per_class: 73.3459 (79.9129) 
Training Epoch: [140/1000] Step: [260 / 285] Batch Time: 0.1484 (0.1564) Data Time: 0.0132 (0.0233) Average Loss: 0.5938 (0.7408) Average CE Loss (Source):  0.5938 ( 0.7408) Learning Rate: 0.1000 (0.1000) Top1_base: 82.8125 (79.4531) Top1_base_per_class: 81.8016 (79.8259) 
Training Epoch: [140/1000] Step: [270 / 285] Batch Time: 0.1777 (0.1562) Data Time: 0.0465 (0.0232) Average Loss: 0.7883 (0.7421) Average CE Loss (Source):  0.7883 ( 0.7421) Learning Rate: 0.1000 (0.1000) Top1_base: 78.1250 (79.4068) Top1_base_per_class: 81.9185 (79.8083) 
Training Epoch: [140/1000] Step: [280 / 285] Batch Time: 0.1457 (0.1559) Data Time: 0.0120 (0.0228) Average Loss: 0.8170 (0.7441) Average CE Loss (Source):  0.8170 ( 0.7441) Learning Rate: 0.1000 (0.1000) Top1_base: 78.1250 (79.3694) Top1_base_per_class: 81.0916 (79.7608) 
Training Epoch: [141/1000] Step: [0] Batch Time: 0.1464 (0.1560) Data Time: 0.0116 (0.0229) Average Loss: 0.7190 (0.7455) Average CE Loss (Source):  0.7190 ( 0.7455) Learning Rate: 0.1000 (0.1000) Top1_base: 77.3438 (79.3010) Top1_base_per_class: 77.7879 (79.7201) 
Training Epoch: [141/1000] Step: [10 / 285] Batch Time: 0.1467 (0.2340) Data Time: 0.0145 (0.1017) Average Loss: 0.6858 (0.6910) Average CE Loss (Source):  0.6858 ( 0.6910) Learning Rate: 0.1000 (0.1000) Top1_base: 82.8125 (80.9375) Top1_base_per_class: 81.8954 (81.6051) 
Training Epoch: [141/1000] Step: [20 / 285] Batch Time: 0.1469 (0.1974) Data Time: 0.0132 (0.0653) Average Loss: 0.8330 (0.7071) Average CE Loss (Source):  0.8330 ( 0.7071) Learning Rate: 0.1000 (0.1000) Top1_base: 74.2188 (80.4297) Top1_base_per_class: 73.6842 (81.2246) 
Training Epoch: [141/1000] Step: [30 / 285] Batch Time: 0.1461 (0.1850) Data Time: 0.0147 (0.0529) Average Loss: 0.8641 (0.7154) Average CE Loss (Source):  0.8641 ( 0.7154) Learning Rate: 0.1000 (0.1000) Top1_base: 74.2188 (80.1302) Top1_base_per_class: 75.1572 (81.0583) 
Training Epoch: [141/1000] Step: [40 / 285] Batch Time: 0.1433 (0.1768) Data Time: 0.0129 (0.0447) Average Loss: 0.6840 (0.7107) Average CE Loss (Source):  0.6840 ( 0.7107) Learning Rate: 0.1000 (0.1000) Top1_base: 79.6875 (80.3711) Top1_base_per_class: 78.8782 (80.9240) 
Training Epoch: [141/1000] Step: [50 / 285] Batch Time: 0.1481 (0.1708) Data Time: 0.0168 (0.0387) Average Loss: 0.8234 (0.7123) Average CE Loss (Source):  0.8234 ( 0.7123) Learning Rate: 0.1000 (0.1000) Top1_base: 77.3438 (80.1250) Top1_base_per_class: 76.1111 (80.6235) 
Training Epoch: [141/1000] Step: [60 / 285] Batch Time: 0.1453 (0.1678) Data Time: 0.0131 (0.0357) Average Loss: 0.6474 (0.7164) Average CE Loss (Source):  0.6474 ( 0.7164) Learning Rate: 0.1000 (0.1000) Top1_base: 81.2500 (80.0391) Top1_base_per_class: 83.0460 (80.3996) 
Training Epoch: [141/1000] Step: [70 / 285] Batch Time: 0.1461 (0.1654) Data Time: 0.0133 (0.0334) Average Loss: 0.5232 (0.7238) Average CE Loss (Source):  0.5232 ( 0.7238) Learning Rate: 0.1000 (0.1000) Top1_base: 84.3750 (79.8438) Top1_base_per_class: 86.3743 (80.3482) 
Training Epoch: [141/1000] Step: [80 / 285] Batch Time: 0.1455 (0.1641) Data Time: 0.0133 (0.0321) Average Loss: 0.5853 (0.7284) Average CE Loss (Source):  0.5853 ( 0.7284) Learning Rate: 0.1000 (0.1000) Top1_base: 83.5938 (79.6973) Top1_base_per_class: 81.4815 (80.1184) 
Training Epoch: [141/1000] Step: [90 / 285] Batch Time: 0.1457 (0.1624) Data Time: 0.0133 (0.0305) Average Loss: 0.5655 (0.7282) Average CE Loss (Source):  0.5655 ( 0.7282) Learning Rate: 0.1000 (0.1000) Top1_base: 85.9375 (79.7396) Top1_base_per_class: 85.7184 (80.0704) 
Training Epoch: [141/1000] Step: [100 / 285] Batch Time: 0.1684 (0.1630) Data Time: 0.0384 (0.0311) Average Loss: 0.8046 (0.7276) Average CE Loss (Source):  0.8046 ( 0.7276) Learning Rate: 0.1000 (0.1000) Top1_base: 78.1250 (79.7578) Top1_base_per_class: 78.2424 (80.1306) 
Training Epoch: [141/1000] Step: [110 / 285] Batch Time: 0.1459 (0.1629) Data Time: 0.0121 (0.0308) Average Loss: 0.6257 (0.7289) Average CE Loss (Source):  0.6257 ( 0.7289) Learning Rate: 0.1000 (0.1000) Top1_base: 83.5938 (79.7301) Top1_base_per_class: 87.0755 (80.1454) 
Training Epoch: [141/1000] Step: [120 / 285] Batch Time: 0.3559 (0.1636) Data Time: 0.2256 (0.0316) Average Loss: 0.5596 (0.7264) Average CE Loss (Source):  0.5596 ( 0.7264) Learning Rate: 0.1000 (0.1000) Top1_base: 81.2500 (79.8047) Top1_base_per_class: 82.6061 (80.2498) 
Training Epoch: [141/1000] Step: [130 / 285] Batch Time: 0.1431 (0.1635) Data Time: 0.0101 (0.0315) Average Loss: 0.6510 (0.7276) Average CE Loss (Source):  0.6510 ( 0.7276) Learning Rate: 0.1000 (0.1000) Top1_base: 80.4688 (79.8017) Top1_base_per_class: 76.4546 (80.1429) 
Training Epoch: [141/1000] Step: [140 / 285] Batch Time: 0.1940 (0.1638) Data Time: 0.0600 (0.0317) Average Loss: 0.9547 (0.7324) Average CE Loss (Source):  0.9547 ( 0.7324) Learning Rate: 0.1000 (0.1000) Top1_base: 71.8750 (79.6708) Top1_base_per_class: 69.7947 (79.9533) 
Training Epoch: [141/1000] Step: [150 / 285] Batch Time: 0.1436 (0.1636) Data Time: 0.0130 (0.0315) Average Loss: 0.7199 (0.7311) Average CE Loss (Source):  0.7199 ( 0.7311) Learning Rate: 0.1000 (0.1000) Top1_base: 78.1250 (79.6198) Top1_base_per_class: 79.9843 (80.0364) 
Training Epoch: [141/1000] Step: [160 / 285] Batch Time: 0.2809 (0.1638) Data Time: 0.1483 (0.0318) Average Loss: 0.8135 (0.7365) Average CE Loss (Source):  0.8135 ( 0.7365) Learning Rate: 0.1000 (0.1000) Top1_base: 76.5625 (79.4678) Top1_base_per_class: 75.2244 (79.8403) 
Training Epoch: [141/1000] Step: [170 / 285] Batch Time: 0.1462 (0.1631) Data Time: 0.0110 (0.0310) Average Loss: 0.6776 (0.7388) Average CE Loss (Source):  0.6776 ( 0.7388) Learning Rate: 0.1000 (0.1000) Top1_base: 77.3438 (79.4347) Top1_base_per_class: 80.2516 (79.8199) 
Training Epoch: [141/1000] Step: [180 / 285] Batch Time: 0.1764 (0.1626) Data Time: 0.0387 (0.0303) Average Loss: 0.7323 (0.7397) Average CE Loss (Source):  0.7323 ( 0.7397) Learning Rate: 0.1000 (0.1000) Top1_base: 77.3438 (79.3229) Top1_base_per_class: 75.4802 (79.6895) 
Training Epoch: [141/1000] Step: [190 / 285] Batch Time: 0.1487 (0.1621) Data Time: 0.0131 (0.0297) Average Loss: 0.6756 (0.7390) Average CE Loss (Source):  0.6756 ( 0.7390) Learning Rate: 0.1000 (0.1000) Top1_base: 78.1250 (79.3339) Top1_base_per_class: 78.5714 (79.7225) 
Training Epoch: [141/1000] Step: [200 / 285] Batch Time: 0.1985 (0.1622) Data Time: 0.0654 (0.0297) Average Loss: 0.6128 (0.7399) Average CE Loss (Source):  0.6128 ( 0.7399) Learning Rate: 0.1000 (0.1000) Top1_base: 78.9062 (79.2617) Top1_base_per_class: 76.1494 (79.6655) 
Training Epoch: [141/1000] Step: [210 / 285] Batch Time: 0.1477 (0.1616) Data Time: 0.0123 (0.0291) Average Loss: 0.5737 (0.7385) Average CE Loss (Source):  0.5737 ( 0.7385) Learning Rate: 0.1000 (0.1000) Top1_base: 84.3750 (79.2746) Top1_base_per_class: 88.8988 (79.6966) 
Training Epoch: [141/1000] Step: [220 / 285] Batch Time: 0.2039 (0.1612) Data Time: 0.0686 (0.0287) Average Loss: 0.7373 (0.7391) Average CE Loss (Source):  0.7373 ( 0.7391) Learning Rate: 0.1000 (0.1000) Top1_base: 78.1250 (79.2827) Top1_base_per_class: 82.7836 (79.7809) 
Training Epoch: [141/1000] Step: [230 / 285] Batch Time: 0.1435 (0.1610) Data Time: 0.0107 (0.0285) Average Loss: 0.7327 (0.7382) Average CE Loss (Source):  0.7327 ( 0.7382) Learning Rate: 0.1000 (0.1000) Top1_base: 76.5625 (79.2595) Top1_base_per_class: 77.8736 (79.7771) 
Training Epoch: [141/1000] Step: [240 / 285] Batch Time: 0.1791 (0.1610) Data Time: 0.0462 (0.0286) Average Loss: 0.7842 (0.7402) Average CE Loss (Source):  0.7842 ( 0.7402) Learning Rate: 0.1000 (0.1000) Top1_base: 77.3438 (79.2155) Top1_base_per_class: 78.0509 (79.6855) 
Training Epoch: [141/1000] Step: [250 / 285] Batch Time: 0.1453 (0.1605) Data Time: 0.0123 (0.0280) Average Loss: 0.9102 (0.7399) Average CE Loss (Source):  0.9102 ( 0.7399) Learning Rate: 0.1000 (0.1000) Top1_base: 79.6875 (79.2219) Top1_base_per_class: 77.9944 (79.6740) 
Training Epoch: [141/1000] Step: [260 / 285] Batch Time: 0.1480 (0.1606) Data Time: 0.0161 (0.0281) Average Loss: 0.6657 (0.7407) Average CE Loss (Source):  0.6657 ( 0.7407) Learning Rate: 0.1000 (0.1000) Top1_base: 82.0312 (79.1617) Top1_base_per_class: 82.4107 (79.6277) 
Training Epoch: [141/1000] Step: [270 / 285] Batch Time: 0.1439 (0.1602) Data Time: 0.0140 (0.0277) Average Loss: 0.7177 (0.7415) Average CE Loss (Source):  0.7177 ( 0.7415) Learning Rate: 0.1000 (0.1000) Top1_base: 78.1250 (79.0943) Top1_base_per_class: 78.0564 (79.6134) 
Training Epoch: [141/1000] Step: [280 / 285] Batch Time: 0.3032 (0.1603) Data Time: 0.1720 (0.0278) Average Loss: 0.6698 (0.7417) Average CE Loss (Source):  0.6698 ( 0.7417) Learning Rate: 0.1000 (0.1000) Top1_base: 80.4688 (79.0458) Top1_base_per_class: 80.8333 (79.5427) 
Training Epoch: [142/1000] Step: [0] Batch Time: 0.1405 (0.1601) Data Time: 0.0118 (0.0275) Average Loss: 0.8632 (0.7430) Average CE Loss (Source):  0.8632 ( 0.7430) Learning Rate: 0.1000 (0.1000) Top1_base: 73.4375 (79.0515) Top1_base_per_class: 76.2865 (79.5297) 
 14%|█▍        | 142/1000 [1:50:38<11:04:23, 46.46s/it] 14%|█▍        | 143/1000 [1:51:22<10:53:59, 45.79s/it]Training Epoch: [142/1000] Step: [10 / 285] Batch Time: 0.1435 (0.2289) Data Time: 0.0127 (0.0973) Average Loss: 0.7787 (0.7150) Average CE Loss (Source):  0.7787 ( 0.7150) Learning Rate: 0.1000 (0.1000) Top1_base: 80.4688 (79.5312) Top1_base_per_class: 81.9697 (80.2248) 
Training Epoch: [142/1000] Step: [20 / 285] Batch Time: 0.1467 (0.1927) Data Time: 0.0133 (0.0608) Average Loss: 0.6120 (0.7044) Average CE Loss (Source):  0.6120 ( 0.7044) Learning Rate: 0.1000 (0.1000) Top1_base: 85.1562 (80.0781) Top1_base_per_class: 85.6364 (80.6214) 
Training Epoch: [142/1000] Step: [30 / 285] Batch Time: 0.1459 (0.1820) Data Time: 0.0129 (0.0500) Average Loss: 0.8459 (0.6841) Average CE Loss (Source):  0.8459 ( 0.6841) Learning Rate: 0.1000 (0.1000) Top1_base: 72.6562 (80.4427) Top1_base_per_class: 75.1488 (80.9361) 
Training Epoch: [142/1000] Step: [40 / 285] Batch Time: 0.1421 (0.1727) Data Time: 0.0111 (0.0406) Average Loss: 0.6314 (0.7003) Average CE Loss (Source):  0.6314 ( 0.7003) Learning Rate: 0.1000 (0.1000) Top1_base: 83.5938 (80.3906) Top1_base_per_class: 85.0000 (80.8463) 
Training Epoch: [142/1000] Step: [50 / 285] Batch Time: 0.1482 (0.1696) Data Time: 0.0154 (0.0374) Average Loss: 0.6997 (0.7070) Average CE Loss (Source):  0.6997 ( 0.7070) Learning Rate: 0.1000 (0.1000) Top1_base: 82.8125 (80.2812) Top1_base_per_class: 84.0303 (80.7648) 
Training Epoch: [142/1000] Step: [60 / 285] Batch Time: 0.1452 (0.1669) Data Time: 0.0117 (0.0347) Average Loss: 0.7620 (0.7107) Average CE Loss (Source):  0.7620 ( 0.7107) Learning Rate: 0.1000 (0.1000) Top1_base: 78.9062 (80.3516) Top1_base_per_class: 83.1845 (80.6745) 
Training Epoch: [142/1000] Step: [70 / 285] Batch Time: 0.1418 (0.1643) Data Time: 0.0121 (0.0323) Average Loss: 0.8933 (0.7175) Average CE Loss (Source):  0.8933 ( 0.7175) Learning Rate: 0.1000 (0.1000) Top1_base: 78.1250 (80.4129) Top1_base_per_class: 73.4329 (80.7197) 
Training Epoch: [142/1000] Step: [80 / 285] Batch Time: 0.1423 (0.1640) Data Time: 0.0108 (0.0320) Average Loss: 0.7630 (0.7152) Average CE Loss (Source):  0.7630 ( 0.7152) Learning Rate: 0.1000 (0.1000) Top1_base: 77.3438 (80.2344) Top1_base_per_class: 77.9167 (80.5785) 
Training Epoch: [142/1000] Step: [90 / 285] Batch Time: 0.1500 (0.1642) Data Time: 0.0156 (0.0321) Average Loss: 0.5946 (0.7106) Average CE Loss (Source):  0.5946 ( 0.7106) Learning Rate: 0.1000 (0.1000) Top1_base: 80.4688 (80.2691) Top1_base_per_class: 80.5556 (80.5838) 
Training Epoch: [142/1000] Step: [100 / 285] Batch Time: 0.1469 (0.1627) Data Time: 0.0117 (0.0305) Average Loss: 0.7044 (0.7121) Average CE Loss (Source):  0.7044 ( 0.7121) Learning Rate: 0.1000 (0.1000) Top1_base: 82.0312 (80.2422) Top1_base_per_class: 82.3810 (80.4958) 
Training Epoch: [142/1000] Step: [110 / 285] Batch Time: 0.1497 (0.1615) Data Time: 0.0145 (0.0289) Average Loss: 0.9017 (0.7136) Average CE Loss (Source):  0.9017 ( 0.7136) Learning Rate: 0.1000 (0.1000) Top1_base: 73.4375 (80.2273) Top1_base_per_class: 70.6918 (80.3954) 
Training Epoch: [142/1000] Step: [120 / 285] Batch Time: 0.1458 (0.1602) Data Time: 0.0130 (0.0276) Average Loss: 0.8085 (0.7179) Average CE Loss (Source):  0.8085 ( 0.7179) Learning Rate: 0.1000 (0.1000) Top1_base: 76.5625 (80.0586) Top1_base_per_class: 80.5357 (80.2790) 
Training Epoch: [142/1000] Step: [130 / 285] Batch Time: 0.1437 (0.1590) Data Time: 0.0130 (0.0264) Average Loss: 0.8868 (0.7190) Average CE Loss (Source):  0.8868 ( 0.7190) Learning Rate: 0.1000 (0.1000) Top1_base: 78.9062 (80.0721) Top1_base_per_class: 80.5411 (80.3691) 
Training Epoch: [142/1000] Step: [140 / 285] Batch Time: 0.1481 (0.1588) Data Time: 0.0107 (0.0262) Average Loss: 0.7732 (0.7220) Average CE Loss (Source):  0.7732 ( 0.7220) Learning Rate: 0.1000 (0.1000) Top1_base: 77.3438 (79.9609) Top1_base_per_class: 77.9240 (80.2445) 
Training Epoch: [142/1000] Step: [150 / 285] Batch Time: 0.1529 (0.1582) Data Time: 0.0135 (0.0253) Average Loss: 0.5826 (0.7241) Average CE Loss (Source):  0.5826 ( 0.7241) Learning Rate: 0.1000 (0.1000) Top1_base: 83.5938 (79.8438) Top1_base_per_class: 82.3670 (80.1880) 
Training Epoch: [142/1000] Step: [160 / 285] Batch Time: 0.1426 (0.1576) Data Time: 0.0104 (0.0246) Average Loss: 0.7316 (0.7288) Average CE Loss (Source):  0.7316 ( 0.7288) Learning Rate: 0.1000 (0.1000) Top1_base: 78.9062 (79.7266) Top1_base_per_class: 76.0577 (80.0719) 
Training Epoch: [142/1000] Step: [170 / 285] Batch Time: 0.1474 (0.1576) Data Time: 0.0133 (0.0245) Average Loss: 0.6098 (0.7304) Average CE Loss (Source):  0.6098 ( 0.7304) Learning Rate: 0.1000 (0.1000) Top1_base: 84.3750 (79.7426) Top1_base_per_class: 85.9615 (80.1021) 
Training Epoch: [142/1000] Step: [180 / 285] Batch Time: 0.1435 (0.1569) Data Time: 0.0105 (0.0239) Average Loss: 0.7233 (0.7278) Average CE Loss (Source):  0.7233 ( 0.7278) Learning Rate: 0.1000 (0.1000) Top1_base: 83.5938 (79.8003) Top1_base_per_class: 86.6667 (80.2098) 
Training Epoch: [142/1000] Step: [190 / 285] Batch Time: 0.1524 (0.1565) Data Time: 0.0159 (0.0233) Average Loss: 0.6313 (0.7301) Average CE Loss (Source):  0.6313 ( 0.7301) Learning Rate: 0.1000 (0.1000) Top1_base: 82.0312 (79.6711) Top1_base_per_class: 81.4035 (80.1157) 
Training Epoch: [142/1000] Step: [200 / 285] Batch Time: 0.1443 (0.1570) Data Time: 0.0108 (0.0238) Average Loss: 0.4739 (0.7324) Average CE Loss (Source):  0.4739 ( 0.7324) Learning Rate: 0.1000 (0.1000) Top1_base: 85.1562 (79.6172) Top1_base_per_class: 85.5059 (80.0096) 
Training Epoch: [142/1000] Step: [210 / 285] Batch Time: 0.1426 (0.1566) Data Time: 0.0118 (0.0234) Average Loss: 0.9110 (0.7334) Average CE Loss (Source):  0.9110 ( 0.7334) Learning Rate: 0.1000 (0.1000) Top1_base: 72.6562 (79.5908) Top1_base_per_class: 69.6797 (79.9727) 
Training Epoch: [142/1000] Step: [220 / 285] Batch Time: 0.1434 (0.1563) Data Time: 0.0107 (0.0231) Average Loss: 0.7697 (0.7346) Average CE Loss (Source):  0.7697 ( 0.7346) Learning Rate: 0.1000 (0.1000) Top1_base: 78.9062 (79.5881) Top1_base_per_class: 75.1572 (79.8942) 
Training Epoch: [142/1000] Step: [230 / 285] Batch Time: 0.1507 (0.1560) Data Time: 0.0149 (0.0229) Average Loss: 0.8463 (0.7354) Average CE Loss (Source):  0.8463 ( 0.7354) Learning Rate: 0.1000 (0.1000) Top1_base: 74.2188 (79.5720) Top1_base_per_class: 75.7062 (79.9110) 
Training Epoch: [142/1000] Step: [240 / 285] Batch Time: 0.1436 (0.1557) Data Time: 0.0105 (0.0226) Average Loss: 0.7707 (0.7361) Average CE Loss (Source):  0.7707 ( 0.7361) Learning Rate: 0.1000 (0.1000) Top1_base: 79.6875 (79.5215) Top1_base_per_class: 77.5862 (79.8733) 
Training Epoch: [142/1000] Step: [250 / 285] Batch Time: 0.1693 (0.1554) Data Time: 0.0360 (0.0223) Average Loss: 0.8354 (0.7370) Average CE Loss (Source):  0.8354 ( 0.7370) Learning Rate: 0.1000 (0.1000) Top1_base: 77.3438 (79.4844) Top1_base_per_class: 77.4680 (79.8729) 
Training Epoch: [142/1000] Step: [260 / 285] Batch Time: 0.1451 (0.1552) Data Time: 0.0104 (0.0220) Average Loss: 0.9984 (0.7380) Average CE Loss (Source):  0.9984 ( 0.7380) Learning Rate: 0.1000 (0.1000) Top1_base: 71.8750 (79.4832) Top1_base_per_class: 70.8929 (79.8792) 
Training Epoch: [142/1000] Step: [270 / 285] Batch Time: 0.1437 (0.1550) Data Time: 0.0131 (0.0219) Average Loss: 0.6921 (0.7383) Average CE Loss (Source):  0.6921 ( 0.7383) Learning Rate: 0.1000 (0.1000) Top1_base: 83.5938 (79.4618) Top1_base_per_class: 84.6154 (79.8435) 
Training Epoch: [142/1000] Step: [280 / 285] Batch Time: 0.1431 (0.1550) Data Time: 0.0100 (0.0218) Average Loss: 0.7831 (0.7383) Average CE Loss (Source):  0.7831 ( 0.7383) Learning Rate: 0.1000 (0.1000) Top1_base: 79.6875 (79.4727) Top1_base_per_class: 79.7368 (79.8181) 
Training Epoch: [143/1000] Step: [0] Batch Time: 0.1407 (0.1549) Data Time: 0.0099 (0.0217) Average Loss: 0.6171 (0.7378) Average CE Loss (Source):  0.6171 ( 0.7378) Learning Rate: 0.1000 (0.1000) Top1_base: 82.0312 (79.4709) Top1_base_per_class: 83.1790 (79.7953) 
Training Epoch: [143/1000] Step: [10 / 285] Batch Time: 0.1468 (0.2250) Data Time: 0.0137 (0.0920) Average Loss: 0.7181 (0.6569) Average CE Loss (Source):  0.7181 ( 0.6569) Learning Rate: 0.1000 (0.1000) Top1_base: 78.1250 (81.4844) Top1_base_per_class: 76.9643 (81.9315) 
Training Epoch: [143/1000] Step: [20 / 285] Batch Time: 0.1498 (0.1950) Data Time: 0.0174 (0.0622) Average Loss: 0.8492 (0.6741) Average CE Loss (Source):  0.8492 ( 0.6741) Learning Rate: 0.1000 (0.1000) Top1_base: 80.4688 (81.0156) Top1_base_per_class: 78.5535 (81.0970) 
Training Epoch: [143/1000] Step: [30 / 285] Batch Time: 0.1479 (0.1806) Data Time: 0.0157 (0.0475) Average Loss: 0.8013 (0.7033) Average CE Loss (Source):  0.8013 ( 0.7033) Learning Rate: 0.1000 (0.1000) Top1_base: 78.9062 (80.5990) Top1_base_per_class: 79.4599 (80.4641) 
Training Epoch: [143/1000] Step: [40 / 285] Batch Time: 0.1528 (0.1737) Data Time: 0.0137 (0.0405) Average Loss: 0.7096 (0.6975) Average CE Loss (Source):  0.7096 ( 0.6975) Learning Rate: 0.1000 (0.1000) Top1_base: 79.6875 (80.8594) Top1_base_per_class: 80.9563 (80.9290) 
Training Epoch: [143/1000] Step: [50 / 285] Batch Time: 0.1765 (0.1699) Data Time: 0.0461 (0.0368) Average Loss: 0.7517 (0.6925) Average CE Loss (Source):  0.7517 ( 0.6925) Learning Rate: 0.1000 (0.1000) Top1_base: 79.6875 (80.7812) Top1_base_per_class: 82.7469 (80.9570) 
Training Epoch: [143/1000] Step: [60 / 285] Batch Time: 0.1463 (0.1670) Data Time: 0.0142 (0.0339) Average Loss: 0.5122 (0.6985) Average CE Loss (Source):  0.5122 ( 0.6985) Learning Rate: 0.1000 (0.1000) Top1_base: 83.5938 (80.5599) Top1_base_per_class: 83.5965 (80.7187) 
Training Epoch: [143/1000] Step: [70 / 285] Batch Time: 0.1480 (0.1654) Data Time: 0.0134 (0.0323) Average Loss: 0.7471 (0.7039) Average CE Loss (Source):  0.7471 ( 0.7039) Learning Rate: 0.1000 (0.1000) Top1_base: 78.9062 (80.3571) Top1_base_per_class: 82.3308 (80.5950) 
Training Epoch: [143/1000] Step: [80 / 285] Batch Time: 0.1619 (0.1636) Data Time: 0.0272 (0.0303) Average Loss: 0.7909 (0.7035) Average CE Loss (Source):  0.7909 ( 0.7035) Learning Rate: 0.1000 (0.1000) Top1_base: 78.9062 (80.2637) Top1_base_per_class: 78.4112 (80.5065) 
Training Epoch: [143/1000] Step: [90 / 285] Batch Time: 0.1487 (0.1628) Data Time: 0.0113 (0.0295) Average Loss: 0.7425 (0.7175) Average CE Loss (Source):  0.7425 ( 0.7175) Learning Rate: 0.1000 (0.1000) Top1_base: 75.7812 (79.9306) Top1_base_per_class: 76.2147 (80.2424) 
Training Epoch: [143/1000] Step: [100 / 285] Batch Time: 0.1476 (0.1618) Data Time: 0.0140 (0.0285) Average Loss: 0.7121 (0.7179) Average CE Loss (Source):  0.7121 ( 0.7179) Learning Rate: 0.1000 (0.1000) Top1_base: 81.2500 (80.0000) Top1_base_per_class: 80.8036 (80.2541) 
Training Epoch: [143/1000] Step: [110 / 285] Batch Time: 0.1440 (0.1624) Data Time: 0.0127 (0.0290) Average Loss: 0.7146 (0.7215) Average CE Loss (Source):  0.7146 ( 0.7215) Learning Rate: 0.1000 (0.1000) Top1_base: 80.4688 (79.8793) Top1_base_per_class: 80.4938 (80.1013) 
Training Epoch: [143/1000] Step: [120 / 285] Batch Time: 0.1486 (0.1624) Data Time: 0.0135 (0.0290) Average Loss: 0.9196 (0.7220) Average CE Loss (Source):  0.9196 ( 0.7220) Learning Rate: 0.1000 (0.1000) Top1_base: 77.3438 (79.8047) Top1_base_per_class: 76.4506 (80.0292) 
Training Epoch: [143/1000] Step: [130 / 285] Batch Time: 0.1433 (0.1623) Data Time: 0.0126 (0.0287) Average Loss: 0.7561 (0.7202) Average CE Loss (Source):  0.7561 ( 0.7202) Learning Rate: 0.1000 (0.1000) Top1_base: 81.2500 (79.8798) Top1_base_per_class: 78.7273 (80.0714) 
Training Epoch: [143/1000] Step: [140 / 285] Batch Time: 0.1485 (0.1618) Data Time: 0.0136 (0.0280) Average Loss: 0.7754 (0.7177) Average CE Loss (Source):  0.7754 ( 0.7177) Learning Rate: 0.1000 (0.1000) Top1_base: 78.1250 (79.9777) Top1_base_per_class: 80.3846 (80.1143) 
Training Epoch: [143/1000] Step: [150 / 285] Batch Time: 0.1470 (0.1610) Data Time: 0.0108 (0.0272) Average Loss: 0.6751 (0.7198) Average CE Loss (Source):  0.6751 ( 0.7198) Learning Rate: 0.1000 (0.1000) Top1_base: 79.6875 (79.8802) Top1_base_per_class: 77.2024 (80.0176) 
Training Epoch: [143/1000] Step: [160 / 285] Batch Time: 0.1490 (0.1604) Data Time: 0.0141 (0.0266) Average Loss: 0.7597 (0.7214) Average CE Loss (Source):  0.7597 ( 0.7214) Learning Rate: 0.1000 (0.1000) Top1_base: 80.4688 (79.8340) Top1_base_per_class: 83.6012 (79.9757) 
Training Epoch: [143/1000] Step: [170 / 285] Batch Time: 0.1439 (0.1602) Data Time: 0.0135 (0.0265) Average Loss: 0.8206 (0.7233) Average CE Loss (Source):  0.8206 ( 0.7233) Learning Rate: 0.1000 (0.1000) Top1_base: 78.1250 (79.7978) Top1_base_per_class: 77.2436 (79.9895) 
Training Epoch: [143/1000] Step: [180 / 285] Batch Time: 0.1513 (0.1597) Data Time: 0.0174 (0.0260) Average Loss: 0.7094 (0.7235) Average CE Loss (Source):  0.7094 ( 0.7235) Learning Rate: 0.1000 (0.1000) Top1_base: 78.9062 (79.7873) Top1_base_per_class: 78.3631 (79.9916) 
Training Epoch: [143/1000] Step: [190 / 285] Batch Time: 0.1452 (0.1591) Data Time: 0.0144 (0.0254) Average Loss: 0.6627 (0.7248) Average CE Loss (Source):  0.6627 ( 0.7248) Learning Rate: 0.1000 (0.1000) Top1_base: 78.9062 (79.7368) Top1_base_per_class: 80.3869 (79.9667) 
Training Epoch: [143/1000] Step: [200 / 285] Batch Time: 0.1473 (0.1585) Data Time: 0.0134 (0.0248) Average Loss: 0.7279 (0.7254) Average CE Loss (Source):  0.7279 ( 0.7254) Learning Rate: 0.1000 (0.1000) Top1_base: 80.4688 (79.6641) Top1_base_per_class: 78.7500 (79.8714) 
Training Epoch: [143/1000] Step: [210 / 285] Batch Time: 0.1431 (0.1588) Data Time: 0.0131 (0.0251) Average Loss: 0.7888 (0.7286) Average CE Loss (Source):  0.7888 ( 0.7286) Learning Rate: 0.1000 (0.1000) Top1_base: 76.5625 (79.5089) Top1_base_per_class: 78.7601 (79.7325) 
Training Epoch: [143/1000] Step: [220 / 285] Batch Time: 0.1468 (0.1585) Data Time: 0.0120 (0.0249) Average Loss: 0.9036 (0.7313) Average CE Loss (Source):  0.9036 ( 0.7313) Learning Rate: 0.1000 (0.1000) Top1_base: 74.2188 (79.4567) Top1_base_per_class: 71.4689 (79.7194) 
Training Epoch: [143/1000] Step: [230 / 285] Batch Time: 0.1440 (0.1584) Data Time: 0.0140 (0.0248) Average Loss: 0.6769 (0.7337) Average CE Loss (Source):  0.6769 ( 0.7337) Learning Rate: 0.1000 (0.1000) Top1_base: 82.0312 (79.4124) Top1_base_per_class: 80.3509 (79.6468) 
Training Epoch: [143/1000] Step: [240 / 285] Batch Time: 0.1437 (0.1582) Data Time: 0.0116 (0.0247) Average Loss: 0.7041 (0.7333) Average CE Loss (Source):  0.7041 ( 0.7333) Learning Rate: 0.1000 (0.1000) Top1_base: 78.9062 (79.3750) Top1_base_per_class: 74.0385 (79.6235) 
Training Epoch: [143/1000] Step: [250 / 285] Batch Time: 0.1466 (0.1580) Data Time: 0.0145 (0.0245) Average Loss: 0.9200 (0.7365) Average CE Loss (Source):  0.9200 ( 0.7365) Learning Rate: 0.1000 (0.1000) Top1_base: 76.5625 (79.2969) Top1_base_per_class: 78.6741 (79.5872) 
Training Epoch: [143/1000] Step: [260 / 285] Batch Time: 0.1444 (0.1576) Data Time: 0.0117 (0.0242) Average Loss: 0.7732 (0.7375) Average CE Loss (Source):  0.7732 ( 0.7375) Learning Rate: 0.1000 (0.1000) Top1_base: 77.3438 (79.2428) Top1_base_per_class: 78.7871 (79.5507) 
Training Epoch: [143/1000] Step: [270 / 285] Batch Time: 0.1442 (0.1574) Data Time: 0.0111 (0.0239) Average Loss: 0.8802 (0.7367) Average CE Loss (Source):  0.8802 ( 0.7367) Learning Rate: 0.1000 (0.1000) Top1_base: 76.5625 (79.2737) Top1_base_per_class: 76.6667 (79.5921) 
Training Epoch: [143/1000] Step: [280 / 285] Batch Time: 0.1514 (0.1571) Data Time: 0.0150 (0.0236) Average Loss: 0.6207 (0.7378) Average CE Loss (Source):  0.6207 ( 0.7378) Learning Rate: 0.1000 (0.1000) Top1_base: 80.4688 (79.2327) Top1_base_per_class: 81.0544 (79.5492) 
Training Epoch: [144/1000] Step: [0] Batch Time: 0.1455 (0.1570) Data Time: 0.0118 (0.0235) Average Loss: 0.9038 (0.7383) Average CE Loss (Source):  0.9038 ( 0.7383) Learning Rate: 0.1000 (0.1000) Top1_base: 75.0000 (79.2160) Top1_base_per_class: 77.4702 (79.5691) 
 14%|█▍        | 144/1000 [1:52:09<11:00:35, 46.30s/it] 14%|█▍        | 145/1000 [1:52:54<10:51:24, 45.71s/it]Training Epoch: [144/1000] Step: [10 / 285] Batch Time: 0.1451 (0.2439) Data Time: 0.0108 (0.1113) Average Loss: 0.7433 (0.6719) Average CE Loss (Source):  0.7433 ( 0.6719) Learning Rate: 0.1000 (0.1000) Top1_base: 78.9062 (80.3906) Top1_base_per_class: 79.2816 (80.6355) 
Training Epoch: [144/1000] Step: [20 / 285] Batch Time: 0.1468 (0.1999) Data Time: 0.0144 (0.0671) Average Loss: 0.5908 (0.6814) Average CE Loss (Source):  0.5908 ( 0.6814) Learning Rate: 0.1000 (0.1000) Top1_base: 85.9375 (80.7812) Top1_base_per_class: 85.1488 (80.9789) 
Training Epoch: [144/1000] Step: [30 / 285] Batch Time: 0.1467 (0.1861) Data Time: 0.0119 (0.0530) Average Loss: 0.4574 (0.6926) Average CE Loss (Source):  0.4574 ( 0.6926) Learning Rate: 0.1000 (0.1000) Top1_base: 85.1562 (80.4167) Top1_base_per_class: 87.4830 (80.8837) 
Training Epoch: [144/1000] Step: [40 / 285] Batch Time: 0.1467 (0.1788) Data Time: 0.0126 (0.0457) Average Loss: 0.6832 (0.7020) Average CE Loss (Source):  0.6832 ( 0.7020) Learning Rate: 0.1000 (0.1000) Top1_base: 83.5938 (80.5078) Top1_base_per_class: 83.2759 (81.0008) 
Training Epoch: [144/1000] Step: [50 / 285] Batch Time: 0.1463 (0.1748) Data Time: 0.0112 (0.0416) Average Loss: 0.6551 (0.6937) Average CE Loss (Source):  0.6551 ( 0.6937) Learning Rate: 0.1000 (0.1000) Top1_base: 82.0312 (80.6250) Top1_base_per_class: 78.9831 (80.9077) 
Training Epoch: [144/1000] Step: [60 / 285] Batch Time: 0.1450 (0.1706) Data Time: 0.0133 (0.0373) Average Loss: 0.6096 (0.6990) Average CE Loss (Source):  0.6096 ( 0.6990) Learning Rate: 0.1000 (0.1000) Top1_base: 82.0312 (80.4948) Top1_base_per_class: 85.5864 (80.6697) 
Training Epoch: [144/1000] Step: [70 / 285] Batch Time: 0.1442 (0.1698) Data Time: 0.0125 (0.0367) Average Loss: 0.8497 (0.7011) Average CE Loss (Source):  0.8497 ( 0.7011) Learning Rate: 0.1000 (0.1000) Top1_base: 78.1250 (80.3348) Top1_base_per_class: 80.2083 (80.4782) 
Training Epoch: [144/1000] Step: [80 / 285] Batch Time: 0.1471 (0.1673) Data Time: 0.0112 (0.0341) Average Loss: 0.7201 (0.6998) Average CE Loss (Source):  0.7201 ( 0.6998) Learning Rate: 0.1000 (0.1000) Top1_base: 79.6875 (80.3711) Top1_base_per_class: 81.9005 (80.5433) 
Training Epoch: [144/1000] Step: [90 / 285] Batch Time: 0.1469 (0.1653) Data Time: 0.0120 (0.0321) Average Loss: 0.7061 (0.7027) Average CE Loss (Source):  0.7061 ( 0.7027) Learning Rate: 0.1000 (0.1000) Top1_base: 81.2500 (80.3819) Top1_base_per_class: 80.8036 (80.5881) 
Training Epoch: [144/1000] Step: [100 / 285] Batch Time: 0.1452 (0.1640) Data Time: 0.0122 (0.0309) Average Loss: 0.7197 (0.7060) Average CE Loss (Source):  0.7197 ( 0.7060) Learning Rate: 0.1000 (0.1000) Top1_base: 82.8125 (80.2500) Top1_base_per_class: 82.8274 (80.4326) 
Training Epoch: [144/1000] Step: [110 / 285] Batch Time: 0.1482 (0.1630) Data Time: 0.0172 (0.0299) Average Loss: 0.7320 (0.7049) Average CE Loss (Source):  0.7320 ( 0.7049) Learning Rate: 0.1000 (0.1000) Top1_base: 79.6875 (80.2770) Top1_base_per_class: 79.8148 (80.5626) 
Training Epoch: [144/1000] Step: [120 / 285] Batch Time: 0.1437 (0.1620) Data Time: 0.0123 (0.0290) Average Loss: 0.7620 (0.7019) Average CE Loss (Source):  0.7620 ( 0.7019) Learning Rate: 0.1000 (0.1000) Top1_base: 79.6875 (80.3971) Top1_base_per_class: 78.4641 (80.6778) 
Training Epoch: [144/1000] Step: [130 / 285] Batch Time: 0.1712 (0.1618) Data Time: 0.0403 (0.0287) Average Loss: 0.8724 (0.7063) Average CE Loss (Source):  0.8724 ( 0.7063) Learning Rate: 0.1000 (0.1000) Top1_base: 78.9062 (80.3365) Top1_base_per_class: 80.6667 (80.5990) 
Training Epoch: [144/1000] Step: [140 / 285] Batch Time: 0.1454 (0.1608) Data Time: 0.0125 (0.0277) Average Loss: 0.8069 (0.7126) Average CE Loss (Source):  0.8069 ( 0.7126) Learning Rate: 0.1000 (0.1000) Top1_base: 78.1250 (80.0837) Top1_base_per_class: 76.8441 (80.2858) 
Training Epoch: [144/1000] Step: [150 / 285] Batch Time: 0.1479 (0.1601) Data Time: 0.0164 (0.0269) Average Loss: 0.6463 (0.7184) Average CE Loss (Source):  0.6463 ( 0.7184) Learning Rate: 0.1000 (0.1000) Top1_base: 80.4688 (79.9948) Top1_base_per_class: 79.9697 (80.1989) 
Training Epoch: [144/1000] Step: [160 / 285] Batch Time: 0.1447 (0.1595) Data Time: 0.0142 (0.0262) Average Loss: 0.6164 (0.7203) Average CE Loss (Source):  0.6164 ( 0.7203) Learning Rate: 0.1000 (0.1000) Top1_base: 82.8125 (79.8975) Top1_base_per_class: 84.5152 (80.0495) 
Training Epoch: [144/1000] Step: [170 / 285] Batch Time: 0.1504 (0.1590) Data Time: 0.0169 (0.0258) Average Loss: 0.7032 (0.7194) Average CE Loss (Source):  0.7032 ( 0.7194) Learning Rate: 0.1000 (0.1000) Top1_base: 78.1250 (79.9311) Top1_base_per_class: 75.2299 (80.0584) 
Training Epoch: [144/1000] Step: [180 / 285] Batch Time: 0.1493 (0.1583) Data Time: 0.0167 (0.0251) Average Loss: 0.7714 (0.7202) Average CE Loss (Source):  0.7714 ( 0.7202) Learning Rate: 0.1000 (0.1000) Top1_base: 78.1250 (79.9089) Top1_base_per_class: 76.9492 (80.0442) 
Training Epoch: [144/1000] Step: [190 / 285] Batch Time: 0.1453 (0.1577) Data Time: 0.0118 (0.0245) Average Loss: 0.5672 (0.7211) Average CE Loss (Source):  0.5672 ( 0.7211) Learning Rate: 0.1000 (0.1000) Top1_base: 81.2500 (79.8561) Top1_base_per_class: 81.5123 (80.0398) 
Training Epoch: [144/1000] Step: [200 / 285] Batch Time: 0.1502 (0.1574) Data Time: 0.0152 (0.0242) Average Loss: 0.8167 (0.7233) Average CE Loss (Source):  0.8167 ( 0.7233) Learning Rate: 0.1000 (0.1000) Top1_base: 78.1250 (79.7539) Top1_base_per_class: 76.9048 (79.9494) 
Training Epoch: [144/1000] Step: [210 / 285] Batch Time: 0.1465 (0.1570) Data Time: 0.0117 (0.0237) Average Loss: 0.7654 (0.7242) Average CE Loss (Source):  0.7654 ( 0.7242) Learning Rate: 0.1000 (0.1000) Top1_base: 77.3438 (79.7098) Top1_base_per_class: 76.1828 (79.9154) 
Training Epoch: [144/1000] Step: [220 / 285] Batch Time: 0.1518 (0.1572) Data Time: 0.0158 (0.0240) Average Loss: 0.6603 (0.7235) Average CE Loss (Source):  0.6603 ( 0.7235) Learning Rate: 0.1000 (0.1000) Top1_base: 82.0312 (79.7266) Top1_base_per_class: 83.6494 (79.9283) 
Training Epoch: [144/1000] Step: [230 / 285] Batch Time: 0.1502 (0.1569) Data Time: 0.0128 (0.0235) Average Loss: 0.7306 (0.7230) Average CE Loss (Source):  0.7306 ( 0.7230) Learning Rate: 0.1000 (0.1000) Top1_base: 79.6875 (79.7113) Top1_base_per_class: 84.0000 (79.9483) 
Training Epoch: [144/1000] Step: [240 / 285] Batch Time: 0.1451 (0.1565) Data Time: 0.0119 (0.0231) Average Loss: 0.7954 (0.7252) Average CE Loss (Source):  0.7954 ( 0.7252) Learning Rate: 0.1000 (0.1000) Top1_base: 77.3438 (79.6680) Top1_base_per_class: 77.7083 (79.9181) 
Training Epoch: [144/1000] Step: [250 / 285] Batch Time: 0.1490 (0.1563) Data Time: 0.0127 (0.0229) Average Loss: 0.8209 (0.7270) Average CE Loss (Source):  0.8209 ( 0.7270) Learning Rate: 0.1000 (0.1000) Top1_base: 75.7812 (79.6344) Top1_base_per_class: 76.8518 (79.9072) 
Training Epoch: [144/1000] Step: [260 / 285] Batch Time: 0.1493 (0.1561) Data Time: 0.0154 (0.0225) Average Loss: 0.7780 (0.7290) Average CE Loss (Source):  0.7780 ( 0.7290) Learning Rate: 0.1000 (0.1000) Top1_base: 79.6875 (79.6424) Top1_base_per_class: 76.3463 (79.8996) 
Training Epoch: [144/1000] Step: [270 / 285] Batch Time: 0.1470 (0.1557) Data Time: 0.0148 (0.0222) Average Loss: 0.8339 (0.7314) Average CE Loss (Source):  0.8339 ( 0.7314) Learning Rate: 0.1000 (0.1000) Top1_base: 81.2500 (79.5891) Top1_base_per_class: 81.6082 (79.8599) 
Training Epoch: [144/1000] Step: [280 / 285] Batch Time: 0.1480 (0.1555) Data Time: 0.0136 (0.0219) Average Loss: 0.8833 (0.7349) Average CE Loss (Source):  0.8833 ( 0.7349) Learning Rate: 0.1000 (0.1000) Top1_base: 74.2188 (79.4922) Top1_base_per_class: 73.8388 (79.7970) 
Training Epoch: [145/1000] Step: [0] Batch Time: 0.1460 (0.1553) Data Time: 0.0121 (0.0218) Average Loss: 0.7786 (0.7358) Average CE Loss (Source):  0.7786 ( 0.7358) Learning Rate: 0.1000 (0.1000) Top1_base: 78.9062 (79.4518) Top1_base_per_class: 78.0173 (79.7397) 
Training Epoch: [145/1000] Step: [10 / 285] Batch Time: 0.1410 (0.2303) Data Time: 0.0106 (0.0991) Average Loss: 0.7861 (0.6590) Average CE Loss (Source):  0.7861 ( 0.6590) Learning Rate: 0.1000 (0.1000) Top1_base: 74.2188 (81.8750) Top1_base_per_class: 70.9259 (81.3628) 
Training Epoch: [145/1000] Step: [20 / 285] Batch Time: 0.1432 (0.1934) Data Time: 0.0125 (0.0614) Average Loss: 0.6116 (0.6770) Average CE Loss (Source):  0.6116 ( 0.6770) Learning Rate: 0.1000 (0.1000) Top1_base: 85.1562 (81.4062) Top1_base_per_class: 87.4304 (81.6919) 
Training Epoch: [145/1000] Step: [30 / 285] Batch Time: 0.1589 (0.1802) Data Time: 0.0247 (0.0476) Average Loss: 0.8053 (0.6993) Average CE Loss (Source):  0.8053 ( 0.6993) Learning Rate: 0.1000 (0.1000) Top1_base: 77.3438 (80.6250) Top1_base_per_class: 74.1975 (80.8852) 
Training Epoch: [145/1000] Step: [40 / 285] Batch Time: 0.1482 (0.1741) Data Time: 0.0154 (0.0416) Average Loss: 0.5437 (0.6937) Average CE Loss (Source):  0.5437 ( 0.6937) Learning Rate: 0.1000 (0.1000) Top1_base: 83.5938 (80.6641) Top1_base_per_class: 84.4753 (80.8363) 
Training Epoch: [145/1000] Step: [50 / 285] Batch Time: 0.1430 (0.1700) Data Time: 0.0129 (0.0377) Average Loss: 0.7817 (0.7066) Average CE Loss (Source):  0.7817 ( 0.7066) Learning Rate: 0.1000 (0.1000) Top1_base: 80.4688 (80.2812) Top1_base_per_class: 76.3030 (80.4618) 
Training Epoch: [145/1000] Step: [60 / 285] Batch Time: 0.1501 (0.1670) Data Time: 0.0166 (0.0347) Average Loss: 0.5657 (0.7072) Average CE Loss (Source):  0.5657 ( 0.7072) Learning Rate: 0.1000 (0.1000) Top1_base: 83.5938 (80.2083) Top1_base_per_class: 83.6389 (80.4406) 
Training Epoch: [145/1000] Step: [70 / 285] Batch Time: 0.1494 (0.1665) Data Time: 0.0159 (0.0340) Average Loss: 0.7867 (0.7049) Average CE Loss (Source):  0.7867 ( 0.7049) Learning Rate: 0.1000 (0.1000) Top1_base: 78.1250 (80.2567) Top1_base_per_class: 82.7679 (80.5330) 
Training Epoch: [145/1000] Step: [80 / 285] Batch Time: 0.1500 (0.1644) Data Time: 0.0165 (0.0316) Average Loss: 0.6972 (0.7074) Average CE Loss (Source):  0.6972 ( 0.7074) Learning Rate: 0.1000 (0.1000) Top1_base: 79.6875 (80.1562) Top1_base_per_class: 80.2464 (80.3116) 
Training Epoch: [145/1000] Step: [90 / 285] Batch Time: 0.1494 (0.1640) Data Time: 0.0158 (0.0312) Average Loss: 0.9046 (0.7055) Average CE Loss (Source):  0.9046 ( 0.7055) Learning Rate: 0.1000 (0.1000) Top1_base: 72.6562 (80.2344) Top1_base_per_class: 74.2949 (80.4517) 
Training Epoch: [145/1000] Step: [100 / 285] Batch Time: 0.1484 (0.1634) Data Time: 0.0156 (0.0306) Average Loss: 0.6967 (0.7036) Average CE Loss (Source):  0.6967 ( 0.7036) Learning Rate: 0.1000 (0.1000) Top1_base: 81.2500 (80.2422) Top1_base_per_class: 79.4340 (80.4295) 
Training Epoch: [145/1000] Step: [110 / 285] Batch Time: 0.1487 (0.1624) Data Time: 0.0152 (0.0295) Average Loss: 0.9426 (0.7071) Average CE Loss (Source):  0.9426 ( 0.7071) Learning Rate: 0.1000 (0.1000) Top1_base: 73.4375 (80.1847) Top1_base_per_class: 73.3333 (80.4297) 
Training Epoch: [145/1000] Step: [120 / 285] Batch Time: 0.1471 (0.1620) Data Time: 0.0121 (0.0292) Average Loss: 0.8665 (0.7100) Average CE Loss (Source):  0.8665 ( 0.7100) Learning Rate: 0.1000 (0.1000) Top1_base: 74.2188 (79.9870) Top1_base_per_class: 77.1637 (80.2782) 
Training Epoch: [145/1000] Step: [130 / 285] Batch Time: 0.1414 (0.1615) Data Time: 0.0108 (0.0288) Average Loss: 0.6752 (0.7126) Average CE Loss (Source):  0.6752 ( 0.7126) Learning Rate: 0.1000 (0.1000) Top1_base: 82.0312 (79.8918) Top1_base_per_class: 82.2701 (80.2588) 
Training Epoch: [145/1000] Step: [140 / 285] Batch Time: 0.1460 (0.1616) Data Time: 0.0118 (0.0289) Average Loss: 0.6772 (0.7156) Average CE Loss (Source):  0.6772 ( 0.7156) Learning Rate: 0.1000 (0.1000) Top1_base: 79.6875 (79.8326) Top1_base_per_class: 82.8139 (80.2746) 
Training Epoch: [145/1000] Step: [150 / 285] Batch Time: 0.1480 (0.1610) Data Time: 0.0142 (0.0282) Average Loss: 0.5972 (0.7113) Average CE Loss (Source):  0.5972 ( 0.7113) Learning Rate: 0.1000 (0.1000) Top1_base: 82.0312 (79.9375) Top1_base_per_class: 81.6029 (80.3992) 
Training Epoch: [145/1000] Step: [160 / 285] Batch Time: 0.1427 (0.1603) Data Time: 0.0122 (0.0276) Average Loss: 0.6672 (0.7083) Average CE Loss (Source):  0.6672 ( 0.7083) Learning Rate: 0.1000 (0.1000) Top1_base: 81.2500 (80.0098) Top1_base_per_class: 79.9091 (80.4505) 
Training Epoch: [145/1000] Step: [170 / 285] Batch Time: 0.1401 (0.1596) Data Time: 0.0107 (0.0269) Average Loss: 0.6062 (0.7137) Average CE Loss (Source):  0.6062 ( 0.7137) Learning Rate: 0.1000 (0.1000) Top1_base: 80.4688 (79.8483) Top1_base_per_class: 81.0000 (80.3162) 
Training Epoch: [145/1000] Step: [180 / 285] Batch Time: 0.1440 (0.1590) Data Time: 0.0119 (0.0263) Average Loss: 0.8005 (0.7156) Average CE Loss (Source):  0.8005 ( 0.7156) Learning Rate: 0.1000 (0.1000) Top1_base: 79.6875 (79.8438) Top1_base_per_class: 80.6970 (80.2543) 
Training Epoch: [145/1000] Step: [190 / 285] Batch Time: 0.1494 (0.1585) Data Time: 0.0144 (0.0257) Average Loss: 0.9277 (0.7193) Average CE Loss (Source):  0.9277 ( 0.7193) Learning Rate: 0.1000 (0.1000) Top1_base: 74.2188 (79.7368) Top1_base_per_class: 72.2956 (80.1957) 
Training Epoch: [145/1000] Step: [200 / 285] Batch Time: 0.1473 (0.1588) Data Time: 0.0137 (0.0260) Average Loss: 0.6477 (0.7213) Average CE Loss (Source):  0.6477 ( 0.7213) Learning Rate: 0.1000 (0.1000) Top1_base: 84.3750 (79.6758) Top1_base_per_class: 87.5731 (80.1418) 
Training Epoch: [145/1000] Step: [210 / 285] Batch Time: 0.1426 (0.1588) Data Time: 0.0114 (0.0260) Average Loss: 0.8814 (0.7247) Average CE Loss (Source):  0.8814 ( 0.7247) Learning Rate: 0.1000 (0.1000) Top1_base: 77.3438 (79.6615) Top1_base_per_class: 75.2874 (80.1004) 
Training Epoch: [145/1000] Step: [220 / 285] Batch Time: 0.1431 (0.1583) Data Time: 0.0122 (0.0256) Average Loss: 0.7259 (0.7258) Average CE Loss (Source):  0.7259 ( 0.7258) Learning Rate: 0.1000 (0.1000) Top1_base: 82.8125 (79.6484) Top1_base_per_class: 82.5758 (80.0868) 
Training Epoch: [145/1000] Step: [230 / 285] Batch Time: 0.1458 (0.1583) Data Time: 0.0128 (0.0255) Average Loss: 0.7947 (0.7277) Average CE Loss (Source):  0.7947 ( 0.7277) Learning Rate: 0.1000 (0.1000) Top1_base: 77.3438 (79.5992) Top1_base_per_class: 80.9722 (80.0522) 
Training Epoch: [145/1000] Step: [240 / 285] Batch Time: 0.1431 (0.1583) Data Time: 0.0116 (0.0255) Average Loss: 0.5357 (0.7286) Average CE Loss (Source):  0.5357 ( 0.7286) Learning Rate: 0.1000 (0.1000) Top1_base: 84.3750 (79.5833) Top1_base_per_class: 84.1349 (80.0483) 
Training Epoch: [145/1000] Step: [250 / 285] Batch Time: 0.1499 (0.1578) Data Time: 0.0142 (0.0250) Average Loss: 0.6796 (0.7303) Average CE Loss (Source):  0.6796 ( 0.7303) Learning Rate: 0.1000 (0.1000) Top1_base: 79.6875 (79.4656) Top1_base_per_class: 81.5497 (79.9137) 
Training Epoch: [145/1000] Step: [260 / 285] Batch Time: 0.1418 (0.1574) Data Time: 0.0116 (0.0246) Average Loss: 0.8924 (0.7323) Average CE Loss (Source):  0.8924 ( 0.7323) Learning Rate: 0.1000 (0.1000) Top1_base: 78.9062 (79.3990) Top1_base_per_class: 78.2716 (79.8248) 
Training Epoch: [145/1000] Step: [270 / 285] Batch Time: 0.1420 (0.1573) Data Time: 0.0113 (0.0245) Average Loss: 0.7611 (0.7338) Average CE Loss (Source):  0.7611 ( 0.7338) Learning Rate: 0.1000 (0.1000) Top1_base: 83.5938 (79.3808) Top1_base_per_class: 86.9091 (79.8251) 
Training Epoch: [145/1000] Step: [280 / 285] Batch Time: 0.1455 (0.1571) Data Time: 0.0133 (0.0243) Average Loss: 0.7427 (0.7328) Average CE Loss (Source):  0.7427 ( 0.7328) Learning Rate: 0.1000 (0.1000) Top1_base: 80.4688 (79.4057) Top1_base_per_class: 84.1212 (79.8470) 
Training Epoch: [146/1000] Step: [0] Batch Time: 0.1387 (0.1570) Data Time: 0.0113 (0.0243) Average Loss: 0.8240 (0.7325) Average CE Loss (Source):  0.8240 ( 0.7325) Learning Rate: 0.1000 (0.1000) Top1_base: 79.6875 (79.4271) Top1_base_per_class: 82.2327 (79.8747) 
 15%|█▍        | 146/1000 [1:53:41<10:59:14, 46.32s/it] 15%|█▍        | 147/1000 [1:54:26<10:50:18, 45.74s/it]Training Epoch: [146/1000] Step: [10 / 285] Batch Time: 0.1449 (0.2407) Data Time: 0.0141 (0.1086) Average Loss: 0.5493 (0.6584) Average CE Loss (Source):  0.5493 ( 0.6584) Learning Rate: 0.1000 (0.1000) Top1_base: 85.9375 (81.0938) Top1_base_per_class: 87.9938 (82.1110) 
Training Epoch: [146/1000] Step: [20 / 285] Batch Time: 0.1445 (0.1991) Data Time: 0.0127 (0.0667) Average Loss: 0.8155 (0.7300) Average CE Loss (Source):  0.8155 ( 0.7300) Learning Rate: 0.1000 (0.1000) Top1_base: 80.4688 (79.6875) Top1_base_per_class: 78.1609 (80.0503) 
Training Epoch: [146/1000] Step: [30 / 285] Batch Time: 0.1457 (0.1845) Data Time: 0.0143 (0.0519) Average Loss: 0.6104 (0.7325) Average CE Loss (Source):  0.6104 ( 0.7325) Learning Rate: 0.1000 (0.1000) Top1_base: 83.5938 (79.4271) Top1_base_per_class: 83.1037 (79.9046) 
Training Epoch: [146/1000] Step: [40 / 285] Batch Time: 0.1471 (0.1783) Data Time: 0.0150 (0.0456) Average Loss: 0.6003 (0.7204) Average CE Loss (Source):  0.6003 ( 0.7204) Learning Rate: 0.1000 (0.1000) Top1_base: 79.6875 (79.5898) Top1_base_per_class: 79.4136 (79.9858) 
Training Epoch: [146/1000] Step: [50 / 285] Batch Time: 0.1453 (0.1719) Data Time: 0.0121 (0.0392) Average Loss: 0.4424 (0.7034) Average CE Loss (Source):  0.4424 ( 0.7034) Learning Rate: 0.1000 (0.1000) Top1_base: 86.7188 (80.0938) Top1_base_per_class: 83.3333 (80.4914) 
Training Epoch: [146/1000] Step: [60 / 285] Batch Time: 0.1449 (0.1678) Data Time: 0.0124 (0.0350) Average Loss: 1.0055 (0.7112) Average CE Loss (Source):  1.0055 ( 0.7112) Learning Rate: 0.1000 (0.1000) Top1_base: 76.5625 (79.8958) Top1_base_per_class: 77.1131 (80.5718) 
Training Epoch: [146/1000] Step: [70 / 285] Batch Time: 0.1436 (0.1666) Data Time: 0.0120 (0.0336) Average Loss: 0.7097 (0.7054) Average CE Loss (Source):  0.7097 ( 0.7054) Learning Rate: 0.1000 (0.1000) Top1_base: 80.4688 (79.9777) Top1_base_per_class: 79.0000 (80.5840) 
Training Epoch: [146/1000] Step: [80 / 285] Batch Time: 0.1468 (0.1655) Data Time: 0.0148 (0.0325) Average Loss: 0.5586 (0.7071) Average CE Loss (Source):  0.5586 ( 0.7071) Learning Rate: 0.1000 (0.1000) Top1_base: 85.1562 (80.0488) Top1_base_per_class: 87.9592 (80.5890) 
Training Epoch: [146/1000] Step: [90 / 285] Batch Time: 0.1446 (0.1643) Data Time: 0.0109 (0.0313) Average Loss: 0.6947 (0.7175) Average CE Loss (Source):  0.6947 ( 0.7175) Learning Rate: 0.1000 (0.1000) Top1_base: 79.6875 (79.7830) Top1_base_per_class: 78.2738 (80.2494) 
Training Epoch: [146/1000] Step: [100 / 285] Batch Time: 0.1447 (0.1625) Data Time: 0.0125 (0.0295) Average Loss: 0.6996 (0.7170) Average CE Loss (Source):  0.6996 ( 0.7170) Learning Rate: 0.1000 (0.1000) Top1_base: 78.9062 (79.8047) Top1_base_per_class: 77.4802 (80.2810) 
Training Epoch: [146/1000] Step: [110 / 285] Batch Time: 0.1450 (0.1619) Data Time: 0.0122 (0.0288) Average Loss: 0.6968 (0.7193) Average CE Loss (Source):  0.6968 ( 0.7193) Learning Rate: 0.1000 (0.1000) Top1_base: 79.6875 (79.8153) Top1_base_per_class: 82.5617 (80.3422) 
Training Epoch: [146/1000] Step: [120 / 285] Batch Time: 0.1496 (0.1619) Data Time: 0.0140 (0.0285) Average Loss: 0.8245 (0.7225) Average CE Loss (Source):  0.8245 ( 0.7225) Learning Rate: 0.1000 (0.1000) Top1_base: 78.1250 (79.6289) Top1_base_per_class: 82.6984 (80.2178) 
Training Epoch: [146/1000] Step: [130 / 285] Batch Time: 0.1450 (0.1610) Data Time: 0.0124 (0.0276) Average Loss: 0.8373 (0.7262) Average CE Loss (Source):  0.8373 ( 0.7262) Learning Rate: 0.1000 (0.1000) Top1_base: 81.2500 (79.5312) Top1_base_per_class: 79.4643 (80.1607) 
Training Epoch: [146/1000] Step: [140 / 285] Batch Time: 0.1437 (0.1609) Data Time: 0.0125 (0.0275) Average Loss: 0.7653 (0.7269) Average CE Loss (Source):  0.7653 ( 0.7269) Learning Rate: 0.1000 (0.1000) Top1_base: 80.4688 (79.4922) Top1_base_per_class: 82.4843 (80.1421) 
Training Epoch: [146/1000] Step: [150 / 285] Batch Time: 0.1464 (0.1602) Data Time: 0.0125 (0.0269) Average Loss: 0.7045 (0.7285) Average CE Loss (Source):  0.7045 ( 0.7285) Learning Rate: 0.1000 (0.1000) Top1_base: 78.1250 (79.4427) Top1_base_per_class: 77.8442 (80.0661) 
Training Epoch: [146/1000] Step: [160 / 285] Batch Time: 0.1439 (0.1593) Data Time: 0.0121 (0.0260) Average Loss: 0.9673 (0.7314) Average CE Loss (Source):  0.9673 ( 0.7314) Learning Rate: 0.1000 (0.1000) Top1_base: 73.4375 (79.3457) Top1_base_per_class: 72.3016 (79.9137) 
Training Epoch: [146/1000] Step: [170 / 285] Batch Time: 0.1471 (0.1588) Data Time: 0.0142 (0.0255) Average Loss: 0.6255 (0.7293) Average CE Loss (Source):  0.6255 ( 0.7293) Learning Rate: 0.1000 (0.1000) Top1_base: 83.5938 (79.3199) Top1_base_per_class: 81.9591 (79.8662) 
Training Epoch: [146/1000] Step: [180 / 285] Batch Time: 0.1486 (0.1582) Data Time: 0.0146 (0.0248) Average Loss: 0.6613 (0.7306) Average CE Loss (Source):  0.6613 ( 0.7306) Learning Rate: 0.1000 (0.1000) Top1_base: 81.2500 (79.2752) Top1_base_per_class: 82.8869 (79.8782) 
Training Epoch: [146/1000] Step: [190 / 285] Batch Time: 0.1468 (0.1580) Data Time: 0.0120 (0.0245) Average Loss: 0.5062 (0.7308) Average CE Loss (Source):  0.5062 ( 0.7308) Learning Rate: 0.1000 (0.1000) Top1_base: 86.7188 (79.2393) Top1_base_per_class: 87.7976 (79.8508) 
Training Epoch: [146/1000] Step: [200 / 285] Batch Time: 0.1469 (0.1576) Data Time: 0.0137 (0.0240) Average Loss: 0.7439 (0.7325) Average CE Loss (Source):  0.7439 ( 0.7325) Learning Rate: 0.1000 (0.1000) Top1_base: 78.1250 (79.1172) Top1_base_per_class: 78.4615 (79.7676) 
Training Epoch: [146/1000] Step: [210 / 285] Batch Time: 0.1483 (0.1573) Data Time: 0.0141 (0.0235) Average Loss: 0.8901 (0.7303) Average CE Loss (Source):  0.8901 ( 0.7303) Learning Rate: 0.1000 (0.1000) Top1_base: 78.9062 (79.2522) Top1_base_per_class: 80.1212 (79.8512) 
Training Epoch: [146/1000] Step: [220 / 285] Batch Time: 0.1466 (0.1569) Data Time: 0.0121 (0.0231) Average Loss: 0.7530 (0.7317) Average CE Loss (Source):  0.7530 ( 0.7317) Learning Rate: 0.1000 (0.1000) Top1_base: 78.9062 (79.2081) Top1_base_per_class: 80.9075 (79.8151) 
Training Epoch: [146/1000] Step: [230 / 285] Batch Time: 0.1453 (0.1566) Data Time: 0.0148 (0.0228) Average Loss: 0.8436 (0.7308) Average CE Loss (Source):  0.8436 ( 0.7308) Learning Rate: 0.1000 (0.1000) Top1_base: 73.4375 (79.2357) Top1_base_per_class: 74.3333 (79.8441) 
Training Epoch: [146/1000] Step: [240 / 285] Batch Time: 0.1466 (0.1563) Data Time: 0.0138 (0.0225) Average Loss: 0.7799 (0.7328) Average CE Loss (Source):  0.7799 ( 0.7328) Learning Rate: 0.1000 (0.1000) Top1_base: 78.1250 (79.1829) Top1_base_per_class: 75.6548 (79.8047) 
Training Epoch: [146/1000] Step: [250 / 285] Batch Time: 0.1425 (0.1560) Data Time: 0.0107 (0.0223) Average Loss: 0.7558 (0.7346) Average CE Loss (Source):  0.7558 ( 0.7346) Learning Rate: 0.1000 (0.1000) Top1_base: 81.2500 (79.1531) Top1_base_per_class: 81.1012 (79.7981) 
Training Epoch: [146/1000] Step: [260 / 285] Batch Time: 0.1485 (0.1558) Data Time: 0.0160 (0.0221) Average Loss: 0.8070 (0.7380) Average CE Loss (Source):  0.8070 ( 0.7380) Learning Rate: 0.1000 (0.1000) Top1_base: 77.3438 (79.0925) Top1_base_per_class: 79.3860 (79.7842) 
Training Epoch: [146/1000] Step: [270 / 285] Batch Time: 0.1453 (0.1560) Data Time: 0.0148 (0.0223) Average Loss: 0.9946 (0.7388) Average CE Loss (Source):  0.9946 ( 0.7388) Learning Rate: 0.1000 (0.1000) Top1_base: 73.4375 (79.1030) Top1_base_per_class: 75.5769 (79.8076) 
Training Epoch: [146/1000] Step: [280 / 285] Batch Time: 0.1453 (0.1558) Data Time: 0.0132 (0.0221) Average Loss: 0.8411 (0.7392) Average CE Loss (Source):  0.8411 ( 0.7392) Learning Rate: 0.1000 (0.1000) Top1_base: 75.0000 (79.0681) Top1_base_per_class: 70.8182 (79.7304) 
Training Epoch: [147/1000] Step: [0] Batch Time: 0.1453 (0.1556) Data Time: 0.0126 (0.0219) Average Loss: 0.6112 (0.7370) Average CE Loss (Source):  0.6112 ( 0.7370) Learning Rate: 0.1000 (0.1000) Top1_base: 83.5938 (79.1201) Top1_base_per_class: 82.7011 (79.7609) 
Training Epoch: [147/1000] Step: [10 / 285] Batch Time: 0.1461 (0.2297) Data Time: 0.0133 (0.0965) Average Loss: 0.7101 (0.7988) Average CE Loss (Source):  0.7101 ( 0.7988) Learning Rate: 0.1000 (0.1000) Top1_base: 82.8125 (78.4375) Top1_base_per_class: 86.4778 (78.7958) 
Training Epoch: [147/1000] Step: [20 / 285] Batch Time: 0.1425 (0.1891) Data Time: 0.0106 (0.0559) Average Loss: 0.6539 (0.7434) Average CE Loss (Source):  0.6539 ( 0.7434) Learning Rate: 0.1000 (0.1000) Top1_base: 80.4688 (79.2188) Top1_base_per_class: 83.4026 (79.6223) 
Training Epoch: [147/1000] Step: [30 / 285] Batch Time: 0.1522 (0.1768) Data Time: 0.0179 (0.0434) Average Loss: 0.7632 (0.7164) Average CE Loss (Source):  0.7632 ( 0.7164) Learning Rate: 0.1000 (0.1000) Top1_base: 77.3438 (79.7917) Top1_base_per_class: 77.7778 (80.2615) 
Training Epoch: [147/1000] Step: [40 / 285] Batch Time: 0.1421 (0.1703) Data Time: 0.0107 (0.0371) Average Loss: 0.8213 (0.7053) Average CE Loss (Source):  0.8213 ( 0.7053) Learning Rate: 0.1000 (0.1000) Top1_base: 76.5625 (79.9805) Top1_base_per_class: 77.5962 (80.3846) 
Training Epoch: [147/1000] Step: [50 / 285] Batch Time: 0.2054 (0.1675) Data Time: 0.0711 (0.0342) Average Loss: 0.9108 (0.7164) Average CE Loss (Source):  0.9108 ( 0.7164) Learning Rate: 0.1000 (0.1000) Top1_base: 77.3438 (79.7656) Top1_base_per_class: 83.5965 (80.3623) 
Training Epoch: [147/1000] Step: [60 / 285] Batch Time: 0.1441 (0.1659) Data Time: 0.0106 (0.0325) Average Loss: 0.8059 (0.7124) Average CE Loss (Source):  0.8059 ( 0.7124) Learning Rate: 0.1000 (0.1000) Top1_base: 76.5625 (79.8438) Top1_base_per_class: 78.4242 (80.3415) 
Training Epoch: [147/1000] Step: [70 / 285] Batch Time: 0.1510 (0.1644) Data Time: 0.0163 (0.0310) Average Loss: 0.6470 (0.7234) Average CE Loss (Source):  0.6470 ( 0.7234) Learning Rate: 0.1000 (0.1000) Top1_base: 79.6875 (79.6205) Top1_base_per_class: 82.5265 (79.9460) 
Training Epoch: [147/1000] Step: [80 / 285] Batch Time: 0.1440 (0.1639) Data Time: 0.0111 (0.0304) Average Loss: 0.6434 (0.7159) Average CE Loss (Source):  0.6434 ( 0.7159) Learning Rate: 0.1000 (0.1000) Top1_base: 82.0312 (79.9707) Top1_base_per_class: 80.1786 (80.2294) 
Training Epoch: [147/1000] Step: [90 / 285] Batch Time: 0.1696 (0.1641) Data Time: 0.0348 (0.0306) Average Loss: 0.9638 (0.7186) Average CE Loss (Source):  0.9638 ( 0.7186) Learning Rate: 0.1000 (0.1000) Top1_base: 67.9688 (79.8264) Top1_base_per_class: 69.9180 (80.1501) 
Training Epoch: [147/1000] Step: [100 / 285] Batch Time: 0.1428 (0.1634) Data Time: 0.0112 (0.0299) Average Loss: 0.7521 (0.7202) Average CE Loss (Source):  0.7521 ( 0.7202) Learning Rate: 0.1000 (0.1000) Top1_base: 78.1250 (79.8672) Top1_base_per_class: 78.0000 (80.1959) 
Training Epoch: [147/1000] Step: [110 / 285] Batch Time: 0.1712 (0.1624) Data Time: 0.0370 (0.0289) Average Loss: 0.6621 (0.7249) Average CE Loss (Source):  0.6621 ( 0.7249) Learning Rate: 0.1000 (0.1000) Top1_base: 80.4688 (79.7585) Top1_base_per_class: 79.5572 (80.1208) 
Training Epoch: [147/1000] Step: [120 / 285] Batch Time: 0.1431 (0.1615) Data Time: 0.0116 (0.0280) Average Loss: 0.5221 (0.7228) Average CE Loss (Source):  0.5221 ( 0.7228) Learning Rate: 0.1000 (0.1000) Top1_base: 87.5000 (79.7721) Top1_base_per_class: 90.3274 (80.1525) 
Training Epoch: [147/1000] Step: [130 / 285] Batch Time: 0.1514 (0.1611) Data Time: 0.0184 (0.0277) Average Loss: 0.8612 (0.7251) Average CE Loss (Source):  0.8612 ( 0.7251) Learning Rate: 0.1000 (0.1000) Top1_base: 75.7812 (79.6635) Top1_base_per_class: 77.0909 (80.0778) 
Training Epoch: [147/1000] Step: [140 / 285] Batch Time: 0.1437 (0.1601) Data Time: 0.0118 (0.0267) Average Loss: 0.8057 (0.7267) Average CE Loss (Source):  0.8057 ( 0.7267) Learning Rate: 0.1000 (0.1000) Top1_base: 78.9062 (79.5982) Top1_base_per_class: 80.1515 (79.9723) 
Training Epoch: [147/1000] Step: [150 / 285] Batch Time: 0.1518 (0.1592) Data Time: 0.0181 (0.0258) Average Loss: 0.6598 (0.7259) Average CE Loss (Source):  0.6598 ( 0.7259) Learning Rate: 0.1000 (0.1000) Top1_base: 82.8125 (79.6667) Top1_base_per_class: 81.2121 (80.0068) 
Training Epoch: [147/1000] Step: [160 / 285] Batch Time: 0.1465 (0.1585) Data Time: 0.0119 (0.0251) Average Loss: 0.8765 (0.7315) Average CE Loss (Source):  0.8765 ( 0.7315) Learning Rate: 0.1000 (0.1000) Top1_base: 77.3438 (79.4971) Top1_base_per_class: 79.1369 (79.8667) 
Training Epoch: [147/1000] Step: [170 / 285] Batch Time: 0.2014 (0.1583) Data Time: 0.0683 (0.0249) Average Loss: 0.6346 (0.7302) Average CE Loss (Source):  0.6346 ( 0.7302) Learning Rate: 0.1000 (0.1000) Top1_base: 83.5938 (79.5542) Top1_base_per_class: 82.8704 (79.9177) 
Training Epoch: [147/1000] Step: [180 / 285] Batch Time: 0.1430 (0.1578) Data Time: 0.0101 (0.0245) Average Loss: 0.6850 (0.7326) Average CE Loss (Source):  0.6850 ( 0.7326) Learning Rate: 0.1000 (0.1000) Top1_base: 80.4688 (79.5095) Top1_base_per_class: 81.0819 (79.9135) 
Training Epoch: [147/1000] Step: [190 / 285] Batch Time: 0.1510 (0.1574) Data Time: 0.0174 (0.0240) Average Loss: 0.7077 (0.7343) Average CE Loss (Source):  0.7077 ( 0.7343) Learning Rate: 0.1000 (0.1000) Top1_base: 78.9062 (79.4613) Top1_base_per_class: 78.1579 (79.8664) 
Training Epoch: [147/1000] Step: [200 / 285] Batch Time: 0.1455 (0.1568) Data Time: 0.0115 (0.0235) Average Loss: 0.8144 (0.7370) Average CE Loss (Source):  0.8144 ( 0.7370) Learning Rate: 0.1000 (0.1000) Top1_base: 74.2188 (79.4062) Top1_base_per_class: 75.9568 (79.7981) 
Training Epoch: [147/1000] Step: [210 / 285] Batch Time: 0.1768 (0.1565) Data Time: 0.0464 (0.0232) Average Loss: 0.8087 (0.7376) Average CE Loss (Source):  0.8087 ( 0.7376) Learning Rate: 0.1000 (0.1000) Top1_base: 77.3438 (79.3824) Top1_base_per_class: 78.1790 (79.7886) 
Training Epoch: [147/1000] Step: [220 / 285] Batch Time: 0.1489 (0.1564) Data Time: 0.0132 (0.0231) Average Loss: 0.8275 (0.7369) Average CE Loss (Source):  0.8275 ( 0.7369) Learning Rate: 0.1000 (0.1000) Top1_base: 75.0000 (79.3608) Top1_base_per_class: 77.0760 (79.8627) 
Training Epoch: [147/1000] Step: [230 / 285] Batch Time: 0.1691 (0.1564) Data Time: 0.0378 (0.0232) Average Loss: 0.5453 (0.7372) Average CE Loss (Source):  0.5453 ( 0.7372) Learning Rate: 0.1000 (0.1000) Top1_base: 83.5938 (79.3750) Top1_base_per_class: 85.6725 (79.8040) 
Training Epoch: [147/1000] Step: [240 / 285] Batch Time: 0.1436 (0.1561) Data Time: 0.0118 (0.0228) Average Loss: 0.7726 (0.7373) Average CE Loss (Source):  0.7726 ( 0.7373) Learning Rate: 0.1000 (0.1000) Top1_base: 78.9062 (79.3066) Top1_base_per_class: 77.3585 (79.7154) 
Training Epoch: [147/1000] Step: [250 / 285] Batch Time: 0.1537 (0.1560) Data Time: 0.0199 (0.0227) Average Loss: 0.8494 (0.7402) Average CE Loss (Source):  0.8494 ( 0.7402) Learning Rate: 0.1000 (0.1000) Top1_base: 79.6875 (79.2875) Top1_base_per_class: 81.7398 (79.7331) 
Training Epoch: [147/1000] Step: [260 / 285] Batch Time: 0.1430 (0.1556) Data Time: 0.0102 (0.0224) Average Loss: 0.5285 (0.7409) Average CE Loss (Source):  0.5285 ( 0.7409) Learning Rate: 0.1000 (0.1000) Top1_base: 85.9375 (79.2638) Top1_base_per_class: 82.7576 (79.7080) 
Training Epoch: [147/1000] Step: [270 / 285] Batch Time: 0.1480 (0.1554) Data Time: 0.0167 (0.0221) Average Loss: 0.7730 (0.7438) Average CE Loss (Source):  0.7730 ( 0.7438) Learning Rate: 0.1000 (0.1000) Top1_base: 78.9062 (79.2014) Top1_base_per_class: 77.1605 (79.6598) 
Training Epoch: [147/1000] Step: [280 / 285] Batch Time: 0.1419 (0.1554) Data Time: 0.0123 (0.0222) Average Loss: 0.7297 (0.7440) Average CE Loss (Source):  0.7297 ( 0.7440) Learning Rate: 0.1000 (0.1000) Top1_base: 83.5938 (79.1908) Top1_base_per_class: 80.3846 (79.6407) 
Training Epoch: [148/1000] Step: [0] Batch Time: 0.1431 (0.1552) Data Time: 0.0105 (0.0220) Average Loss: 0.7577 (0.7438) Average CE Loss (Source):  0.7577 ( 0.7438) Learning Rate: 0.1000 (0.1000) Top1_base: 79.6875 (79.1721) Top1_base_per_class: 80.1150 (79.6133) 
 15%|█▍        | 148/1000 [1:55:13<10:54:57, 46.12s/it] 15%|█▍        | 149/1000 [1:55:57<10:46:57, 45.61s/it]Training Epoch: [148/1000] Step: [10 / 285] Batch Time: 0.1734 (0.2274) Data Time: 0.0405 (0.0939) Average Loss: 0.7200 (0.6771) Average CE Loss (Source):  0.7200 ( 0.6771) Learning Rate: 0.1000 (0.1000) Top1_base: 79.6875 (80.5469) Top1_base_per_class: 79.5198 (80.8270) 
Training Epoch: [148/1000] Step: [20 / 285] Batch Time: 0.1459 (0.1996) Data Time: 0.0110 (0.0663) Average Loss: 0.6834 (0.6674) Average CE Loss (Source):  0.6834 ( 0.6674) Learning Rate: 0.1000 (0.1000) Top1_base: 82.8125 (81.3672) Top1_base_per_class: 82.3270 (81.8142) 
Training Epoch: [148/1000] Step: [30 / 285] Batch Time: 0.1459 (0.1830) Data Time: 0.0145 (0.0497) Average Loss: 0.9754 (0.6874) Average CE Loss (Source):  0.9754 ( 0.6874) Learning Rate: 0.1000 (0.1000) Top1_base: 75.7812 (80.7812) Top1_base_per_class: 75.2830 (81.2504) 
Training Epoch: [148/1000] Step: [40 / 285] Batch Time: 0.1417 (0.1798) Data Time: 0.0104 (0.0466) Average Loss: 0.7720 (0.6882) Average CE Loss (Source):  0.7720 ( 0.6882) Learning Rate: 0.1000 (0.1000) Top1_base: 76.5625 (80.7031) Top1_base_per_class: 74.5238 (81.1738) 
Training Epoch: [148/1000] Step: [50 / 285] Batch Time: 0.1508 (0.1733) Data Time: 0.0183 (0.0402) Average Loss: 0.5586 (0.6977) Average CE Loss (Source):  0.5586 ( 0.6977) Learning Rate: 0.1000 (0.1000) Top1_base: 86.7188 (80.8594) Top1_base_per_class: 85.4923 (81.4287) 
Training Epoch: [148/1000] Step: [60 / 285] Batch Time: 0.1441 (0.1687) Data Time: 0.0104 (0.0356) Average Loss: 0.6885 (0.6918) Average CE Loss (Source):  0.6885 ( 0.6918) Learning Rate: 0.1000 (0.1000) Top1_base: 80.4688 (80.9505) Top1_base_per_class: 82.2012 (81.5088) 
Training Epoch: [148/1000] Step: [70 / 285] Batch Time: 0.3185 (0.1688) Data Time: 0.1875 (0.0357) Average Loss: 0.8283 (0.6992) Average CE Loss (Source):  0.8283 ( 0.6992) Learning Rate: 0.1000 (0.1000) Top1_base: 75.0000 (80.5804) Top1_base_per_class: 80.2542 (81.1714) 
Training Epoch: [148/1000] Step: [80 / 285] Batch Time: 0.1412 (0.1662) Data Time: 0.0124 (0.0333) Average Loss: 0.8083 (0.7012) Average CE Loss (Source):  0.8083 ( 0.7012) Learning Rate: 0.1000 (0.1000) Top1_base: 77.3438 (80.3125) Top1_base_per_class: 82.1242 (81.0589) 
Training Epoch: [148/1000] Step: [90 / 285] Batch Time: 0.1476 (0.1638) Data Time: 0.0154 (0.0310) Average Loss: 0.6823 (0.7036) Average CE Loss (Source):  0.6823 ( 0.7036) Learning Rate: 0.1000 (0.1000) Top1_base: 82.0312 (80.1997) Top1_base_per_class: 79.4577 (80.8917) 
Training Epoch: [148/1000] Step: [100 / 285] Batch Time: 0.1451 (0.1619) Data Time: 0.0111 (0.0292) Average Loss: 0.5092 (0.6996) Average CE Loss (Source):  0.5092 ( 0.6996) Learning Rate: 0.1000 (0.1000) Top1_base: 84.3750 (80.3750) Top1_base_per_class: 84.2727 (80.9945) 
Training Epoch: [148/1000] Step: [110 / 285] Batch Time: 0.1954 (0.1617) Data Time: 0.0639 (0.0291) Average Loss: 0.6728 (0.7030) Average CE Loss (Source):  0.6728 ( 0.7030) Learning Rate: 0.1000 (0.1000) Top1_base: 80.4688 (80.2983) Top1_base_per_class: 80.8479 (80.9125) 
Training Epoch: [148/1000] Step: [120 / 285] Batch Time: 0.1450 (0.1603) Data Time: 0.0146 (0.0278) Average Loss: 0.7109 (0.7084) Average CE Loss (Source):  0.7109 ( 0.7084) Learning Rate: 0.1000 (0.1000) Top1_base: 78.1250 (80.0651) Top1_base_per_class: 75.8456 (80.7103) 
Training Epoch: [148/1000] Step: [130 / 285] Batch Time: 0.1751 (0.1594) Data Time: 0.0422 (0.0268) Average Loss: 0.6498 (0.7093) Average CE Loss (Source):  0.6498 ( 0.7093) Learning Rate: 0.1000 (0.1000) Top1_base: 78.9062 (80.0180) Top1_base_per_class: 79.2560 (80.6343) 
Training Epoch: [148/1000] Step: [140 / 285] Batch Time: 0.1467 (0.1586) Data Time: 0.0122 (0.0261) Average Loss: 0.7696 (0.7104) Average CE Loss (Source):  0.7696 ( 0.7104) Learning Rate: 0.1000 (0.1000) Top1_base: 75.7812 (79.9330) Top1_base_per_class: 77.7299 (80.5388) 
Training Epoch: [148/1000] Step: [150 / 285] Batch Time: 0.1759 (0.1583) Data Time: 0.0445 (0.0258) Average Loss: 0.7461 (0.7099) Average CE Loss (Source):  0.7461 ( 0.7099) Learning Rate: 0.1000 (0.1000) Top1_base: 77.3438 (79.9635) Top1_base_per_class: 79.0909 (80.5460) 
Training Epoch: [148/1000] Step: [160 / 285] Batch Time: 0.1447 (0.1579) Data Time: 0.0119 (0.0253) Average Loss: 0.7522 (0.7112) Average CE Loss (Source):  0.7522 ( 0.7112) Learning Rate: 0.1000 (0.1000) Top1_base: 77.3438 (79.8438) Top1_base_per_class: 78.7500 (80.3542) 
Training Epoch: [148/1000] Step: [170 / 285] Batch Time: 0.2352 (0.1586) Data Time: 0.1021 (0.0260) Average Loss: 0.8274 (0.7094) Average CE Loss (Source):  0.8274 ( 0.7094) Learning Rate: 0.1000 (0.1000) Top1_base: 77.3438 (79.9127) Top1_base_per_class: 76.2573 (80.3826) 
Training Epoch: [148/1000] Step: [180 / 285] Batch Time: 0.1461 (0.1583) Data Time: 0.0133 (0.0258) Average Loss: 0.5046 (0.7105) Average CE Loss (Source):  0.5046 ( 0.7105) Learning Rate: 0.1000 (0.1000) Top1_base: 82.8125 (79.8741) Top1_base_per_class: 83.9891 (80.3212) 
Training Epoch: [148/1000] Step: [190 / 285] Batch Time: 0.1567 (0.1578) Data Time: 0.0245 (0.0252) Average Loss: 0.7004 (0.7150) Average CE Loss (Source):  0.7004 ( 0.7150) Learning Rate: 0.1000 (0.1000) Top1_base: 77.3438 (79.8067) Top1_base_per_class: 77.2881 (80.2665) 
Training Epoch: [148/1000] Step: [200 / 285] Batch Time: 0.1473 (0.1580) Data Time: 0.0137 (0.0255) Average Loss: 0.6883 (0.7160) Average CE Loss (Source):  0.6883 ( 0.7160) Learning Rate: 0.1000 (0.1000) Top1_base: 82.0312 (79.7266) Top1_base_per_class: 82.7243 (80.1771) 
Training Epoch: [148/1000] Step: [210 / 285] Batch Time: 0.1968 (0.1587) Data Time: 0.0642 (0.0261) Average Loss: 0.4359 (0.7129) Average CE Loss (Source):  0.4359 ( 0.7129) Learning Rate: 0.1000 (0.1000) Top1_base: 85.1562 (79.8363) Top1_base_per_class: 87.6836 (80.2931) 
Training Epoch: [148/1000] Step: [220 / 285] Batch Time: 0.1441 (0.1583) Data Time: 0.0103 (0.0258) Average Loss: 0.6626 (0.7123) Average CE Loss (Source):  0.6626 ( 0.7123) Learning Rate: 0.1000 (0.1000) Top1_base: 81.2500 (79.8544) Top1_base_per_class: 82.6437 (80.3143) 
Training Epoch: [148/1000] Step: [230 / 285] Batch Time: 0.1544 (0.1578) Data Time: 0.0235 (0.0253) Average Loss: 0.7498 (0.7170) Average CE Loss (Source):  0.7498 ( 0.7170) Learning Rate: 0.1000 (0.1000) Top1_base: 78.9062 (79.7520) Top1_base_per_class: 82.1053 (80.2539) 
Training Epoch: [148/1000] Step: [240 / 285] Batch Time: 0.1438 (0.1574) Data Time: 0.0109 (0.0249) Average Loss: 0.8276 (0.7208) Average CE Loss (Source):  0.8276 ( 0.7208) Learning Rate: 0.1000 (0.1000) Top1_base: 78.9062 (79.6842) Top1_base_per_class: 76.6667 (80.1456) 
Training Epoch: [148/1000] Step: [250 / 285] Batch Time: 0.1478 (0.1570) Data Time: 0.0157 (0.0245) Average Loss: 0.7393 (0.7209) Average CE Loss (Source):  0.7393 ( 0.7209) Learning Rate: 0.1000 (0.1000) Top1_base: 78.9062 (79.6625) Top1_base_per_class: 79.3711 (80.1329) 
Training Epoch: [148/1000] Step: [260 / 285] Batch Time: 0.1445 (0.1566) Data Time: 0.0125 (0.0240) Average Loss: 1.1066 (0.7233) Average CE Loss (Source):  1.1066 ( 0.7233) Learning Rate: 0.1000 (0.1000) Top1_base: 67.9688 (79.5643) Top1_base_per_class: 70.0000 (80.0355) 
Training Epoch: [148/1000] Step: [270 / 285] Batch Time: 0.1487 (0.1562) Data Time: 0.0161 (0.0236) Average Loss: 0.7328 (0.7255) Average CE Loss (Source):  0.7328 ( 0.7255) Learning Rate: 0.1000 (0.1000) Top1_base: 78.1250 (79.4821) Top1_base_per_class: 81.6379 (79.9736) 
Training Epoch: [148/1000] Step: [280 / 285] Batch Time: 0.1461 (0.1558) Data Time: 0.0112 (0.0233) Average Loss: 0.6969 (0.7262) Average CE Loss (Source):  0.6969 ( 0.7262) Learning Rate: 0.1000 (0.1000) Top1_base: 78.1250 (79.4280) Top1_base_per_class: 80.9290 (79.8998) 
Training Epoch: [149/1000] Step: [0] Batch Time: 0.1456 (0.1557) Data Time: 0.0125 (0.0231) Average Loss: 0.7387 (0.7276) Average CE Loss (Source):  0.7387 ( 0.7276) Learning Rate: 0.1000 (0.1000) Top1_base: 76.5625 (79.3586) Top1_base_per_class: 78.3417 (79.8516) 
Training Epoch: [149/1000] Step: [10 / 285] Batch Time: 0.1469 (0.2400) Data Time: 0.0121 (0.1069) Average Loss: 0.5727 (0.6860) Average CE Loss (Source):  0.5727 ( 0.6860) Learning Rate: 0.1000 (0.1000) Top1_base: 82.8125 (81.3281) Top1_base_per_class: 84.0000 (81.0512) 
Training Epoch: [149/1000] Step: [20 / 285] Batch Time: 0.1457 (0.1965) Data Time: 0.0136 (0.0638) Average Loss: 0.8851 (0.7136) Average CE Loss (Source):  0.8851 ( 0.7136) Learning Rate: 0.1000 (0.1000) Top1_base: 75.7812 (80.8984) Top1_base_per_class: 77.1818 (81.0321) 
Training Epoch: [149/1000] Step: [30 / 285] Batch Time: 0.1474 (0.1826) Data Time: 0.0130 (0.0498) Average Loss: 0.5111 (0.6861) Average CE Loss (Source):  0.5111 ( 0.6861) Learning Rate: 0.1000 (0.1000) Top1_base: 85.1562 (81.0417) Top1_base_per_class: 86.6624 (81.2351) 
Training Epoch: [149/1000] Step: [40 / 285] Batch Time: 0.1431 (0.1751) Data Time: 0.0120 (0.0423) Average Loss: 0.9456 (0.7069) Average CE Loss (Source):  0.9456 ( 0.7069) Learning Rate: 0.1000 (0.1000) Top1_base: 68.7500 (80.5469) Top1_base_per_class: 72.5397 (80.8102) 
Training Epoch: [149/1000] Step: [50 / 285] Batch Time: 0.1426 (0.1726) Data Time: 0.0126 (0.0400) Average Loss: 0.5801 (0.7027) Average CE Loss (Source):  0.5801 ( 0.7027) Learning Rate: 0.1000 (0.1000) Top1_base: 83.5938 (80.4531) Top1_base_per_class: 83.4849 (80.9353) 
Training Epoch: [149/1000] Step: [60 / 285] Batch Time: 0.1430 (0.1697) Data Time: 0.0117 (0.0371) Average Loss: 0.7832 (0.7150) Average CE Loss (Source):  0.7832 ( 0.7150) Learning Rate: 0.1000 (0.1000) Top1_base: 77.3438 (80.1432) Top1_base_per_class: 81.6458 (80.7447) 
Training Epoch: [149/1000] Step: [70 / 285] Batch Time: 0.1455 (0.1677) Data Time: 0.0119 (0.0350) Average Loss: 0.6416 (0.7131) Average CE Loss (Source):  0.6416 ( 0.7131) Learning Rate: 0.1000 (0.1000) Top1_base: 81.2500 (80.0335) Top1_base_per_class: 82.5152 (80.6693) 
Training Epoch: [149/1000] Step: [80 / 285] Batch Time: 0.1430 (0.1649) Data Time: 0.0117 (0.0324) Average Loss: 0.6577 (0.7165) Average CE Loss (Source):  0.6577 ( 0.7165) Learning Rate: 0.1000 (0.1000) Top1_base: 79.6875 (80.0000) Top1_base_per_class: 82.1698 (80.6798) 
Training Epoch: [149/1000] Step: [90 / 285] Batch Time: 0.1459 (0.1634) Data Time: 0.0120 (0.0308) Average Loss: 0.6812 (0.7200) Average CE Loss (Source):  0.6812 ( 0.7200) Learning Rate: 0.1000 (0.1000) Top1_base: 82.0312 (79.9132) Top1_base_per_class: 84.9107 (80.5967) 
Training Epoch: [149/1000] Step: [100 / 285] Batch Time: 0.1435 (0.1620) Data Time: 0.0129 (0.0294) Average Loss: 0.7626 (0.7220) Average CE Loss (Source):  0.7626 ( 0.7220) Learning Rate: 0.1000 (0.1000) Top1_base: 77.3438 (79.8672) Top1_base_per_class: 80.0298 (80.5635) 
Training Epoch: [149/1000] Step: [110 / 285] Batch Time: 0.1459 (0.1616) Data Time: 0.0121 (0.0290) Average Loss: 0.5922 (0.7198) Average CE Loss (Source):  0.5922 ( 0.7198) Learning Rate: 0.1000 (0.1000) Top1_base: 85.1562 (79.9574) Top1_base_per_class: 84.4253 (80.6894) 
Training Epoch: [149/1000] Step: [120 / 285] Batch Time: 0.1447 (0.1602) Data Time: 0.0121 (0.0276) Average Loss: 0.8820 (0.7214) Average CE Loss (Source):  0.8820 ( 0.7214) Learning Rate: 0.1000 (0.1000) Top1_base: 76.5625 (79.9349) Top1_base_per_class: 75.2976 (80.7467) 
Training Epoch: [149/1000] Step: [130 / 285] Batch Time: 0.1456 (0.1600) Data Time: 0.0120 (0.0274) Average Loss: 0.6234 (0.7225) Average CE Loss (Source):  0.6234 ( 0.7225) Learning Rate: 0.1000 (0.1000) Top1_base: 82.8125 (79.9159) Top1_base_per_class: 83.2099 (80.6416) 
Training Epoch: [149/1000] Step: [140 / 285] Batch Time: 0.1698 (0.1595) Data Time: 0.0380 (0.0269) Average Loss: 0.7951 (0.7239) Average CE Loss (Source):  0.7951 ( 0.7239) Learning Rate: 0.1000 (0.1000) Top1_base: 82.8125 (79.8549) Top1_base_per_class: 83.9942 (80.5769) 
Training Epoch: [149/1000] Step: [150 / 285] Batch Time: 0.1453 (0.1592) Data Time: 0.0128 (0.0266) Average Loss: 0.6533 (0.7233) Average CE Loss (Source):  0.6533 ( 0.7233) Learning Rate: 0.1000 (0.1000) Top1_base: 81.2500 (79.9375) Top1_base_per_class: 80.9649 (80.6566) 
Training Epoch: [149/1000] Step: [160 / 285] Batch Time: 0.1693 (0.1588) Data Time: 0.0375 (0.0263) Average Loss: 0.8434 (0.7280) Average CE Loss (Source):  0.8434 ( 0.7280) Learning Rate: 0.1000 (0.1000) Top1_base: 79.6875 (79.7656) Top1_base_per_class: 83.3041 (80.4876) 
Training Epoch: [149/1000] Step: [170 / 285] Batch Time: 0.1471 (0.1583) Data Time: 0.0123 (0.0257) Average Loss: 0.8700 (0.7352) Average CE Loss (Source):  0.8700 ( 0.7352) Learning Rate: 0.1000 (0.1000) Top1_base: 82.0312 (79.5083) Top1_base_per_class: 82.0115 (80.2312) 
Training Epoch: [149/1000] Step: [180 / 285] Batch Time: 0.2007 (0.1584) Data Time: 0.0691 (0.0259) Average Loss: 1.0664 (0.7374) Average CE Loss (Source):  1.0664 ( 0.7374) Learning Rate: 0.1000 (0.1000) Top1_base: 69.5312 (79.4705) Top1_base_per_class: 70.5203 (80.1917) 
Training Epoch: [149/1000] Step: [190 / 285] Batch Time: 0.1418 (0.1580) Data Time: 0.0107 (0.0255) Average Loss: 0.7758 (0.7404) Average CE Loss (Source):  0.7758 ( 0.7404) Learning Rate: 0.1000 (0.1000) Top1_base: 77.3438 (79.3914) Top1_base_per_class: 77.4722 (80.1023) 
Training Epoch: [149/1000] Step: [200 / 285] Batch Time: 0.3218 (0.1589) Data Time: 0.1884 (0.0264) Average Loss: 0.6419 (0.7411) Average CE Loss (Source):  0.6419 ( 0.7411) Learning Rate: 0.1000 (0.1000) Top1_base: 82.0312 (79.3750) Top1_base_per_class: 80.5059 (80.0678) 
Training Epoch: [149/1000] Step: [210 / 285] Batch Time: 0.1480 (0.1584) Data Time: 0.0137 (0.0260) Average Loss: 0.8040 (0.7409) Average CE Loss (Source):  0.8040 ( 0.7409) Learning Rate: 0.1000 (0.1000) Top1_base: 78.1250 (79.3564) Top1_base_per_class: 81.7544 (79.9854) 
Training Epoch: [149/1000] Step: [220 / 285] Batch Time: 0.2103 (0.1585) Data Time: 0.0791 (0.0260) Average Loss: 0.6765 (0.7414) Average CE Loss (Source):  0.6765 ( 0.7414) Learning Rate: 0.1000 (0.1000) Top1_base: 83.5938 (79.3040) Top1_base_per_class: 82.3343 (79.9434) 
Training Epoch: [149/1000] Step: [230 / 285] Batch Time: 0.1490 (0.1581) Data Time: 0.0143 (0.0256) Average Loss: 0.6690 (0.7422) Average CE Loss (Source):  0.6690 ( 0.7422) Learning Rate: 0.1000 (0.1000) Top1_base: 82.8125 (79.2867) Top1_base_per_class: 83.7853 (79.9402) 
Training Epoch: [149/1000] Step: [240 / 285] Batch Time: 0.1509 (0.1580) Data Time: 0.0174 (0.0256) Average Loss: 0.8235 (0.7404) Average CE Loss (Source):  0.8235 ( 0.7404) Learning Rate: 0.1000 (0.1000) Top1_base: 78.1250 (79.2969) Top1_base_per_class: 81.8079 (80.0005) 
Training Epoch: [149/1000] Step: [250 / 285] Batch Time: 0.1420 (0.1576) Data Time: 0.0108 (0.0250) Average Loss: 0.6935 (0.7428) Average CE Loss (Source):  0.6935 ( 0.7428) Learning Rate: 0.1000 (0.1000) Top1_base: 82.8125 (79.2250) Top1_base_per_class: 82.8869 (79.9504) 
Training Epoch: [149/1000] Step: [260 / 285] Batch Time: 0.1508 (0.1574) Data Time: 0.0167 (0.0248) Average Loss: 0.7612 (0.7421) Average CE Loss (Source):  0.7612 ( 0.7421) Learning Rate: 0.1000 (0.1000) Top1_base: 78.1250 (79.2488) Top1_base_per_class: 77.9598 (79.9271) 
Training Epoch: [149/1000] Step: [270 / 285] Batch Time: 0.1501 (0.1571) Data Time: 0.0136 (0.0244) Average Loss: 0.6544 (0.7452) Average CE Loss (Source):  0.6544 ( 0.7452) Learning Rate: 0.1000 (0.1000) Top1_base: 79.6875 (79.0943) Top1_base_per_class: 77.5817 (79.7536) 
Training Epoch: [149/1000] Step: [280 / 285] Batch Time: 0.1506 (0.1570) Data Time: 0.0158 (0.0242) Average Loss: 0.8447 (0.7454) Average CE Loss (Source):  0.8447 ( 0.7454) Learning Rate: 0.1000 (0.1000) Top1_base: 75.7812 (79.1044) Top1_base_per_class: 78.3642 (79.7633) 
Training Epoch: [150/1000] Step: [0] Batch Time: 0.1465 (0.1571) Data Time: 0.0105 (0.0242) Average Loss: 0.6767 (0.7461) Average CE Loss (Source):  0.6767 ( 0.7461) Learning Rate: 0.1000 (0.1000) Top1_base: 81.2500 (79.0789) Top1_base_per_class: 83.7427 (79.7332) 
 15%|█▌        | 150/1000 [1:56:45<10:54:36, 46.21s/it] 15%|█▌        | 151/1000 [1:57:30<10:48:04, 45.80s/it]Training Epoch: [150/1000] Step: [10 / 285] Batch Time: 0.1427 (0.2258) Data Time: 0.0116 (0.0930) Average Loss: 0.8302 (0.7212) Average CE Loss (Source):  0.8302 ( 0.7212) Learning Rate: 0.1000 (0.1000) Top1_base: 76.5625 (79.6875) Top1_base_per_class: 77.3099 (80.0877) 
Training Epoch: [150/1000] Step: [20 / 285] Batch Time: 0.1483 (0.1922) Data Time: 0.0141 (0.0591) Average Loss: 0.5555 (0.6987) Average CE Loss (Source):  0.5555 ( 0.6987) Learning Rate: 0.1000 (0.1000) Top1_base: 86.7188 (80.7812) Top1_base_per_class: 85.7062 (81.1894) 
Training Epoch: [150/1000] Step: [30 / 285] Batch Time: 0.1664 (0.1807) Data Time: 0.0337 (0.0475) Average Loss: 0.6826 (0.7030) Average CE Loss (Source):  0.6826 ( 0.7030) Learning Rate: 0.1000 (0.1000) Top1_base: 82.0312 (80.1302) Top1_base_per_class: 82.3270 (80.4206) 
Training Epoch: [150/1000] Step: [40 / 285] Batch Time: 0.1454 (0.1736) Data Time: 0.0132 (0.0404) Average Loss: 0.5849 (0.6913) Average CE Loss (Source):  0.5849 ( 0.6913) Learning Rate: 0.1000 (0.1000) Top1_base: 82.8125 (80.4297) Top1_base_per_class: 81.7857 (80.7942) 
Training Epoch: [150/1000] Step: [50 / 285] Batch Time: 0.1440 (0.1689) Data Time: 0.0127 (0.0357) Average Loss: 0.6026 (0.6961) Average CE Loss (Source):  0.6026 ( 0.6961) Learning Rate: 0.1000 (0.1000) Top1_base: 84.3750 (80.3906) Top1_base_per_class: 84.3410 (80.9426) 
Training Epoch: [150/1000] Step: [60 / 285] Batch Time: 0.1500 (0.1665) Data Time: 0.0175 (0.0332) Average Loss: 0.7086 (0.7029) Average CE Loss (Source):  0.7086 ( 0.7029) Learning Rate: 0.1000 (0.1000) Top1_base: 81.2500 (80.2344) Top1_base_per_class: 84.4025 (80.8974) 
Training Epoch: [150/1000] Step: [70 / 285] Batch Time: 0.1523 (0.1662) Data Time: 0.0187 (0.0329) Average Loss: 0.8234 (0.7082) Average CE Loss (Source):  0.8234 ( 0.7082) Learning Rate: 0.1000 (0.1000) Top1_base: 78.1250 (80.1004) Top1_base_per_class: 79.7619 (80.6297) 
Training Epoch: [150/1000] Step: [80 / 285] Batch Time: 0.1461 (0.1658) Data Time: 0.0133 (0.0326) Average Loss: 0.6374 (0.7178) Average CE Loss (Source):  0.6374 ( 0.7178) Learning Rate: 0.1000 (0.1000) Top1_base: 82.8125 (79.9512) Top1_base_per_class: 84.6726 (80.4998) 
Training Epoch: [150/1000] Step: [90 / 285] Batch Time: 0.1732 (0.1640) Data Time: 0.0415 (0.0308) Average Loss: 0.6454 (0.7216) Average CE Loss (Source):  0.6454 ( 0.7216) Learning Rate: 0.1000 (0.1000) Top1_base: 82.8125 (79.8438) Top1_base_per_class: 83.3648 (80.3496) 
Training Epoch: [150/1000] Step: [100 / 285] Batch Time: 0.1862 (0.1633) Data Time: 0.0511 (0.0301) Average Loss: 0.7466 (0.7167) Average CE Loss (Source):  0.7466 ( 0.7167) Learning Rate: 0.1000 (0.1000) Top1_base: 79.6875 (79.9766) Top1_base_per_class: 79.7821 (80.5462) 
Training Epoch: [150/1000] Step: [110 / 285] Batch Time: 0.1749 (0.1626) Data Time: 0.0441 (0.0295) Average Loss: 0.7664 (0.7140) Average CE Loss (Source):  0.7664 ( 0.7140) Learning Rate: 0.1000 (0.1000) Top1_base: 78.1250 (80.0355) Top1_base_per_class: 78.7654 (80.5576) 
Training Epoch: [150/1000] Step: [120 / 285] Batch Time: 0.1488 (0.1619) Data Time: 0.0150 (0.0288) Average Loss: 0.9280 (0.7184) Average CE Loss (Source):  0.9280 ( 0.7184) Learning Rate: 0.1000 (0.1000) Top1_base: 76.5625 (79.9284) Top1_base_per_class: 77.1469 (80.4462) 
Training Epoch: [150/1000] Step: [130 / 285] Batch Time: 0.1486 (0.1614) Data Time: 0.0175 (0.0283) Average Loss: 0.6649 (0.7191) Average CE Loss (Source):  0.6649 ( 0.7191) Learning Rate: 0.1000 (0.1000) Top1_base: 76.5625 (79.8498) Top1_base_per_class: 74.8918 (80.3695) 
Training Epoch: [150/1000] Step: [140 / 285] Batch Time: 0.1435 (0.1607) Data Time: 0.0122 (0.0276) Average Loss: 0.8922 (0.7234) Average CE Loss (Source):  0.8922 ( 0.7234) Learning Rate: 0.1000 (0.1000) Top1_base: 72.6562 (79.8047) Top1_base_per_class: 73.3013 (80.2969) 
Training Epoch: [150/1000] Step: [150 / 285] Batch Time: 0.1633 (0.1601) Data Time: 0.0313 (0.0271) Average Loss: 0.6242 (0.7227) Average CE Loss (Source):  0.6242 ( 0.7227) Learning Rate: 0.1000 (0.1000) Top1_base: 81.2500 (79.8229) Top1_base_per_class: 83.8596 (80.3269) 
Training Epoch: [150/1000] Step: [160 / 285] Batch Time: 0.1438 (0.1601) Data Time: 0.0125 (0.0271) Average Loss: 0.6096 (0.7225) Average CE Loss (Source):  0.6096 ( 0.7225) Learning Rate: 0.1000 (0.1000) Top1_base: 82.8125 (79.8291) Top1_base_per_class: 81.8421 (80.3046) 
Training Epoch: [150/1000] Step: [170 / 285] Batch Time: 0.1483 (0.1598) Data Time: 0.0165 (0.0269) Average Loss: 0.8573 (0.7210) Average CE Loss (Source):  0.8573 ( 0.7210) Learning Rate: 0.1000 (0.1000) Top1_base: 73.4375 (79.8392) Top1_base_per_class: 77.1818 (80.3563) 
Training Epoch: [150/1000] Step: [180 / 285] Batch Time: 0.1463 (0.1592) Data Time: 0.0117 (0.0264) Average Loss: 1.1956 (0.7284) Average CE Loss (Source):  1.1956 ( 0.7284) Learning Rate: 0.1000 (0.1000) Top1_base: 75.0000 (79.6745) Top1_base_per_class: 77.9806 (80.2494) 
Training Epoch: [150/1000] Step: [190 / 285] Batch Time: 0.1810 (0.1590) Data Time: 0.0491 (0.0261) Average Loss: 0.6181 (0.7309) Average CE Loss (Source):  0.6181 ( 0.7309) Learning Rate: 0.1000 (0.1000) Top1_base: 80.4688 (79.5724) Top1_base_per_class: 82.3360 (80.1448) 
Training Epoch: [150/1000] Step: [200 / 285] Batch Time: 0.1423 (0.1590) Data Time: 0.0109 (0.0261) Average Loss: 0.7636 (0.7288) Average CE Loss (Source):  0.7636 ( 0.7288) Learning Rate: 0.1000 (0.1000) Top1_base: 80.4688 (79.6133) Top1_base_per_class: 84.1212 (80.2027) 
Training Epoch: [150/1000] Step: [210 / 285] Batch Time: 0.1733 (0.1585) Data Time: 0.0422 (0.0257) Average Loss: 0.7066 (0.7319) Average CE Loss (Source):  0.7066 ( 0.7319) Learning Rate: 0.1000 (0.1000) Top1_base: 80.4688 (79.5685) Top1_base_per_class: 83.3929 (80.1332) 
Training Epoch: [150/1000] Step: [220 / 285] Batch Time: 0.1480 (0.1581) Data Time: 0.0150 (0.0253) Average Loss: 0.7929 (0.7322) Average CE Loss (Source):  0.7929 ( 0.7322) Learning Rate: 0.1000 (0.1000) Top1_base: 75.0000 (79.5170) Top1_base_per_class: 76.6818 (80.1197) 
Training Epoch: [150/1000] Step: [230 / 285] Batch Time: 0.1921 (0.1580) Data Time: 0.0590 (0.0252) Average Loss: 0.7096 (0.7317) Average CE Loss (Source):  0.7096 ( 0.7317) Learning Rate: 0.1000 (0.1000) Top1_base: 82.0312 (79.5041) Top1_base_per_class: 81.9355 (80.1021) 
Training Epoch: [150/1000] Step: [240 / 285] Batch Time: 0.1452 (0.1577) Data Time: 0.0131 (0.0249) Average Loss: 0.8188 (0.7347) Average CE Loss (Source):  0.8188 ( 0.7347) Learning Rate: 0.1000 (0.1000) Top1_base: 78.1250 (79.4010) Top1_base_per_class: 79.0606 (80.0210) 
Training Epoch: [150/1000] Step: [250 / 285] Batch Time: 0.2033 (0.1575) Data Time: 0.0716 (0.0247) Average Loss: 0.7020 (0.7378) Average CE Loss (Source):  0.7020 ( 0.7378) Learning Rate: 0.1000 (0.1000) Top1_base: 77.3438 (79.2812) Top1_base_per_class: 76.1420 (79.8800) 
Training Epoch: [150/1000] Step: [260 / 285] Batch Time: 0.1482 (0.1573) Data Time: 0.0140 (0.0245) Average Loss: 0.6760 (0.7346) Average CE Loss (Source):  0.6760 ( 0.7346) Learning Rate: 0.1000 (0.1000) Top1_base: 80.4688 (79.3450) Top1_base_per_class: 78.5088 (79.9327) 
Training Epoch: [150/1000] Step: [270 / 285] Batch Time: 0.1627 (0.1573) Data Time: 0.0316 (0.0245) Average Loss: 0.8340 (0.7343) Average CE Loss (Source):  0.8340 ( 0.7343) Learning Rate: 0.1000 (0.1000) Top1_base: 73.4375 (79.3576) Top1_base_per_class: 77.2123 (79.9023) 
Training Epoch: [150/1000] Step: [280 / 285] Batch Time: 0.1438 (0.1571) Data Time: 0.0123 (0.0243) Average Loss: 0.7720 (0.7368) Average CE Loss (Source):  0.7720 ( 0.7368) Learning Rate: 0.1000 (0.1000) Top1_base: 79.6875 (79.3248) Top1_base_per_class: 77.2756 (79.8917) 
Training Epoch: [151/1000] Step: [0] Batch Time: 0.1425 (0.1571) Data Time: 0.0111 (0.0244) Average Loss: 0.6838 (0.7367) Average CE Loss (Source):  0.6838 ( 0.7367) Learning Rate: 0.1000 (0.1000) Top1_base: 79.6875 (79.3284) Top1_base_per_class: 79.3965 (79.9237) 
Training Epoch: [151/1000] Step: [10 / 285] Batch Time: 0.1489 (0.2366) Data Time: 0.0129 (0.1036) Average Loss: 0.6310 (0.6583) Average CE Loss (Source):  0.6310 ( 0.6583) Learning Rate: 0.1000 (0.1000) Top1_base: 81.2500 (80.6250) Top1_base_per_class: 82.2989 (81.0229) 
Training Epoch: [151/1000] Step: [20 / 285] Batch Time: 0.1459 (0.1969) Data Time: 0.0116 (0.0636) Average Loss: 0.6479 (0.6789) Average CE Loss (Source):  0.6479 ( 0.6789) Learning Rate: 0.1000 (0.1000) Top1_base: 82.8125 (80.0781) Top1_base_per_class: 83.7719 (79.8900) 
Training Epoch: [151/1000] Step: [30 / 285] Batch Time: 0.1493 (0.1847) Data Time: 0.0125 (0.0508) Average Loss: 0.5741 (0.6591) Average CE Loss (Source):  0.5741 ( 0.6591) Learning Rate: 0.1000 (0.1000) Top1_base: 84.3750 (80.6771) Top1_base_per_class: 83.3626 (80.8641) 
Training Epoch: [151/1000] Step: [40 / 285] Batch Time: 0.1429 (0.1779) Data Time: 0.0097 (0.0438) Average Loss: 0.6433 (0.6482) Average CE Loss (Source):  0.6433 ( 0.6482) Learning Rate: 0.1000 (0.1000) Top1_base: 80.4688 (81.1719) Top1_base_per_class: 82.2222 (81.6172) 
Training Epoch: [151/1000] Step: [50 / 285] Batch Time: 0.1429 (0.1722) Data Time: 0.0128 (0.0384) Average Loss: 0.7399 (0.6590) Average CE Loss (Source):  0.7399 ( 0.6590) Learning Rate: 0.1000 (0.1000) Top1_base: 78.1250 (81.1250) Top1_base_per_class: 79.1051 (81.6107) 
Training Epoch: [151/1000] Step: [60 / 285] Batch Time: 0.1457 (0.1689) Data Time: 0.0132 (0.0354) Average Loss: 0.6122 (0.6711) Average CE Loss (Source):  0.6122 ( 0.6711) Learning Rate: 0.1000 (0.1000) Top1_base: 84.3750 (81.0156) Top1_base_per_class: 85.5357 (81.4989) 
Training Epoch: [151/1000] Step: [70 / 285] Batch Time: 0.1512 (0.1665) Data Time: 0.0152 (0.0328) Average Loss: 0.8010 (0.6713) Average CE Loss (Source):  0.8010 ( 0.6713) Learning Rate: 0.1000 (0.1000) Top1_base: 80.4688 (81.0379) Top1_base_per_class: 79.0556 (81.5854) 
Training Epoch: [151/1000] Step: [80 / 285] Batch Time: 0.1452 (0.1641) Data Time: 0.0104 (0.0303) Average Loss: 0.5712 (0.6793) Average CE Loss (Source):  0.5712 ( 0.6793) Learning Rate: 0.1000 (0.1000) Top1_base: 83.5938 (80.8203) Top1_base_per_class: 82.7869 (81.3947) 
Training Epoch: [151/1000] Step: [90 / 285] Batch Time: 0.1527 (0.1632) Data Time: 0.0164 (0.0292) Average Loss: 0.8605 (0.6923) Average CE Loss (Source):  0.8605 ( 0.6923) Learning Rate: 0.1000 (0.1000) Top1_base: 74.2188 (80.5035) Top1_base_per_class: 75.6322 (81.1380) 
Training Epoch: [151/1000] Step: [100 / 285] Batch Time: 0.1452 (0.1617) Data Time: 0.0111 (0.0276) Average Loss: 0.8201 (0.6943) Average CE Loss (Source):  0.8201 ( 0.6943) Learning Rate: 0.1000 (0.1000) Top1_base: 75.7812 (80.4922) Top1_base_per_class: 73.9697 (81.1842) 
Training Epoch: [151/1000] Step: [110 / 285] Batch Time: 0.2456 (0.1615) Data Time: 0.1164 (0.0274) Average Loss: 0.7700 (0.6963) Average CE Loss (Source):  0.7700 ( 0.6963) Learning Rate: 0.1000 (0.1000) Top1_base: 77.3438 (80.3480) Top1_base_per_class: 76.9524 (80.9731) 
Training Epoch: [151/1000] Step: [120 / 285] Batch Time: 0.1457 (0.1610) Data Time: 0.0109 (0.0270) Average Loss: 0.6347 (0.6952) Average CE Loss (Source):  0.6347 ( 0.6952) Learning Rate: 0.1000 (0.1000) Top1_base: 85.9375 (80.4818) Top1_base_per_class: 86.1111 (80.9765) 
Training Epoch: [151/1000] Step: [130 / 285] Batch Time: 0.1489 (0.1601) Data Time: 0.0183 (0.0259) Average Loss: 0.7826 (0.6971) Average CE Loss (Source):  0.7826 ( 0.6971) Learning Rate: 0.1000 (0.1000) Top1_base: 78.9062 (80.4507) Top1_base_per_class: 80.8929 (80.9778) 
Training Epoch: [151/1000] Step: [140 / 285] Batch Time: 0.1452 (0.1592) Data Time: 0.0115 (0.0250) Average Loss: 0.7752 (0.6984) Average CE Loss (Source):  0.7752 ( 0.6984) Learning Rate: 0.1000 (0.1000) Top1_base: 75.7812 (80.3237) Top1_base_per_class: 76.8129 (80.8583) 
Training Epoch: [151/1000] Step: [150 / 285] Batch Time: 0.1470 (0.1585) Data Time: 0.0157 (0.0243) Average Loss: 0.7697 (0.7005) Average CE Loss (Source):  0.7697 ( 0.7005) Learning Rate: 0.1000 (0.1000) Top1_base: 81.2500 (80.3385) Top1_base_per_class: 83.6012 (80.9420) 
Training Epoch: [151/1000] Step: [160 / 285] Batch Time: 0.1424 (0.1582) Data Time: 0.0106 (0.0241) Average Loss: 0.7318 (0.7022) Average CE Loss (Source):  0.7318 ( 0.7022) Learning Rate: 0.1000 (0.1000) Top1_base: 78.1250 (80.2637) Top1_base_per_class: 80.0893 (80.7755) 
Training Epoch: [151/1000] Step: [170 / 285] Batch Time: 0.1497 (0.1579) Data Time: 0.0163 (0.0238) Average Loss: 0.6410 (0.7057) Average CE Loss (Source):  0.6410 ( 0.7057) Learning Rate: 0.1000 (0.1000) Top1_base: 85.1562 (80.1884) Top1_base_per_class: 83.1515 (80.6273) 
Training Epoch: [151/1000] Step: [180 / 285] Batch Time: 0.1496 (0.1580) Data Time: 0.0141 (0.0241) Average Loss: 0.6861 (0.7080) Average CE Loss (Source):  0.6861 ( 0.7080) Learning Rate: 0.1000 (0.1000) Top1_base: 79.6875 (80.0694) Top1_base_per_class: 82.5744 (80.5518) 
Training Epoch: [151/1000] Step: [190 / 285] Batch Time: 0.1712 (0.1580) Data Time: 0.0346 (0.0240) Average Loss: 0.8089 (0.7071) Average CE Loss (Source):  0.8089 ( 0.7071) Learning Rate: 0.1000 (0.1000) Top1_base: 75.0000 (80.1439) Top1_base_per_class: 77.1795 (80.6262) 
Training Epoch: [151/1000] Step: [200 / 285] Batch Time: 0.1452 (0.1574) Data Time: 0.0139 (0.0234) Average Loss: 0.7454 (0.7079) Average CE Loss (Source):  0.7454 ( 0.7079) Learning Rate: 0.1000 (0.1000) Top1_base: 77.3438 (80.1289) Top1_base_per_class: 76.0234 (80.6037) 
Training Epoch: [151/1000] Step: [210 / 285] Batch Time: 0.1546 (0.1570) Data Time: 0.0193 (0.0229) Average Loss: 0.6937 (0.7081) Average CE Loss (Source):  0.6937 ( 0.7081) Learning Rate: 0.1000 (0.1000) Top1_base: 80.4688 (80.1265) Top1_base_per_class: 81.1765 (80.5927) 
Training Epoch: [151/1000] Step: [220 / 285] Batch Time: 0.1439 (0.1565) Data Time: 0.0122 (0.0225) Average Loss: 0.7006 (0.7101) Average CE Loss (Source):  0.7006 ( 0.7101) Learning Rate: 0.1000 (0.1000) Top1_base: 76.5625 (80.0923) Top1_base_per_class: 80.9195 (80.5413) 
Training Epoch: [151/1000] Step: [230 / 285] Batch Time: 0.1507 (0.1563) Data Time: 0.0176 (0.0223) Average Loss: 0.8209 (0.7139) Average CE Loss (Source):  0.8209 ( 0.7139) Learning Rate: 0.1000 (0.1000) Top1_base: 75.7812 (80.0068) Top1_base_per_class: 76.6981 (80.4440) 
Training Epoch: [151/1000] Step: [240 / 285] Batch Time: 0.1461 (0.1559) Data Time: 0.0126 (0.0220) Average Loss: 0.7785 (0.7160) Average CE Loss (Source):  0.7785 ( 0.7160) Learning Rate: 0.1000 (0.1000) Top1_base: 75.7812 (79.9805) Top1_base_per_class: 78.8272 (80.3968) 
Training Epoch: [151/1000] Step: [250 / 285] Batch Time: 0.1529 (0.1556) Data Time: 0.0159 (0.0216) Average Loss: 0.9370 (0.7203) Average CE Loss (Source):  0.9370 ( 0.7203) Learning Rate: 0.1000 (0.1000) Top1_base: 67.9688 (79.8563) Top1_base_per_class: 71.7576 (80.3018) 
Training Epoch: [151/1000] Step: [260 / 285] Batch Time: 0.1435 (0.1553) Data Time: 0.0116 (0.0213) Average Loss: 0.9307 (0.7233) Average CE Loss (Source):  0.9307 ( 0.7233) Learning Rate: 0.1000 (0.1000) Top1_base: 71.8750 (79.7536) Top1_base_per_class: 69.3899 (80.1563) 
Training Epoch: [151/1000] Step: [270 / 285] Batch Time: 0.1512 (0.1550) Data Time: 0.0174 (0.0211) Average Loss: 0.8046 (0.7269) Average CE Loss (Source):  0.8046 ( 0.7269) Learning Rate: 0.1000 (0.1000) Top1_base: 79.6875 (79.6528) Top1_base_per_class: 81.8342 (80.0460) 
Training Epoch: [151/1000] Step: [280 / 285] Batch Time: 0.1430 (0.1547) Data Time: 0.0114 (0.0208) Average Loss: 0.7154 (0.7268) Average CE Loss (Source):  0.7154 ( 0.7268) Learning Rate: 0.1000 (0.1000) Top1_base: 77.3438 (79.6456) Top1_base_per_class: 77.4138 (80.0472) 
Training Epoch: [152/1000] Step: [0] Batch Time: 0.1423 (0.1545) Data Time: 0.0103 (0.0206) Average Loss: 0.9225 (0.7280) Average CE Loss (Source):  0.9225 ( 0.7280) Learning Rate: 0.1000 (0.1000) Top1_base: 75.7812 (79.5970) Top1_base_per_class: 81.2346 (80.0211) 
 15%|█▌        | 152/1000 [1:58:16<10:51:42, 46.11s/it] 15%|█▌        | 153/1000 [1:59:01<10:42:56, 45.54s/it]Training Epoch: [152/1000] Step: [10 / 285] Batch Time: 0.1461 (0.2350) Data Time: 0.0151 (0.1029) Average Loss: 0.4373 (0.7184) Average CE Loss (Source):  0.4373 ( 0.7184) Learning Rate: 0.1000 (0.1000) Top1_base: 86.7188 (80.6250) Top1_base_per_class: 87.3030 (80.9079) 
Training Epoch: [152/1000] Step: [20 / 285] Batch Time: 0.1474 (0.1971) Data Time: 0.0115 (0.0643) Average Loss: 0.9626 (0.7158) Average CE Loss (Source):  0.9626 ( 0.7158) Learning Rate: 0.1000 (0.1000) Top1_base: 75.0000 (80.5078) Top1_base_per_class: 78.6970 (80.4540) 
Training Epoch: [152/1000] Step: [30 / 285] Batch Time: 0.1849 (0.1876) Data Time: 0.0517 (0.0550) Average Loss: 0.8864 (0.7312) Average CE Loss (Source):  0.8864 ( 0.7312) Learning Rate: 0.1000 (0.1000) Top1_base: 74.2188 (80.0000) Top1_base_per_class: 71.6358 (79.9160) 
Training Epoch: [152/1000] Step: [40 / 285] Batch Time: 0.1444 (0.1775) Data Time: 0.0123 (0.0450) Average Loss: 0.7254 (0.7292) Average CE Loss (Source):  0.7254 ( 0.7292) Learning Rate: 0.1000 (0.1000) Top1_base: 78.9062 (79.8633) Top1_base_per_class: 78.5909 (79.7802) 
Training Epoch: [152/1000] Step: [50 / 285] Batch Time: 0.1769 (0.1739) Data Time: 0.0446 (0.0412) Average Loss: 0.4631 (0.7188) Average CE Loss (Source):  0.4631 ( 0.7188) Learning Rate: 0.1000 (0.1000) Top1_base: 86.7188 (80.1719) Top1_base_per_class: 84.0774 (80.2878) 
Training Epoch: [152/1000] Step: [60 / 285] Batch Time: 0.1446 (0.1692) Data Time: 0.0112 (0.0365) Average Loss: 0.6534 (0.7189) Average CE Loss (Source):  0.6534 ( 0.7189) Learning Rate: 0.1000 (0.1000) Top1_base: 79.6875 (79.9219) Top1_base_per_class: 83.6364 (80.1035) 
Training Epoch: [152/1000] Step: [70 / 285] Batch Time: 0.1501 (0.1674) Data Time: 0.0157 (0.0340) Average Loss: 0.7900 (0.7176) Average CE Loss (Source):  0.7900 ( 0.7176) Learning Rate: 0.1000 (0.1000) Top1_base: 78.9062 (79.9107) Top1_base_per_class: 76.1529 (80.2019) 
Training Epoch: [152/1000] Step: [80 / 285] Batch Time: 0.1469 (0.1657) Data Time: 0.0109 (0.0320) Average Loss: 0.5616 (0.7190) Average CE Loss (Source):  0.5616 ( 0.7190) Learning Rate: 0.1000 (0.1000) Top1_base: 85.1562 (79.9609) Top1_base_per_class: 85.5229 (80.3591) 
Training Epoch: [152/1000] Step: [90 / 285] Batch Time: 0.1489 (0.1641) Data Time: 0.0161 (0.0304) Average Loss: 0.8186 (0.7149) Average CE Loss (Source):  0.8186 ( 0.7149) Learning Rate: 0.1000 (0.1000) Top1_base: 78.9062 (80.0000) Top1_base_per_class: 79.0303 (80.4859) 
Training Epoch: [152/1000] Step: [100 / 285] Batch Time: 0.1472 (0.1625) Data Time: 0.0104 (0.0287) Average Loss: 0.6285 (0.7132) Average CE Loss (Source):  0.6285 ( 0.7132) Learning Rate: 0.1000 (0.1000) Top1_base: 80.4688 (80.0859) Top1_base_per_class: 81.0488 (80.6179) 
Training Epoch: [152/1000] Step: [110 / 285] Batch Time: 0.1510 (0.1620) Data Time: 0.0163 (0.0282) Average Loss: 0.6224 (0.7168) Average CE Loss (Source):  0.6224 ( 0.7168) Learning Rate: 0.1000 (0.1000) Top1_base: 83.5938 (80.0142) Top1_base_per_class: 83.9815 (80.5770) 
Training Epoch: [152/1000] Step: [120 / 285] Batch Time: 0.1416 (0.1613) Data Time: 0.0112 (0.0274) Average Loss: 0.7101 (0.7121) Average CE Loss (Source):  0.7101 ( 0.7121) Learning Rate: 0.1000 (0.1000) Top1_base: 76.5625 (80.0391) Top1_base_per_class: 75.5732 (80.4638) 
Training Epoch: [152/1000] Step: [130 / 285] Batch Time: 0.1506 (0.1602) Data Time: 0.0170 (0.0264) Average Loss: 0.8075 (0.7117) Average CE Loss (Source):  0.8075 ( 0.7117) Learning Rate: 0.1000 (0.1000) Top1_base: 76.5625 (80.0120) Top1_base_per_class: 76.6503 (80.4646) 
Training Epoch: [152/1000] Step: [140 / 285] Batch Time: 0.1481 (0.1593) Data Time: 0.0159 (0.0254) Average Loss: 0.8048 (0.7139) Average CE Loss (Source):  0.8048 ( 0.7139) Learning Rate: 0.1000 (0.1000) Top1_base: 77.3438 (80.0000) Top1_base_per_class: 78.0357 (80.4094) 
Training Epoch: [152/1000] Step: [150 / 285] Batch Time: 0.2056 (0.1588) Data Time: 0.0722 (0.0250) Average Loss: 0.8014 (0.7171) Average CE Loss (Source):  0.8014 ( 0.7171) Learning Rate: 0.1000 (0.1000) Top1_base: 77.3438 (79.8854) Top1_base_per_class: 78.3046 (80.2944) 
Training Epoch: [152/1000] Step: [160 / 285] Batch Time: 0.1474 (0.1588) Data Time: 0.0103 (0.0251) Average Loss: 0.6861 (0.7178) Average CE Loss (Source):  0.6861 ( 0.7178) Learning Rate: 0.1000 (0.1000) Top1_base: 82.0312 (79.8291) Top1_base_per_class: 81.1342 (80.2302) 
Training Epoch: [152/1000] Step: [170 / 285] Batch Time: 0.1480 (0.1581) Data Time: 0.0147 (0.0244) Average Loss: 0.5706 (0.7201) Average CE Loss (Source):  0.5706 ( 0.7201) Learning Rate: 0.1000 (0.1000) Top1_base: 83.5938 (79.7656) Top1_base_per_class: 84.6605 (80.1787) 
Training Epoch: [152/1000] Step: [180 / 285] Batch Time: 0.1450 (0.1578) Data Time: 0.0105 (0.0241) Average Loss: 0.8109 (0.7235) Average CE Loss (Source):  0.8109 ( 0.7235) Learning Rate: 0.1000 (0.1000) Top1_base: 78.9062 (79.6571) Top1_base_per_class: 80.8642 (80.0702) 
Training Epoch: [152/1000] Step: [190 / 285] Batch Time: 0.1499 (0.1574) Data Time: 0.0171 (0.0236) Average Loss: 0.7321 (0.7250) Average CE Loss (Source):  0.7321 ( 0.7250) Learning Rate: 0.1000 (0.1000) Top1_base: 81.2500 (79.6793) Top1_base_per_class: 82.2840 (80.0909) 
Training Epoch: [152/1000] Step: [200 / 285] Batch Time: 0.1486 (0.1569) Data Time: 0.0122 (0.0230) Average Loss: 0.5643 (0.7236) Average CE Loss (Source):  0.5643 ( 0.7236) Learning Rate: 0.1000 (0.1000) Top1_base: 83.5938 (79.6328) Top1_base_per_class: 84.7839 (80.0379) 
Training Epoch: [152/1000] Step: [210 / 285] Batch Time: 0.1499 (0.1565) Data Time: 0.0154 (0.0226) Average Loss: 0.7834 (0.7224) Average CE Loss (Source):  0.7834 ( 0.7224) Learning Rate: 0.1000 (0.1000) Top1_base: 81.2500 (79.6912) Top1_base_per_class: 81.8878 (80.1170) 
Training Epoch: [152/1000] Step: [220 / 285] Batch Time: 0.1446 (0.1560) Data Time: 0.0140 (0.0222) Average Loss: 0.9140 (0.7219) Average CE Loss (Source):  0.9140 ( 0.7219) Learning Rate: 0.1000 (0.1000) Top1_base: 75.7812 (79.7088) Top1_base_per_class: 76.9182 (80.1022) 
Training Epoch: [152/1000] Step: [230 / 285] Batch Time: 0.1487 (0.1556) Data Time: 0.0165 (0.0218) Average Loss: 0.7880 (0.7246) Average CE Loss (Source):  0.7880 ( 0.7246) Learning Rate: 0.1000 (0.1000) Top1_base: 72.6562 (79.5992) Top1_base_per_class: 76.9811 (79.9954) 
Training Epoch: [152/1000] Step: [240 / 285] Batch Time: 0.1462 (0.1553) Data Time: 0.0157 (0.0216) Average Loss: 0.7201 (0.7254) Average CE Loss (Source):  0.7201 ( 0.7254) Learning Rate: 0.1000 (0.1000) Top1_base: 79.6875 (79.5898) Top1_base_per_class: 85.4094 (79.9947) 
Training Epoch: [152/1000] Step: [250 / 285] Batch Time: 0.2448 (0.1554) Data Time: 0.1126 (0.0217) Average Loss: 0.5584 (0.7244) Average CE Loss (Source):  0.5584 ( 0.7244) Learning Rate: 0.1000 (0.1000) Top1_base: 83.5938 (79.6312) Top1_base_per_class: 81.4242 (80.0656) 
Training Epoch: [152/1000] Step: [260 / 285] Batch Time: 0.1644 (0.1553) Data Time: 0.0345 (0.0216) Average Loss: 0.6118 (0.7265) Average CE Loss (Source):  0.6118 ( 0.7265) Learning Rate: 0.1000 (0.1000) Top1_base: 82.8125 (79.5944) Top1_base_per_class: 81.2798 (80.0276) 
Training Epoch: [152/1000] Step: [270 / 285] Batch Time: 0.1803 (0.1552) Data Time: 0.0493 (0.0216) Average Loss: 0.6512 (0.7247) Average CE Loss (Source):  0.6512 ( 0.7247) Learning Rate: 0.1000 (0.1000) Top1_base: 80.4688 (79.6354) Top1_base_per_class: 84.9405 (80.0756) 
Training Epoch: [152/1000] Step: [280 / 285] Batch Time: 0.1460 (0.1551) Data Time: 0.0131 (0.0215) Average Loss: 0.5279 (0.7239) Average CE Loss (Source):  0.5279 ( 0.7239) Learning Rate: 0.1000 (0.1000) Top1_base: 85.1562 (79.6373) Top1_base_per_class: 81.9091 (80.0656) 
Training Epoch: [153/1000] Step: [0] Batch Time: 0.1423 (0.1549) Data Time: 0.0114 (0.0214) Average Loss: 0.9574 (0.7251) Average CE Loss (Source):  0.9574 ( 0.7251) Learning Rate: 0.1000 (0.1000) Top1_base: 74.2188 (79.6053) Top1_base_per_class: 74.3000 (80.0319) 
Training Epoch: [153/1000] Step: [10 / 285] Batch Time: 0.1437 (0.2362) Data Time: 0.0123 (0.1031) Average Loss: 0.6639 (0.6651) Average CE Loss (Source):  0.6639 ( 0.6651) Learning Rate: 0.1000 (0.1000) Top1_base: 82.0312 (81.6406) Top1_base_per_class: 79.4709 (81.4510) 
Training Epoch: [153/1000] Step: [20 / 285] Batch Time: 0.1429 (0.1968) Data Time: 0.0113 (0.0640) Average Loss: 0.6114 (0.6746) Average CE Loss (Source):  0.6114 ( 0.6746) Learning Rate: 0.1000 (0.1000) Top1_base: 84.3750 (81.0156) Top1_base_per_class: 87.8846 (81.6921) 
Training Epoch: [153/1000] Step: [30 / 285] Batch Time: 0.1488 (0.1829) Data Time: 0.0137 (0.0498) Average Loss: 0.6563 (0.6906) Average CE Loss (Source):  0.6563 ( 0.6906) Learning Rate: 0.1000 (0.1000) Top1_base: 78.9062 (80.5469) Top1_base_per_class: 78.4746 (80.9558) 
Training Epoch: [153/1000] Step: [40 / 285] Batch Time: 0.1471 (0.1748) Data Time: 0.0138 (0.0416) Average Loss: 0.7769 (0.6958) Average CE Loss (Source):  0.7769 ( 0.6958) Learning Rate: 0.1000 (0.1000) Top1_base: 76.5625 (80.2344) Top1_base_per_class: 75.8772 (80.6600) 
Training Epoch: [153/1000] Step: [50 / 285] Batch Time: 0.1473 (0.1712) Data Time: 0.0118 (0.0380) Average Loss: 0.7729 (0.7123) Average CE Loss (Source):  0.7729 ( 0.7123) Learning Rate: 0.1000 (0.1000) Top1_base: 78.9062 (80.0938) Top1_base_per_class: 78.3898 (80.5261) 
Training Epoch: [153/1000] Step: [60 / 285] Batch Time: 0.1465 (0.1682) Data Time: 0.0134 (0.0350) Average Loss: 0.9050 (0.7242) Average CE Loss (Source):  0.9050 ( 0.7242) Learning Rate: 0.1000 (0.1000) Top1_base: 75.7812 (79.7786) Top1_base_per_class: 76.2424 (79.9851) 
Training Epoch: [153/1000] Step: [70 / 285] Batch Time: 0.1468 (0.1659) Data Time: 0.0119 (0.0326) Average Loss: 0.8067 (0.7323) Average CE Loss (Source):  0.8067 ( 0.7323) Learning Rate: 0.1000 (0.1000) Top1_base: 75.0000 (79.3973) Top1_base_per_class: 74.1060 (79.5373) 
Training Epoch: [153/1000] Step: [80 / 285] Batch Time: 0.1468 (0.1651) Data Time: 0.0136 (0.0318) Average Loss: 0.7721 (0.7358) Average CE Loss (Source):  0.7721 ( 0.7358) Learning Rate: 0.1000 (0.1000) Top1_base: 78.9062 (79.2773) Top1_base_per_class: 79.8214 (79.5063) 
Training Epoch: [153/1000] Step: [90 / 285] Batch Time: 0.1471 (0.1642) Data Time: 0.0124 (0.0309) Average Loss: 0.6662 (0.7333) Average CE Loss (Source):  0.6662 ( 0.7333) Learning Rate: 0.1000 (0.1000) Top1_base: 80.4688 (79.3403) Top1_base_per_class: 83.9524 (79.6031) 
Training Epoch: [153/1000] Step: [100 / 285] Batch Time: 0.1472 (0.1632) Data Time: 0.0144 (0.0299) Average Loss: 0.7484 (0.7330) Average CE Loss (Source):  0.7484 ( 0.7330) Learning Rate: 0.1000 (0.1000) Top1_base: 77.3438 (79.3359) Top1_base_per_class: 79.4242 (79.6704) 
Training Epoch: [153/1000] Step: [110 / 285] Batch Time: 0.1448 (0.1622) Data Time: 0.0101 (0.0289) Average Loss: 0.8022 (0.7262) Average CE Loss (Source):  0.8022 ( 0.7262) Learning Rate: 0.1000 (0.1000) Top1_base: 79.6875 (79.6236) Top1_base_per_class: 78.3621 (80.0271) 
Training Epoch: [153/1000] Step: [120 / 285] Batch Time: 0.1780 (0.1611) Data Time: 0.0453 (0.0279) Average Loss: 0.7820 (0.7244) Average CE Loss (Source):  0.7820 ( 0.7244) Learning Rate: 0.1000 (0.1000) Top1_base: 79.6875 (79.6940) Top1_base_per_class: 80.1235 (80.1518) 
Training Epoch: [153/1000] Step: [130 / 285] Batch Time: 0.1444 (0.1608) Data Time: 0.0105 (0.0276) Average Loss: 0.6921 (0.7190) Average CE Loss (Source):  0.6921 ( 0.7190) Learning Rate: 0.1000 (0.1000) Top1_base: 80.4688 (79.7897) Top1_base_per_class: 78.7356 (80.2224) 
Training Epoch: [153/1000] Step: [140 / 285] Batch Time: 0.1543 (0.1606) Data Time: 0.0215 (0.0274) Average Loss: 0.8222 (0.7264) Average CE Loss (Source):  0.8222 ( 0.7264) Learning Rate: 0.1000 (0.1000) Top1_base: 78.1250 (79.5592) Top1_base_per_class: 79.1667 (80.0079) 
Training Epoch: [153/1000] Step: [150 / 285] Batch Time: 0.1463 (0.1603) Data Time: 0.0121 (0.0271) Average Loss: 0.7083 (0.7305) Average CE Loss (Source):  0.7083 ( 0.7305) Learning Rate: 0.1000 (0.1000) Top1_base: 80.4688 (79.4688) Top1_base_per_class: 84.0909 (80.0404) 
Training Epoch: [153/1000] Step: [160 / 285] Batch Time: 0.1693 (0.1602) Data Time: 0.0372 (0.0270) Average Loss: 0.6824 (0.7342) Average CE Loss (Source):  0.6824 ( 0.7342) Learning Rate: 0.1000 (0.1000) Top1_base: 81.2500 (79.3848) Top1_base_per_class: 84.0396 (80.0167) 
Training Epoch: [153/1000] Step: [170 / 285] Batch Time: 0.1425 (0.1598) Data Time: 0.0114 (0.0266) Average Loss: 0.7509 (0.7343) Average CE Loss (Source):  0.7509 ( 0.7343) Learning Rate: 0.1000 (0.1000) Top1_base: 78.1250 (79.3382) Top1_base_per_class: 79.9718 (79.9880) 
Training Epoch: [153/1000] Step: [180 / 285] Batch Time: 0.1592 (0.1597) Data Time: 0.0282 (0.0266) Average Loss: 1.0181 (0.7388) Average CE Loss (Source):  1.0181 ( 0.7388) Learning Rate: 0.1000 (0.1000) Top1_base: 72.6562 (79.2144) Top1_base_per_class: 71.9753 (79.7748) 
Training Epoch: [153/1000] Step: [190 / 285] Batch Time: 0.1461 (0.1599) Data Time: 0.0119 (0.0268) Average Loss: 0.9383 (0.7393) Average CE Loss (Source):  0.9383 ( 0.7393) Learning Rate: 0.1000 (0.1000) Top1_base: 75.0000 (79.2229) Top1_base_per_class: 72.2276 (79.7596) 
Training Epoch: [153/1000] Step: [200 / 285] Batch Time: 0.1497 (0.1594) Data Time: 0.0173 (0.0264) Average Loss: 0.5932 (0.7407) Average CE Loss (Source):  0.5932 ( 0.7407) Learning Rate: 0.1000 (0.1000) Top1_base: 78.9062 (79.1836) Top1_base_per_class: 80.8745 (79.7248) 
Training Epoch: [153/1000] Step: [210 / 285] Batch Time: 0.1458 (0.1588) Data Time: 0.0121 (0.0257) Average Loss: 0.6373 (0.7423) Average CE Loss (Source):  0.6373 ( 0.7423) Learning Rate: 0.1000 (0.1000) Top1_base: 81.2500 (79.1815) Top1_base_per_class: 80.6364 (79.7099) 
Training Epoch: [153/1000] Step: [220 / 285] Batch Time: 0.1637 (0.1583) Data Time: 0.0294 (0.0252) Average Loss: 0.6562 (0.7476) Average CE Loss (Source):  0.6562 ( 0.7476) Learning Rate: 0.1000 (0.1000) Top1_base: 79.6875 (79.0412) Top1_base_per_class: 80.0877 (79.5066) 
Training Epoch: [153/1000] Step: [230 / 285] Batch Time: 0.1447 (0.1584) Data Time: 0.0106 (0.0253) Average Loss: 0.8304 (0.7496) Average CE Loss (Source):  0.8304 ( 0.7496) Learning Rate: 0.1000 (0.1000) Top1_base: 78.9062 (78.9844) Top1_base_per_class: 78.6723 (79.4518) 
Training Epoch: [153/1000] Step: [240 / 285] Batch Time: 0.2480 (0.1584) Data Time: 0.1164 (0.0254) Average Loss: 0.7616 (0.7499) Average CE Loss (Source):  0.7616 ( 0.7499) Learning Rate: 0.1000 (0.1000) Top1_base: 79.6875 (78.9714) Top1_base_per_class: 79.0000 (79.4703) 
Training Epoch: [153/1000] Step: [250 / 285] Batch Time: 0.1462 (0.1581) Data Time: 0.0118 (0.0251) Average Loss: 0.7218 (0.7524) Average CE Loss (Source):  0.7218 ( 0.7524) Learning Rate: 0.1000 (0.1000) Top1_base: 78.1250 (78.9656) Top1_base_per_class: 77.6786 (79.4644) 
Training Epoch: [153/1000] Step: [260 / 285] Batch Time: 0.2580 (0.1583) Data Time: 0.1261 (0.0253) Average Loss: 0.6900 (0.7528) Average CE Loss (Source):  0.6900 ( 0.7528) Learning Rate: 0.1000 (0.1000) Top1_base: 79.6875 (78.9393) Top1_base_per_class: 82.1637 (79.4341) 
Training Epoch: [153/1000] Step: [270 / 285] Batch Time: 0.1430 (0.1579) Data Time: 0.0104 (0.0249) Average Loss: 0.7388 (0.7530) Average CE Loss (Source):  0.7388 ( 0.7530) Learning Rate: 0.1000 (0.1000) Top1_base: 76.5625 (78.9352) Top1_base_per_class: 75.5762 (79.4302) 
Training Epoch: [153/1000] Step: [280 / 285] Batch Time: 0.1619 (0.1578) Data Time: 0.0279 (0.0247) Average Loss: 0.7700 (0.7549) Average CE Loss (Source):  0.7700 ( 0.7549) Learning Rate: 0.1000 (0.1000) Top1_base: 80.4688 (78.8588) Top1_base_per_class: 81.8006 (79.3273) 
Training Epoch: [154/1000] Step: [0] Batch Time: 0.1408 (0.1576) Data Time: 0.0113 (0.0246) Average Loss: 0.6471 (0.7549) Average CE Loss (Source):  0.6471 ( 0.7549) Learning Rate: 0.1000 (0.1000) Top1_base: 80.4688 (78.8514) Top1_base_per_class: 78.1404 (79.3176) 
 15%|█▌        | 154/1000 [1:59:49<10:51:44, 46.22s/it] 16%|█▌        | 155/1000 [2:00:33<10:45:04, 45.80s/it]Training Epoch: [154/1000] Step: [10 / 285] Batch Time: 0.1501 (0.2405) Data Time: 0.0126 (0.1068) Average Loss: 0.7817 (0.6888) Average CE Loss (Source):  0.7817 ( 0.6888) Learning Rate: 0.1000 (0.1000) Top1_base: 76.5625 (80.1562) Top1_base_per_class: 75.7407 (80.4308) 
Training Epoch: [154/1000] Step: [20 / 285] Batch Time: 0.1477 (0.1977) Data Time: 0.0147 (0.0650) Average Loss: 0.7605 (0.7018) Average CE Loss (Source):  0.7605 ( 0.7018) Learning Rate: 0.1000 (0.1000) Top1_base: 77.3438 (80.2734) Top1_base_per_class: 73.4936 (80.7498) 
Training Epoch: [154/1000] Step: [30 / 285] Batch Time: 0.1478 (0.1879) Data Time: 0.0121 (0.0550) Average Loss: 0.7658 (0.7222) Average CE Loss (Source):  0.7658 ( 0.7222) Learning Rate: 0.1000 (0.1000) Top1_base: 82.0312 (79.9740) Top1_base_per_class: 84.1667 (80.5696) 
Training Epoch: [154/1000] Step: [40 / 285] Batch Time: 0.1434 (0.1796) Data Time: 0.0123 (0.0466) Average Loss: 0.7891 (0.7234) Average CE Loss (Source):  0.7891 ( 0.7234) Learning Rate: 0.1000 (0.1000) Top1_base: 81.2500 (80.1758) Top1_base_per_class: 79.1484 (81.0021) 
Training Epoch: [154/1000] Step: [50 / 285] Batch Time: 0.1466 (0.1745) Data Time: 0.0120 (0.0412) Average Loss: 0.5141 (0.7115) Average CE Loss (Source):  0.5141 ( 0.7115) Learning Rate: 0.1000 (0.1000) Top1_base: 83.5938 (80.2656) Top1_base_per_class: 84.6970 (81.1519) 
Training Epoch: [154/1000] Step: [60 / 285] Batch Time: 0.1415 (0.1720) Data Time: 0.0114 (0.0390) Average Loss: 0.6257 (0.7116) Average CE Loss (Source):  0.6257 ( 0.7116) Learning Rate: 0.1000 (0.1000) Top1_base: 79.6875 (80.2474) Top1_base_per_class: 82.3765 (81.2126) 
Training Epoch: [154/1000] Step: [70 / 285] Batch Time: 0.1454 (0.1704) Data Time: 0.0116 (0.0373) Average Loss: 0.6953 (0.7117) Average CE Loss (Source):  0.6953 ( 0.7117) Learning Rate: 0.1000 (0.1000) Top1_base: 79.6875 (80.1116) Top1_base_per_class: 82.4528 (81.2126) 
Training Epoch: [154/1000] Step: [80 / 285] Batch Time: 0.1459 (0.1681) Data Time: 0.0130 (0.0349) Average Loss: 0.7205 (0.7082) Average CE Loss (Source):  0.7205 ( 0.7082) Learning Rate: 0.1000 (0.1000) Top1_base: 76.5625 (80.0977) Top1_base_per_class: 75.6173 (81.1800) 
Training Epoch: [154/1000] Step: [90 / 285] Batch Time: 0.1494 (0.1658) Data Time: 0.0139 (0.0325) Average Loss: 0.6428 (0.7084) Average CE Loss (Source):  0.6428 ( 0.7084) Learning Rate: 0.1000 (0.1000) Top1_base: 82.8125 (80.1042) Top1_base_per_class: 82.7576 (81.1122) 
Training Epoch: [154/1000] Step: [100 / 285] Batch Time: 0.1445 (0.1642) Data Time: 0.0124 (0.0310) Average Loss: 0.7561 (0.7108) Average CE Loss (Source):  0.7561 ( 0.7108) Learning Rate: 0.1000 (0.1000) Top1_base: 81.2500 (80.0391) Top1_base_per_class: 81.4881 (80.8871) 
Training Epoch: [154/1000] Step: [110 / 285] Batch Time: 0.1468 (0.1630) Data Time: 0.0135 (0.0298) Average Loss: 0.7920 (0.7145) Average CE Loss (Source):  0.7920 ( 0.7145) Learning Rate: 0.1000 (0.1000) Top1_base: 77.3438 (79.9787) Top1_base_per_class: 74.1072 (80.7975) 
Training Epoch: [154/1000] Step: [120 / 285] Batch Time: 0.1478 (0.1619) Data Time: 0.0159 (0.0287) Average Loss: 0.9532 (0.7205) Average CE Loss (Source):  0.9532 ( 0.7205) Learning Rate: 0.1000 (0.1000) Top1_base: 75.0000 (79.8438) Top1_base_per_class: 76.4620 (80.6212) 
Training Epoch: [154/1000] Step: [130 / 285] Batch Time: 0.1451 (0.1615) Data Time: 0.0129 (0.0283) Average Loss: 0.8403 (0.7200) Average CE Loss (Source):  0.8403 ( 0.7200) Learning Rate: 0.1000 (0.1000) Top1_base: 75.7812 (79.8858) Top1_base_per_class: 78.4641 (80.6238) 
Training Epoch: [154/1000] Step: [140 / 285] Batch Time: 0.1463 (0.1606) Data Time: 0.0137 (0.0275) Average Loss: 0.6955 (0.7237) Average CE Loss (Source):  0.6955 ( 0.7237) Learning Rate: 0.1000 (0.1000) Top1_base: 82.8125 (79.7824) Top1_base_per_class: 82.6667 (80.5051) 
Training Epoch: [154/1000] Step: [150 / 285] Batch Time: 0.1431 (0.1601) Data Time: 0.0112 (0.0270) Average Loss: 0.6280 (0.7265) Average CE Loss (Source):  0.6280 ( 0.7265) Learning Rate: 0.1000 (0.1000) Top1_base: 85.1562 (79.7708) Top1_base_per_class: 83.2075 (80.4597) 
Training Epoch: [154/1000] Step: [160 / 285] Batch Time: 0.1466 (0.1593) Data Time: 0.0144 (0.0261) Average Loss: 0.6833 (0.7227) Average CE Loss (Source):  0.6833 ( 0.7227) Learning Rate: 0.1000 (0.1000) Top1_base: 83.5938 (79.8047) Top1_base_per_class: 83.4211 (80.5067) 
Training Epoch: [154/1000] Step: [170 / 285] Batch Time: 0.1423 (0.1595) Data Time: 0.0113 (0.0264) Average Loss: 0.7750 (0.7208) Average CE Loss (Source):  0.7750 ( 0.7208) Learning Rate: 0.1000 (0.1000) Top1_base: 79.6875 (79.8483) Top1_base_per_class: 81.5819 (80.5092) 
Training Epoch: [154/1000] Step: [180 / 285] Batch Time: 0.1437 (0.1591) Data Time: 0.0117 (0.0261) Average Loss: 0.6217 (0.7228) Average CE Loss (Source):  0.6217 ( 0.7228) Learning Rate: 0.1000 (0.1000) Top1_base: 78.1250 (79.7656) Top1_base_per_class: 77.0977 (80.4783) 
Training Epoch: [154/1000] Step: [190 / 285] Batch Time: 0.1436 (0.1585) Data Time: 0.0132 (0.0255) Average Loss: 0.8851 (0.7234) Average CE Loss (Source):  0.8851 ( 0.7234) Learning Rate: 0.1000 (0.1000) Top1_base: 75.7812 (79.7738) Top1_base_per_class: 76.2302 (80.5016) 
Training Epoch: [154/1000] Step: [200 / 285] Batch Time: 0.1461 (0.1583) Data Time: 0.0118 (0.0254) Average Loss: 0.9784 (0.7264) Average CE Loss (Source):  0.9784 ( 0.7264) Learning Rate: 0.1000 (0.1000) Top1_base: 76.5625 (79.6914) Top1_base_per_class: 77.8249 (80.4161) 
Training Epoch: [154/1000] Step: [210 / 285] Batch Time: 0.1428 (0.1582) Data Time: 0.0112 (0.0252) Average Loss: 0.8818 (0.7285) Average CE Loss (Source):  0.8818 ( 0.7285) Learning Rate: 0.1000 (0.1000) Top1_base: 79.6875 (79.6243) Top1_base_per_class: 82.7083 (80.3393) 
Training Epoch: [154/1000] Step: [220 / 285] Batch Time: 0.1464 (0.1577) Data Time: 0.0117 (0.0247) Average Loss: 0.5763 (0.7290) Average CE Loss (Source):  0.5763 ( 0.7290) Learning Rate: 0.1000 (0.1000) Top1_base: 82.8125 (79.6094) Top1_base_per_class: 82.3099 (80.3670) 
Training Epoch: [154/1000] Step: [230 / 285] Batch Time: 0.1505 (0.1575) Data Time: 0.0125 (0.0244) Average Loss: 0.9227 (0.7313) Average CE Loss (Source):  0.9227 ( 0.7313) Learning Rate: 0.1000 (0.1000) Top1_base: 78.1250 (79.5448) Top1_base_per_class: 74.7126 (80.3146) 
Training Epoch: [154/1000] Step: [240 / 285] Batch Time: 0.1454 (0.1571) Data Time: 0.0130 (0.0239) Average Loss: 0.7867 (0.7314) Average CE Loss (Source):  0.7867 ( 0.7314) Learning Rate: 0.1000 (0.1000) Top1_base: 75.7812 (79.5312) Top1_base_per_class: 74.3827 (80.2501) 
Training Epoch: [154/1000] Step: [250 / 285] Batch Time: 0.1485 (0.1567) Data Time: 0.0148 (0.0235) Average Loss: 0.7443 (0.7307) Average CE Loss (Source):  0.7443 ( 0.7307) Learning Rate: 0.1000 (0.1000) Top1_base: 78.9062 (79.5344) Top1_base_per_class: 78.1250 (80.2731) 
Training Epoch: [154/1000] Step: [260 / 285] Batch Time: 0.1433 (0.1563) Data Time: 0.0116 (0.0231) Average Loss: 1.0977 (0.7358) Average CE Loss (Source):  1.0977 ( 0.7358) Learning Rate: 0.1000 (0.1000) Top1_base: 69.5312 (79.4351) Top1_base_per_class: 72.3333 (80.1839) 
Training Epoch: [154/1000] Step: [270 / 285] Batch Time: 0.1493 (0.1563) Data Time: 0.0155 (0.0231) Average Loss: 0.7326 (0.7382) Average CE Loss (Source):  0.7326 ( 0.7382) Learning Rate: 0.1000 (0.1000) Top1_base: 78.9062 (79.3837) Top1_base_per_class: 82.2222 (80.1346) 
Training Epoch: [154/1000] Step: [280 / 285] Batch Time: 0.1430 (0.1567) Data Time: 0.0103 (0.0235) Average Loss: 0.9604 (0.7416) Average CE Loss (Source):  0.9604 ( 0.7416) Learning Rate: 0.1000 (0.1000) Top1_base: 74.2188 (79.2885) Top1_base_per_class: 75.0821 (80.0472) 
Training Epoch: [155/1000] Step: [0] Batch Time: 0.2173 (0.1571) Data Time: 0.0844 (0.0239) Average Loss: 0.6586 (0.7408) Average CE Loss (Source):  0.6586 ( 0.7408) Learning Rate: 0.1000 (0.1000) Top1_base: 80.4688 (79.3311) Top1_base_per_class: 83.7562 (80.0807) 
Training Epoch: [155/1000] Step: [10 / 285] Batch Time: 0.1438 (0.2479) Data Time: 0.0125 (0.1146) Average Loss: 0.6977 (0.6977) Average CE Loss (Source):  0.6977 ( 0.6977) Learning Rate: 0.1000 (0.1000) Top1_base: 80.4688 (80.0000) Top1_base_per_class: 80.4094 (80.4046) 
Training Epoch: [155/1000] Step: [20 / 285] Batch Time: 0.1481 (0.2028) Data Time: 0.0153 (0.0697) Average Loss: 0.5644 (0.7195) Average CE Loss (Source):  0.5644 ( 0.7195) Learning Rate: 0.1000 (0.1000) Top1_base: 87.5000 (79.5703) Top1_base_per_class: 85.7759 (80.0340) 
Training Epoch: [155/1000] Step: [30 / 285] Batch Time: 0.1453 (0.1910) Data Time: 0.0112 (0.0583) Average Loss: 0.7665 (0.7180) Average CE Loss (Source):  0.7665 ( 0.7180) Learning Rate: 0.1000 (0.1000) Top1_base: 76.5625 (79.7917) Top1_base_per_class: 74.3103 (79.8718) 
Training Epoch: [155/1000] Step: [40 / 285] Batch Time: 0.1462 (0.1813) Data Time: 0.0143 (0.0483) Average Loss: 0.7907 (0.7185) Average CE Loss (Source):  0.7907 ( 0.7185) Learning Rate: 0.1000 (0.1000) Top1_base: 76.5625 (79.6484) Top1_base_per_class: 75.9568 (79.6457) 
Training Epoch: [155/1000] Step: [50 / 285] Batch Time: 0.1475 (0.1764) Data Time: 0.0129 (0.0434) Average Loss: 0.8173 (0.7171) Average CE Loss (Source):  0.8173 ( 0.7171) Learning Rate: 0.1000 (0.1000) Top1_base: 76.5625 (79.5781) Top1_base_per_class: 76.9643 (79.7495) 
Training Epoch: [155/1000] Step: [60 / 285] Batch Time: 0.1465 (0.1726) Data Time: 0.0129 (0.0397) Average Loss: 0.7958 (0.7218) Average CE Loss (Source):  0.7958 ( 0.7218) Learning Rate: 0.1000 (0.1000) Top1_base: 75.7812 (79.5443) Top1_base_per_class: 74.8104 (79.7877) 
Training Epoch: [155/1000] Step: [70 / 285] Batch Time: 0.1445 (0.1711) Data Time: 0.0100 (0.0380) Average Loss: 0.6115 (0.7201) Average CE Loss (Source):  0.6115 ( 0.7201) Learning Rate: 0.1000 (0.1000) Top1_base: 85.1562 (79.5647) Top1_base_per_class: 86.2842 (79.7294) 
Training Epoch: [155/1000] Step: [80 / 285] Batch Time: 0.1452 (0.1702) Data Time: 0.0107 (0.0371) Average Loss: 0.6608 (0.7196) Average CE Loss (Source):  0.6608 ( 0.7196) Learning Rate: 0.1000 (0.1000) Top1_base: 80.4688 (79.5215) Top1_base_per_class: 77.6316 (79.6471) 
Training Epoch: [155/1000] Step: [90 / 285] Batch Time: 0.1444 (0.1685) Data Time: 0.0104 (0.0355) Average Loss: 0.6735 (0.7247) Average CE Loss (Source):  0.6735 ( 0.7247) Learning Rate: 0.1000 (0.1000) Top1_base: 79.6875 (79.4444) Top1_base_per_class: 81.9941 (79.6476) 
Training Epoch: [155/1000] Step: [100 / 285] Batch Time: 0.1469 (0.1668) Data Time: 0.0141 (0.0338) Average Loss: 0.8192 (0.7259) Average CE Loss (Source):  0.8192 ( 0.7259) Learning Rate: 0.1000 (0.1000) Top1_base: 76.5625 (79.4844) Top1_base_per_class: 79.2982 (79.7361) 
Training Epoch: [155/1000] Step: [110 / 285] Batch Time: 0.1448 (0.1664) Data Time: 0.0107 (0.0334) Average Loss: 0.6899 (0.7308) Average CE Loss (Source):  0.6899 ( 0.7308) Learning Rate: 0.1000 (0.1000) Top1_base: 80.4688 (79.3679) Top1_base_per_class: 79.4737 (79.6463) 
Training Epoch: [155/1000] Step: [120 / 285] Batch Time: 0.1463 (0.1652) Data Time: 0.0127 (0.0322) Average Loss: 0.5058 (0.7319) Average CE Loss (Source):  0.5058 ( 0.7319) Learning Rate: 0.1000 (0.1000) Top1_base: 86.7188 (79.4010) Top1_base_per_class: 88.3929 (79.7988) 
Training Epoch: [155/1000] Step: [130 / 285] Batch Time: 0.1450 (0.1646) Data Time: 0.0104 (0.0316) Average Loss: 0.7208 (0.7286) Average CE Loss (Source):  0.7208 ( 0.7286) Learning Rate: 0.1000 (0.1000) Top1_base: 77.3438 (79.4291) Top1_base_per_class: 74.8725 (79.8148) 
Training Epoch: [155/1000] Step: [140 / 285] Batch Time: 0.1434 (0.1636) Data Time: 0.0122 (0.0307) Average Loss: 0.6786 (0.7315) Average CE Loss (Source):  0.6786 ( 0.7315) Learning Rate: 0.1000 (0.1000) Top1_base: 83.5938 (79.3415) Top1_base_per_class: 84.6541 (79.7970) 
Training Epoch: [155/1000] Step: [150 / 285] Batch Time: 0.1448 (0.1638) Data Time: 0.0101 (0.0308) Average Loss: 0.7259 (0.7330) Average CE Loss (Source):  0.7259 ( 0.7330) Learning Rate: 0.1000 (0.1000) Top1_base: 81.2500 (79.3594) Top1_base_per_class: 82.2321 (79.8368) 
Training Epoch: [155/1000] Step: [160 / 285] Batch Time: 0.1444 (0.1635) Data Time: 0.0121 (0.0306) Average Loss: 0.4749 (0.7310) Average CE Loss (Source):  0.4749 ( 0.7310) Learning Rate: 0.1000 (0.1000) Top1_base: 88.2812 (79.4287) Top1_base_per_class: 88.3333 (79.8824) 
Training Epoch: [155/1000] Step: [170 / 285] Batch Time: 0.1445 (0.1626) Data Time: 0.0106 (0.0297) Average Loss: 0.9797 (0.7284) Average CE Loss (Source):  0.9797 ( 0.7284) Learning Rate: 0.1000 (0.1000) Top1_base: 74.2188 (79.4945) Top1_base_per_class: 75.7310 (79.9685) 
Training Epoch: [155/1000] Step: [180 / 285] Batch Time: 0.1448 (0.1621) Data Time: 0.0117 (0.0292) Average Loss: 0.8039 (0.7309) Average CE Loss (Source):  0.8039 ( 0.7309) Learning Rate: 0.1000 (0.1000) Top1_base: 73.4375 (79.4097) Top1_base_per_class: 71.2654 (79.8678) 
Training Epoch: [155/1000] Step: [190 / 285] Batch Time: 0.1450 (0.1612) Data Time: 0.0104 (0.0284) Average Loss: 0.5864 (0.7296) Average CE Loss (Source):  0.5864 ( 0.7296) Learning Rate: 0.1000 (0.1000) Top1_base: 84.3750 (79.4449) Top1_base_per_class: 87.6437 (79.8648) 
Training Epoch: [155/1000] Step: [200 / 285] Batch Time: 0.1429 (0.1609) Data Time: 0.0112 (0.0280) Average Loss: 0.8350 (0.7323) Average CE Loss (Source):  0.8350 ( 0.7323) Learning Rate: 0.1000 (0.1000) Top1_base: 74.2188 (79.3750) Top1_base_per_class: 76.4848 (79.8069) 
Training Epoch: [155/1000] Step: [210 / 285] Batch Time: 0.1454 (0.1605) Data Time: 0.0114 (0.0276) Average Loss: 0.8009 (0.7330) Average CE Loss (Source):  0.8009 ( 0.7330) Learning Rate: 0.1000 (0.1000) Top1_base: 78.9062 (79.3750) Top1_base_per_class: 80.2160 (79.8087) 
Training Epoch: [155/1000] Step: [220 / 285] Batch Time: 0.1426 (0.1601) Data Time: 0.0110 (0.0272) Average Loss: 1.1655 (0.7334) Average CE Loss (Source):  1.1655 ( 0.7334) Learning Rate: 0.1000 (0.1000) Top1_base: 70.3125 (79.3750) Top1_base_per_class: 73.7457 (79.8258) 
Training Epoch: [155/1000] Step: [230 / 285] Batch Time: 0.1416 (0.1597) Data Time: 0.0116 (0.0267) Average Loss: 1.0026 (0.7340) Average CE Loss (Source):  1.0026 ( 0.7340) Learning Rate: 0.1000 (0.1000) Top1_base: 75.0000 (79.3716) Top1_base_per_class: 76.9780 (79.8345) 
Training Epoch: [155/1000] Step: [240 / 285] Batch Time: 0.1456 (0.1592) Data Time: 0.0128 (0.0261) Average Loss: 0.7715 (0.7351) Average CE Loss (Source):  0.7715 ( 0.7351) Learning Rate: 0.1000 (0.1000) Top1_base: 79.6875 (79.3587) Top1_base_per_class: 80.1923 (79.8010) 
Training Epoch: [155/1000] Step: [250 / 285] Batch Time: 0.1461 (0.1589) Data Time: 0.0142 (0.0259) Average Loss: 0.9856 (0.7355) Average CE Loss (Source):  0.9856 ( 0.7355) Learning Rate: 0.1000 (0.1000) Top1_base: 73.4375 (79.3625) Top1_base_per_class: 77.0175 (79.8122) 
Training Epoch: [155/1000] Step: [260 / 285] Batch Time: 0.1436 (0.1587) Data Time: 0.0107 (0.0257) Average Loss: 0.8411 (0.7391) Average CE Loss (Source):  0.8411 ( 0.7391) Learning Rate: 0.1000 (0.1000) Top1_base: 76.5625 (79.2969) Top1_base_per_class: 78.3918 (79.7804) 
Training Epoch: [155/1000] Step: [270 / 285] Batch Time: 0.1487 (0.1584) Data Time: 0.0118 (0.0254) Average Loss: 0.5731 (0.7386) Average CE Loss (Source):  0.5731 ( 0.7386) Learning Rate: 0.1000 (0.1000) Top1_base: 86.7188 (79.3316) Top1_base_per_class: 85.4093 (79.8165) 
Training Epoch: [155/1000] Step: [280 / 285] Batch Time: 0.1498 (0.1582) Data Time: 0.0150 (0.0251) Average Loss: 0.8104 (0.7386) Average CE Loss (Source):  0.8104 ( 0.7386) Learning Rate: 0.1000 (0.1000) Top1_base: 81.2500 (79.3304) Top1_base_per_class: 76.6667 (79.8364) 
Training Epoch: [156/1000] Step: [0] Batch Time: 0.1781 (0.1584) Data Time: 0.0455 (0.0252) Average Loss: 0.9017 (0.7379) Average CE Loss (Source):  0.9017 ( 0.7379) Learning Rate: 0.1000 (0.1000) Top1_base: 75.7812 (79.3394) Top1_base_per_class: 78.2581 (79.8608) 
 16%|█▌        | 156/1000 [2:01:21<10:53:23, 46.45s/it] 16%|█▌        | 157/1000 [2:02:06<10:45:26, 45.94s/it]Training Epoch: [156/1000] Step: [10 / 285] Batch Time: 0.1440 (0.2382) Data Time: 0.0122 (0.1054) Average Loss: 0.4759 (0.7053) Average CE Loss (Source):  0.4759 ( 0.7053) Learning Rate: 0.1000 (0.1000) Top1_base: 88.2812 (79.6875) Top1_base_per_class: 86.5774 (80.1867) 
Training Epoch: [156/1000] Step: [20 / 285] Batch Time: 0.1456 (0.1980) Data Time: 0.0128 (0.0653) Average Loss: 0.5450 (0.6943) Average CE Loss (Source):  0.5450 ( 0.6943) Learning Rate: 0.1000 (0.1000) Top1_base: 82.8125 (80.1953) Top1_base_per_class: 84.9123 (80.9417) 
Training Epoch: [156/1000] Step: [30 / 285] Batch Time: 0.1874 (0.1856) Data Time: 0.0558 (0.0525) Average Loss: 0.7352 (0.7061) Average CE Loss (Source):  0.7352 ( 0.7061) Learning Rate: 0.1000 (0.1000) Top1_base: 78.9062 (79.8438) Top1_base_per_class: 76.3580 (80.3986) 
Training Epoch: [156/1000] Step: [40 / 285] Batch Time: 0.1466 (0.1772) Data Time: 0.0153 (0.0443) Average Loss: 0.6746 (0.7079) Average CE Loss (Source):  0.6746 ( 0.7079) Learning Rate: 0.1000 (0.1000) Top1_base: 81.2500 (79.7852) Top1_base_per_class: 81.6220 (80.3694) 
Training Epoch: [156/1000] Step: [50 / 285] Batch Time: 0.2804 (0.1738) Data Time: 0.1456 (0.0409) Average Loss: 0.8083 (0.7050) Average CE Loss (Source):  0.8083 ( 0.7050) Learning Rate: 0.1000 (0.1000) Top1_base: 78.9062 (80.1094) Top1_base_per_class: 80.1713 (80.7708) 
Training Epoch: [156/1000] Step: [60 / 285] Batch Time: 0.1464 (0.1700) Data Time: 0.0152 (0.0370) Average Loss: 0.7794 (0.7100) Average CE Loss (Source):  0.7794 ( 0.7100) Learning Rate: 0.1000 (0.1000) Top1_base: 76.5625 (80.0391) Top1_base_per_class: 78.4906 (80.7760) 
Training Epoch: [156/1000] Step: [70 / 285] Batch Time: 0.1996 (0.1688) Data Time: 0.0663 (0.0358) Average Loss: 0.8998 (0.7056) Average CE Loss (Source):  0.8998 ( 0.7056) Learning Rate: 0.1000 (0.1000) Top1_base: 75.0000 (80.0446) Top1_base_per_class: 72.2727 (80.6319) 
Training Epoch: [156/1000] Step: [80 / 285] Batch Time: 0.1478 (0.1662) Data Time: 0.0157 (0.0333) Average Loss: 0.5368 (0.7027) Average CE Loss (Source):  0.5368 ( 0.7027) Learning Rate: 0.1000 (0.1000) Top1_base: 85.9375 (80.1953) Top1_base_per_class: 86.8713 (80.6936) 
Training Epoch: [156/1000] Step: [90 / 285] Batch Time: 0.1592 (0.1663) Data Time: 0.0286 (0.0334) Average Loss: 0.5359 (0.7006) Average CE Loss (Source):  0.5359 ( 0.7006) Learning Rate: 0.1000 (0.1000) Top1_base: 82.8125 (80.1823) Top1_base_per_class: 84.4898 (80.7100) 
Training Epoch: [156/1000] Step: [100 / 285] Batch Time: 0.1442 (0.1655) Data Time: 0.0132 (0.0326) Average Loss: 0.6000 (0.6998) Average CE Loss (Source):  0.6000 ( 0.6998) Learning Rate: 0.1000 (0.1000) Top1_base: 81.2500 (80.1641) Top1_base_per_class: 78.8679 (80.6768) 
Training Epoch: [156/1000] Step: [110 / 285] Batch Time: 0.1707 (0.1642) Data Time: 0.0398 (0.0313) Average Loss: 0.5432 (0.6987) Average CE Loss (Source):  0.5432 ( 0.6987) Learning Rate: 0.1000 (0.1000) Top1_base: 83.5938 (80.2486) Top1_base_per_class: 84.6199 (80.7891) 
Training Epoch: [156/1000] Step: [120 / 285] Batch Time: 0.1458 (0.1633) Data Time: 0.0134 (0.0303) Average Loss: 0.7156 (0.6975) Average CE Loss (Source):  0.7156 ( 0.6975) Learning Rate: 0.1000 (0.1000) Top1_base: 76.5625 (80.3255) Top1_base_per_class: 76.2179 (80.8537) 
Training Epoch: [156/1000] Step: [130 / 285] Batch Time: 0.1593 (0.1624) Data Time: 0.0265 (0.0294) Average Loss: 0.5972 (0.6954) Average CE Loss (Source):  0.5972 ( 0.6954) Learning Rate: 0.1000 (0.1000) Top1_base: 81.2500 (80.4026) Top1_base_per_class: 79.5739 (80.9714) 
Training Epoch: [156/1000] Step: [140 / 285] Batch Time: 0.1438 (0.1620) Data Time: 0.0122 (0.0291) Average Loss: 0.7082 (0.6965) Average CE Loss (Source):  0.7082 ( 0.6965) Learning Rate: 0.1000 (0.1000) Top1_base: 78.1250 (80.4185) Top1_base_per_class: 80.4321 (81.0283) 
Training Epoch: [156/1000] Step: [150 / 285] Batch Time: 0.1564 (0.1612) Data Time: 0.0235 (0.0282) Average Loss: 0.6942 (0.6978) Average CE Loss (Source):  0.6942 ( 0.6978) Learning Rate: 0.1000 (0.1000) Top1_base: 78.9062 (80.3802) Top1_base_per_class: 80.0298 (81.0040) 
Training Epoch: [156/1000] Step: [160 / 285] Batch Time: 0.1455 (0.1605) Data Time: 0.0130 (0.0275) Average Loss: 0.6455 (0.7008) Average CE Loss (Source):  0.6455 ( 0.7008) Learning Rate: 0.1000 (0.1000) Top1_base: 79.6875 (80.2881) Top1_base_per_class: 82.8751 (80.9680) 
Training Epoch: [156/1000] Step: [170 / 285] Batch Time: 0.1639 (0.1599) Data Time: 0.0309 (0.0269) Average Loss: 0.8874 (0.7017) Average CE Loss (Source):  0.8874 ( 0.7017) Learning Rate: 0.1000 (0.1000) Top1_base: 77.3438 (80.2895) Top1_base_per_class: 79.6131 (80.9657) 
Training Epoch: [156/1000] Step: [180 / 285] Batch Time: 0.1438 (0.1599) Data Time: 0.0124 (0.0269) Average Loss: 0.8152 (0.7031) Average CE Loss (Source):  0.8152 ( 0.7031) Learning Rate: 0.1000 (0.1000) Top1_base: 81.2500 (80.2865) Top1_base_per_class: 84.5283 (81.0610) 
Training Epoch: [156/1000] Step: [190 / 285] Batch Time: 0.1499 (0.1595) Data Time: 0.0144 (0.0265) Average Loss: 0.7415 (0.7044) Average CE Loss (Source):  0.7415 ( 0.7044) Learning Rate: 0.1000 (0.1000) Top1_base: 75.0000 (80.2508) Top1_base_per_class: 76.6374 (80.9909) 
Training Epoch: [156/1000] Step: [200 / 285] Batch Time: 0.1471 (0.1590) Data Time: 0.0134 (0.0260) Average Loss: 0.8066 (0.7067) Average CE Loss (Source):  0.8066 ( 0.7067) Learning Rate: 0.1000 (0.1000) Top1_base: 75.7812 (80.1250) Top1_base_per_class: 79.8512 (80.8838) 
Training Epoch: [156/1000] Step: [210 / 285] Batch Time: 0.1519 (0.1585) Data Time: 0.0187 (0.0255) Average Loss: 0.7097 (0.7068) Average CE Loss (Source):  0.7097 ( 0.7068) Learning Rate: 0.1000 (0.1000) Top1_base: 80.4688 (80.1042) Top1_base_per_class: 83.9327 (80.8595) 
Training Epoch: [156/1000] Step: [220 / 285] Batch Time: 0.1446 (0.1581) Data Time: 0.0141 (0.0251) Average Loss: 0.9243 (0.7102) Average CE Loss (Source):  0.9243 ( 0.7102) Learning Rate: 0.1000 (0.1000) Top1_base: 72.6562 (80.0000) Top1_base_per_class: 69.7500 (80.7275) 
Training Epoch: [156/1000] Step: [230 / 285] Batch Time: 0.1511 (0.1576) Data Time: 0.0193 (0.0246) Average Loss: 0.6587 (0.7107) Average CE Loss (Source):  0.6587 ( 0.7107) Learning Rate: 0.1000 (0.1000) Top1_base: 79.6875 (79.9592) Top1_base_per_class: 79.1177 (80.6138) 
Training Epoch: [156/1000] Step: [240 / 285] Batch Time: 0.1478 (0.1572) Data Time: 0.0150 (0.0242) Average Loss: 0.6318 (0.7125) Average CE Loss (Source):  0.6318 ( 0.7125) Learning Rate: 0.1000 (0.1000) Top1_base: 81.2500 (79.8893) Top1_base_per_class: 81.3939 (80.5294) 
Training Epoch: [156/1000] Step: [250 / 285] Batch Time: 0.1512 (0.1570) Data Time: 0.0158 (0.0239) Average Loss: 0.8789 (0.7158) Average CE Loss (Source):  0.8789 ( 0.7158) Learning Rate: 0.1000 (0.1000) Top1_base: 76.5625 (79.7656) Top1_base_per_class: 76.2963 (80.4322) 
Training Epoch: [156/1000] Step: [260 / 285] Batch Time: 0.1475 (0.1571) Data Time: 0.0154 (0.0239) Average Loss: 0.9527 (0.7176) Average CE Loss (Source):  0.9527 ( 0.7176) Learning Rate: 0.1000 (0.1000) Top1_base: 73.4375 (79.6935) Top1_base_per_class: 79.8699 (80.3734) 
Training Epoch: [156/1000] Step: [270 / 285] Batch Time: 0.2234 (0.1571) Data Time: 0.0885 (0.0239) Average Loss: 0.8049 (0.7206) Average CE Loss (Source):  0.8049 ( 0.7206) Learning Rate: 0.1000 (0.1000) Top1_base: 78.9062 (79.6094) Top1_base_per_class: 78.4700 (80.2509) 
Training Epoch: [156/1000] Step: [280 / 285] Batch Time: 0.1506 (0.1569) Data Time: 0.0157 (0.0235) Average Loss: 0.7961 (0.7188) Average CE Loss (Source):  0.7961 ( 0.7188) Learning Rate: 0.1000 (0.1000) Top1_base: 75.7812 (79.6373) Top1_base_per_class: 75.9434 (80.2999) 
Training Epoch: [157/1000] Step: [0] Batch Time: 0.1416 (0.1568) Data Time: 0.0112 (0.0234) Average Loss: 0.6724 (0.7192) Average CE Loss (Source):  0.6724 ( 0.7192) Learning Rate: 0.1000 (0.1000) Top1_base: 80.4688 (79.6409) Top1_base_per_class: 76.1818 (80.2674) 
Training Epoch: [157/1000] Step: [10 / 285] Batch Time: 0.1439 (0.2324) Data Time: 0.0109 (0.0999) Average Loss: 0.6826 (0.6532) Average CE Loss (Source):  0.6826 ( 0.6532) Learning Rate: 0.1000 (0.1000) Top1_base: 82.8125 (81.8750) Top1_base_per_class: 81.8182 (82.1427) 
Training Epoch: [157/1000] Step: [20 / 285] Batch Time: 0.1454 (0.1939) Data Time: 0.0121 (0.0611) Average Loss: 0.5712 (0.6441) Average CE Loss (Source):  0.5712 ( 0.6441) Learning Rate: 0.1000 (0.1000) Top1_base: 80.4688 (81.6797) Top1_base_per_class: 79.1071 (82.0907) 
Training Epoch: [157/1000] Step: [30 / 285] Batch Time: 0.1439 (0.1867) Data Time: 0.0112 (0.0541) Average Loss: 0.7351 (0.6638) Average CE Loss (Source):  0.7351 ( 0.6638) Learning Rate: 0.1000 (0.1000) Top1_base: 82.0312 (80.8073) Top1_base_per_class: 82.5893 (81.2710) 
Training Epoch: [157/1000] Step: [40 / 285] Batch Time: 0.1489 (0.1780) Data Time: 0.0151 (0.0452) Average Loss: 0.7702 (0.6712) Average CE Loss (Source):  0.7702 ( 0.6712) Learning Rate: 0.1000 (0.1000) Top1_base: 78.1250 (80.6836) Top1_base_per_class: 79.2284 (81.1743) 
Training Epoch: [157/1000] Step: [50 / 285] Batch Time: 0.1439 (0.1721) Data Time: 0.0102 (0.0392) Average Loss: 0.7317 (0.6653) Average CE Loss (Source):  0.7317 ( 0.6653) Learning Rate: 0.1000 (0.1000) Top1_base: 80.4688 (80.9844) Top1_base_per_class: 80.3419 (81.3538) 
Training Epoch: [157/1000] Step: [60 / 285] Batch Time: 0.1460 (0.1676) Data Time: 0.0124 (0.0348) Average Loss: 0.7845 (0.6641) Average CE Loss (Source):  0.7845 ( 0.6641) Learning Rate: 0.1000 (0.1000) Top1_base: 78.9062 (81.1849) Top1_base_per_class: 78.3929 (81.6996) 
Training Epoch: [157/1000] Step: [70 / 285] Batch Time: 0.1422 (0.1656) Data Time: 0.0112 (0.0327) Average Loss: 0.7616 (0.6708) Average CE Loss (Source):  0.7616 ( 0.6708) Learning Rate: 0.1000 (0.1000) Top1_base: 77.3438 (80.9375) Top1_base_per_class: 77.3684 (81.5605) 
Training Epoch: [157/1000] Step: [80 / 285] Batch Time: 0.1426 (0.1641) Data Time: 0.0109 (0.0313) Average Loss: 0.6885 (0.6697) Average CE Loss (Source):  0.6885 ( 0.6697) Learning Rate: 0.1000 (0.1000) Top1_base: 80.4688 (81.0449) Top1_base_per_class: 81.7879 (81.6664) 
Training Epoch: [157/1000] Step: [90 / 285] Batch Time: 0.1488 (0.1624) Data Time: 0.0113 (0.0293) Average Loss: 0.6947 (0.6725) Average CE Loss (Source):  0.6947 ( 0.6725) Learning Rate: 0.1000 (0.1000) Top1_base: 83.5938 (81.0417) Top1_base_per_class: 83.8393 (81.6846) 
Training Epoch: [157/1000] Step: [100 / 285] Batch Time: 0.1493 (0.1610) Data Time: 0.0147 (0.0278) Average Loss: 0.6795 (0.6734) Average CE Loss (Source):  0.6795 ( 0.6734) Learning Rate: 0.1000 (0.1000) Top1_base: 78.9062 (80.9375) Top1_base_per_class: 79.3624 (81.6204) 
Training Epoch: [157/1000] Step: [110 / 285] Batch Time: 0.1476 (0.1604) Data Time: 0.0104 (0.0269) Average Loss: 0.8995 (0.6764) Average CE Loss (Source):  0.8995 ( 0.6764) Learning Rate: 0.1000 (0.1000) Top1_base: 78.1250 (80.9162) Top1_base_per_class: 77.5496 (81.5057) 
Training Epoch: [157/1000] Step: [120 / 285] Batch Time: 0.1444 (0.1597) Data Time: 0.0133 (0.0262) Average Loss: 0.7436 (0.6790) Average CE Loss (Source):  0.7436 ( 0.6790) Learning Rate: 0.1000 (0.1000) Top1_base: 77.3438 (80.8789) Top1_base_per_class: 78.6364 (81.4747) 
Training Epoch: [157/1000] Step: [130 / 285] Batch Time: 0.1470 (0.1587) Data Time: 0.0107 (0.0252) Average Loss: 0.7307 (0.6824) Average CE Loss (Source):  0.7307 ( 0.6824) Learning Rate: 0.1000 (0.1000) Top1_base: 75.7812 (80.7332) Top1_base_per_class: 72.9532 (81.2247) 
Training Epoch: [157/1000] Step: [140 / 285] Batch Time: 0.1455 (0.1578) Data Time: 0.0137 (0.0244) Average Loss: 0.6170 (0.6837) Average CE Loss (Source):  0.6170 ( 0.6837) Learning Rate: 0.1000 (0.1000) Top1_base: 83.5938 (80.6641) Top1_base_per_class: 85.8176 (81.2410) 
Training Epoch: [157/1000] Step: [150 / 285] Batch Time: 0.1458 (0.1570) Data Time: 0.0117 (0.0237) Average Loss: 0.6640 (0.6836) Average CE Loss (Source):  0.6640 ( 0.6836) Learning Rate: 0.1000 (0.1000) Top1_base: 82.8125 (80.7396) Top1_base_per_class: 81.7576 (81.3396) 
Training Epoch: [157/1000] Step: [160 / 285] Batch Time: 0.1464 (0.1567) Data Time: 0.0128 (0.0233) Average Loss: 0.5669 (0.6836) Average CE Loss (Source):  0.5669 ( 0.6836) Learning Rate: 0.1000 (0.1000) Top1_base: 85.9375 (80.7666) Top1_base_per_class: 85.8333 (81.3826) 
Training Epoch: [157/1000] Step: [170 / 285] Batch Time: 0.1471 (0.1565) Data Time: 0.0114 (0.0230) Average Loss: 0.9340 (0.6891) Average CE Loss (Source):  0.9340 ( 0.6891) Learning Rate: 0.1000 (0.1000) Top1_base: 73.4375 (80.5331) Top1_base_per_class: 71.5705 (81.1657) 
Training Epoch: [157/1000] Step: [180 / 285] Batch Time: 0.1469 (0.1563) Data Time: 0.0131 (0.0228) Average Loss: 0.5208 (0.6915) Average CE Loss (Source):  0.5208 ( 0.6915) Learning Rate: 0.1000 (0.1000) Top1_base: 85.9375 (80.4774) Top1_base_per_class: 86.3055 (81.1258) 
Training Epoch: [157/1000] Step: [190 / 285] Batch Time: 0.1447 (0.1564) Data Time: 0.0123 (0.0230) Average Loss: 0.8072 (0.6974) Average CE Loss (Source):  0.8072 ( 0.6974) Learning Rate: 0.1000 (0.1000) Top1_base: 74.2188 (80.3495) Top1_base_per_class: 72.0238 (80.9707) 
Training Epoch: [157/1000] Step: [200 / 285] Batch Time: 0.1452 (0.1560) Data Time: 0.0127 (0.0227) Average Loss: 0.7495 (0.7004) Average CE Loss (Source):  0.7495 ( 0.7004) Learning Rate: 0.1000 (0.1000) Top1_base: 78.9062 (80.2773) Top1_base_per_class: 75.6289 (80.8726) 
Training Epoch: [157/1000] Step: [210 / 285] Batch Time: 0.1450 (0.1556) Data Time: 0.0113 (0.0222) Average Loss: 0.9443 (0.7030) Average CE Loss (Source):  0.9443 ( 0.7030) Learning Rate: 0.1000 (0.1000) Top1_base: 71.0938 (80.1749) Top1_base_per_class: 71.5797 (80.7445) 
Training Epoch: [157/1000] Step: [220 / 285] Batch Time: 0.1484 (0.1551) Data Time: 0.0132 (0.0218) Average Loss: 0.6912 (0.7052) Average CE Loss (Source):  0.6912 ( 0.7052) Learning Rate: 0.1000 (0.1000) Top1_base: 81.2500 (80.0994) Top1_base_per_class: 80.8436 (80.6609) 
Training Epoch: [157/1000] Step: [230 / 285] Batch Time: 0.1453 (0.1553) Data Time: 0.0137 (0.0221) Average Loss: 0.8500 (0.7067) Average CE Loss (Source):  0.8500 ( 0.7067) Learning Rate: 0.1000 (0.1000) Top1_base: 75.7812 (80.0408) Top1_base_per_class: 72.5887 (80.5492) 
Training Epoch: [157/1000] Step: [240 / 285] Batch Time: 0.1473 (0.1555) Data Time: 0.0150 (0.0223) Average Loss: 0.6461 (0.7087) Average CE Loss (Source):  0.6461 ( 0.7087) Learning Rate: 0.1000 (0.1000) Top1_base: 80.4688 (80.0033) Top1_base_per_class: 78.7107 (80.5011) 
Training Epoch: [157/1000] Step: [250 / 285] Batch Time: 0.1446 (0.1552) Data Time: 0.0135 (0.0220) Average Loss: 0.6829 (0.7096) Average CE Loss (Source):  0.6829 ( 0.7096) Learning Rate: 0.1000 (0.1000) Top1_base: 81.2500 (79.9469) Top1_base_per_class: 82.7119 (80.4781) 
Training Epoch: [157/1000] Step: [260 / 285] Batch Time: 0.1479 (0.1551) Data Time: 0.0150 (0.0220) Average Loss: 0.7628 (0.7142) Average CE Loss (Source):  0.7628 ( 0.7142) Learning Rate: 0.1000 (0.1000) Top1_base: 76.5625 (79.8828) Top1_base_per_class: 77.1212 (80.4111) 
Training Epoch: [157/1000] Step: [270 / 285] Batch Time: 0.1437 (0.1548) Data Time: 0.0102 (0.0216) Average Loss: 0.6872 (0.7147) Average CE Loss (Source):  0.6872 ( 0.7147) Learning Rate: 0.1000 (0.1000) Top1_base: 82.8125 (79.8814) Top1_base_per_class: 81.6049 (80.4050) 
Training Epoch: [157/1000] Step: [280 / 285] Batch Time: 0.1493 (0.1545) Data Time: 0.0146 (0.0214) Average Loss: 0.6527 (0.7167) Average CE Loss (Source):  0.6527 ( 0.7167) Learning Rate: 0.1000 (0.1000) Top1_base: 80.4688 (79.8186) Top1_base_per_class: 78.3333 (80.3222) 
Training Epoch: [158/1000] Step: [0] Batch Time: 0.1491 (0.1545) Data Time: 0.0158 (0.0213) Average Loss: 0.5791 (0.7167) Average CE Loss (Source):  0.5791 ( 0.7167) Learning Rate: 0.1000 (0.1000) Top1_base: 82.0312 (79.8136) Top1_base_per_class: 81.1300 (80.3180) 
 16%|█▌        | 158/1000 [2:02:53<10:48:31, 46.21s/it] 16%|█▌        | 159/1000 [2:03:39<10:49:17, 46.32s/it]Training Epoch: [158/1000] Step: [10 / 285] Batch Time: 0.1467 (0.2340) Data Time: 0.0116 (0.1016) Average Loss: 0.7680 (0.7089) Average CE Loss (Source):  0.7680 ( 0.7089) Learning Rate: 0.1000 (0.1000) Top1_base: 77.3438 (79.2188) Top1_base_per_class: 75.9141 (79.9456) 
Training Epoch: [158/1000] Step: [20 / 285] Batch Time: 0.1435 (0.1964) Data Time: 0.0111 (0.0634) Average Loss: 0.8529 (0.6878) Average CE Loss (Source):  0.8529 ( 0.6878) Learning Rate: 0.1000 (0.1000) Top1_base: 77.3438 (80.8203) Top1_base_per_class: 81.9913 (80.9346) 
Training Epoch: [158/1000] Step: [30 / 285] Batch Time: 0.1544 (0.1867) Data Time: 0.0224 (0.0536) Average Loss: 0.6173 (0.6783) Average CE Loss (Source):  0.6173 ( 0.6783) Learning Rate: 0.1000 (0.1000) Top1_base: 82.8125 (81.2500) Top1_base_per_class: 82.6503 (81.2239) 
Training Epoch: [158/1000] Step: [40 / 285] Batch Time: 0.1447 (0.1808) Data Time: 0.0128 (0.0476) Average Loss: 0.7126 (0.6740) Average CE Loss (Source):  0.7126 ( 0.6740) Learning Rate: 0.1000 (0.1000) Top1_base: 78.1250 (81.1719) Top1_base_per_class: 77.4702 (81.2299) 
Training Epoch: [158/1000] Step: [50 / 285] Batch Time: 0.1783 (0.1768) Data Time: 0.0469 (0.0437) Average Loss: 0.8997 (0.6796) Average CE Loss (Source):  0.8997 ( 0.6796) Learning Rate: 0.1000 (0.1000) Top1_base: 78.9062 (81.0312) Top1_base_per_class: 82.2024 (81.1367) 
Training Epoch: [158/1000] Step: [60 / 285] Batch Time: 0.1456 (0.1726) Data Time: 0.0108 (0.0395) Average Loss: 0.6288 (0.6804) Average CE Loss (Source):  0.6288 ( 0.6804) Learning Rate: 0.1000 (0.1000) Top1_base: 81.2500 (80.8984) Top1_base_per_class: 79.9221 (81.0727) 
Training Epoch: [158/1000] Step: [70 / 285] Batch Time: 0.1486 (0.1699) Data Time: 0.0156 (0.0369) Average Loss: 0.7569 (0.6929) Average CE Loss (Source):  0.7569 ( 0.6929) Learning Rate: 0.1000 (0.1000) Top1_base: 76.5625 (80.4576) Top1_base_per_class: 77.7874 (80.9103) 
Training Epoch: [158/1000] Step: [80 / 285] Batch Time: 0.1454 (0.1675) Data Time: 0.0128 (0.0346) Average Loss: 0.7202 (0.6937) Average CE Loss (Source):  0.7202 ( 0.6937) Learning Rate: 0.1000 (0.1000) Top1_base: 75.7812 (80.3613) Top1_base_per_class: 78.6723 (80.9495) 
Training Epoch: [158/1000] Step: [90 / 285] Batch Time: 0.2023 (0.1664) Data Time: 0.0708 (0.0336) Average Loss: 0.7990 (0.6967) Average CE Loss (Source):  0.7990 ( 0.6967) Learning Rate: 0.1000 (0.1000) Top1_base: 81.2500 (80.3993) Top1_base_per_class: 79.9248 (80.9943) 
Training Epoch: [158/1000] Step: [100 / 285] Batch Time: 0.1470 (0.1654) Data Time: 0.0145 (0.0328) Average Loss: 0.6193 (0.7057) Average CE Loss (Source):  0.6193 ( 0.7057) Learning Rate: 0.1000 (0.1000) Top1_base: 80.4688 (80.0703) Top1_base_per_class: 79.0396 (80.6732) 
Training Epoch: [158/1000] Step: [110 / 285] Batch Time: 0.2440 (0.1667) Data Time: 0.1109 (0.0341) Average Loss: 0.7537 (0.7083) Average CE Loss (Source):  0.7537 ( 0.7083) Learning Rate: 0.1000 (0.1000) Top1_base: 75.7812 (79.9858) Top1_base_per_class: 74.6469 (80.5055) 
Training Epoch: [158/1000] Step: [120 / 285] Batch Time: 0.1433 (0.1661) Data Time: 0.0117 (0.0336) Average Loss: 0.7940 (0.7134) Average CE Loss (Source):  0.7940 ( 0.7134) Learning Rate: 0.1000 (0.1000) Top1_base: 79.6875 (79.8568) Top1_base_per_class: 77.9464 (80.2939) 
Training Epoch: [158/1000] Step: [130 / 285] Batch Time: 0.2177 (0.1652) Data Time: 0.0868 (0.0328) Average Loss: 0.8056 (0.7155) Average CE Loss (Source):  0.8056 ( 0.7155) Learning Rate: 0.1000 (0.1000) Top1_base: 78.9062 (79.9339) Top1_base_per_class: 78.1694 (80.3430) 
Training Epoch: [158/1000] Step: [140 / 285] Batch Time: 0.1448 (0.1652) Data Time: 0.0134 (0.0327) Average Loss: 0.6943 (0.7137) Average CE Loss (Source):  0.6943 ( 0.7137) Learning Rate: 0.1000 (0.1000) Top1_base: 83.5938 (79.9777) Top1_base_per_class: 84.1358 (80.3520) 
Training Epoch: [158/1000] Step: [150 / 285] Batch Time: 0.1835 (0.1653) Data Time: 0.0508 (0.0329) Average Loss: 0.6454 (0.7168) Average CE Loss (Source):  0.6454 ( 0.7168) Learning Rate: 0.1000 (0.1000) Top1_base: 82.0312 (79.9323) Top1_base_per_class: 78.5119 (80.2286) 
Training Epoch: [158/1000] Step: [160 / 285] Batch Time: 0.1429 (0.1649) Data Time: 0.0112 (0.0326) Average Loss: 0.5407 (0.7168) Average CE Loss (Source):  0.5407 ( 0.7168) Learning Rate: 0.1000 (0.1000) Top1_base: 82.0312 (79.8438) Top1_base_per_class: 83.5317 (80.1429) 
Training Epoch: [158/1000] Step: [170 / 285] Batch Time: 0.2266 (0.1647) Data Time: 0.0938 (0.0324) Average Loss: 0.6376 (0.7135) Average CE Loss (Source):  0.6376 ( 0.7135) Learning Rate: 0.1000 (0.1000) Top1_base: 82.8125 (79.9632) Top1_base_per_class: 82.8704 (80.2944) 
Training Epoch: [158/1000] Step: [180 / 285] Batch Time: 0.1443 (0.1639) Data Time: 0.0128 (0.0316) Average Loss: 0.8433 (0.7125) Average CE Loss (Source):  0.8433 ( 0.7125) Learning Rate: 0.1000 (0.1000) Top1_base: 74.2188 (79.9696) Top1_base_per_class: 78.3290 (80.2562) 
Training Epoch: [158/1000] Step: [190 / 285] Batch Time: 0.2267 (0.1642) Data Time: 0.0934 (0.0319) Average Loss: 0.6501 (0.7162) Average CE Loss (Source):  0.6501 ( 0.7162) Learning Rate: 0.1000 (0.1000) Top1_base: 82.0312 (79.8438) Top1_base_per_class: 80.8642 (80.1060) 
Training Epoch: [158/1000] Step: [200 / 285] Batch Time: 0.1432 (0.1638) Data Time: 0.0123 (0.0315) Average Loss: 0.6534 (0.7178) Average CE Loss (Source):  0.6534 ( 0.7178) Learning Rate: 0.1000 (0.1000) Top1_base: 81.2500 (79.8047) Top1_base_per_class: 82.8869 (80.0615) 
Training Epoch: [158/1000] Step: [210 / 285] Batch Time: 0.1679 (0.1640) Data Time: 0.0354 (0.0317) Average Loss: 0.8129 (0.7198) Average CE Loss (Source):  0.8129 ( 0.7198) Learning Rate: 0.1000 (0.1000) Top1_base: 78.9062 (79.7135) Top1_base_per_class: 76.1607 (80.0010) 
Training Epoch: [158/1000] Step: [220 / 285] Batch Time: 0.1471 (0.1639) Data Time: 0.0150 (0.0316) Average Loss: 0.7267 (0.7207) Average CE Loss (Source):  0.7267 ( 0.7207) Learning Rate: 0.1000 (0.1000) Top1_base: 77.3438 (79.7727) Top1_base_per_class: 78.5380 (80.1084) 
Training Epoch: [158/1000] Step: [230 / 285] Batch Time: 0.2455 (0.1638) Data Time: 0.1151 (0.0315) Average Loss: 0.8638 (0.7221) Average CE Loss (Source):  0.8638 ( 0.7221) Learning Rate: 0.1000 (0.1000) Top1_base: 75.0000 (79.7283) Top1_base_per_class: 78.1515 (80.1077) 
Training Epoch: [158/1000] Step: [240 / 285] Batch Time: 0.1443 (0.1635) Data Time: 0.0129 (0.0312) Average Loss: 0.7148 (0.7219) Average CE Loss (Source):  0.7148 ( 0.7219) Learning Rate: 0.1000 (0.1000) Top1_base: 85.9375 (79.7233) Top1_base_per_class: 86.0577 (80.1342) 
Training Epoch: [158/1000] Step: [250 / 285] Batch Time: 0.3100 (0.1637) Data Time: 0.1772 (0.0314) Average Loss: 0.8274 (0.7248) Average CE Loss (Source):  0.8274 ( 0.7248) Learning Rate: 0.1000 (0.1000) Top1_base: 75.0000 (79.6250) Top1_base_per_class: 75.7273 (80.0544) 
Training Epoch: [158/1000] Step: [260 / 285] Batch Time: 0.1423 (0.1642) Data Time: 0.0111 (0.0319) Average Loss: 0.8833 (0.7262) Average CE Loss (Source):  0.8833 ( 0.7262) Learning Rate: 0.1000 (0.1000) Top1_base: 79.6875 (79.6635) Top1_base_per_class: 78.1132 (80.0962) 
Training Epoch: [158/1000] Step: [270 / 285] Batch Time: 0.1505 (0.1637) Data Time: 0.0160 (0.0314) Average Loss: 0.6444 (0.7262) Average CE Loss (Source):  0.6444 ( 0.7262) Learning Rate: 0.1000 (0.1000) Top1_base: 78.9062 (79.6615) Top1_base_per_class: 83.2398 (80.0887) 
Training Epoch: [158/1000] Step: [280 / 285] Batch Time: 0.1416 (0.1635) Data Time: 0.0108 (0.0312) Average Loss: 0.7112 (0.7281) Average CE Loss (Source):  0.7112 ( 0.7281) Learning Rate: 0.1000 (0.1000) Top1_base: 78.1250 (79.5592) Top1_base_per_class: 80.5301 (79.9767) 
Training Epoch: [159/1000] Step: [0] Batch Time: 0.1395 (0.1632) Data Time: 0.0106 (0.0308) Average Loss: 0.8462 (0.7274) Average CE Loss (Source):  0.8462 ( 0.7274) Learning Rate: 0.1000 (0.1000) Top1_base: 75.0000 (79.5751) Top1_base_per_class: 72.5683 (79.9705) 
Training Epoch: [159/1000] Step: [10 / 285] Batch Time: 0.1457 (0.2293) Data Time: 0.0148 (0.0968) Average Loss: 0.6915 (0.6559) Average CE Loss (Source):  0.6915 ( 0.6559) Learning Rate: 0.1000 (0.1000) Top1_base: 82.0312 (81.5625) Top1_base_per_class: 81.8827 (82.0341) 
Training Epoch: [159/1000] Step: [20 / 285] Batch Time: 0.1453 (0.1959) Data Time: 0.0128 (0.0635) Average Loss: 0.6891 (0.6955) Average CE Loss (Source):  0.6891 ( 0.6955) Learning Rate: 0.1000 (0.1000) Top1_base: 78.1250 (79.9609) Top1_base_per_class: 75.0962 (80.2037) 
Training Epoch: [159/1000] Step: [30 / 285] Batch Time: 0.1465 (0.1794) Data Time: 0.0136 (0.0469) Average Loss: 0.6464 (0.6997) Average CE Loss (Source):  0.6464 ( 0.6997) Learning Rate: 0.1000 (0.1000) Top1_base: 77.3438 (79.6875) Top1_base_per_class: 80.3390 (79.9130) 
Training Epoch: [159/1000] Step: [40 / 285] Batch Time: 0.1444 (0.1739) Data Time: 0.0107 (0.0411) Average Loss: 0.7179 (0.6945) Average CE Loss (Source):  0.7179 ( 0.6945) Learning Rate: 0.1000 (0.1000) Top1_base: 80.4688 (79.8242) Top1_base_per_class: 82.3392 (80.3578) 
Training Epoch: [159/1000] Step: [50 / 285] Batch Time: 0.1437 (0.1697) Data Time: 0.0134 (0.0369) Average Loss: 0.7380 (0.6954) Average CE Loss (Source):  0.7380 ( 0.6954) Learning Rate: 0.1000 (0.1000) Top1_base: 80.4688 (79.9688) Top1_base_per_class: 81.9091 (80.5514) 
Training Epoch: [159/1000] Step: [60 / 285] Batch Time: 0.1433 (0.1661) Data Time: 0.0108 (0.0333) Average Loss: 0.7431 (0.6987) Average CE Loss (Source):  0.7431 ( 0.6987) Learning Rate: 0.1000 (0.1000) Top1_base: 77.3438 (80.0000) Top1_base_per_class: 75.4167 (80.3851) 
Training Epoch: [159/1000] Step: [70 / 285] Batch Time: 0.1472 (0.1650) Data Time: 0.0127 (0.0321) Average Loss: 0.6767 (0.6990) Average CE Loss (Source):  0.6767 ( 0.6990) Learning Rate: 0.1000 (0.1000) Top1_base: 84.3750 (80.2009) Top1_base_per_class: 84.3519 (80.6230) 
Training Epoch: [159/1000] Step: [80 / 285] Batch Time: 0.1445 (0.1628) Data Time: 0.0118 (0.0299) Average Loss: 0.7703 (0.7025) Average CE Loss (Source):  0.7703 ( 0.7025) Learning Rate: 0.1000 (0.1000) Top1_base: 79.6875 (80.1172) Top1_base_per_class: 78.5494 (80.5401) 
Training Epoch: [159/1000] Step: [90 / 285] Batch Time: 0.1501 (0.1612) Data Time: 0.0162 (0.0281) Average Loss: 0.6140 (0.7073) Average CE Loss (Source):  0.6140 ( 0.7073) Learning Rate: 0.1000 (0.1000) Top1_base: 82.8125 (80.1910) Top1_base_per_class: 84.4536 (80.5493) 
Training Epoch: [159/1000] Step: [100 / 285] Batch Time: 0.1441 (0.1598) Data Time: 0.0111 (0.0267) Average Loss: 0.6575 (0.7072) Average CE Loss (Source):  0.6575 ( 0.7072) Learning Rate: 0.1000 (0.1000) Top1_base: 83.5938 (80.2188) Top1_base_per_class: 83.6494 (80.6510) 
Training Epoch: [159/1000] Step: [110 / 285] Batch Time: 0.1492 (0.1590) Data Time: 0.0155 (0.0259) Average Loss: 0.8168 (0.7063) Average CE Loss (Source):  0.8168 ( 0.7063) Learning Rate: 0.1000 (0.1000) Top1_base: 75.0000 (80.1349) Top1_base_per_class: 76.0458 (80.5948) 
Training Epoch: [159/1000] Step: [120 / 285] Batch Time: 0.1424 (0.1597) Data Time: 0.0104 (0.0266) Average Loss: 0.8074 (0.7071) Average CE Loss (Source):  0.8074 ( 0.7071) Learning Rate: 0.1000 (0.1000) Top1_base: 79.6875 (80.1172) Top1_base_per_class: 81.1728 (80.6205) 
Training Epoch: [159/1000] Step: [130 / 285] Batch Time: 0.1526 (0.1589) Data Time: 0.0181 (0.0258) Average Loss: 0.7404 (0.7141) Average CE Loss (Source):  0.7404 ( 0.7141) Learning Rate: 0.1000 (0.1000) Top1_base: 78.1250 (79.9940) Top1_base_per_class: 77.2126 (80.4157) 
Training Epoch: [159/1000] Step: [140 / 285] Batch Time: 0.1424 (0.1596) Data Time: 0.0104 (0.0265) Average Loss: 0.7964 (0.7159) Average CE Loss (Source):  0.7964 ( 0.7159) Learning Rate: 0.1000 (0.1000) Top1_base: 75.7812 (79.9330) Top1_base_per_class: 75.7190 (80.3375) 
Training Epoch: [159/1000] Step: [150 / 285] Batch Time: 0.1490 (0.1588) Data Time: 0.0134 (0.0256) Average Loss: 0.7783 (0.7166) Average CE Loss (Source):  0.7783 ( 0.7166) Learning Rate: 0.1000 (0.1000) Top1_base: 81.2500 (79.9531) Top1_base_per_class: 81.6944 (80.3304) 
Training Epoch: [159/1000] Step: [160 / 285] Batch Time: 0.1417 (0.1581) Data Time: 0.0111 (0.0250) Average Loss: 0.7849 (0.7151) Average CE Loss (Source):  0.7849 ( 0.7151) Learning Rate: 0.1000 (0.1000) Top1_base: 78.9062 (79.9658) Top1_base_per_class: 80.7280 (80.3547) 
Training Epoch: [159/1000] Step: [170 / 285] Batch Time: 0.1463 (0.1580) Data Time: 0.0129 (0.0249) Average Loss: 0.7310 (0.7173) Average CE Loss (Source):  0.7310 ( 0.7173) Learning Rate: 0.1000 (0.1000) Top1_base: 76.5625 (79.8897) Top1_base_per_class: 79.5455 (80.3332) 
Training Epoch: [159/1000] Step: [180 / 285] Batch Time: 0.1427 (0.1574) Data Time: 0.0114 (0.0243) Average Loss: 0.7853 (0.7173) Average CE Loss (Source):  0.7853 ( 0.7173) Learning Rate: 0.1000 (0.1000) Top1_base: 75.7812 (79.8611) Top1_base_per_class: 77.2222 (80.3571) 
Training Epoch: [159/1000] Step: [190 / 285] Batch Time: 0.1473 (0.1570) Data Time: 0.0137 (0.0239) Average Loss: 1.0501 (0.7222) Average CE Loss (Source):  1.0501 ( 0.7222) Learning Rate: 0.1000 (0.1000) Top1_base: 72.6562 (79.7286) Top1_base_per_class: 74.3910 (80.2316) 
Training Epoch: [159/1000] Step: [200 / 285] Batch Time: 0.1434 (0.1569) Data Time: 0.0111 (0.0238) Average Loss: 0.8140 (0.7217) Average CE Loss (Source):  0.8140 ( 0.7217) Learning Rate: 0.1000 (0.1000) Top1_base: 76.5625 (79.8086) Top1_base_per_class: 79.4753 (80.3170) 
Training Epoch: [159/1000] Step: [210 / 285] Batch Time: 0.1467 (0.1566) Data Time: 0.0126 (0.0235) Average Loss: 0.9327 (0.7248) Average CE Loss (Source):  0.9327 ( 0.7248) Learning Rate: 0.1000 (0.1000) Top1_base: 75.7812 (79.7098) Top1_base_per_class: 77.8485 (80.2250) 
Training Epoch: [159/1000] Step: [220 / 285] Batch Time: 0.1430 (0.1563) Data Time: 0.0120 (0.0232) Average Loss: 0.8926 (0.7252) Average CE Loss (Source):  0.8926 ( 0.7252) Learning Rate: 0.1000 (0.1000) Top1_base: 75.7812 (79.7053) Top1_base_per_class: 76.8452 (80.2102) 
Training Epoch: [159/1000] Step: [230 / 285] Batch Time: 0.1521 (0.1562) Data Time: 0.0150 (0.0230) Average Loss: 0.9628 (0.7296) Average CE Loss (Source):  0.9628 ( 0.7296) Learning Rate: 0.1000 (0.1000) Top1_base: 76.5625 (79.5958) Top1_base_per_class: 77.3856 (80.0984) 
Training Epoch: [159/1000] Step: [240 / 285] Batch Time: 0.1443 (0.1565) Data Time: 0.0116 (0.0233) Average Loss: 0.9013 (0.7339) Average CE Loss (Source):  0.9013 ( 0.7339) Learning Rate: 0.1000 (0.1000) Top1_base: 75.0000 (79.4629) Top1_base_per_class: 75.5556 (80.0150) 
Training Epoch: [159/1000] Step: [250 / 285] Batch Time: 0.1485 (0.1562) Data Time: 0.0136 (0.0228) Average Loss: 0.7037 (0.7354) Average CE Loss (Source):  0.7037 ( 0.7354) Learning Rate: 0.1000 (0.1000) Top1_base: 80.4688 (79.3875) Top1_base_per_class: 82.4532 (79.9369) 
Training Epoch: [159/1000] Step: [260 / 285] Batch Time: 0.1440 (0.1564) Data Time: 0.0117 (0.0231) Average Loss: 0.7407 (0.7356) Average CE Loss (Source):  0.7407 ( 0.7356) Learning Rate: 0.1000 (0.1000) Top1_base: 78.9062 (79.3690) Top1_base_per_class: 75.5952 (79.8974) 
Training Epoch: [159/1000] Step: [270 / 285] Batch Time: 0.1468 (0.1561) Data Time: 0.0137 (0.0227) Average Loss: 0.9232 (0.7372) Average CE Loss (Source):  0.9232 ( 0.7372) Learning Rate: 0.1000 (0.1000) Top1_base: 71.8750 (79.3200) Top1_base_per_class: 72.7198 (79.8675) 
Training Epoch: [159/1000] Step: [280 / 285] Batch Time: 0.1431 (0.1557) Data Time: 0.0110 (0.0224) Average Loss: 0.8735 (0.7397) Average CE Loss (Source):  0.8735 ( 0.7397) Learning Rate: 0.1000 (0.1000) Top1_base: 72.6562 (79.2299) Top1_base_per_class: 70.0000 (79.7525) 
Training Epoch: [160/1000] Step: [0] Batch Time: 0.1422 (0.1555) Data Time: 0.0104 (0.0222) Average Loss: 0.7671 (0.7399) Average CE Loss (Source):  0.7671 ( 0.7399) Learning Rate: 0.1000 (0.1000) Top1_base: 80.4688 (79.2215) Top1_base_per_class: 82.3276 (79.7682) 
 16%|█▌        | 160/1000 [2:04:27<10:51:59, 46.57s/it] 16%|█▌        | 161/1000 [2:05:11<10:41:49, 45.90s/it]Training Epoch: [160/1000] Step: [10 / 285] Batch Time: 0.1456 (0.2248) Data Time: 0.0107 (0.0918) Average Loss: 0.6949 (0.6677) Average CE Loss (Source):  0.6949 ( 0.6677) Learning Rate: 0.1000 (0.1000) Top1_base: 84.3750 (81.3281) Top1_base_per_class: 84.7701 (80.4953) 
Training Epoch: [160/1000] Step: [20 / 285] Batch Time: 0.1475 (0.1915) Data Time: 0.0133 (0.0587) Average Loss: 0.9957 (0.7118) Average CE Loss (Source):  0.9957 ( 0.7118) Learning Rate: 0.1000 (0.1000) Top1_base: 70.3125 (79.8828) Top1_base_per_class: 69.7076 (79.9805) 
Training Epoch: [160/1000] Step: [30 / 285] Batch Time: 0.1462 (0.1859) Data Time: 0.0102 (0.0531) Average Loss: 0.7598 (0.7095) Average CE Loss (Source):  0.7598 ( 0.7095) Learning Rate: 0.1000 (0.1000) Top1_base: 78.9062 (79.9219) Top1_base_per_class: 76.0152 (80.2288) 
Training Epoch: [160/1000] Step: [40 / 285] Batch Time: 0.1462 (0.1774) Data Time: 0.0145 (0.0446) Average Loss: 0.6555 (0.7149) Average CE Loss (Source):  0.6555 ( 0.7149) Learning Rate: 0.1000 (0.1000) Top1_base: 82.0312 (79.9414) Top1_base_per_class: 80.7143 (80.1728) 
Training Epoch: [160/1000] Step: [50 / 285] Batch Time: 0.1467 (0.1738) Data Time: 0.0129 (0.0411) Average Loss: 0.6564 (0.7098) Average CE Loss (Source):  0.6564 ( 0.7098) Learning Rate: 0.1000 (0.1000) Top1_base: 79.6875 (79.9062) Top1_base_per_class: 81.7544 (80.3304) 
Training Epoch: [160/1000] Step: [60 / 285] Batch Time: 0.1457 (0.1702) Data Time: 0.0128 (0.0375) Average Loss: 0.6346 (0.7153) Average CE Loss (Source):  0.6346 ( 0.7153) Learning Rate: 0.1000 (0.1000) Top1_base: 82.0312 (79.7005) Top1_base_per_class: 81.3636 (80.0724) 
Training Epoch: [160/1000] Step: [70 / 285] Batch Time: 0.1417 (0.1687) Data Time: 0.0116 (0.0362) Average Loss: 0.7923 (0.7133) Average CE Loss (Source):  0.7923 ( 0.7133) Learning Rate: 0.1000 (0.1000) Top1_base: 78.1250 (79.8661) Top1_base_per_class: 80.2044 (80.5030) 
Training Epoch: [160/1000] Step: [80 / 285] Batch Time: 0.1495 (0.1664) Data Time: 0.0148 (0.0336) Average Loss: 0.6211 (0.7132) Average CE Loss (Source):  0.6211 ( 0.7132) Learning Rate: 0.1000 (0.1000) Top1_base: 82.8125 (79.9902) Top1_base_per_class: 85.1775 (80.6778) 
Training Epoch: [160/1000] Step: [90 / 285] Batch Time: 0.1473 (0.1645) Data Time: 0.0107 (0.0313) Average Loss: 0.7218 (0.7046) Average CE Loss (Source):  0.7218 ( 0.7046) Learning Rate: 0.1000 (0.1000) Top1_base: 78.9062 (80.3472) Top1_base_per_class: 73.7845 (80.8279) 
Training Epoch: [160/1000] Step: [100 / 285] Batch Time: 0.1471 (0.1627) Data Time: 0.0135 (0.0295) Average Loss: 0.7256 (0.7003) Average CE Loss (Source):  0.7256 ( 0.7003) Learning Rate: 0.1000 (0.1000) Top1_base: 75.7812 (80.4375) Top1_base_per_class: 74.4253 (80.9020) 
Training Epoch: [160/1000] Step: [110 / 285] Batch Time: 0.1445 (0.1615) Data Time: 0.0106 (0.0282) Average Loss: 0.6056 (0.6950) Average CE Loss (Source):  0.6056 ( 0.6950) Learning Rate: 0.1000 (0.1000) Top1_base: 84.3750 (80.6818) Top1_base_per_class: 84.9718 (81.1370) 
Training Epoch: [160/1000] Step: [120 / 285] Batch Time: 0.1511 (0.1604) Data Time: 0.0160 (0.0270) Average Loss: 0.5711 (0.6961) Average CE Loss (Source):  0.5711 ( 0.6961) Learning Rate: 0.1000 (0.1000) Top1_base: 82.8125 (80.6706) Top1_base_per_class: 84.0678 (81.1185) 
Training Epoch: [160/1000] Step: [130 / 285] Batch Time: 0.1427 (0.1597) Data Time: 0.0129 (0.0263) Average Loss: 0.6936 (0.6948) Average CE Loss (Source):  0.6936 ( 0.6948) Learning Rate: 0.1000 (0.1000) Top1_base: 78.9062 (80.6671) Top1_base_per_class: 80.0000 (81.1415) 
Training Epoch: [160/1000] Step: [140 / 285] Batch Time: 0.1483 (0.1591) Data Time: 0.0152 (0.0256) Average Loss: 0.8765 (0.6934) Average CE Loss (Source):  0.8765 ( 0.6934) Learning Rate: 0.1000 (0.1000) Top1_base: 75.0000 (80.6641) Top1_base_per_class: 80.2830 (81.2261) 
Training Epoch: [160/1000] Step: [150 / 285] Batch Time: 0.1468 (0.1583) Data Time: 0.0108 (0.0248) Average Loss: 0.9387 (0.6960) Average CE Loss (Source):  0.9387 ( 0.6960) Learning Rate: 0.1000 (0.1000) Top1_base: 71.0938 (80.4792) Top1_base_per_class: 73.6970 (81.0312) 
Training Epoch: [160/1000] Step: [160 / 285] Batch Time: 0.1485 (0.1579) Data Time: 0.0153 (0.0242) Average Loss: 0.8990 (0.7011) Average CE Loss (Source):  0.8990 ( 0.7011) Learning Rate: 0.1000 (0.1000) Top1_base: 77.3438 (80.3857) Top1_base_per_class: 75.9877 (80.9089) 
Training Epoch: [160/1000] Step: [170 / 285] Batch Time: 0.1458 (0.1573) Data Time: 0.0106 (0.0236) Average Loss: 0.6352 (0.7075) Average CE Loss (Source):  0.6352 ( 0.7075) Learning Rate: 0.1000 (0.1000) Top1_base: 81.2500 (80.1838) Top1_base_per_class: 77.9697 (80.6661) 
Training Epoch: [160/1000] Step: [180 / 285] Batch Time: 0.1526 (0.1568) Data Time: 0.0186 (0.0230) Average Loss: 0.7853 (0.7100) Average CE Loss (Source):  0.7853 ( 0.7100) Learning Rate: 0.1000 (0.1000) Top1_base: 77.3438 (80.0825) Top1_base_per_class: 77.3131 (80.5469) 
Training Epoch: [160/1000] Step: [190 / 285] Batch Time: 0.1475 (0.1564) Data Time: 0.0106 (0.0225) Average Loss: 0.8495 (0.7132) Average CE Loss (Source):  0.8495 ( 0.7132) Learning Rate: 0.1000 (0.1000) Top1_base: 77.3438 (79.9959) Top1_base_per_class: 80.8333 (80.5042) 
Training Epoch: [160/1000] Step: [200 / 285] Batch Time: 0.1448 (0.1559) Data Time: 0.0119 (0.0221) Average Loss: 0.5713 (0.7149) Average CE Loss (Source):  0.5713 ( 0.7149) Learning Rate: 0.1000 (0.1000) Top1_base: 84.3750 (79.9492) Top1_base_per_class: 83.8580 (80.4462) 
Training Epoch: [160/1000] Step: [210 / 285] Batch Time: 0.1482 (0.1557) Data Time: 0.0121 (0.0218) Average Loss: 0.8259 (0.7160) Average CE Loss (Source):  0.8259 ( 0.7160) Learning Rate: 0.1000 (0.1000) Top1_base: 77.3438 (79.9368) Top1_base_per_class: 79.0741 (80.4051) 
Training Epoch: [160/1000] Step: [220 / 285] Batch Time: 0.1528 (0.1554) Data Time: 0.0173 (0.0215) Average Loss: 0.7375 (0.7207) Average CE Loss (Source):  0.7375 ( 0.7207) Learning Rate: 0.1000 (0.1000) Top1_base: 78.9062 (79.8011) Top1_base_per_class: 80.8036 (80.3046) 
Training Epoch: [160/1000] Step: [230 / 285] Batch Time: 0.1464 (0.1551) Data Time: 0.0104 (0.0211) Average Loss: 0.7317 (0.7219) Average CE Loss (Source):  0.7317 ( 0.7219) Learning Rate: 0.1000 (0.1000) Top1_base: 80.4688 (79.8098) Top1_base_per_class: 75.6044 (80.2462) 
Training Epoch: [160/1000] Step: [240 / 285] Batch Time: 0.1513 (0.1550) Data Time: 0.0174 (0.0209) Average Loss: 0.8289 (0.7269) Average CE Loss (Source):  0.8289 ( 0.7269) Learning Rate: 0.1000 (0.1000) Top1_base: 74.2188 (79.6615) Top1_base_per_class: 74.0741 (80.1105) 
Training Epoch: [160/1000] Step: [250 / 285] Batch Time: 0.1479 (0.1547) Data Time: 0.0105 (0.0206) Average Loss: 0.7378 (0.7271) Average CE Loss (Source):  0.7378 ( 0.7271) Learning Rate: 0.1000 (0.1000) Top1_base: 80.4688 (79.6375) Top1_base_per_class: 83.3631 (80.0881) 
Training Epoch: [160/1000] Step: [260 / 285] Batch Time: 0.1464 (0.1554) Data Time: 0.0121 (0.0212) Average Loss: 0.7578 (0.7283) Average CE Loss (Source):  0.7578 ( 0.7283) Learning Rate: 0.1000 (0.1000) Top1_base: 78.9062 (79.5913) Top1_base_per_class: 81.6369 (80.0377) 
Training Epoch: [160/1000] Step: [270 / 285] Batch Time: 0.1418 (0.1551) Data Time: 0.0118 (0.0210) Average Loss: 0.5788 (0.7278) Average CE Loss (Source):  0.5788 ( 0.7278) Learning Rate: 0.1000 (0.1000) Top1_base: 83.5938 (79.6325) Top1_base_per_class: 80.5476 (80.0183) 
Training Epoch: [160/1000] Step: [280 / 285] Batch Time: 0.1418 (0.1556) Data Time: 0.0106 (0.0215) Average Loss: 0.7827 (0.7300) Average CE Loss (Source):  0.7827 ( 0.7300) Learning Rate: 0.1000 (0.1000) Top1_base: 77.3438 (79.5619) Top1_base_per_class: 80.3480 (79.9342) 
Training Epoch: [161/1000] Step: [0] Batch Time: 0.1381 (0.1553) Data Time: 0.0093 (0.0213) Average Loss: 0.7608 (0.7296) Average CE Loss (Source):  0.7608 ( 0.7296) Learning Rate: 0.1000 (0.1000) Top1_base: 73.4375 (79.5312) Top1_base_per_class: 72.0513 (79.9058) 
Training Epoch: [161/1000] Step: [10 / 285] Batch Time: 0.1473 (0.2369) Data Time: 0.0149 (0.1040) Average Loss: 0.5626 (0.6853) Average CE Loss (Source):  0.5626 ( 0.6853) Learning Rate: 0.1000 (0.1000) Top1_base: 82.8125 (80.9375) Top1_base_per_class: 85.0962 (81.5217) 
Training Epoch: [161/1000] Step: [20 / 285] Batch Time: 0.1437 (0.1929) Data Time: 0.0101 (0.0604) Average Loss: 0.8359 (0.6773) Average CE Loss (Source):  0.8359 ( 0.6773) Learning Rate: 0.1000 (0.1000) Top1_base: 75.7812 (80.9766) Top1_base_per_class: 78.3974 (81.9679) 
Training Epoch: [161/1000] Step: [30 / 285] Batch Time: 0.1440 (0.1835) Data Time: 0.0121 (0.0508) Average Loss: 0.7298 (0.7020) Average CE Loss (Source):  0.7298 ( 0.7020) Learning Rate: 0.1000 (0.1000) Top1_base: 81.2500 (80.2604) Top1_base_per_class: 80.6725 (81.1662) 
Training Epoch: [161/1000] Step: [40 / 285] Batch Time: 0.1458 (0.1748) Data Time: 0.0117 (0.0420) Average Loss: 0.7639 (0.6881) Average CE Loss (Source):  0.7639 ( 0.6881) Learning Rate: 0.1000 (0.1000) Top1_base: 80.4688 (80.5664) Top1_base_per_class: 80.1258 (81.1207) 
Training Epoch: [161/1000] Step: [50 / 285] Batch Time: 0.1474 (0.1707) Data Time: 0.0122 (0.0374) Average Loss: 0.7269 (0.6945) Average CE Loss (Source):  0.7269 ( 0.6945) Learning Rate: 0.1000 (0.1000) Top1_base: 81.2500 (80.5156) Top1_base_per_class: 82.2043 (81.1456) 
Training Epoch: [161/1000] Step: [60 / 285] Batch Time: 0.1444 (0.1673) Data Time: 0.0125 (0.0343) Average Loss: 0.6739 (0.6894) Average CE Loss (Source):  0.6739 ( 0.6894) Learning Rate: 0.1000 (0.1000) Top1_base: 83.5938 (80.5729) Top1_base_per_class: 84.0059 (81.1101) 
Training Epoch: [161/1000] Step: [70 / 285] Batch Time: 0.1441 (0.1649) Data Time: 0.0117 (0.0319) Average Loss: 0.6708 (0.6943) Average CE Loss (Source):  0.6708 ( 0.6943) Learning Rate: 0.1000 (0.1000) Top1_base: 82.0312 (80.4353) Top1_base_per_class: 84.2648 (80.9700) 
Training Epoch: [161/1000] Step: [80 / 285] Batch Time: 0.1453 (0.1625) Data Time: 0.0106 (0.0296) Average Loss: 0.9048 (0.6995) Average CE Loss (Source):  0.9048 ( 0.6995) Learning Rate: 0.1000 (0.1000) Top1_base: 81.2500 (80.4883) Top1_base_per_class: 85.1235 (81.0192) 
Training Epoch: [161/1000] Step: [90 / 285] Batch Time: 0.1464 (0.1616) Data Time: 0.0121 (0.0287) Average Loss: 0.8283 (0.7048) Average CE Loss (Source):  0.8283 ( 0.7048) Learning Rate: 0.1000 (0.1000) Top1_base: 77.3438 (80.3472) Top1_base_per_class: 76.9444 (80.8585) 
Training Epoch: [161/1000] Step: [100 / 285] Batch Time: 0.1428 (0.1604) Data Time: 0.0115 (0.0276) Average Loss: 0.6054 (0.7061) Average CE Loss (Source):  0.6054 ( 0.7061) Learning Rate: 0.1000 (0.1000) Top1_base: 83.5938 (80.3516) Top1_base_per_class: 83.5802 (80.9711) 
Training Epoch: [161/1000] Step: [110 / 285] Batch Time: 0.1922 (0.1609) Data Time: 0.0587 (0.0281) Average Loss: 0.7966 (0.7073) Average CE Loss (Source):  0.7966 ( 0.7073) Learning Rate: 0.1000 (0.1000) Top1_base: 79.6875 (80.3693) Top1_base_per_class: 79.6505 (81.0317) 
Training Epoch: [161/1000] Step: [120 / 285] Batch Time: 0.1469 (0.1608) Data Time: 0.0115 (0.0280) Average Loss: 0.8761 (0.7044) Average CE Loss (Source):  0.8761 ( 0.7044) Learning Rate: 0.1000 (0.1000) Top1_base: 76.5625 (80.4362) Top1_base_per_class: 79.6855 (81.0719) 
Training Epoch: [161/1000] Step: [130 / 285] Batch Time: 0.1522 (0.1607) Data Time: 0.0214 (0.0279) Average Loss: 0.9434 (0.7059) Average CE Loss (Source):  0.9434 ( 0.7059) Learning Rate: 0.1000 (0.1000) Top1_base: 74.2188 (80.3666) Top1_base_per_class: 76.2727 (81.0066) 
Training Epoch: [161/1000] Step: [140 / 285] Batch Time: 0.1437 (0.1599) Data Time: 0.0110 (0.0271) Average Loss: 0.6847 (0.7071) Average CE Loss (Source):  0.6847 ( 0.7071) Learning Rate: 0.1000 (0.1000) Top1_base: 79.6875 (80.2679) Top1_base_per_class: 82.0231 (80.9221) 
Training Epoch: [161/1000] Step: [150 / 285] Batch Time: 0.2743 (0.1603) Data Time: 0.1406 (0.0275) Average Loss: 0.7297 (0.7101) Average CE Loss (Source):  0.7297 ( 0.7101) Learning Rate: 0.1000 (0.1000) Top1_base: 78.9062 (80.1719) Top1_base_per_class: 81.6970 (80.8169) 
Training Epoch: [161/1000] Step: [160 / 285] Batch Time: 0.1439 (0.1600) Data Time: 0.0134 (0.0272) Average Loss: 0.6249 (0.7060) Average CE Loss (Source):  0.6249 ( 0.7060) Learning Rate: 0.1000 (0.1000) Top1_base: 88.2812 (80.2881) Top1_base_per_class: 82.3270 (80.9469) 
Training Epoch: [161/1000] Step: [170 / 285] Batch Time: 0.2525 (0.1604) Data Time: 0.1187 (0.0275) Average Loss: 0.6600 (0.7087) Average CE Loss (Source):  0.6600 ( 0.7087) Learning Rate: 0.1000 (0.1000) Top1_base: 79.6875 (80.2390) Top1_base_per_class: 81.2069 (80.9059) 
Training Epoch: [161/1000] Step: [180 / 285] Batch Time: 0.1441 (0.1595) Data Time: 0.0135 (0.0267) Average Loss: 0.7269 (0.7084) Average CE Loss (Source):  0.7269 ( 0.7084) Learning Rate: 0.1000 (0.1000) Top1_base: 81.2500 (80.2127) Top1_base_per_class: 78.4591 (80.9273) 
Training Epoch: [161/1000] Step: [190 / 285] Batch Time: 0.1466 (0.1587) Data Time: 0.0148 (0.0260) Average Loss: 0.4801 (0.7107) Average CE Loss (Source):  0.4801 ( 0.7107) Learning Rate: 0.1000 (0.1000) Top1_base: 87.5000 (80.0946) Top1_base_per_class: 88.7736 (80.8204) 
Training Epoch: [161/1000] Step: [200 / 285] Batch Time: 0.1473 (0.1584) Data Time: 0.0113 (0.0255) Average Loss: 0.7299 (0.7101) Average CE Loss (Source):  0.7299 ( 0.7101) Learning Rate: 0.1000 (0.1000) Top1_base: 82.8125 (80.1055) Top1_base_per_class: 81.7251 (80.8198) 
Training Epoch: [161/1000] Step: [210 / 285] Batch Time: 0.1489 (0.1578) Data Time: 0.0172 (0.0249) Average Loss: 0.6235 (0.7106) Average CE Loss (Source):  0.6235 ( 0.7106) Learning Rate: 0.1000 (0.1000) Top1_base: 82.0312 (80.1004) Top1_base_per_class: 84.1954 (80.8058) 
Training Epoch: [161/1000] Step: [220 / 285] Batch Time: 0.1512 (0.1574) Data Time: 0.0147 (0.0246) Average Loss: 0.6701 (0.7147) Average CE Loss (Source):  0.6701 ( 0.7147) Learning Rate: 0.1000 (0.1000) Top1_base: 79.6875 (79.9964) Top1_base_per_class: 74.7879 (80.6974) 
Training Epoch: [161/1000] Step: [230 / 285] Batch Time: 0.1968 (0.1575) Data Time: 0.0631 (0.0245) Average Loss: 0.7308 (0.7141) Average CE Loss (Source):  0.7308 ( 0.7141) Learning Rate: 0.1000 (0.1000) Top1_base: 77.3438 (79.9966) Top1_base_per_class: 77.7006 (80.7157) 
Training Epoch: [161/1000] Step: [240 / 285] Batch Time: 0.1440 (0.1575) Data Time: 0.0135 (0.0245) Average Loss: 0.7080 (0.7151) Average CE Loss (Source):  0.7080 ( 0.7151) Learning Rate: 0.1000 (0.1000) Top1_base: 82.8125 (79.9447) Top1_base_per_class: 77.9762 (80.6245) 
Training Epoch: [161/1000] Step: [250 / 285] Batch Time: 0.1700 (0.1575) Data Time: 0.0354 (0.0244) Average Loss: 0.7474 (0.7156) Average CE Loss (Source):  0.7474 ( 0.7156) Learning Rate: 0.1000 (0.1000) Top1_base: 80.4688 (80.0094) Top1_base_per_class: 77.4107 (80.6701) 
Training Epoch: [161/1000] Step: [260 / 285] Batch Time: 0.1452 (0.1571) Data Time: 0.0112 (0.0241) Average Loss: 0.7882 (0.7201) Average CE Loss (Source):  0.7882 ( 0.7201) Learning Rate: 0.1000 (0.1000) Top1_base: 75.7812 (79.8768) Top1_base_per_class: 78.3962 (80.5492) 
Training Epoch: [161/1000] Step: [270 / 285] Batch Time: 0.1500 (0.1570) Data Time: 0.0164 (0.0240) Average Loss: 0.8155 (0.7220) Average CE Loss (Source):  0.8155 ( 0.7220) Learning Rate: 0.1000 (0.1000) Top1_base: 78.1250 (79.8206) Top1_base_per_class: 82.7778 (80.4934) 
Training Epoch: [161/1000] Step: [280 / 285] Batch Time: 0.1428 (0.1567) Data Time: 0.0122 (0.0236) Average Loss: 0.7318 (0.7241) Average CE Loss (Source):  0.7318 ( 0.7241) Learning Rate: 0.1000 (0.1000) Top1_base: 78.9062 (79.7796) Top1_base_per_class: 80.9091 (80.4708) 
Training Epoch: [162/1000] Step: [0] Batch Time: 0.1461 (0.1565) Data Time: 0.0119 (0.0234) Average Loss: 0.7096 (0.7250) Average CE Loss (Source):  0.7096 ( 0.7250) Learning Rate: 0.1000 (0.1000) Top1_base: 81.2500 (79.7917) Top1_base_per_class: 81.0632 (80.4853) 
 16%|█▌        | 162/1000 [2:05:58<10:47:07, 46.33s/it] 16%|█▋        | 163/1000 [2:06:44<10:43:08, 46.10s/it]Training Epoch: [162/1000] Step: [10 / 285] Batch Time: 0.1438 (0.2369) Data Time: 0.0116 (0.1048) Average Loss: 0.7008 (0.6907) Average CE Loss (Source):  0.7008 ( 0.6907) Learning Rate: 0.1000 (0.1000) Top1_base: 79.6875 (80.5469) Top1_base_per_class: 81.2931 (81.2108) 
Training Epoch: [162/1000] Step: [20 / 285] Batch Time: 0.1432 (0.1919) Data Time: 0.0130 (0.0603) Average Loss: 0.8091 (0.6895) Average CE Loss (Source):  0.8091 ( 0.6895) Learning Rate: 0.1000 (0.1000) Top1_base: 78.9062 (80.8594) Top1_base_per_class: 80.3954 (80.9806) 
Training Epoch: [162/1000] Step: [30 / 285] Batch Time: 0.1434 (0.1824) Data Time: 0.0128 (0.0507) Average Loss: 0.6483 (0.6867) Average CE Loss (Source):  0.6483 ( 0.6867) Learning Rate: 0.1000 (0.1000) Top1_base: 78.1250 (80.5208) Top1_base_per_class: 79.2727 (81.0390) 
Training Epoch: [162/1000] Step: [40 / 285] Batch Time: 0.1464 (0.1758) Data Time: 0.0107 (0.0438) Average Loss: 0.5061 (0.7024) Average CE Loss (Source):  0.5061 ( 0.7024) Learning Rate: 0.1000 (0.1000) Top1_base: 87.5000 (80.1562) Top1_base_per_class: 89.5115 (81.1433) 
Training Epoch: [162/1000] Step: [50 / 285] Batch Time: 0.1446 (0.1712) Data Time: 0.0136 (0.0392) Average Loss: 0.7086 (0.7144) Average CE Loss (Source):  0.7086 ( 0.7144) Learning Rate: 0.1000 (0.1000) Top1_base: 78.9062 (79.7344) Top1_base_per_class: 78.9771 (80.4303) 
Training Epoch: [162/1000] Step: [60 / 285] Batch Time: 0.1479 (0.1675) Data Time: 0.0141 (0.0353) Average Loss: 0.4893 (0.7164) Average CE Loss (Source):  0.4893 ( 0.7164) Learning Rate: 0.1000 (0.1000) Top1_base: 86.7188 (79.8698) Top1_base_per_class: 86.2573 (80.3837) 
Training Epoch: [162/1000] Step: [70 / 285] Batch Time: 0.1939 (0.1660) Data Time: 0.0628 (0.0337) Average Loss: 0.5304 (0.7049) Average CE Loss (Source):  0.5304 ( 0.7049) Learning Rate: 0.1000 (0.1000) Top1_base: 85.9375 (80.2232) Top1_base_per_class: 85.9064 (80.8070) 
Training Epoch: [162/1000] Step: [80 / 285] Batch Time: 0.1443 (0.1662) Data Time: 0.0107 (0.0338) Average Loss: 0.5407 (0.7026) Average CE Loss (Source):  0.5407 ( 0.7026) Learning Rate: 0.1000 (0.1000) Top1_base: 83.5938 (80.3906) Top1_base_per_class: 81.4198 (81.0083) 
Training Epoch: [162/1000] Step: [90 / 285] Batch Time: 0.1477 (0.1650) Data Time: 0.0165 (0.0326) Average Loss: 0.6940 (0.7082) Average CE Loss (Source):  0.6940 ( 0.7082) Learning Rate: 0.1000 (0.1000) Top1_base: 79.6875 (80.2517) Top1_base_per_class: 79.0432 (80.8100) 
Training Epoch: [162/1000] Step: [100 / 285] Batch Time: 0.1447 (0.1639) Data Time: 0.0108 (0.0315) Average Loss: 0.6602 (0.7044) Average CE Loss (Source):  0.6602 ( 0.7044) Learning Rate: 0.1000 (0.1000) Top1_base: 82.8125 (80.2500) Top1_base_per_class: 84.9425 (80.8040) 
Training Epoch: [162/1000] Step: [110 / 285] Batch Time: 0.1854 (0.1634) Data Time: 0.0537 (0.0310) Average Loss: 0.6355 (0.7041) Average CE Loss (Source):  0.6355 ( 0.7041) Learning Rate: 0.1000 (0.1000) Top1_base: 85.1562 (80.2628) Top1_base_per_class: 85.0595 (80.8576) 
Training Epoch: [162/1000] Step: [120 / 285] Batch Time: 0.1424 (0.1636) Data Time: 0.0105 (0.0312) Average Loss: 0.7598 (0.7028) Average CE Loss (Source):  0.7598 ( 0.7028) Learning Rate: 0.1000 (0.1000) Top1_base: 77.3438 (80.3060) Top1_base_per_class: 75.3107 (80.9341) 
Training Epoch: [162/1000] Step: [130 / 285] Batch Time: 0.1855 (0.1628) Data Time: 0.0534 (0.0304) Average Loss: 1.0262 (0.7049) Average CE Loss (Source):  1.0262 ( 0.7049) Learning Rate: 0.1000 (0.1000) Top1_base: 69.5312 (80.1923) Top1_base_per_class: 69.5402 (80.8675) 
Training Epoch: [162/1000] Step: [140 / 285] Batch Time: 0.1452 (0.1623) Data Time: 0.0107 (0.0298) Average Loss: 0.8058 (0.7089) Average CE Loss (Source):  0.8058 ( 0.7089) Learning Rate: 0.1000 (0.1000) Top1_base: 78.1250 (80.1451) Top1_base_per_class: 77.0000 (80.9411) 
Training Epoch: [162/1000] Step: [150 / 285] Batch Time: 0.2535 (0.1623) Data Time: 0.1227 (0.0298) Average Loss: 0.5435 (0.7108) Average CE Loss (Source):  0.5435 ( 0.7108) Learning Rate: 0.1000 (0.1000) Top1_base: 85.1562 (80.0781) Top1_base_per_class: 83.0638 (80.8340) 
Training Epoch: [162/1000] Step: [160 / 285] Batch Time: 0.1437 (0.1614) Data Time: 0.0104 (0.0289) Average Loss: 0.7119 (0.7128) Average CE Loss (Source):  0.7119 ( 0.7128) Learning Rate: 0.1000 (0.1000) Top1_base: 79.6875 (80.0391) Top1_base_per_class: 82.5157 (80.7952) 
Training Epoch: [162/1000] Step: [170 / 285] Batch Time: 0.1582 (0.1611) Data Time: 0.0267 (0.0286) Average Loss: 0.8978 (0.7144) Average CE Loss (Source):  0.8978 ( 0.7144) Learning Rate: 0.1000 (0.1000) Top1_base: 73.4375 (79.9494) Top1_base_per_class: 72.9885 (80.7561) 
Training Epoch: [162/1000] Step: [180 / 285] Batch Time: 0.1458 (0.1606) Data Time: 0.0109 (0.0280) Average Loss: 0.5777 (0.7123) Average CE Loss (Source):  0.5777 ( 0.7123) Learning Rate: 0.1000 (0.1000) Top1_base: 82.0312 (80.0217) Top1_base_per_class: 82.7044 (80.8053) 
Training Epoch: [162/1000] Step: [190 / 285] Batch Time: 0.2194 (0.1609) Data Time: 0.0873 (0.0283) Average Loss: 0.6733 (0.7098) Average CE Loss (Source):  0.6733 ( 0.7098) Learning Rate: 0.1000 (0.1000) Top1_base: 80.4688 (80.0905) Top1_base_per_class: 81.1309 (80.8708) 
Training Epoch: [162/1000] Step: [200 / 285] Batch Time: 0.1452 (0.1605) Data Time: 0.0099 (0.0280) Average Loss: 0.7582 (0.7150) Average CE Loss (Source):  0.7582 ( 0.7150) Learning Rate: 0.1000 (0.1000) Top1_base: 77.3438 (79.9688) Top1_base_per_class: 80.3055 (80.6804) 
Training Epoch: [162/1000] Step: [210 / 285] Batch Time: 0.1697 (0.1605) Data Time: 0.0379 (0.0279) Average Loss: 0.7229 (0.7154) Average CE Loss (Source):  0.7229 ( 0.7154) Learning Rate: 0.1000 (0.1000) Top1_base: 76.5625 (79.9628) Top1_base_per_class: 76.9643 (80.6829) 
Training Epoch: [162/1000] Step: [220 / 285] Batch Time: 0.1442 (0.1599) Data Time: 0.0107 (0.0274) Average Loss: 0.7952 (0.7149) Average CE Loss (Source):  0.7952 ( 0.7149) Learning Rate: 0.1000 (0.1000) Top1_base: 76.5625 (80.0107) Top1_base_per_class: 77.3030 (80.7310) 
Training Epoch: [162/1000] Step: [230 / 285] Batch Time: 0.2740 (0.1603) Data Time: 0.1435 (0.0277) Average Loss: 0.8475 (0.7172) Average CE Loss (Source):  0.8475 ( 0.7172) Learning Rate: 0.1000 (0.1000) Top1_base: 73.4375 (79.8743) Top1_base_per_class: 75.0000 (80.5902) 
Training Epoch: [162/1000] Step: [240 / 285] Batch Time: 0.1457 (0.1604) Data Time: 0.0104 (0.0279) Average Loss: 0.7168 (0.7163) Average CE Loss (Source):  0.7168 ( 0.7163) Learning Rate: 0.1000 (0.1000) Top1_base: 80.4688 (79.8926) Top1_base_per_class: 81.0234 (80.5923) 
Training Epoch: [162/1000] Step: [250 / 285] Batch Time: 0.1889 (0.1607) Data Time: 0.0579 (0.0281) Average Loss: 0.6588 (0.7165) Average CE Loss (Source):  0.6588 ( 0.7165) Learning Rate: 0.1000 (0.1000) Top1_base: 82.0312 (79.8937) Top1_base_per_class: 82.0402 (80.5927) 
Training Epoch: [162/1000] Step: [260 / 285] Batch Time: 0.1434 (0.1604) Data Time: 0.0105 (0.0278) Average Loss: 0.6943 (0.7171) Average CE Loss (Source):  0.6943 ( 0.7171) Learning Rate: 0.1000 (0.1000) Top1_base: 76.5625 (79.8678) Top1_base_per_class: 78.3333 (80.5566) 
Training Epoch: [162/1000] Step: [270 / 285] Batch Time: 0.1768 (0.1603) Data Time: 0.0447 (0.0277) Average Loss: 0.8537 (0.7191) Average CE Loss (Source):  0.8537 ( 0.7191) Learning Rate: 0.1000 (0.1000) Top1_base: 82.0312 (79.8582) Top1_base_per_class: 79.4940 (80.5040) 
Training Epoch: [162/1000] Step: [280 / 285] Batch Time: 0.1449 (0.1599) Data Time: 0.0103 (0.0274) Average Loss: 0.8179 (0.7211) Average CE Loss (Source):  0.8179 ( 0.7211) Learning Rate: 0.1000 (0.1000) Top1_base: 71.0938 (79.7377) Top1_base_per_class: 73.1818 (80.4088) 
Training Epoch: [163/1000] Step: [0] Batch Time: 0.1395 (0.1597) Data Time: 0.0098 (0.0271) Average Loss: 0.7584 (0.7233) Average CE Loss (Source):  0.7584 ( 0.7233) Learning Rate: 0.1000 (0.1000) Top1_base: 78.1250 (79.6957) Top1_base_per_class: 80.1977 (80.3643) 
Training Epoch: [163/1000] Step: [10 / 285] Batch Time: 0.1484 (0.2356) Data Time: 0.0127 (0.1000) Average Loss: 0.7948 (0.6957) Average CE Loss (Source):  0.7948 ( 0.6957) Learning Rate: 0.1000 (0.1000) Top1_base: 78.1250 (80.8594) Top1_base_per_class: 79.8469 (80.7053) 
Training Epoch: [163/1000] Step: [20 / 285] Batch Time: 0.1447 (0.1963) Data Time: 0.0137 (0.0620) Average Loss: 0.6341 (0.6609) Average CE Loss (Source):  0.6341 ( 0.6609) Learning Rate: 0.1000 (0.1000) Top1_base: 83.5938 (81.4062) Top1_base_per_class: 84.9691 (81.0464) 
Training Epoch: [163/1000] Step: [30 / 285] Batch Time: 0.1450 (0.1863) Data Time: 0.0110 (0.0525) Average Loss: 0.6079 (0.6378) Average CE Loss (Source):  0.6079 ( 0.6378) Learning Rate: 0.1000 (0.1000) Top1_base: 85.9375 (81.7188) Top1_base_per_class: 84.7531 (81.7363) 
Training Epoch: [163/1000] Step: [40 / 285] Batch Time: 0.1481 (0.1764) Data Time: 0.0144 (0.0427) Average Loss: 0.7627 (0.6621) Average CE Loss (Source):  0.7627 ( 0.6621) Learning Rate: 0.1000 (0.1000) Top1_base: 78.1250 (81.3086) Top1_base_per_class: 81.3743 (81.6121) 
Training Epoch: [163/1000] Step: [50 / 285] Batch Time: 0.1459 (0.1728) Data Time: 0.0106 (0.0392) Average Loss: 0.8534 (0.6601) Average CE Loss (Source):  0.8534 ( 0.6601) Learning Rate: 0.1000 (0.1000) Top1_base: 78.1250 (81.4062) Top1_base_per_class: 79.7414 (81.7718) 
Training Epoch: [163/1000] Step: [60 / 285] Batch Time: 0.1472 (0.1687) Data Time: 0.0158 (0.0352) Average Loss: 0.7067 (0.6593) Average CE Loss (Source):  0.7067 ( 0.6593) Learning Rate: 0.1000 (0.1000) Top1_base: 82.0312 (81.3672) Top1_base_per_class: 82.5617 (81.8654) 
Training Epoch: [163/1000] Step: [70 / 285] Batch Time: 0.1462 (0.1662) Data Time: 0.0105 (0.0328) Average Loss: 0.7003 (0.6626) Average CE Loss (Source):  0.7003 ( 0.6626) Learning Rate: 0.1000 (0.1000) Top1_base: 80.4688 (81.4844) Top1_base_per_class: 81.2281 (82.0988) 
Training Epoch: [163/1000] Step: [80 / 285] Batch Time: 0.1480 (0.1643) Data Time: 0.0153 (0.0310) Average Loss: 0.4978 (0.6690) Average CE Loss (Source):  0.4978 ( 0.6690) Learning Rate: 0.1000 (0.1000) Top1_base: 89.0625 (81.4746) Top1_base_per_class: 89.8810 (82.0462) 
Training Epoch: [163/1000] Step: [90 / 285] Batch Time: 0.1446 (0.1632) Data Time: 0.0107 (0.0300) Average Loss: 0.8559 (0.6718) Average CE Loss (Source):  0.8559 ( 0.6718) Learning Rate: 0.1000 (0.1000) Top1_base: 75.7812 (81.3455) Top1_base_per_class: 71.6379 (81.9333) 
Training Epoch: [163/1000] Step: [100 / 285] Batch Time: 0.1563 (0.1635) Data Time: 0.0240 (0.0305) Average Loss: 0.6981 (0.6738) Average CE Loss (Source):  0.6981 ( 0.6738) Learning Rate: 0.1000 (0.1000) Top1_base: 83.5938 (81.2891) Top1_base_per_class: 86.3462 (81.9347) 
Training Epoch: [163/1000] Step: [110 / 285] Batch Time: 0.1447 (0.1620) Data Time: 0.0111 (0.0289) Average Loss: 0.5632 (0.6748) Average CE Loss (Source):  0.5632 ( 0.6748) Learning Rate: 0.1000 (0.1000) Top1_base: 82.0312 (81.2003) Top1_base_per_class: 83.9744 (81.9186) 
Training Epoch: [163/1000] Step: [120 / 285] Batch Time: 0.1651 (0.1612) Data Time: 0.0346 (0.0282) Average Loss: 0.5876 (0.6774) Average CE Loss (Source):  0.5876 ( 0.6774) Learning Rate: 0.1000 (0.1000) Top1_base: 82.8125 (81.1784) Top1_base_per_class: 82.6667 (81.9153) 
Training Epoch: [163/1000] Step: [130 / 285] Batch Time: 0.1457 (0.1603) Data Time: 0.0107 (0.0274) Average Loss: 0.8377 (0.6789) Average CE Loss (Source):  0.8377 ( 0.6789) Learning Rate: 0.1000 (0.1000) Top1_base: 78.9062 (81.1298) Top1_base_per_class: 80.5247 (81.9076) 
Training Epoch: [163/1000] Step: [140 / 285] Batch Time: 0.2004 (0.1605) Data Time: 0.0695 (0.0276) Average Loss: 0.6456 (0.6801) Average CE Loss (Source):  0.6456 ( 0.6801) Learning Rate: 0.1000 (0.1000) Top1_base: 81.2500 (81.0770) Top1_base_per_class: 79.7661 (81.7638) 
Training Epoch: [163/1000] Step: [150 / 285] Batch Time: 0.1454 (0.1600) Data Time: 0.0108 (0.0271) Average Loss: 0.6608 (0.6889) Average CE Loss (Source):  0.6608 ( 0.6889) Learning Rate: 0.1000 (0.1000) Top1_base: 80.4688 (80.8073) Top1_base_per_class: 78.9697 (81.5227) 
Training Epoch: [163/1000] Step: [160 / 285] Batch Time: 0.2961 (0.1604) Data Time: 0.1649 (0.0275) Average Loss: 0.8615 (0.6931) Average CE Loss (Source):  0.8615 ( 0.6931) Learning Rate: 0.1000 (0.1000) Top1_base: 75.0000 (80.6299) Top1_base_per_class: 78.9881 (81.2883) 
Training Epoch: [163/1000] Step: [170 / 285] Batch Time: 0.1457 (0.1605) Data Time: 0.0106 (0.0276) Average Loss: 0.7917 (0.6972) Average CE Loss (Source):  0.7917 ( 0.6972) Learning Rate: 0.1000 (0.1000) Top1_base: 78.1250 (80.5561) Top1_base_per_class: 78.8793 (81.2300) 
Training Epoch: [163/1000] Step: [180 / 285] Batch Time: 0.1894 (0.1602) Data Time: 0.0585 (0.0274) Average Loss: 0.6278 (0.6984) Average CE Loss (Source):  0.6278 ( 0.6984) Learning Rate: 0.1000 (0.1000) Top1_base: 81.2500 (80.5165) Top1_base_per_class: 79.2398 (81.1022) 
Training Epoch: [163/1000] Step: [190 / 285] Batch Time: 0.1443 (0.1599) Data Time: 0.0119 (0.0270) Average Loss: 0.6673 (0.6975) Average CE Loss (Source):  0.6673 ( 0.6975) Learning Rate: 0.1000 (0.1000) Top1_base: 82.8125 (80.6003) Top1_base_per_class: 85.4088 (81.1922) 
Training Epoch: [163/1000] Step: [200 / 285] Batch Time: 0.2023 (0.1598) Data Time: 0.0692 (0.0269) Average Loss: 0.7911 (0.6997) Average CE Loss (Source):  0.7911 ( 0.6997) Learning Rate: 0.1000 (0.1000) Top1_base: 75.7812 (80.5117) Top1_base_per_class: 80.0303 (81.0979) 
Training Epoch: [163/1000] Step: [210 / 285] Batch Time: 0.1441 (0.1596) Data Time: 0.0107 (0.0268) Average Loss: 0.7718 (0.6991) Average CE Loss (Source):  0.7718 ( 0.6991) Learning Rate: 0.1000 (0.1000) Top1_base: 80.4688 (80.5394) Top1_base_per_class: 83.6218 (81.1296) 
Training Epoch: [163/1000] Step: [220 / 285] Batch Time: 0.1531 (0.1591) Data Time: 0.0214 (0.0263) Average Loss: 0.7032 (0.7014) Average CE Loss (Source):  0.7032 ( 0.7014) Learning Rate: 0.1000 (0.1000) Top1_base: 82.8125 (80.4794) Top1_base_per_class: 84.8898 (81.0555) 
Training Epoch: [163/1000] Step: [230 / 285] Batch Time: 0.1473 (0.1589) Data Time: 0.0107 (0.0261) Average Loss: 0.5952 (0.7026) Average CE Loss (Source):  0.5952 ( 0.7026) Learning Rate: 0.1000 (0.1000) Top1_base: 84.3750 (80.4212) Top1_base_per_class: 81.9697 (81.0090) 
Training Epoch: [163/1000] Step: [240 / 285] Batch Time: 0.1626 (0.1587) Data Time: 0.0303 (0.0258) Average Loss: 0.7690 (0.7052) Average CE Loss (Source):  0.7690 ( 0.7052) Learning Rate: 0.1000 (0.1000) Top1_base: 78.1250 (80.3092) Top1_base_per_class: 78.0460 (80.9130) 
Training Epoch: [163/1000] Step: [250 / 285] Batch Time: 0.1422 (0.1585) Data Time: 0.0125 (0.0256) Average Loss: 0.6154 (0.7089) Average CE Loss (Source):  0.6154 ( 0.7089) Learning Rate: 0.1000 (0.1000) Top1_base: 84.3750 (80.1813) Top1_base_per_class: 83.5143 (80.7306) 
Training Epoch: [163/1000] Step: [260 / 285] Batch Time: 0.1791 (0.1585) Data Time: 0.0462 (0.0257) Average Loss: 0.7556 (0.7098) Average CE Loss (Source):  0.7556 ( 0.7098) Learning Rate: 0.1000 (0.1000) Top1_base: 78.1250 (80.1653) Top1_base_per_class: 77.6730 (80.6836) 
Training Epoch: [163/1000] Step: [270 / 285] Batch Time: 0.1473 (0.1583) Data Time: 0.0103 (0.0255) Average Loss: 0.8195 (0.7131) Average CE Loss (Source):  0.8195 ( 0.7131) Learning Rate: 0.1000 (0.1000) Top1_base: 75.7812 (80.0608) Top1_base_per_class: 74.7661 (80.6008) 
Training Epoch: [163/1000] Step: [280 / 285] Batch Time: 0.1926 (0.1583) Data Time: 0.0588 (0.0253) Average Loss: 0.8421 (0.7155) Average CE Loss (Source):  0.8421 ( 0.7155) Learning Rate: 0.1000 (0.1000) Top1_base: 76.5625 (80.0112) Top1_base_per_class: 78.8889 (80.5567) 
Training Epoch: [164/1000] Step: [0] Batch Time: 0.1421 (0.1580) Data Time: 0.0117 (0.0251) Average Loss: 0.7695 (0.7146) Average CE Loss (Source):  0.7695 ( 0.7146) Learning Rate: 0.1000 (0.1000) Top1_base: 75.7812 (80.0548) Top1_base_per_class: 77.0000 (80.6223) 
 16%|█▋        | 164/1000 [2:07:32<10:49:48, 46.64s/it] 16%|█▋        | 165/1000 [2:08:17<10:41:11, 46.07s/it]Training Epoch: [164/1000] Step: [10 / 285] Batch Time: 0.2428 (0.2375) Data Time: 0.1093 (0.1045) Average Loss: 0.6613 (0.6446) Average CE Loss (Source):  0.6613 ( 0.6446) Learning Rate: 0.1000 (0.1000) Top1_base: 78.1250 (81.9531) Top1_base_per_class: 79.0476 (83.1077) 
Training Epoch: [164/1000] Step: [20 / 285] Batch Time: 0.1445 (0.2004) Data Time: 0.0109 (0.0681) Average Loss: 0.7299 (0.6779) Average CE Loss (Source):  0.7299 ( 0.6779) Learning Rate: 0.1000 (0.1000) Top1_base: 78.9062 (80.7812) Top1_base_per_class: 77.7193 (80.9439) 
Training Epoch: [164/1000] Step: [30 / 285] Batch Time: 0.1799 (0.1865) Data Time: 0.0471 (0.0542) Average Loss: 0.7579 (0.6896) Average CE Loss (Source):  0.7579 ( 0.6896) Learning Rate: 0.1000 (0.1000) Top1_base: 79.6875 (80.5208) Top1_base_per_class: 80.0309 (80.5670) 
Training Epoch: [164/1000] Step: [40 / 285] Batch Time: 0.1453 (0.1790) Data Time: 0.0120 (0.0465) Average Loss: 0.5924 (0.6735) Average CE Loss (Source):  0.5924 ( 0.6735) Learning Rate: 0.1000 (0.1000) Top1_base: 82.8125 (80.9180) Top1_base_per_class: 80.0000 (81.0672) 
Training Epoch: [164/1000] Step: [50 / 285] Batch Time: 0.3201 (0.1798) Data Time: 0.1861 (0.0472) Average Loss: 0.6952 (0.6780) Average CE Loss (Source):  0.6952 ( 0.6780) Learning Rate: 0.1000 (0.1000) Top1_base: 82.8125 (80.7500) Top1_base_per_class: 79.5757 (80.8847) 
Training Epoch: [164/1000] Step: [60 / 285] Batch Time: 0.1459 (0.1741) Data Time: 0.0121 (0.0416) Average Loss: 0.5148 (0.6800) Average CE Loss (Source):  0.5148 ( 0.6800) Learning Rate: 0.1000 (0.1000) Top1_base: 84.3750 (80.6510) Top1_base_per_class: 86.0920 (80.8672) 
Training Epoch: [164/1000] Step: [70 / 285] Batch Time: 0.1946 (0.1733) Data Time: 0.0609 (0.0408) Average Loss: 0.7023 (0.6865) Average CE Loss (Source):  0.7023 ( 0.6865) Learning Rate: 0.1000 (0.1000) Top1_base: 81.2500 (80.6027) Top1_base_per_class: 83.2319 (80.8719) 
Training Epoch: [164/1000] Step: [80 / 285] Batch Time: 0.1424 (0.1708) Data Time: 0.0112 (0.0383) Average Loss: 1.0630 (0.6877) Average CE Loss (Source):  1.0630 ( 0.6877) Learning Rate: 0.1000 (0.1000) Top1_base: 71.8750 (80.4492) Top1_base_per_class: 75.4133 (80.6952) 
Training Epoch: [164/1000] Step: [90 / 285] Batch Time: 0.1502 (0.1681) Data Time: 0.0168 (0.0355) Average Loss: 0.6331 (0.6894) Average CE Loss (Source):  0.6331 ( 0.6894) Learning Rate: 0.1000 (0.1000) Top1_base: 79.6875 (80.3212) Top1_base_per_class: 80.8631 (80.6057) 
Training Epoch: [164/1000] Step: [100 / 285] Batch Time: 0.1448 (0.1670) Data Time: 0.0103 (0.0343) Average Loss: 0.8220 (0.6904) Average CE Loss (Source):  0.8220 ( 0.6904) Learning Rate: 0.1000 (0.1000) Top1_base: 75.0000 (80.3828) Top1_base_per_class: 73.7576 (80.6552) 
Training Epoch: [164/1000] Step: [110 / 285] Batch Time: 0.1517 (0.1653) Data Time: 0.0161 (0.0324) Average Loss: 0.8895 (0.6949) Average CE Loss (Source):  0.8895 ( 0.6949) Learning Rate: 0.1000 (0.1000) Top1_base: 75.7812 (80.2699) Top1_base_per_class: 76.9095 (80.5537) 
Training Epoch: [164/1000] Step: [120 / 285] Batch Time: 0.1464 (0.1639) Data Time: 0.0121 (0.0307) Average Loss: 0.5751 (0.7010) Average CE Loss (Source):  0.5751 ( 0.7010) Learning Rate: 0.1000 (0.1000) Top1_base: 81.2500 (80.0260) Top1_base_per_class: 84.3636 (80.3730) 
Training Epoch: [164/1000] Step: [130 / 285] Batch Time: 0.1530 (0.1628) Data Time: 0.0156 (0.0294) Average Loss: 0.4131 (0.6967) Average CE Loss (Source):  0.4131 ( 0.6967) Learning Rate: 0.1000 (0.1000) Top1_base: 88.2812 (80.1262) Top1_base_per_class: 90.6240 (80.4065) 
Training Epoch: [164/1000] Step: [140 / 285] Batch Time: 0.1469 (0.1617) Data Time: 0.0137 (0.0284) Average Loss: 0.6651 (0.6974) Average CE Loss (Source):  0.6651 ( 0.6974) Learning Rate: 0.1000 (0.1000) Top1_base: 83.5938 (80.1116) Top1_base_per_class: 88.1645 (80.3857) 
Training Epoch: [164/1000] Step: [150 / 285] Batch Time: 0.1491 (0.1606) Data Time: 0.0155 (0.0274) Average Loss: 0.6916 (0.6973) Average CE Loss (Source):  0.6916 ( 0.6973) Learning Rate: 0.1000 (0.1000) Top1_base: 82.0312 (80.1094) Top1_base_per_class: 85.8123 (80.4176) 
Training Epoch: [164/1000] Step: [160 / 285] Batch Time: 0.1470 (0.1598) Data Time: 0.0141 (0.0265) Average Loss: 0.7152 (0.6993) Average CE Loss (Source):  0.7152 ( 0.6993) Learning Rate: 0.1000 (0.1000) Top1_base: 78.9062 (80.1514) Top1_base_per_class: 82.1186 (80.4963) 
Training Epoch: [164/1000] Step: [170 / 285] Batch Time: 0.1679 (0.1595) Data Time: 0.0334 (0.0263) Average Loss: 0.8107 (0.6989) Average CE Loss (Source):  0.8107 ( 0.6989) Learning Rate: 0.1000 (0.1000) Top1_base: 82.8125 (80.2252) Top1_base_per_class: 82.9678 (80.5814) 
Training Epoch: [164/1000] Step: [180 / 285] Batch Time: 0.1434 (0.1594) Data Time: 0.0129 (0.0262) Average Loss: 0.6199 (0.6978) Average CE Loss (Source):  0.6199 ( 0.6978) Learning Rate: 0.1000 (0.1000) Top1_base: 82.0312 (80.2431) Top1_base_per_class: 82.5000 (80.5976) 
Training Epoch: [164/1000] Step: [190 / 285] Batch Time: 0.1515 (0.1592) Data Time: 0.0187 (0.0260) Average Loss: 0.6649 (0.6964) Average CE Loss (Source):  0.6649 ( 0.6964) Learning Rate: 0.1000 (0.1000) Top1_base: 80.4688 (80.2549) Top1_base_per_class: 77.6602 (80.5631) 
Training Epoch: [164/1000] Step: [200 / 285] Batch Time: 0.1476 (0.1585) Data Time: 0.0146 (0.0254) Average Loss: 0.6354 (0.6986) Average CE Loss (Source):  0.6354 ( 0.6986) Learning Rate: 0.1000 (0.1000) Top1_base: 82.8125 (80.2070) Top1_base_per_class: 83.3046 (80.4909) 
Training Epoch: [164/1000] Step: [210 / 285] Batch Time: 0.1640 (0.1584) Data Time: 0.0334 (0.0253) Average Loss: 0.6897 (0.6990) Average CE Loss (Source):  0.6897 ( 0.6990) Learning Rate: 0.1000 (0.1000) Top1_base: 82.0312 (80.2083) Top1_base_per_class: 81.9253 (80.5436) 
Training Epoch: [164/1000] Step: [220 / 285] Batch Time: 0.1425 (0.1578) Data Time: 0.0105 (0.0248) Average Loss: 0.8663 (0.7034) Average CE Loss (Source):  0.8663 ( 0.7034) Learning Rate: 0.1000 (0.1000) Top1_base: 77.3438 (80.1172) Top1_base_per_class: 75.9649 (80.4901) 
Training Epoch: [164/1000] Step: [230 / 285] Batch Time: 0.2225 (0.1578) Data Time: 0.0892 (0.0248) Average Loss: 0.6796 (0.7064) Average CE Loss (Source):  0.6796 ( 0.7064) Learning Rate: 0.1000 (0.1000) Top1_base: 77.3438 (80.0510) Top1_base_per_class: 79.5833 (80.4329) 
Training Epoch: [164/1000] Step: [240 / 285] Batch Time: 0.1464 (0.1576) Data Time: 0.0127 (0.0246) Average Loss: 0.7799 (0.7071) Average CE Loss (Source):  0.7799 ( 0.7071) Learning Rate: 0.1000 (0.1000) Top1_base: 77.3438 (80.0163) Top1_base_per_class: 79.0178 (80.4316) 
Training Epoch: [164/1000] Step: [250 / 285] Batch Time: 0.1826 (0.1575) Data Time: 0.0497 (0.0245) Average Loss: 0.5904 (0.7084) Average CE Loss (Source):  0.5904 ( 0.7084) Learning Rate: 0.1000 (0.1000) Top1_base: 85.9375 (80.0187) Top1_base_per_class: 83.8788 (80.4227) 
Training Epoch: [164/1000] Step: [260 / 285] Batch Time: 0.1418 (0.1574) Data Time: 0.0104 (0.0244) Average Loss: 0.8782 (0.7094) Average CE Loss (Source):  0.8782 ( 0.7094) Learning Rate: 0.1000 (0.1000) Top1_base: 76.5625 (79.9730) Top1_base_per_class: 77.7160 (80.4197) 
Training Epoch: [164/1000] Step: [270 / 285] Batch Time: 0.1444 (0.1571) Data Time: 0.0138 (0.0242) Average Loss: 0.8892 (0.7117) Average CE Loss (Source):  0.8892 ( 0.7117) Learning Rate: 0.1000 (0.1000) Top1_base: 73.4375 (79.8929) Top1_base_per_class: 74.6726 (80.3542) 
Training Epoch: [164/1000] Step: [280 / 285] Batch Time: 0.1424 (0.1569) Data Time: 0.0106 (0.0240) Average Loss: 0.4909 (0.7127) Average CE Loss (Source):  0.4909 ( 0.7127) Learning Rate: 0.1000 (0.1000) Top1_base: 86.7188 (79.8270) Top1_base_per_class: 87.1795 (80.2779) 
Training Epoch: [165/1000] Step: [0] Batch Time: 0.1409 (0.1568) Data Time: 0.0098 (0.0239) Average Loss: 0.6788 (0.7128) Average CE Loss (Source):  0.6788 ( 0.7128) Learning Rate: 0.1000 (0.1000) Top1_base: 82.8125 (79.8410) Top1_base_per_class: 83.1447 (80.2719) 
Training Epoch: [165/1000] Step: [10 / 285] Batch Time: 0.1497 (0.2327) Data Time: 0.0155 (0.0998) Average Loss: 0.7089 (0.6768) Average CE Loss (Source):  0.7089 ( 0.6768) Learning Rate: 0.1000 (0.1000) Top1_base: 79.6875 (81.0156) Top1_base_per_class: 82.7011 (81.8133) 
Training Epoch: [165/1000] Step: [20 / 285] Batch Time: 0.1458 (0.1929) Data Time: 0.0142 (0.0599) Average Loss: 0.6522 (0.6712) Average CE Loss (Source):  0.6522 ( 0.6712) Learning Rate: 0.1000 (0.1000) Top1_base: 83.5938 (81.4062) Top1_base_per_class: 85.3395 (81.8620) 
Training Epoch: [165/1000] Step: [30 / 285] Batch Time: 0.1459 (0.1802) Data Time: 0.0114 (0.0471) Average Loss: 0.5100 (0.6530) Average CE Loss (Source):  0.5100 ( 0.6530) Learning Rate: 0.1000 (0.1000) Top1_base: 86.7188 (81.6927) Top1_base_per_class: 84.6491 (82.0611) 
Training Epoch: [165/1000] Step: [40 / 285] Batch Time: 0.1456 (0.1724) Data Time: 0.0120 (0.0396) Average Loss: 0.8058 (0.6749) Average CE Loss (Source):  0.8058 ( 0.6749) Learning Rate: 0.1000 (0.1000) Top1_base: 78.1250 (81.4648) Top1_base_per_class: 77.2807 (81.7235) 
Training Epoch: [165/1000] Step: [50 / 285] Batch Time: 0.1777 (0.1686) Data Time: 0.0434 (0.0360) Average Loss: 0.7492 (0.6880) Average CE Loss (Source):  0.7492 ( 0.6880) Learning Rate: 0.1000 (0.1000) Top1_base: 80.4688 (81.2812) Top1_base_per_class: 79.3860 (81.4463) 
Training Epoch: [165/1000] Step: [60 / 285] Batch Time: 0.1474 (0.1660) Data Time: 0.0130 (0.0334) Average Loss: 0.8879 (0.6908) Average CE Loss (Source):  0.8879 ( 0.6908) Learning Rate: 0.1000 (0.1000) Top1_base: 75.0000 (81.2109) Top1_base_per_class: 77.1775 (81.4865) 
Training Epoch: [165/1000] Step: [70 / 285] Batch Time: 0.1462 (0.1635) Data Time: 0.0146 (0.0309) Average Loss: 0.6014 (0.6869) Average CE Loss (Source):  0.6014 ( 0.6869) Learning Rate: 0.1000 (0.1000) Top1_base: 82.8125 (81.1496) Top1_base_per_class: 82.5862 (81.6154) 
Training Epoch: [165/1000] Step: [80 / 285] Batch Time: 0.1763 (0.1625) Data Time: 0.0438 (0.0301) Average Loss: 0.6903 (0.6803) Average CE Loss (Source):  0.6903 ( 0.6803) Learning Rate: 0.1000 (0.1000) Top1_base: 85.1562 (81.2500) Top1_base_per_class: 89.1525 (81.7479) 
Training Epoch: [165/1000] Step: [90 / 285] Batch Time: 0.1475 (0.1607) Data Time: 0.0132 (0.0282) Average Loss: 0.4837 (0.6774) Average CE Loss (Source):  0.4837 ( 0.6774) Learning Rate: 0.1000 (0.1000) Top1_base: 84.3750 (81.2674) Top1_base_per_class: 85.2083 (81.7036) 
Training Epoch: [165/1000] Step: [100 / 285] Batch Time: 0.1470 (0.1612) Data Time: 0.0139 (0.0279) Average Loss: 1.0488 (0.6782) Average CE Loss (Source):  1.0488 ( 0.6782) Learning Rate: 0.1000 (0.1000) Top1_base: 69.5312 (81.2266) Top1_base_per_class: 67.7381 (81.7196) 
Training Epoch: [165/1000] Step: [110 / 285] Batch Time: 0.1495 (0.1601) Data Time: 0.0182 (0.0269) Average Loss: 0.6222 (0.6800) Average CE Loss (Source):  0.6222 ( 0.6800) Learning Rate: 0.1000 (0.1000) Top1_base: 83.5938 (81.1364) Top1_base_per_class: 81.6981 (81.6950) 
Training Epoch: [165/1000] Step: [120 / 285] Batch Time: 0.1505 (0.1593) Data Time: 0.0163 (0.0260) Average Loss: 0.7839 (0.6850) Average CE Loss (Source):  0.7839 ( 0.6850) Learning Rate: 0.1000 (0.1000) Top1_base: 76.5625 (80.9505) Top1_base_per_class: 80.6790 (81.5526) 
Training Epoch: [165/1000] Step: [130 / 285] Batch Time: 0.1874 (0.1593) Data Time: 0.0503 (0.0258) Average Loss: 0.7878 (0.6845) Average CE Loss (Source):  0.7878 ( 0.6845) Learning Rate: 0.1000 (0.1000) Top1_base: 83.5938 (81.0216) Top1_base_per_class: 82.1818 (81.5832) 
Training Epoch: [165/1000] Step: [140 / 285] Batch Time: 0.1477 (0.1587) Data Time: 0.0147 (0.0249) Average Loss: 0.9675 (0.6901) Average CE Loss (Source):  0.9675 ( 0.6901) Learning Rate: 0.1000 (0.1000) Top1_base: 73.4375 (80.7924) Top1_base_per_class: 77.1577 (81.4060) 
Training Epoch: [165/1000] Step: [150 / 285] Batch Time: 0.1477 (0.1579) Data Time: 0.0131 (0.0242) Average Loss: 0.7390 (0.6933) Average CE Loss (Source):  0.7390 ( 0.6933) Learning Rate: 0.1000 (0.1000) Top1_base: 80.4688 (80.6875) Top1_base_per_class: 84.6610 (81.3017) 
Training Epoch: [165/1000] Step: [160 / 285] Batch Time: 0.1463 (0.1571) Data Time: 0.0150 (0.0235) Average Loss: 0.5358 (0.6935) Average CE Loss (Source):  0.5358 ( 0.6935) Learning Rate: 0.1000 (0.1000) Top1_base: 85.1562 (80.6592) Top1_base_per_class: 87.0909 (81.2958) 
Training Epoch: [165/1000] Step: [170 / 285] Batch Time: 0.1862 (0.1572) Data Time: 0.0563 (0.0237) Average Loss: 0.7961 (0.6938) Average CE Loss (Source):  0.7961 ( 0.6938) Learning Rate: 0.1000 (0.1000) Top1_base: 81.2500 (80.5928) Top1_base_per_class: 78.0508 (81.2187) 
Training Epoch: [165/1000] Step: [180 / 285] Batch Time: 0.1465 (0.1566) Data Time: 0.0126 (0.0231) Average Loss: 0.7643 (0.6988) Average CE Loss (Source):  0.7643 ( 0.6988) Learning Rate: 0.1000 (0.1000) Top1_base: 83.5938 (80.4557) Top1_base_per_class: 84.4643 (81.0287) 
Training Epoch: [165/1000] Step: [190 / 285] Batch Time: 0.1453 (0.1563) Data Time: 0.0117 (0.0229) Average Loss: 0.5986 (0.6977) Average CE Loss (Source):  0.5986 ( 0.6977) Learning Rate: 0.1000 (0.1000) Top1_base: 81.2500 (80.5099) Top1_base_per_class: 82.6099 (81.0279) 
Training Epoch: [165/1000] Step: [200 / 285] Batch Time: 0.2037 (0.1568) Data Time: 0.0723 (0.0234) Average Loss: 0.6758 (0.6977) Average CE Loss (Source):  0.6758 ( 0.6977) Learning Rate: 0.1000 (0.1000) Top1_base: 82.8125 (80.5664) Top1_base_per_class: 80.8036 (81.0679) 
Training Epoch: [165/1000] Step: [210 / 285] Batch Time: 0.1460 (0.1567) Data Time: 0.0108 (0.0233) Average Loss: 1.0195 (0.7040) Average CE Loss (Source):  1.0195 ( 0.7040) Learning Rate: 0.1000 (0.1000) Top1_base: 71.8750 (80.3757) Top1_base_per_class: 75.5660 (80.8878) 
Training Epoch: [165/1000] Step: [220 / 285] Batch Time: 0.2197 (0.1566) Data Time: 0.0869 (0.0232) Average Loss: 0.7200 (0.7054) Average CE Loss (Source):  0.7200 ( 0.7054) Learning Rate: 0.1000 (0.1000) Top1_base: 78.1250 (80.3800) Top1_base_per_class: 79.4444 (80.8846) 
Training Epoch: [165/1000] Step: [230 / 285] Batch Time: 0.1444 (0.1562) Data Time: 0.0105 (0.0229) Average Loss: 0.8179 (0.7069) Average CE Loss (Source):  0.8179 ( 0.7069) Learning Rate: 0.1000 (0.1000) Top1_base: 75.0000 (80.3329) Top1_base_per_class: 77.7679 (80.8083) 
Training Epoch: [165/1000] Step: [240 / 285] Batch Time: 0.2210 (0.1565) Data Time: 0.0904 (0.0232) Average Loss: 0.8723 (0.7093) Average CE Loss (Source):  0.8723 ( 0.7093) Learning Rate: 0.1000 (0.1000) Top1_base: 72.6562 (80.2799) Top1_base_per_class: 77.0909 (80.7984) 
Training Epoch: [165/1000] Step: [250 / 285] Batch Time: 0.1440 (0.1567) Data Time: 0.0102 (0.0235) Average Loss: 0.6769 (0.7097) Average CE Loss (Source):  0.6769 ( 0.7097) Learning Rate: 0.1000 (0.1000) Top1_base: 82.8125 (80.2844) Top1_base_per_class: 84.3966 (80.7945) 
Training Epoch: [165/1000] Step: [260 / 285] Batch Time: 0.1721 (0.1566) Data Time: 0.0381 (0.0234) Average Loss: 0.7186 (0.7119) Average CE Loss (Source):  0.7186 ( 0.7119) Learning Rate: 0.1000 (0.1000) Top1_base: 82.0312 (80.2073) Top1_base_per_class: 78.9722 (80.6915) 
Training Epoch: [165/1000] Step: [270 / 285] Batch Time: 0.1439 (0.1567) Data Time: 0.0103 (0.0235) Average Loss: 0.4960 (0.7125) Average CE Loss (Source):  0.4960 ( 0.7125) Learning Rate: 0.1000 (0.1000) Top1_base: 84.3750 (80.1823) Top1_base_per_class: 81.8927 (80.6618) 
Training Epoch: [165/1000] Step: [280 / 285] Batch Time: 0.1697 (0.1569) Data Time: 0.0375 (0.0238) Average Loss: 0.7004 (0.7129) Average CE Loss (Source):  0.7004 ( 0.7129) Learning Rate: 0.1000 (0.1000) Top1_base: 80.4688 (80.1423) Top1_base_per_class: 77.3636 (80.6086) 
Training Epoch: [166/1000] Step: [0] Batch Time: 0.1405 (0.1570) Data Time: 0.0116 (0.0240) Average Loss: 0.7586 (0.7136) Average CE Loss (Source):  0.7586 ( 0.7136) Learning Rate: 0.1000 (0.1000) Top1_base: 78.1250 (80.1179) Top1_base_per_class: 75.9394 (80.5630) 
 17%|█▋        | 166/1000 [2:09:04<10:46:33, 46.52s/it] 17%|█▋        | 167/1000 [2:09:49<10:38:51, 46.02s/it]Training Epoch: [166/1000] Step: [10 / 285] Batch Time: 0.1676 (0.2300) Data Time: 0.0361 (0.0963) Average Loss: 0.5257 (0.7598) Average CE Loss (Source):  0.5257 ( 0.7598) Learning Rate: 0.1000 (0.1000) Top1_base: 89.8438 (80.4688) Top1_base_per_class: 88.8182 (81.1169) 
Training Epoch: [166/1000] Step: [20 / 285] Batch Time: 0.1446 (0.1942) Data Time: 0.0134 (0.0612) Average Loss: 0.6408 (0.7317) Average CE Loss (Source):  0.6408 ( 0.7317) Learning Rate: 0.1000 (0.1000) Top1_base: 82.0312 (80.7812) Top1_base_per_class: 80.5848 (81.3637) 
Training Epoch: [166/1000] Step: [30 / 285] Batch Time: 0.1456 (0.1836) Data Time: 0.0130 (0.0506) Average Loss: 0.8375 (0.7236) Average CE Loss (Source):  0.8375 ( 0.7236) Learning Rate: 0.1000 (0.1000) Top1_base: 75.7812 (80.3906) Top1_base_per_class: 74.2453 (80.8647) 
Training Epoch: [166/1000] Step: [40 / 285] Batch Time: 0.1506 (0.1782) Data Time: 0.0150 (0.0445) Average Loss: 0.5641 (0.7094) Average CE Loss (Source):  0.5641 ( 0.7094) Learning Rate: 0.1000 (0.1000) Top1_base: 84.3750 (80.7422) Top1_base_per_class: 83.9831 (81.0369) 
Training Epoch: [166/1000] Step: [50 / 285] Batch Time: 0.1503 (0.1737) Data Time: 0.0152 (0.0395) Average Loss: 0.6604 (0.7117) Average CE Loss (Source):  0.6604 ( 0.7117) Learning Rate: 0.1000 (0.1000) Top1_base: 78.9062 (80.5469) Top1_base_per_class: 80.6797 (80.9375) 
Training Epoch: [166/1000] Step: [60 / 285] Batch Time: 0.1481 (0.1704) Data Time: 0.0123 (0.0361) Average Loss: 1.0581 (0.7139) Average CE Loss (Source):  1.0581 ( 0.7139) Learning Rate: 0.1000 (0.1000) Top1_base: 73.4375 (80.4688) Top1_base_per_class: 76.6038 (80.8952) 
Training Epoch: [166/1000] Step: [70 / 285] Batch Time: 0.1462 (0.1699) Data Time: 0.0127 (0.0357) Average Loss: 0.8431 (0.7170) Average CE Loss (Source):  0.8431 ( 0.7170) Learning Rate: 0.1000 (0.1000) Top1_base: 75.0000 (80.2009) Top1_base_per_class: 75.7716 (80.5645) 
Training Epoch: [166/1000] Step: [80 / 285] Batch Time: 0.1942 (0.1677) Data Time: 0.0620 (0.0335) Average Loss: 0.6155 (0.7109) Average CE Loss (Source):  0.6155 ( 0.7109) Learning Rate: 0.1000 (0.1000) Top1_base: 85.1562 (80.3418) Top1_base_per_class: 83.5058 (80.7172) 
Training Epoch: [166/1000] Step: [90 / 285] Batch Time: 0.1485 (0.1662) Data Time: 0.0144 (0.0321) Average Loss: 0.6402 (0.7095) Average CE Loss (Source):  0.6402 ( 0.7095) Learning Rate: 0.1000 (0.1000) Top1_base: 81.2500 (80.3125) Top1_base_per_class: 82.6023 (80.7022) 
Training Epoch: [166/1000] Step: [100 / 285] Batch Time: 0.1510 (0.1645) Data Time: 0.0192 (0.0304) Average Loss: 0.7460 (0.7088) Average CE Loss (Source):  0.7460 ( 0.7088) Learning Rate: 0.1000 (0.1000) Top1_base: 80.4688 (80.3047) Top1_base_per_class: 81.8788 (80.7105) 
Training Epoch: [166/1000] Step: [110 / 285] Batch Time: 0.1465 (0.1632) Data Time: 0.0133 (0.0291) Average Loss: 0.9432 (0.7098) Average CE Loss (Source):  0.9432 ( 0.7098) Learning Rate: 0.1000 (0.1000) Top1_base: 74.2188 (80.3267) Top1_base_per_class: 73.3333 (80.8033) 
Training Epoch: [166/1000] Step: [120 / 285] Batch Time: 0.1490 (0.1618) Data Time: 0.0162 (0.0278) Average Loss: 0.7210 (0.7126) Average CE Loss (Source):  0.7210 ( 0.7126) Learning Rate: 0.1000 (0.1000) Top1_base: 80.4688 (80.2409) Top1_base_per_class: 79.2398 (80.6959) 
Training Epoch: [166/1000] Step: [130 / 285] Batch Time: 0.1470 (0.1605) Data Time: 0.0140 (0.0267) Average Loss: 0.6838 (0.7151) Average CE Loss (Source):  0.6838 ( 0.7151) Learning Rate: 0.1000 (0.1000) Top1_base: 81.2500 (80.0962) Top1_base_per_class: 82.2327 (80.5016) 
Training Epoch: [166/1000] Step: [140 / 285] Batch Time: 0.1852 (0.1598) Data Time: 0.0529 (0.0261) Average Loss: 0.6784 (0.7206) Average CE Loss (Source):  0.6784 ( 0.7206) Learning Rate: 0.1000 (0.1000) Top1_base: 82.8125 (80.0167) Top1_base_per_class: 83.0409 (80.4037) 
Training Epoch: [166/1000] Step: [150 / 285] Batch Time: 0.1451 (0.1601) Data Time: 0.0106 (0.0265) Average Loss: 0.7838 (0.7224) Average CE Loss (Source):  0.7838 ( 0.7224) Learning Rate: 0.1000 (0.1000) Top1_base: 79.6875 (79.9115) Top1_base_per_class: 80.4094 (80.3274) 
Training Epoch: [166/1000] Step: [160 / 285] Batch Time: 0.1482 (0.1596) Data Time: 0.0167 (0.0261) Average Loss: 0.7286 (0.7195) Average CE Loss (Source):  0.7286 ( 0.7195) Learning Rate: 0.1000 (0.1000) Top1_base: 76.5625 (79.9072) Top1_base_per_class: 75.3205 (80.3610) 
Training Epoch: [166/1000] Step: [170 / 285] Batch Time: 0.1453 (0.1590) Data Time: 0.0111 (0.0256) Average Loss: 0.6418 (0.7204) Average CE Loss (Source):  0.6418 ( 0.7204) Learning Rate: 0.1000 (0.1000) Top1_base: 79.6875 (79.8483) Top1_base_per_class: 78.1761 (80.3240) 
Training Epoch: [166/1000] Step: [180 / 285] Batch Time: 0.1874 (0.1586) Data Time: 0.0556 (0.0252) Average Loss: 0.6537 (0.7179) Average CE Loss (Source):  0.6537 ( 0.7179) Learning Rate: 0.1000 (0.1000) Top1_base: 82.8125 (79.9175) Top1_base_per_class: 81.5723 (80.3939) 
Training Epoch: [166/1000] Step: [190 / 285] Batch Time: 0.1466 (0.1582) Data Time: 0.0108 (0.0249) Average Loss: 0.6783 (0.7187) Average CE Loss (Source):  0.6783 ( 0.7187) Learning Rate: 0.1000 (0.1000) Top1_base: 80.4688 (79.9465) Top1_base_per_class: 80.4386 (80.3816) 
Training Epoch: [166/1000] Step: [200 / 285] Batch Time: 0.1701 (0.1582) Data Time: 0.0387 (0.0249) Average Loss: 0.7752 (0.7190) Average CE Loss (Source):  0.7752 ( 0.7190) Learning Rate: 0.1000 (0.1000) Top1_base: 79.6875 (79.9141) Top1_base_per_class: 79.7484 (80.4060) 
Training Epoch: [166/1000] Step: [210 / 285] Batch Time: 0.1451 (0.1582) Data Time: 0.0109 (0.0249) Average Loss: 0.6811 (0.7195) Average CE Loss (Source):  0.6811 ( 0.7195) Learning Rate: 0.1000 (0.1000) Top1_base: 82.8125 (79.9070) Top1_base_per_class: 84.1808 (80.4463) 
Training Epoch: [166/1000] Step: [220 / 285] Batch Time: 0.2577 (0.1582) Data Time: 0.1262 (0.0250) Average Loss: 0.8208 (0.7202) Average CE Loss (Source):  0.8208 ( 0.7202) Learning Rate: 0.1000 (0.1000) Top1_base: 78.1250 (79.9183) Top1_base_per_class: 80.4575 (80.4909) 
Training Epoch: [166/1000] Step: [230 / 285] Batch Time: 0.1460 (0.1579) Data Time: 0.0111 (0.0247) Average Loss: 0.7679 (0.7190) Average CE Loss (Source):  0.7679 ( 0.7190) Learning Rate: 0.1000 (0.1000) Top1_base: 78.1250 (79.9490) Top1_base_per_class: 79.5690 (80.5403) 
Training Epoch: [166/1000] Step: [240 / 285] Batch Time: 0.1669 (0.1578) Data Time: 0.0350 (0.0245) Average Loss: 0.7513 (0.7196) Average CE Loss (Source):  0.7513 ( 0.7196) Learning Rate: 0.1000 (0.1000) Top1_base: 77.3438 (79.9284) Top1_base_per_class: 80.1732 (80.5370) 
Training Epoch: [166/1000] Step: [250 / 285] Batch Time: 0.1435 (0.1574) Data Time: 0.0125 (0.0242) Average Loss: 0.8353 (0.7182) Average CE Loss (Source):  0.8353 ( 0.7182) Learning Rate: 0.1000 (0.1000) Top1_base: 75.7812 (79.9562) Top1_base_per_class: 78.0409 (80.5525) 
Training Epoch: [166/1000] Step: [260 / 285] Batch Time: 0.1751 (0.1573) Data Time: 0.0433 (0.0241) Average Loss: 0.8999 (0.7210) Average CE Loss (Source):  0.8999 ( 0.7210) Learning Rate: 0.1000 (0.1000) Top1_base: 74.2188 (79.8918) Top1_base_per_class: 73.2728 (80.4828) 
Training Epoch: [166/1000] Step: [270 / 285] Batch Time: 0.1442 (0.1571) Data Time: 0.0124 (0.0239) Average Loss: 0.7565 (0.7211) Average CE Loss (Source):  0.7565 ( 0.7211) Learning Rate: 0.1000 (0.1000) Top1_base: 77.3438 (79.8351) Top1_base_per_class: 76.0377 (80.4522) 
Training Epoch: [166/1000] Step: [280 / 285] Batch Time: 0.2042 (0.1572) Data Time: 0.0706 (0.0241) Average Loss: 0.7567 (0.7230) Average CE Loss (Source):  0.7567 ( 0.7230) Learning Rate: 0.1000 (0.1000) Top1_base: 78.1250 (79.7573) Top1_base_per_class: 80.5758 (80.3593) 
Training Epoch: [167/1000] Step: [0] Batch Time: 0.1413 (0.1569) Data Time: 0.0119 (0.0239) Average Loss: 0.8815 (0.7232) Average CE Loss (Source):  0.8815 ( 0.7232) Learning Rate: 0.1000 (0.1000) Top1_base: 72.6562 (79.7341) Top1_base_per_class: 73.9881 (80.3309) 
Training Epoch: [167/1000] Step: [10 / 285] Batch Time: 0.1540 (0.2307) Data Time: 0.0154 (0.0972) Average Loss: 0.5772 (0.6639) Average CE Loss (Source):  0.5772 ( 0.6639) Learning Rate: 0.1000 (0.1000) Top1_base: 85.9375 (82.2656) Top1_base_per_class: 87.5439 (83.3763) 
Training Epoch: [167/1000] Step: [20 / 285] Batch Time: 0.2372 (0.2003) Data Time: 0.1061 (0.0671) Average Loss: 0.6977 (0.7038) Average CE Loss (Source):  0.6977 ( 0.7038) Learning Rate: 0.1000 (0.1000) Top1_base: 82.0312 (80.9766) Top1_base_per_class: 82.0606 (82.0082) 
Training Epoch: [167/1000] Step: [30 / 285] Batch Time: 0.1494 (0.1858) Data Time: 0.0144 (0.0526) Average Loss: 0.6960 (0.6949) Average CE Loss (Source):  0.6960 ( 0.6949) Learning Rate: 0.1000 (0.1000) Top1_base: 81.2500 (81.0938) Top1_base_per_class: 76.9091 (81.7671) 
Training Epoch: [167/1000] Step: [40 / 285] Batch Time: 0.2204 (0.1789) Data Time: 0.0870 (0.0456) Average Loss: 0.8262 (0.6994) Average CE Loss (Source):  0.8262 ( 0.6994) Learning Rate: 0.1000 (0.1000) Top1_base: 78.1250 (81.0742) Top1_base_per_class: 73.0460 (81.5085) 
Training Epoch: [167/1000] Step: [50 / 285] Batch Time: 0.1468 (0.1758) Data Time: 0.0129 (0.0426) Average Loss: 0.6911 (0.7044) Average CE Loss (Source):  0.6911 ( 0.7044) Learning Rate: 0.1000 (0.1000) Top1_base: 82.0312 (80.7344) Top1_base_per_class: 83.2424 (81.1108) 
Training Epoch: [167/1000] Step: [60 / 285] Batch Time: 0.1468 (0.1731) Data Time: 0.0150 (0.0399) Average Loss: 0.6894 (0.7061) Average CE Loss (Source):  0.6894 ( 0.7061) Learning Rate: 0.1000 (0.1000) Top1_base: 80.4688 (80.4557) Top1_base_per_class: 79.8248 (80.9449) 
Training Epoch: [167/1000] Step: [70 / 285] Batch Time: 0.1458 (0.1700) Data Time: 0.0129 (0.0369) Average Loss: 0.7361 (0.7072) Average CE Loss (Source):  0.7361 ( 0.7072) Learning Rate: 0.1000 (0.1000) Top1_base: 82.8125 (80.5246) Top1_base_per_class: 85.2047 (81.0592) 
Training Epoch: [167/1000] Step: [80 / 285] Batch Time: 0.1479 (0.1676) Data Time: 0.0164 (0.0345) Average Loss: 0.6616 (0.7019) Average CE Loss (Source):  0.6616 ( 0.7019) Learning Rate: 0.1000 (0.1000) Top1_base: 79.6875 (80.5273) Top1_base_per_class: 80.3459 (81.1450) 
Training Epoch: [167/1000] Step: [90 / 285] Batch Time: 0.1424 (0.1657) Data Time: 0.0099 (0.0327) Average Loss: 0.8137 (0.7029) Average CE Loss (Source):  0.8137 ( 0.7029) Learning Rate: 0.1000 (0.1000) Top1_base: 76.5625 (80.4514) Top1_base_per_class: 77.5629 (81.0919) 
Training Epoch: [167/1000] Step: [100 / 285] Batch Time: 0.1467 (0.1638) Data Time: 0.0137 (0.0307) Average Loss: 0.6651 (0.7010) Average CE Loss (Source):  0.6651 ( 0.7010) Learning Rate: 0.1000 (0.1000) Top1_base: 84.3750 (80.4375) Top1_base_per_class: 88.4503 (81.0323) 
Training Epoch: [167/1000] Step: [110 / 285] Batch Time: 0.1454 (0.1628) Data Time: 0.0104 (0.0297) Average Loss: 0.7596 (0.7013) Average CE Loss (Source):  0.7596 ( 0.7013) Learning Rate: 0.1000 (0.1000) Top1_base: 80.4688 (80.4119) Top1_base_per_class: 81.9345 (81.0576) 
Training Epoch: [167/1000] Step: [120 / 285] Batch Time: 0.1481 (0.1622) Data Time: 0.0157 (0.0292) Average Loss: 0.7545 (0.7055) Average CE Loss (Source):  0.7545 ( 0.7055) Learning Rate: 0.1000 (0.1000) Top1_base: 77.3438 (80.2669) Top1_base_per_class: 77.2222 (80.9952) 
Training Epoch: [167/1000] Step: [130 / 285] Batch Time: 0.1453 (0.1612) Data Time: 0.0102 (0.0282) Average Loss: 0.6089 (0.7021) Average CE Loss (Source):  0.6089 ( 0.7021) Learning Rate: 0.1000 (0.1000) Top1_base: 83.5938 (80.3666) Top1_base_per_class: 83.0460 (81.1127) 
Training Epoch: [167/1000] Step: [140 / 285] Batch Time: 0.1470 (0.1607) Data Time: 0.0150 (0.0276) Average Loss: 0.7105 (0.7015) Average CE Loss (Source):  0.7105 ( 0.7015) Learning Rate: 0.1000 (0.1000) Top1_base: 81.2500 (80.3460) Top1_base_per_class: 81.3988 (81.1439) 
Training Epoch: [167/1000] Step: [150 / 285] Batch Time: 0.1450 (0.1603) Data Time: 0.0102 (0.0272) Average Loss: 0.8169 (0.7031) Average CE Loss (Source):  0.8169 ( 0.7031) Learning Rate: 0.1000 (0.1000) Top1_base: 76.5625 (80.2760) Top1_base_per_class: 78.0449 (81.0424) 
Training Epoch: [167/1000] Step: [160 / 285] Batch Time: 0.1477 (0.1595) Data Time: 0.0148 (0.0264) Average Loss: 0.7441 (0.7044) Average CE Loss (Source):  0.7441 ( 0.7044) Learning Rate: 0.1000 (0.1000) Top1_base: 76.5625 (80.2344) Top1_base_per_class: 78.4226 (81.0421) 
Training Epoch: [167/1000] Step: [170 / 285] Batch Time: 0.1466 (0.1592) Data Time: 0.0102 (0.0261) Average Loss: 0.6097 (0.7069) Average CE Loss (Source):  0.6097 ( 0.7069) Learning Rate: 0.1000 (0.1000) Top1_base: 78.9062 (80.1379) Top1_base_per_class: 73.6709 (80.8709) 
Training Epoch: [167/1000] Step: [180 / 285] Batch Time: 0.1483 (0.1590) Data Time: 0.0154 (0.0259) Average Loss: 0.8286 (0.7075) Average CE Loss (Source):  0.8286 ( 0.7075) Learning Rate: 0.1000 (0.1000) Top1_base: 78.1250 (80.1389) Top1_base_per_class: 79.5690 (80.8798) 
Training Epoch: [167/1000] Step: [190 / 285] Batch Time: 0.1448 (0.1590) Data Time: 0.0102 (0.0259) Average Loss: 0.7647 (0.7105) Average CE Loss (Source):  0.7647 ( 0.7105) Learning Rate: 0.1000 (0.1000) Top1_base: 78.1250 (80.0206) Top1_base_per_class: 79.3531 (80.7215) 
Training Epoch: [167/1000] Step: [200 / 285] Batch Time: 0.1647 (0.1590) Data Time: 0.0337 (0.0259) Average Loss: 0.6380 (0.7132) Average CE Loss (Source):  0.6380 ( 0.7132) Learning Rate: 0.1000 (0.1000) Top1_base: 81.2500 (79.9531) Top1_base_per_class: 84.8788 (80.5905) 
Training Epoch: [167/1000] Step: [210 / 285] Batch Time: 0.1469 (0.1586) Data Time: 0.0110 (0.0255) Average Loss: 0.5035 (0.7112) Average CE Loss (Source):  0.5035 ( 0.7112) Learning Rate: 0.1000 (0.1000) Top1_base: 83.5938 (80.0074) Top1_base_per_class: 81.3636 (80.6148) 
Training Epoch: [167/1000] Step: [220 / 285] Batch Time: 0.1932 (0.1585) Data Time: 0.0614 (0.0253) Average Loss: 0.7120 (0.7114) Average CE Loss (Source):  0.7120 ( 0.7114) Learning Rate: 0.1000 (0.1000) Top1_base: 78.1250 (80.0142) Top1_base_per_class: 80.5555 (80.6317) 
Training Epoch: [167/1000] Step: [230 / 285] Batch Time: 0.1456 (0.1584) Data Time: 0.0111 (0.0253) Average Loss: 0.6462 (0.7134) Average CE Loss (Source):  0.6462 ( 0.7134) Learning Rate: 0.1000 (0.1000) Top1_base: 84.3750 (80.0068) Top1_base_per_class: 85.5000 (80.6527) 
Training Epoch: [167/1000] Step: [240 / 285] Batch Time: 0.2273 (0.1588) Data Time: 0.0962 (0.0257) Average Loss: 0.5767 (0.7140) Average CE Loss (Source):  0.5767 ( 0.7140) Learning Rate: 0.1000 (0.1000) Top1_base: 85.1562 (79.9642) Top1_base_per_class: 84.1975 (80.5933) 
Training Epoch: [167/1000] Step: [250 / 285] Batch Time: 0.1459 (0.1588) Data Time: 0.0106 (0.0256) Average Loss: 0.6871 (0.7135) Average CE Loss (Source):  0.6871 ( 0.7135) Learning Rate: 0.1000 (0.1000) Top1_base: 80.4688 (79.9719) Top1_base_per_class: 82.5152 (80.6070) 
Training Epoch: [167/1000] Step: [260 / 285] Batch Time: 0.1676 (0.1586) Data Time: 0.0347 (0.0254) Average Loss: 0.9430 (0.7163) Average CE Loss (Source):  0.9430 ( 0.7163) Learning Rate: 0.1000 (0.1000) Top1_base: 73.4375 (79.8798) Top1_base_per_class: 70.9141 (80.4854) 
Training Epoch: [167/1000] Step: [270 / 285] Batch Time: 0.1477 (0.1582) Data Time: 0.0117 (0.0251) Average Loss: 0.8496 (0.7191) Average CE Loss (Source):  0.8496 ( 0.7191) Learning Rate: 0.1000 (0.1000) Top1_base: 80.4688 (79.8177) Top1_base_per_class: 82.6923 (80.4244) 
Training Epoch: [167/1000] Step: [280 / 285] Batch Time: 0.1659 (0.1581) Data Time: 0.0340 (0.0250) Average Loss: 0.7272 (0.7227) Average CE Loss (Source):  0.7272 ( 0.7227) Learning Rate: 0.1000 (0.1000) Top1_base: 79.6875 (79.7321) Top1_base_per_class: 77.4459 (80.3210) 
Training Epoch: [168/1000] Step: [0] Batch Time: 0.1395 (0.1580) Data Time: 0.0097 (0.0249) Average Loss: 0.8776 (0.7241) Average CE Loss (Source):  0.8776 ( 0.7241) Learning Rate: 0.1000 (0.1000) Top1_base: 78.1250 (79.6930) Top1_base_per_class: 80.1724 (80.2597) 
 17%|█▋        | 168/1000 [2:10:37<10:45:34, 46.56s/it] 17%|█▋        | 169/1000 [2:11:22<10:39:20, 46.16s/it]Training Epoch: [168/1000] Step: [10 / 285] Batch Time: 0.1488 (0.2293) Data Time: 0.0155 (0.0974) Average Loss: 0.6263 (0.6341) Average CE Loss (Source):  0.6263 ( 0.6341) Learning Rate: 0.1000 (0.1000) Top1_base: 82.8125 (81.4062) Top1_base_per_class: 81.9048 (81.5935) 
Training Epoch: [168/1000] Step: [20 / 285] Batch Time: 0.1448 (0.1943) Data Time: 0.0140 (0.0619) Average Loss: 0.6316 (0.6297) Average CE Loss (Source):  0.6316 ( 0.6297) Learning Rate: 0.1000 (0.1000) Top1_base: 85.1562 (82.1094) Top1_base_per_class: 86.3141 (82.5754) 
Training Epoch: [168/1000] Step: [30 / 285] Batch Time: 0.1785 (0.1840) Data Time: 0.0432 (0.0510) Average Loss: 0.7550 (0.6491) Average CE Loss (Source):  0.7550 ( 0.6491) Learning Rate: 0.1000 (0.1000) Top1_base: 79.6875 (81.6927) Top1_base_per_class: 80.4167 (82.1976) 
Training Epoch: [168/1000] Step: [40 / 285] Batch Time: 0.1443 (0.1776) Data Time: 0.0113 (0.0444) Average Loss: 0.5297 (0.6471) Average CE Loss (Source):  0.5297 ( 0.6471) Learning Rate: 0.1000 (0.1000) Top1_base: 84.3750 (81.9922) Top1_base_per_class: 82.2126 (82.4142) 
Training Epoch: [168/1000] Step: [50 / 285] Batch Time: 0.1510 (0.1747) Data Time: 0.0164 (0.0415) Average Loss: 0.6040 (0.6520) Average CE Loss (Source):  0.6040 ( 0.6520) Learning Rate: 0.1000 (0.1000) Top1_base: 84.3750 (81.7344) Top1_base_per_class: 84.4848 (82.1378) 
Training Epoch: [168/1000] Step: [60 / 285] Batch Time: 0.1460 (0.1716) Data Time: 0.0134 (0.0384) Average Loss: 0.6307 (0.6581) Average CE Loss (Source):  0.6307 ( 0.6581) Learning Rate: 0.1000 (0.1000) Top1_base: 80.4688 (81.5495) Top1_base_per_class: 81.1905 (82.1112) 
Training Epoch: [168/1000] Step: [70 / 285] Batch Time: 0.2148 (0.1693) Data Time: 0.0801 (0.0361) Average Loss: 0.5327 (0.6687) Average CE Loss (Source):  0.5327 ( 0.6687) Learning Rate: 0.1000 (0.1000) Top1_base: 84.3750 (81.2054) Top1_base_per_class: 81.6964 (81.7623) 
Training Epoch: [168/1000] Step: [80 / 285] Batch Time: 0.1414 (0.1671) Data Time: 0.0102 (0.0340) Average Loss: 0.5977 (0.6707) Average CE Loss (Source):  0.5977 ( 0.6707) Learning Rate: 0.1000 (0.1000) Top1_base: 82.0312 (81.2012) Top1_base_per_class: 82.1428 (81.7098) 
Training Epoch: [168/1000] Step: [90 / 285] Batch Time: 0.1513 (0.1655) Data Time: 0.0165 (0.0324) Average Loss: 0.6870 (0.6729) Average CE Loss (Source):  0.6870 ( 0.6729) Learning Rate: 0.1000 (0.1000) Top1_base: 82.0312 (81.2500) Top1_base_per_class: 83.8690 (81.8573) 
Training Epoch: [168/1000] Step: [100 / 285] Batch Time: 0.1429 (0.1637) Data Time: 0.0105 (0.0305) Average Loss: 0.7714 (0.6759) Average CE Loss (Source):  0.7714 ( 0.6759) Learning Rate: 0.1000 (0.1000) Top1_base: 83.5938 (81.1328) Top1_base_per_class: 81.5093 (81.7669) 
Training Epoch: [168/1000] Step: [110 / 285] Batch Time: 0.2408 (0.1634) Data Time: 0.1065 (0.0302) Average Loss: 0.5090 (0.6788) Average CE Loss (Source):  0.5090 ( 0.6788) Learning Rate: 0.1000 (0.1000) Top1_base: 82.8125 (80.9730) Top1_base_per_class: 78.7571 (81.6219) 
Training Epoch: [168/1000] Step: [120 / 285] Batch Time: 0.1452 (0.1624) Data Time: 0.0127 (0.0292) Average Loss: 0.7117 (0.6820) Average CE Loss (Source):  0.7117 ( 0.6820) Learning Rate: 0.1000 (0.1000) Top1_base: 77.3438 (80.8789) Top1_base_per_class: 77.1131 (81.5353) 
Training Epoch: [168/1000] Step: [130 / 285] Batch Time: 0.1502 (0.1617) Data Time: 0.0168 (0.0286) Average Loss: 0.6601 (0.6843) Average CE Loss (Source):  0.6601 ( 0.6843) Learning Rate: 0.1000 (0.1000) Top1_base: 76.5625 (80.7091) Top1_base_per_class: 78.2164 (81.3877) 
Training Epoch: [168/1000] Step: [140 / 285] Batch Time: 0.1473 (0.1612) Data Time: 0.0145 (0.0281) Average Loss: 0.6076 (0.6844) Average CE Loss (Source):  0.6076 ( 0.6844) Learning Rate: 0.1000 (0.1000) Top1_base: 83.5938 (80.7087) Top1_base_per_class: 84.2857 (81.4235) 
Training Epoch: [168/1000] Step: [150 / 285] Batch Time: 0.1483 (0.1602) Data Time: 0.0132 (0.0272) Average Loss: 0.6461 (0.6860) Average CE Loss (Source):  0.6461 ( 0.6860) Learning Rate: 0.1000 (0.1000) Top1_base: 80.4688 (80.6458) Top1_base_per_class: 80.5172 (81.3370) 
Training Epoch: [168/1000] Step: [160 / 285] Batch Time: 0.1855 (0.1600) Data Time: 0.0537 (0.0270) Average Loss: 0.3985 (0.6854) Average CE Loss (Source):  0.3985 ( 0.6854) Learning Rate: 0.1000 (0.1000) Top1_base: 89.8438 (80.5859) Top1_base_per_class: 91.6333 (81.3203) 
Training Epoch: [168/1000] Step: [170 / 285] Batch Time: 0.1478 (0.1598) Data Time: 0.0128 (0.0268) Average Loss: 0.5721 (0.6829) Average CE Loss (Source):  0.5721 ( 0.6829) Learning Rate: 0.1000 (0.1000) Top1_base: 82.0312 (80.6204) Top1_base_per_class: 82.9012 (81.3225) 
Training Epoch: [168/1000] Step: [180 / 285] Batch Time: 0.1440 (0.1597) Data Time: 0.0123 (0.0267) Average Loss: 0.6956 (0.6870) Average CE Loss (Source):  0.6956 ( 0.6870) Learning Rate: 0.1000 (0.1000) Top1_base: 83.5938 (80.5469) Top1_base_per_class: 80.7471 (81.1755) 
Training Epoch: [168/1000] Step: [190 / 285] Batch Time: 0.1482 (0.1598) Data Time: 0.0125 (0.0268) Average Loss: 0.7770 (0.6879) Average CE Loss (Source):  0.7770 ( 0.6879) Learning Rate: 0.1000 (0.1000) Top1_base: 75.7812 (80.5387) Top1_base_per_class: 77.4671 (81.1534) 
Training Epoch: [168/1000] Step: [200 / 285] Batch Time: 0.1519 (0.1597) Data Time: 0.0193 (0.0267) Average Loss: 0.6765 (0.6889) Average CE Loss (Source):  0.6765 ( 0.6889) Learning Rate: 0.1000 (0.1000) Top1_base: 85.1562 (80.5312) Top1_base_per_class: 88.6885 (81.0881) 
Training Epoch: [168/1000] Step: [210 / 285] Batch Time: 0.1422 (0.1593) Data Time: 0.0106 (0.0263) Average Loss: 0.8320 (0.6916) Average CE Loss (Source):  0.8320 ( 0.6916) Learning Rate: 0.1000 (0.1000) Top1_base: 76.5625 (80.4464) Top1_base_per_class: 76.8155 (80.9562) 
Training Epoch: [168/1000] Step: [220 / 285] Batch Time: 0.2130 (0.1594) Data Time: 0.0817 (0.0265) Average Loss: 0.8460 (0.6947) Average CE Loss (Source):  0.8460 ( 0.6947) Learning Rate: 0.1000 (0.1000) Top1_base: 75.0000 (80.3089) Top1_base_per_class: 74.6384 (80.7930) 
Training Epoch: [168/1000] Step: [230 / 285] Batch Time: 0.1423 (0.1592) Data Time: 0.0109 (0.0263) Average Loss: 0.8650 (0.6985) Average CE Loss (Source):  0.8650 ( 0.6985) Learning Rate: 0.1000 (0.1000) Top1_base: 78.9062 (80.2242) Top1_base_per_class: 80.1235 (80.6726) 
Training Epoch: [168/1000] Step: [240 / 285] Batch Time: 0.1460 (0.1593) Data Time: 0.0148 (0.0264) Average Loss: 0.7640 (0.6987) Average CE Loss (Source):  0.7640 ( 0.6987) Learning Rate: 0.1000 (0.1000) Top1_base: 75.7812 (80.2214) Top1_base_per_class: 74.5198 (80.6699) 
Training Epoch: [168/1000] Step: [250 / 285] Batch Time: 0.1464 (0.1590) Data Time: 0.0132 (0.0262) Average Loss: 0.5702 (0.6992) Average CE Loss (Source):  0.5702 ( 0.6992) Learning Rate: 0.1000 (0.1000) Top1_base: 83.5938 (80.2156) Top1_base_per_class: 82.8120 (80.6623) 
Training Epoch: [168/1000] Step: [260 / 285] Batch Time: 0.2400 (0.1596) Data Time: 0.1087 (0.0268) Average Loss: 0.7199 (0.6994) Average CE Loss (Source):  0.7199 ( 0.6994) Learning Rate: 0.1000 (0.1000) Top1_base: 80.4688 (80.1983) Top1_base_per_class: 79.8428 (80.6028) 
Training Epoch: [168/1000] Step: [270 / 285] Batch Time: 0.1519 (0.1591) Data Time: 0.0145 (0.0263) Average Loss: 0.7623 (0.7031) Average CE Loss (Source):  0.7623 ( 0.7031) Learning Rate: 0.1000 (0.1000) Top1_base: 78.9062 (80.1447) Top1_base_per_class: 79.8246 (80.5555) 
Training Epoch: [168/1000] Step: [280 / 285] Batch Time: 0.1467 (0.1587) Data Time: 0.0144 (0.0258) Average Loss: 0.6970 (0.7040) Average CE Loss (Source):  0.6970 ( 0.7040) Learning Rate: 0.1000 (0.1000) Top1_base: 81.2500 (80.1283) Top1_base_per_class: 81.7576 (80.5616) 
Training Epoch: [169/1000] Step: [0] Batch Time: 0.1446 (0.1585) Data Time: 0.0102 (0.0257) Average Loss: 0.7606 (0.7050) Average CE Loss (Source):  0.7606 ( 0.7050) Learning Rate: 0.1000 (0.1000) Top1_base: 77.3438 (80.0877) Top1_base_per_class: 73.4211 (80.5040) 
Training Epoch: [169/1000] Step: [10 / 285] Batch Time: 0.1438 (0.2330) Data Time: 0.0140 (0.1018) Average Loss: 0.6823 (0.7333) Average CE Loss (Source):  0.6823 ( 0.7333) Learning Rate: 0.1000 (0.1000) Top1_base: 82.0312 (80.1562) Top1_base_per_class: 82.9091 (80.9113) 
Training Epoch: [169/1000] Step: [20 / 285] Batch Time: 0.1444 (0.1899) Data Time: 0.0118 (0.0582) Average Loss: 0.7260 (0.6999) Average CE Loss (Source):  0.7260 ( 0.6999) Learning Rate: 0.1000 (0.1000) Top1_base: 78.9062 (80.7812) Top1_base_per_class: 80.2554 (81.3112) 
Training Epoch: [169/1000] Step: [30 / 285] Batch Time: 0.1440 (0.1806) Data Time: 0.0123 (0.0486) Average Loss: 0.5910 (0.6945) Average CE Loss (Source):  0.5910 ( 0.6945) Learning Rate: 0.1000 (0.1000) Top1_base: 80.4688 (80.6250) Top1_base_per_class: 81.3725 (81.1121) 
Training Epoch: [169/1000] Step: [40 / 285] Batch Time: 0.1456 (0.1727) Data Time: 0.0125 (0.0403) Average Loss: 0.8795 (0.6941) Average CE Loss (Source):  0.8795 ( 0.6941) Learning Rate: 0.1000 (0.1000) Top1_base: 75.7812 (80.5469) Top1_base_per_class: 78.4795 (81.2461) 
Training Epoch: [169/1000] Step: [50 / 285] Batch Time: 0.1466 (0.1738) Data Time: 0.0120 (0.0413) Average Loss: 0.5983 (0.6947) Average CE Loss (Source):  0.5983 ( 0.6947) Learning Rate: 0.1000 (0.1000) Top1_base: 81.2500 (80.4688) Top1_base_per_class: 83.6111 (81.0952) 
Training Epoch: [169/1000] Step: [60 / 285] Batch Time: 0.1436 (0.1709) Data Time: 0.0113 (0.0383) Average Loss: 0.7519 (0.6963) Average CE Loss (Source):  0.7519 ( 0.6963) Learning Rate: 0.1000 (0.1000) Top1_base: 77.3438 (80.4036) Top1_base_per_class: 78.9181 (81.1161) 
Training Epoch: [169/1000] Step: [70 / 285] Batch Time: 0.1492 (0.1687) Data Time: 0.0130 (0.0360) Average Loss: 0.5754 (0.6968) Average CE Loss (Source):  0.5754 ( 0.6968) Learning Rate: 0.1000 (0.1000) Top1_base: 78.1250 (80.2567) Top1_base_per_class: 74.7953 (80.8182) 
Training Epoch: [169/1000] Step: [80 / 285] Batch Time: 0.1436 (0.1690) Data Time: 0.0114 (0.0362) Average Loss: 0.6137 (0.6951) Average CE Loss (Source):  0.6137 ( 0.6951) Learning Rate: 0.1000 (0.1000) Top1_base: 83.5938 (80.4395) Top1_base_per_class: 81.9006 (80.9590) 
Training Epoch: [169/1000] Step: [90 / 285] Batch Time: 0.1466 (0.1675) Data Time: 0.0149 (0.0347) Average Loss: 0.6487 (0.6925) Average CE Loss (Source):  0.6487 ( 0.6925) Learning Rate: 0.1000 (0.1000) Top1_base: 81.2500 (80.5122) Top1_base_per_class: 83.5185 (80.9735) 
Training Epoch: [169/1000] Step: [100 / 285] Batch Time: 0.1447 (0.1654) Data Time: 0.0119 (0.0325) Average Loss: 0.7353 (0.6927) Average CE Loss (Source):  0.7353 ( 0.6927) Learning Rate: 0.1000 (0.1000) Top1_base: 77.3438 (80.5312) Top1_base_per_class: 78.9137 (81.1130) 
Training Epoch: [169/1000] Step: [110 / 285] Batch Time: 0.1429 (0.1638) Data Time: 0.0129 (0.0309) Average Loss: 0.7242 (0.6951) Average CE Loss (Source):  0.7242 ( 0.6951) Learning Rate: 0.1000 (0.1000) Top1_base: 81.2500 (80.5256) Top1_base_per_class: 79.5597 (81.0603) 
Training Epoch: [169/1000] Step: [120 / 285] Batch Time: 0.1452 (0.1634) Data Time: 0.0131 (0.0306) Average Loss: 0.6968 (0.6928) Average CE Loss (Source):  0.6968 ( 0.6928) Learning Rate: 0.1000 (0.1000) Top1_base: 80.4688 (80.5924) Top1_base_per_class: 80.2976 (81.1306) 
Training Epoch: [169/1000] Step: [130 / 285] Batch Time: 0.1486 (0.1623) Data Time: 0.0152 (0.0294) Average Loss: 0.5013 (0.6977) Average CE Loss (Source):  0.5013 ( 0.6977) Learning Rate: 0.1000 (0.1000) Top1_base: 86.7188 (80.4988) Top1_base_per_class: 85.0000 (81.1105) 
Training Epoch: [169/1000] Step: [140 / 285] Batch Time: 0.1565 (0.1616) Data Time: 0.0246 (0.0287) Average Loss: 0.6108 (0.7008) Average CE Loss (Source):  0.6108 ( 0.7008) Learning Rate: 0.1000 (0.1000) Top1_base: 82.0312 (80.4018) Top1_base_per_class: 81.8546 (80.9477) 
Training Epoch: [169/1000] Step: [150 / 285] Batch Time: 0.1427 (0.1613) Data Time: 0.0134 (0.0284) Average Loss: 0.7195 (0.7027) Average CE Loss (Source):  0.7195 ( 0.7027) Learning Rate: 0.1000 (0.1000) Top1_base: 81.2500 (80.3073) Top1_base_per_class: 81.2654 (80.8457) 
Training Epoch: [169/1000] Step: [160 / 285] Batch Time: 0.1478 (0.1609) Data Time: 0.0144 (0.0280) Average Loss: 0.5826 (0.7004) Average CE Loss (Source):  0.5826 ( 0.7004) Learning Rate: 0.1000 (0.1000) Top1_base: 86.7188 (80.3809) Top1_base_per_class: 86.5789 (80.9194) 
Training Epoch: [169/1000] Step: [170 / 285] Batch Time: 0.1486 (0.1607) Data Time: 0.0149 (0.0278) Average Loss: 0.6379 (0.6980) Average CE Loss (Source):  0.6379 ( 0.6980) Learning Rate: 0.1000 (0.1000) Top1_base: 82.8125 (80.3860) Top1_base_per_class: 82.5893 (80.9537) 
Training Epoch: [169/1000] Step: [180 / 285] Batch Time: 0.1989 (0.1606) Data Time: 0.0661 (0.0277) Average Loss: 0.6064 (0.6985) Average CE Loss (Source):  0.6064 ( 0.6985) Learning Rate: 0.1000 (0.1000) Top1_base: 83.5938 (80.3776) Top1_base_per_class: 82.9944 (80.9566) 
Training Epoch: [169/1000] Step: [190 / 285] Batch Time: 0.1471 (0.1603) Data Time: 0.0133 (0.0273) Average Loss: 0.5401 (0.6998) Average CE Loss (Source):  0.5401 ( 0.6998) Learning Rate: 0.1000 (0.1000) Top1_base: 88.2812 (80.3125) Top1_base_per_class: 88.3333 (80.8746) 
Training Epoch: [169/1000] Step: [200 / 285] Batch Time: 0.1868 (0.1609) Data Time: 0.0538 (0.0280) Average Loss: 0.7014 (0.7018) Average CE Loss (Source):  0.7014 ( 0.7018) Learning Rate: 0.1000 (0.1000) Top1_base: 80.4688 (80.2695) Top1_base_per_class: 81.2842 (80.8604) 
Training Epoch: [169/1000] Step: [210 / 285] Batch Time: 0.1410 (0.1606) Data Time: 0.0106 (0.0277) Average Loss: 0.5487 (0.6997) Average CE Loss (Source):  0.5487 ( 0.6997) Learning Rate: 0.1000 (0.1000) Top1_base: 85.1562 (80.2902) Top1_base_per_class: 84.9697 (80.8269) 
Training Epoch: [169/1000] Step: [220 / 285] Batch Time: 0.1896 (0.1606) Data Time: 0.0582 (0.0277) Average Loss: 0.7647 (0.7012) Average CE Loss (Source):  0.7647 ( 0.7012) Learning Rate: 0.1000 (0.1000) Top1_base: 74.2188 (80.2202) Top1_base_per_class: 73.0503 (80.7674) 
Training Epoch: [169/1000] Step: [230 / 285] Batch Time: 0.1396 (0.1604) Data Time: 0.0104 (0.0276) Average Loss: 0.6378 (0.7028) Average CE Loss (Source):  0.6378 ( 0.7028) Learning Rate: 0.1000 (0.1000) Top1_base: 78.9062 (80.1698) Top1_base_per_class: 82.2327 (80.7216) 
Training Epoch: [169/1000] Step: [240 / 285] Batch Time: 0.1802 (0.1602) Data Time: 0.0482 (0.0275) Average Loss: 0.5409 (0.7017) Average CE Loss (Source):  0.5409 ( 0.7017) Learning Rate: 0.1000 (0.1000) Top1_base: 83.5938 (80.1888) Top1_base_per_class: 79.3056 (80.7029) 
Training Epoch: [169/1000] Step: [250 / 285] Batch Time: 0.1462 (0.1601) Data Time: 0.0127 (0.0274) Average Loss: 0.6695 (0.7030) Average CE Loss (Source):  0.6695 ( 0.7030) Learning Rate: 0.1000 (0.1000) Top1_base: 77.3438 (80.1625) Top1_base_per_class: 80.1488 (80.6740) 
Training Epoch: [169/1000] Step: [260 / 285] Batch Time: 0.1557 (0.1599) Data Time: 0.0217 (0.0272) Average Loss: 0.5583 (0.7024) Average CE Loss (Source):  0.5583 ( 0.7024) Learning Rate: 0.1000 (0.1000) Top1_base: 85.1562 (80.1502) Top1_base_per_class: 82.8984 (80.6281) 
Training Epoch: [169/1000] Step: [270 / 285] Batch Time: 0.1472 (0.1596) Data Time: 0.0119 (0.0269) Average Loss: 0.8102 (0.7023) Average CE Loss (Source):  0.8102 ( 0.7023) Learning Rate: 0.1000 (0.1000) Top1_base: 78.1250 (80.1186) Top1_base_per_class: 78.9394 (80.6363) 
Training Epoch: [169/1000] Step: [280 / 285] Batch Time: 0.2823 (0.1597) Data Time: 0.1504 (0.0270) Average Loss: 0.6552 (0.7020) Average CE Loss (Source):  0.6552 ( 0.7020) Learning Rate: 0.1000 (0.1000) Top1_base: 84.3750 (80.0865) Top1_base_per_class: 80.2976 (80.5673) 
Training Epoch: [170/1000] Step: [0] Batch Time: 0.1408 (0.1598) Data Time: 0.0094 (0.0271) Average Loss: 0.8104 (0.7031) Average CE Loss (Source):  0.8104 ( 0.7031) Learning Rate: 0.1000 (0.1000) Top1_base: 72.6562 (80.0548) Top1_base_per_class: 74.0936 (80.5147) 
 17%|█▋        | 170/1000 [2:12:10<10:47:41, 46.82s/it] 17%|█▋        | 171/1000 [2:12:55<10:37:07, 46.11s/it]Training Epoch: [170/1000] Step: [10 / 285] Batch Time: 0.1469 (0.2267) Data Time: 0.0135 (0.0935) Average Loss: 0.6664 (0.6913) Average CE Loss (Source):  0.6664 ( 0.6913) Learning Rate: 0.1000 (0.1000) Top1_base: 82.8125 (81.3281) Top1_base_per_class: 79.6199 (80.4041) 
Training Epoch: [170/1000] Step: [20 / 285] Batch Time: 0.1436 (0.1878) Data Time: 0.0126 (0.0551) Average Loss: 0.6822 (0.7331) Average CE Loss (Source):  0.6822 ( 0.7331) Learning Rate: 0.1000 (0.1000) Top1_base: 80.4688 (79.6875) Top1_base_per_class: 80.7184 (79.2379) 
Training Epoch: [170/1000] Step: [30 / 285] Batch Time: 0.1442 (0.1757) Data Time: 0.0136 (0.0432) Average Loss: 0.5641 (0.7112) Average CE Loss (Source):  0.5641 ( 0.7112) Learning Rate: 0.1000 (0.1000) Top1_base: 86.7188 (80.1042) Top1_base_per_class: 87.3977 (79.8429) 
Training Epoch: [170/1000] Step: [40 / 285] Batch Time: 0.1439 (0.1729) Data Time: 0.0121 (0.0402) Average Loss: 0.5876 (0.7133) Average CE Loss (Source):  0.5876 ( 0.7133) Learning Rate: 0.1000 (0.1000) Top1_base: 82.8125 (80.2930) Top1_base_per_class: 85.6604 (80.2298) 
Training Epoch: [170/1000] Step: [50 / 285] Batch Time: 0.1466 (0.1717) Data Time: 0.0125 (0.0390) Average Loss: 0.6509 (0.7112) Average CE Loss (Source):  0.6509 ( 0.7112) Learning Rate: 0.1000 (0.1000) Top1_base: 84.3750 (80.3281) Top1_base_per_class: 87.1818 (80.4595) 
Training Epoch: [170/1000] Step: [60 / 285] Batch Time: 0.1441 (0.1683) Data Time: 0.0139 (0.0355) Average Loss: 0.6248 (0.7087) Average CE Loss (Source):  0.6248 ( 0.7087) Learning Rate: 0.1000 (0.1000) Top1_base: 84.3750 (80.5078) Top1_base_per_class: 83.3333 (80.5393) 
Training Epoch: [170/1000] Step: [70 / 285] Batch Time: 0.1460 (0.1660) Data Time: 0.0124 (0.0332) Average Loss: 0.6123 (0.7053) Average CE Loss (Source):  0.6123 ( 0.7053) Learning Rate: 0.1000 (0.1000) Top1_base: 84.3750 (80.5246) Top1_base_per_class: 85.6731 (80.4716) 
Training Epoch: [170/1000] Step: [80 / 285] Batch Time: 0.1655 (0.1647) Data Time: 0.0342 (0.0319) Average Loss: 0.7300 (0.7164) Average CE Loss (Source):  0.7300 ( 0.7164) Learning Rate: 0.1000 (0.1000) Top1_base: 76.5625 (80.1758) Top1_base_per_class: 77.6543 (80.1684) 
Training Epoch: [170/1000] Step: [90 / 285] Batch Time: 0.1424 (0.1630) Data Time: 0.0121 (0.0303) Average Loss: 0.6373 (0.7146) Average CE Loss (Source):  0.6373 ( 0.7146) Learning Rate: 0.1000 (0.1000) Top1_base: 85.1562 (80.3125) Top1_base_per_class: 85.5060 (80.4088) 
Training Epoch: [170/1000] Step: [100 / 285] Batch Time: 0.2113 (0.1635) Data Time: 0.0792 (0.0308) Average Loss: 0.7815 (0.7139) Average CE Loss (Source):  0.7815 ( 0.7139) Learning Rate: 0.1000 (0.1000) Top1_base: 79.6875 (80.2734) Top1_base_per_class: 79.7076 (80.4962) 
Training Epoch: [170/1000] Step: [110 / 285] Batch Time: 0.1473 (0.1627) Data Time: 0.0141 (0.0300) Average Loss: 0.7265 (0.7105) Average CE Loss (Source):  0.7265 ( 0.7105) Learning Rate: 0.1000 (0.1000) Top1_base: 80.4688 (80.2557) Top1_base_per_class: 78.3951 (80.4072) 
Training Epoch: [170/1000] Step: [120 / 285] Batch Time: 0.2261 (0.1630) Data Time: 0.0920 (0.0303) Average Loss: 0.6823 (0.7079) Average CE Loss (Source):  0.6823 ( 0.7079) Learning Rate: 0.1000 (0.1000) Top1_base: 80.4688 (80.3711) Top1_base_per_class: 82.5893 (80.5989) 
Training Epoch: [170/1000] Step: [130 / 285] Batch Time: 0.1425 (0.1621) Data Time: 0.0108 (0.0294) Average Loss: 0.7025 (0.7081) Average CE Loss (Source):  0.7025 ( 0.7081) Learning Rate: 0.1000 (0.1000) Top1_base: 78.1250 (80.3846) Top1_base_per_class: 76.8604 (80.6465) 
Training Epoch: [170/1000] Step: [140 / 285] Batch Time: 0.1963 (0.1618) Data Time: 0.0620 (0.0291) Average Loss: 0.7850 (0.7096) Average CE Loss (Source):  0.7850 ( 0.7096) Learning Rate: 0.1000 (0.1000) Top1_base: 73.4375 (80.2567) Top1_base_per_class: 72.9885 (80.5357) 
Training Epoch: [170/1000] Step: [150 / 285] Batch Time: 0.1435 (0.1608) Data Time: 0.0120 (0.0280) Average Loss: 0.7223 (0.7122) Average CE Loss (Source):  0.7223 ( 0.7122) Learning Rate: 0.1000 (0.1000) Top1_base: 81.2500 (80.2031) Top1_base_per_class: 84.0606 (80.5691) 
Training Epoch: [170/1000] Step: [160 / 285] Batch Time: 0.2164 (0.1604) Data Time: 0.0839 (0.0276) Average Loss: 0.7897 (0.7151) Average CE Loss (Source):  0.7897 ( 0.7151) Learning Rate: 0.1000 (0.1000) Top1_base: 80.4688 (80.0391) Top1_base_per_class: 82.5545 (80.4029) 
Training Epoch: [170/1000] Step: [170 / 285] Batch Time: 0.1479 (0.1598) Data Time: 0.0110 (0.0270) Average Loss: 0.7752 (0.7157) Average CE Loss (Source):  0.7752 ( 0.7157) Learning Rate: 0.1000 (0.1000) Top1_base: 78.1250 (80.0506) Top1_base_per_class: 81.8827 (80.5052) 
Training Epoch: [170/1000] Step: [180 / 285] Batch Time: 0.1488 (0.1593) Data Time: 0.0172 (0.0264) Average Loss: 1.0062 (0.7182) Average CE Loss (Source):  1.0062 ( 0.7182) Learning Rate: 0.1000 (0.1000) Top1_base: 72.6562 (79.9609) Top1_base_per_class: 72.4359 (80.4863) 
Training Epoch: [170/1000] Step: [190 / 285] Batch Time: 0.1507 (0.1586) Data Time: 0.0144 (0.0257) Average Loss: 0.9057 (0.7177) Average CE Loss (Source):  0.9057 ( 0.7177) Learning Rate: 0.1000 (0.1000) Top1_base: 76.5625 (79.9548) Top1_base_per_class: 75.0303 (80.5035) 
Training Epoch: [170/1000] Step: [200 / 285] Batch Time: 0.1699 (0.1581) Data Time: 0.0371 (0.0253) Average Loss: 0.6931 (0.7216) Average CE Loss (Source):  0.6931 ( 0.7216) Learning Rate: 0.1000 (0.1000) Top1_base: 81.2500 (79.8633) Top1_base_per_class: 83.1704 (80.4655) 
Training Epoch: [170/1000] Step: [210 / 285] Batch Time: 0.1419 (0.1577) Data Time: 0.0109 (0.0249) Average Loss: 0.6332 (0.7214) Average CE Loss (Source):  0.6332 ( 0.7214) Learning Rate: 0.1000 (0.1000) Top1_base: 82.0312 (79.8438) Top1_base_per_class: 83.3333 (80.4367) 
Training Epoch: [170/1000] Step: [220 / 285] Batch Time: 0.1822 (0.1574) Data Time: 0.0504 (0.0246) Average Loss: 0.6252 (0.7217) Average CE Loss (Source):  0.6252 ( 0.7217) Learning Rate: 0.1000 (0.1000) Top1_base: 85.1562 (79.8153) Top1_base_per_class: 86.5094 (80.3894) 
Training Epoch: [170/1000] Step: [230 / 285] Batch Time: 0.1424 (0.1573) Data Time: 0.0116 (0.0246) Average Loss: 0.8581 (0.7190) Average CE Loss (Source):  0.8581 ( 0.7190) Learning Rate: 0.1000 (0.1000) Top1_base: 72.6562 (79.8539) Top1_base_per_class: 73.8793 (80.4080) 
Training Epoch: [170/1000] Step: [240 / 285] Batch Time: 0.1486 (0.1570) Data Time: 0.0150 (0.0242) Average Loss: 0.8109 (0.7190) Average CE Loss (Source):  0.8109 ( 0.7190) Learning Rate: 0.1000 (0.1000) Top1_base: 78.1250 (79.8275) Top1_base_per_class: 79.9405 (80.4183) 
Training Epoch: [170/1000] Step: [250 / 285] Batch Time: 0.1481 (0.1566) Data Time: 0.0120 (0.0237) Average Loss: 0.9267 (0.7199) Average CE Loss (Source):  0.9267 ( 0.7199) Learning Rate: 0.1000 (0.1000) Top1_base: 75.0000 (79.8406) Top1_base_per_class: 77.9091 (80.4648) 
Training Epoch: [170/1000] Step: [260 / 285] Batch Time: 0.1466 (0.1563) Data Time: 0.0128 (0.0233) Average Loss: 0.5600 (0.7168) Average CE Loss (Source):  0.5600 ( 0.7168) Learning Rate: 0.1000 (0.1000) Top1_base: 85.1562 (79.9069) Top1_base_per_class: 83.0401 (80.5366) 
Training Epoch: [170/1000] Step: [270 / 285] Batch Time: 0.1515 (0.1560) Data Time: 0.0146 (0.0230) Average Loss: 0.7094 (0.7176) Average CE Loss (Source):  0.7094 ( 0.7176) Learning Rate: 0.1000 (0.1000) Top1_base: 78.1250 (79.8987) Top1_base_per_class: 75.8333 (80.5413) 
Training Epoch: [170/1000] Step: [280 / 285] Batch Time: 0.1458 (0.1559) Data Time: 0.0123 (0.0229) Average Loss: 0.6846 (0.7178) Average CE Loss (Source):  0.6846 ( 0.7178) Learning Rate: 0.1000 (0.1000) Top1_base: 83.5938 (79.9163) Top1_base_per_class: 83.5152 (80.5775) 
Training Epoch: [171/1000] Step: [0] Batch Time: 0.1469 (0.1558) Data Time: 0.0107 (0.0227) Average Loss: 0.8424 (0.7192) Average CE Loss (Source):  0.8424 ( 0.7192) Learning Rate: 0.1000 (0.1000) Top1_base: 79.6875 (79.8821) Top1_base_per_class: 79.8870 (80.5336) 
Training Epoch: [171/1000] Step: [10 / 285] Batch Time: 0.1449 (0.2516) Data Time: 0.0115 (0.1188) Average Loss: 0.5009 (0.6450) Average CE Loss (Source):  0.5009 ( 0.6450) Learning Rate: 0.1000 (0.1000) Top1_base: 88.2812 (81.7969) Top1_base_per_class: 86.6374 (82.6189) 
Training Epoch: [171/1000] Step: [20 / 285] Batch Time: 0.1488 (0.2007) Data Time: 0.0144 (0.0676) Average Loss: 0.8136 (0.6636) Average CE Loss (Source):  0.8136 ( 0.6636) Learning Rate: 0.1000 (0.1000) Top1_base: 79.6875 (81.2500) Top1_base_per_class: 79.2398 (82.0116) 
Training Epoch: [171/1000] Step: [30 / 285] Batch Time: 0.2203 (0.1884) Data Time: 0.0879 (0.0552) Average Loss: 0.5158 (0.6699) Average CE Loss (Source):  0.5158 ( 0.6699) Learning Rate: 0.1000 (0.1000) Top1_base: 86.7188 (81.6406) Top1_base_per_class: 88.1481 (82.2841) 
Training Epoch: [171/1000] Step: [40 / 285] Batch Time: 0.1425 (0.1812) Data Time: 0.0116 (0.0482) Average Loss: 0.6534 (0.6727) Average CE Loss (Source):  0.6534 ( 0.6727) Learning Rate: 0.1000 (0.1000) Top1_base: 79.6875 (81.4453) Top1_base_per_class: 78.4770 (81.8982) 
Training Epoch: [171/1000] Step: [50 / 285] Batch Time: 0.1829 (0.1768) Data Time: 0.0501 (0.0437) Average Loss: 0.7007 (0.6838) Average CE Loss (Source):  0.7007 ( 0.6838) Learning Rate: 0.1000 (0.1000) Top1_base: 80.4688 (81.0469) Top1_base_per_class: 79.2398 (81.4163) 
Training Epoch: [171/1000] Step: [60 / 285] Batch Time: 0.1428 (0.1723) Data Time: 0.0125 (0.0393) Average Loss: 0.8597 (0.6909) Average CE Loss (Source):  0.8597 ( 0.6909) Learning Rate: 0.1000 (0.1000) Top1_base: 77.3438 (80.8333) Top1_base_per_class: 77.1131 (81.2005) 
Training Epoch: [171/1000] Step: [70 / 285] Batch Time: 0.1482 (0.1694) Data Time: 0.0166 (0.0364) Average Loss: 0.5811 (0.6909) Average CE Loss (Source):  0.5811 ( 0.6909) Learning Rate: 0.1000 (0.1000) Top1_base: 83.5938 (80.7031) Top1_base_per_class: 83.1845 (81.1486) 
Training Epoch: [171/1000] Step: [80 / 285] Batch Time: 0.1482 (0.1683) Data Time: 0.0149 (0.0352) Average Loss: 0.7922 (0.6894) Average CE Loss (Source):  0.7922 ( 0.6894) Learning Rate: 0.1000 (0.1000) Top1_base: 74.2188 (80.6445) Top1_base_per_class: 73.5490 (80.9729) 
Training Epoch: [171/1000] Step: [90 / 285] Batch Time: 0.1719 (0.1677) Data Time: 0.0401 (0.0346) Average Loss: 0.6596 (0.6894) Average CE Loss (Source):  0.6596 ( 0.6894) Learning Rate: 0.1000 (0.1000) Top1_base: 77.3438 (80.5469) Top1_base_per_class: 80.3955 (81.1068) 
Training Epoch: [171/1000] Step: [100 / 285] Batch Time: 0.1479 (0.1664) Data Time: 0.0145 (0.0333) Average Loss: 0.5391 (0.6924) Average CE Loss (Source):  0.5391 ( 0.6924) Learning Rate: 0.1000 (0.1000) Top1_base: 83.5938 (80.3906) Top1_base_per_class: 83.8462 (80.9460) 
Training Epoch: [171/1000] Step: [110 / 285] Batch Time: 0.1953 (0.1657) Data Time: 0.0636 (0.0326) Average Loss: 0.6689 (0.6967) Average CE Loss (Source):  0.6689 ( 0.6967) Learning Rate: 0.1000 (0.1000) Top1_base: 82.0312 (80.2983) Top1_base_per_class: 83.9506 (80.8504) 
Training Epoch: [171/1000] Step: [120 / 285] Batch Time: 0.1471 (0.1653) Data Time: 0.0137 (0.0322) Average Loss: 0.7340 (0.6979) Average CE Loss (Source):  0.7340 ( 0.6979) Learning Rate: 0.1000 (0.1000) Top1_base: 80.4688 (80.2409) Top1_base_per_class: 81.1494 (80.7546) 
Training Epoch: [171/1000] Step: [130 / 285] Batch Time: 0.2058 (0.1658) Data Time: 0.0734 (0.0328) Average Loss: 0.8572 (0.7015) Average CE Loss (Source):  0.8572 ( 0.7015) Learning Rate: 0.1000 (0.1000) Top1_base: 77.3438 (80.1983) Top1_base_per_class: 79.2857 (80.6483) 
Training Epoch: [171/1000] Step: [140 / 285] Batch Time: 0.1489 (0.1648) Data Time: 0.0141 (0.0318) Average Loss: 0.5670 (0.6961) Average CE Loss (Source):  0.5670 ( 0.6961) Learning Rate: 0.1000 (0.1000) Top1_base: 78.9062 (80.3237) Top1_base_per_class: 77.0278 (80.7157) 
Training Epoch: [171/1000] Step: [150 / 285] Batch Time: 0.1483 (0.1640) Data Time: 0.0171 (0.0310) Average Loss: 0.5606 (0.6957) Average CE Loss (Source):  0.5606 ( 0.6957) Learning Rate: 0.1000 (0.1000) Top1_base: 83.5938 (80.3542) Top1_base_per_class: 80.4719 (80.7362) 
Training Epoch: [171/1000] Step: [160 / 285] Batch Time: 0.1492 (0.1636) Data Time: 0.0145 (0.0306) Average Loss: 0.6960 (0.6979) Average CE Loss (Source):  0.6960 ( 0.6979) Learning Rate: 0.1000 (0.1000) Top1_base: 80.4688 (80.3809) Top1_base_per_class: 81.6940 (80.7926) 
Training Epoch: [171/1000] Step: [170 / 285] Batch Time: 0.1689 (0.1627) Data Time: 0.0340 (0.0297) Average Loss: 0.8422 (0.6990) Average CE Loss (Source):  0.8422 ( 0.6990) Learning Rate: 0.1000 (0.1000) Top1_base: 79.6875 (80.3768) Top1_base_per_class: 84.1808 (80.7726) 
Training Epoch: [171/1000] Step: [180 / 285] Batch Time: 0.1410 (0.1623) Data Time: 0.0116 (0.0293) Average Loss: 0.7246 (0.6979) Average CE Loss (Source):  0.7246 ( 0.6979) Learning Rate: 0.1000 (0.1000) Top1_base: 82.0312 (80.3733) Top1_base_per_class: 81.2500 (80.8112) 
Training Epoch: [171/1000] Step: [190 / 285] Batch Time: 0.1649 (0.1616) Data Time: 0.0306 (0.0286) Average Loss: 0.6645 (0.6989) Average CE Loss (Source):  0.6645 ( 0.6989) Learning Rate: 0.1000 (0.1000) Top1_base: 82.0312 (80.2878) Top1_base_per_class: 78.8218 (80.7143) 
Training Epoch: [171/1000] Step: [200 / 285] Batch Time: 0.1520 (0.1611) Data Time: 0.0135 (0.0278) Average Loss: 0.6117 (0.7007) Average CE Loss (Source):  0.6117 ( 0.7007) Learning Rate: 0.1000 (0.1000) Top1_base: 80.4688 (80.1992) Top1_base_per_class: 81.2727 (80.6229) 
Training Epoch: [171/1000] Step: [210 / 285] Batch Time: 0.2571 (0.1614) Data Time: 0.1272 (0.0282) Average Loss: 0.6647 (0.7026) Average CE Loss (Source):  0.6647 ( 0.7026) Learning Rate: 0.1000 (0.1000) Top1_base: 77.3438 (80.1079) Top1_base_per_class: 76.1310 (80.4970) 
Training Epoch: [171/1000] Step: [220 / 285] Batch Time: 0.1451 (0.1607) Data Time: 0.0122 (0.0275) Average Loss: 0.6585 (0.7054) Average CE Loss (Source):  0.6585 ( 0.7054) Learning Rate: 0.1000 (0.1000) Top1_base: 77.3438 (80.0639) Top1_base_per_class: 80.5556 (80.4945) 
Training Epoch: [171/1000] Step: [230 / 285] Batch Time: 0.2030 (0.1604) Data Time: 0.0712 (0.0273) Average Loss: 0.6866 (0.7056) Average CE Loss (Source):  0.6866 ( 0.7056) Learning Rate: 0.1000 (0.1000) Top1_base: 78.9062 (80.0476) Top1_base_per_class: 79.1813 (80.5127) 
Training Epoch: [171/1000] Step: [240 / 285] Batch Time: 0.1465 (0.1603) Data Time: 0.0143 (0.0272) Average Loss: 0.8602 (0.7078) Average CE Loss (Source):  0.8602 ( 0.7078) Learning Rate: 0.1000 (0.1000) Top1_base: 75.7812 (79.9805) Top1_base_per_class: 75.8631 (80.5087) 
Training Epoch: [171/1000] Step: [250 / 285] Batch Time: 0.2483 (0.1608) Data Time: 0.1174 (0.0277) Average Loss: 0.7190 (0.7085) Average CE Loss (Source):  0.7190 ( 0.7085) Learning Rate: 0.1000 (0.1000) Top1_base: 75.7812 (79.9688) Top1_base_per_class: 80.3939 (80.5564) 
Training Epoch: [171/1000] Step: [260 / 285] Batch Time: 0.1498 (0.1605) Data Time: 0.0148 (0.0274) Average Loss: 0.7843 (0.7089) Average CE Loss (Source):  0.7843 ( 0.7089) Learning Rate: 0.1000 (0.1000) Top1_base: 82.0312 (80.0150) Top1_base_per_class: 82.6017 (80.6130) 
Training Epoch: [171/1000] Step: [270 / 285] Batch Time: 0.1503 (0.1602) Data Time: 0.0173 (0.0271) Average Loss: 0.7144 (0.7119) Average CE Loss (Source):  0.7144 ( 0.7119) Learning Rate: 0.1000 (0.1000) Top1_base: 77.3438 (79.9306) Top1_base_per_class: 76.7529 (80.5565) 
Training Epoch: [171/1000] Step: [280 / 285] Batch Time: 0.1465 (0.1599) Data Time: 0.0130 (0.0268) Average Loss: 0.6884 (0.7154) Average CE Loss (Source):  0.6884 ( 0.7154) Learning Rate: 0.1000 (0.1000) Top1_base: 76.5625 (79.8103) Top1_base_per_class: 79.7661 (80.4415) 
Training Epoch: [172/1000] Step: [0] Batch Time: 0.1412 (0.1597) Data Time: 0.0110 (0.0267) Average Loss: 0.6314 (0.7158) Average CE Loss (Source):  0.6314 ( 0.7158) Learning Rate: 0.1000 (0.1000) Top1_base: 82.8125 (79.8026) Top1_base_per_class: 82.0606 (80.4380) 
 17%|█▋        | 172/1000 [2:13:43<10:45:33, 46.78s/it] 17%|█▋        | 173/1000 [2:14:28<10:38:24, 46.32s/it]Training Epoch: [172/1000] Step: [10 / 285] Batch Time: 0.1437 (0.2285) Data Time: 0.0100 (0.0953) Average Loss: 0.6974 (0.6696) Average CE Loss (Source):  0.6974 ( 0.6696) Learning Rate: 0.1000 (0.1000) Top1_base: 82.0312 (81.7969) Top1_base_per_class: 83.6012 (82.2492) 
Training Epoch: [172/1000] Step: [20 / 285] Batch Time: 0.1483 (0.1918) Data Time: 0.0145 (0.0589) Average Loss: 0.6635 (0.7019) Average CE Loss (Source):  0.6635 ( 0.7019) Learning Rate: 0.1000 (0.1000) Top1_base: 81.2500 (80.7422) Top1_base_per_class: 80.5556 (81.3656) 
Training Epoch: [172/1000] Step: [30 / 285] Batch Time: 0.1449 (0.1794) Data Time: 0.0114 (0.0464) Average Loss: 0.5039 (0.6875) Average CE Loss (Source):  0.5039 ( 0.6875) Learning Rate: 0.1000 (0.1000) Top1_base: 85.1562 (80.8073) Top1_base_per_class: 84.4737 (81.6100) 
Training Epoch: [172/1000] Step: [40 / 285] Batch Time: 0.1454 (0.1751) Data Time: 0.0139 (0.0421) Average Loss: 0.8001 (0.6966) Average CE Loss (Source):  0.8001 ( 0.6966) Learning Rate: 0.1000 (0.1000) Top1_base: 79.6875 (80.4492) Top1_base_per_class: 77.3851 (81.2743) 
Training Epoch: [172/1000] Step: [50 / 285] Batch Time: 0.1452 (0.1700) Data Time: 0.0106 (0.0369) Average Loss: 0.6791 (0.7090) Average CE Loss (Source):  0.6791 ( 0.7090) Learning Rate: 0.1000 (0.1000) Top1_base: 82.8125 (80.1406) Top1_base_per_class: 83.2121 (80.8437) 
Training Epoch: [172/1000] Step: [60 / 285] Batch Time: 0.1467 (0.1667) Data Time: 0.0155 (0.0335) Average Loss: 1.1693 (0.7200) Average CE Loss (Source):  1.1693 ( 0.7200) Learning Rate: 0.1000 (0.1000) Top1_base: 71.0938 (80.1562) Top1_base_per_class: 73.5969 (80.8579) 
Training Epoch: [172/1000] Step: [70 / 285] Batch Time: 0.1454 (0.1650) Data Time: 0.0120 (0.0319) Average Loss: 0.7152 (0.7134) Average CE Loss (Source):  0.7152 ( 0.7134) Learning Rate: 0.1000 (0.1000) Top1_base: 81.2500 (80.2679) Top1_base_per_class: 82.4561 (80.8694) 
Training Epoch: [172/1000] Step: [80 / 285] Batch Time: 0.1465 (0.1654) Data Time: 0.0129 (0.0323) Average Loss: 0.9137 (0.7193) Average CE Loss (Source):  0.9137 ( 0.7193) Learning Rate: 0.1000 (0.1000) Top1_base: 73.4375 (80.1660) Top1_base_per_class: 73.7963 (80.7035) 
Training Epoch: [172/1000] Step: [90 / 285] Batch Time: 0.1430 (0.1638) Data Time: 0.0115 (0.0305) Average Loss: 0.6787 (0.7227) Average CE Loss (Source):  0.6787 ( 0.7227) Learning Rate: 0.1000 (0.1000) Top1_base: 78.1250 (80.0434) Top1_base_per_class: 75.0943 (80.4068) 
Training Epoch: [172/1000] Step: [100 / 285] Batch Time: 0.1488 (0.1621) Data Time: 0.0147 (0.0288) Average Loss: 0.6529 (0.7149) Average CE Loss (Source):  0.6529 ( 0.7149) Learning Rate: 0.1000 (0.1000) Top1_base: 79.6875 (80.2891) Top1_base_per_class: 81.3690 (80.7476) 
Training Epoch: [172/1000] Step: [110 / 285] Batch Time: 0.1493 (0.1614) Data Time: 0.0122 (0.0281) Average Loss: 0.7222 (0.7168) Average CE Loss (Source):  0.7222 ( 0.7168) Learning Rate: 0.1000 (0.1000) Top1_base: 80.4688 (80.2273) Top1_base_per_class: 84.2262 (80.8058) 
Training Epoch: [172/1000] Step: [120 / 285] Batch Time: 0.1521 (0.1605) Data Time: 0.0153 (0.0269) Average Loss: 0.4804 (0.7123) Average CE Loss (Source):  0.4804 ( 0.7123) Learning Rate: 0.1000 (0.1000) Top1_base: 85.1562 (80.2279) Top1_base_per_class: 85.6250 (80.7210) 
Training Epoch: [172/1000] Step: [130 / 285] Batch Time: 0.1463 (0.1596) Data Time: 0.0103 (0.0259) Average Loss: 0.9226 (0.7136) Average CE Loss (Source):  0.9226 ( 0.7136) Learning Rate: 0.1000 (0.1000) Top1_base: 78.9062 (80.2043) Top1_base_per_class: 80.4167 (80.6746) 
Training Epoch: [172/1000] Step: [140 / 285] Batch Time: 0.1500 (0.1588) Data Time: 0.0149 (0.0250) Average Loss: 0.5458 (0.7128) Average CE Loss (Source):  0.5458 ( 0.7128) Learning Rate: 0.1000 (0.1000) Top1_base: 80.4688 (80.1339) Top1_base_per_class: 82.0238 (80.6111) 
Training Epoch: [172/1000] Step: [150 / 285] Batch Time: 0.1484 (0.1581) Data Time: 0.0141 (0.0243) Average Loss: 0.7647 (0.7146) Average CE Loss (Source):  0.7647 ( 0.7146) Learning Rate: 0.1000 (0.1000) Top1_base: 79.6875 (80.0260) Top1_base_per_class: 76.4465 (80.5009) 
Training Epoch: [172/1000] Step: [160 / 285] Batch Time: 0.1446 (0.1579) Data Time: 0.0124 (0.0241) Average Loss: 0.7017 (0.7154) Average CE Loss (Source):  0.7017 ( 0.7154) Learning Rate: 0.1000 (0.1000) Top1_base: 82.8125 (80.0098) Top1_base_per_class: 84.1964 (80.5474) 
Training Epoch: [172/1000] Step: [170 / 285] Batch Time: 0.1461 (0.1581) Data Time: 0.0118 (0.0244) Average Loss: 0.6344 (0.7130) Average CE Loss (Source):  0.6344 ( 0.7130) Learning Rate: 0.1000 (0.1000) Top1_base: 83.5938 (80.1241) Top1_base_per_class: 86.0417 (80.6636) 
Training Epoch: [172/1000] Step: [180 / 285] Batch Time: 0.2049 (0.1578) Data Time: 0.0717 (0.0242) Average Loss: 0.8450 (0.7155) Average CE Loss (Source):  0.8450 ( 0.7155) Learning Rate: 0.1000 (0.1000) Top1_base: 76.5625 (80.0174) Top1_base_per_class: 78.0710 (80.5976) 
Training Epoch: [172/1000] Step: [190 / 285] Batch Time: 0.1447 (0.1588) Data Time: 0.0146 (0.0251) Average Loss: 0.7068 (0.7167) Average CE Loss (Source):  0.7068 ( 0.7167) Learning Rate: 0.1000 (0.1000) Top1_base: 82.0312 (79.9836) Top1_base_per_class: 77.9762 (80.5225) 
Training Epoch: [172/1000] Step: [200 / 285] Batch Time: 0.2250 (0.1592) Data Time: 0.0938 (0.0256) Average Loss: 0.7557 (0.7157) Average CE Loss (Source):  0.7557 ( 0.7157) Learning Rate: 0.1000 (0.1000) Top1_base: 76.5625 (80.0000) Top1_base_per_class: 79.5758 (80.5326) 
Training Epoch: [172/1000] Step: [210 / 285] Batch Time: 0.1458 (0.1592) Data Time: 0.0118 (0.0257) Average Loss: 0.5838 (0.7156) Average CE Loss (Source):  0.5838 ( 0.7156) Learning Rate: 0.1000 (0.1000) Top1_base: 84.3750 (79.9963) Top1_base_per_class: 84.8427 (80.5255) 
Training Epoch: [172/1000] Step: [220 / 285] Batch Time: 0.2067 (0.1594) Data Time: 0.0752 (0.0259) Average Loss: 0.7482 (0.7159) Average CE Loss (Source):  0.7482 ( 0.7159) Learning Rate: 0.1000 (0.1000) Top1_base: 79.6875 (79.9929) Top1_base_per_class: 79.3333 (80.5209) 
Training Epoch: [172/1000] Step: [230 / 285] Batch Time: 0.1448 (0.1591) Data Time: 0.0106 (0.0256) Average Loss: 0.8504 (0.7198) Average CE Loss (Source):  0.8504 ( 0.7198) Learning Rate: 0.1000 (0.1000) Top1_base: 78.1250 (79.9287) Top1_base_per_class: 76.5432 (80.4794) 
Training Epoch: [172/1000] Step: [240 / 285] Batch Time: 0.1657 (0.1589) Data Time: 0.0305 (0.0255) Average Loss: 0.6585 (0.7207) Average CE Loss (Source):  0.6585 ( 0.7207) Learning Rate: 0.1000 (0.1000) Top1_base: 85.9375 (79.9447) Top1_base_per_class: 86.2727 (80.4917) 
Training Epoch: [172/1000] Step: [250 / 285] Batch Time: 0.1444 (0.1587) Data Time: 0.0103 (0.0253) Average Loss: 0.5814 (0.7196) Average CE Loss (Source):  0.5814 ( 0.7196) Learning Rate: 0.1000 (0.1000) Top1_base: 83.5938 (79.9281) Top1_base_per_class: 85.4237 (80.4583) 
Training Epoch: [172/1000] Step: [260 / 285] Batch Time: 0.1652 (0.1584) Data Time: 0.0281 (0.0250) Average Loss: 0.8453 (0.7206) Average CE Loss (Source):  0.8453 ( 0.7206) Learning Rate: 0.1000 (0.1000) Top1_base: 75.0000 (79.8648) Top1_base_per_class: 74.5029 (80.4071) 
Training Epoch: [172/1000] Step: [270 / 285] Batch Time: 0.1417 (0.1584) Data Time: 0.0113 (0.0251) Average Loss: 0.7473 (0.7203) Average CE Loss (Source):  0.7473 ( 0.7203) Learning Rate: 0.1000 (0.1000) Top1_base: 78.9062 (79.8582) Top1_base_per_class: 74.6914 (80.4096) 
Training Epoch: [172/1000] Step: [280 / 285] Batch Time: 0.1909 (0.1586) Data Time: 0.0582 (0.0253) Average Loss: 0.6822 (0.7192) Average CE Loss (Source):  0.6822 ( 0.7192) Learning Rate: 0.1000 (0.1000) Top1_base: 83.5938 (79.8856) Top1_base_per_class: 86.7602 (80.4603) 
Training Epoch: [173/1000] Step: [0] Batch Time: 0.1422 (0.1585) Data Time: 0.0117 (0.0253) Average Loss: 0.7263 (0.7190) Average CE Loss (Source):  0.7263 ( 0.7190) Learning Rate: 0.1000 (0.1000) Top1_base: 78.1250 (79.8766) Top1_base_per_class: 77.8448 (80.4243) 
Training Epoch: [173/1000] Step: [10 / 285] Batch Time: 0.1405 (0.2243) Data Time: 0.0115 (0.0923) Average Loss: 0.6472 (0.6549) Average CE Loss (Source):  0.6472 ( 0.6549) Learning Rate: 0.1000 (0.1000) Top1_base: 82.0312 (82.1094) Top1_base_per_class: 82.5298 (81.5369) 
Training Epoch: [173/1000] Step: [20 / 285] Batch Time: 0.1451 (0.1912) Data Time: 0.0124 (0.0588) Average Loss: 0.8849 (0.6776) Average CE Loss (Source):  0.8849 ( 0.6776) Learning Rate: 0.1000 (0.1000) Top1_base: 74.2188 (80.7812) Top1_base_per_class: 74.9617 (80.7997) 
Training Epoch: [173/1000] Step: [30 / 285] Batch Time: 0.1478 (0.1815) Data Time: 0.0147 (0.0489) Average Loss: 0.6721 (0.6989) Average CE Loss (Source):  0.6721 ( 0.6989) Learning Rate: 0.1000 (0.1000) Top1_base: 79.6875 (79.7135) Top1_base_per_class: 75.2830 (79.6025) 
Training Epoch: [173/1000] Step: [40 / 285] Batch Time: 0.1463 (0.1741) Data Time: 0.0132 (0.0414) Average Loss: 0.8537 (0.6952) Average CE Loss (Source):  0.8537 ( 0.6952) Learning Rate: 0.1000 (0.1000) Top1_base: 78.1250 (80.0391) Top1_base_per_class: 79.9394 (79.9694) 
Training Epoch: [173/1000] Step: [50 / 285] Batch Time: 0.1504 (0.1702) Data Time: 0.0161 (0.0371) Average Loss: 0.7323 (0.6897) Average CE Loss (Source):  0.7323 ( 0.6897) Learning Rate: 0.1000 (0.1000) Top1_base: 77.3438 (80.3594) Top1_base_per_class: 78.2164 (80.3324) 
Training Epoch: [173/1000] Step: [60 / 285] Batch Time: 0.1450 (0.1664) Data Time: 0.0137 (0.0332) Average Loss: 0.8938 (0.6896) Average CE Loss (Source):  0.8938 ( 0.6896) Learning Rate: 0.1000 (0.1000) Top1_base: 72.6562 (80.4557) Top1_base_per_class: 72.3099 (80.5517) 
Training Epoch: [173/1000] Step: [70 / 285] Batch Time: 0.1487 (0.1639) Data Time: 0.0164 (0.0306) Average Loss: 0.7665 (0.6965) Average CE Loss (Source):  0.7665 ( 0.6965) Learning Rate: 0.1000 (0.1000) Top1_base: 78.1250 (80.3795) Top1_base_per_class: 77.4546 (80.4390) 
Training Epoch: [173/1000] Step: [80 / 285] Batch Time: 0.1495 (0.1625) Data Time: 0.0172 (0.0290) Average Loss: 0.6365 (0.6994) Average CE Loss (Source):  0.6365 ( 0.6994) Learning Rate: 0.1000 (0.1000) Top1_base: 81.2500 (80.1953) Top1_base_per_class: 84.2560 (80.3580) 
Training Epoch: [173/1000] Step: [90 / 285] Batch Time: 0.2157 (0.1623) Data Time: 0.0825 (0.0287) Average Loss: 0.6667 (0.7040) Average CE Loss (Source):  0.6667 ( 0.7040) Learning Rate: 0.1000 (0.1000) Top1_base: 79.6875 (80.0608) Top1_base_per_class: 81.5254 (80.2517) 
Training Epoch: [173/1000] Step: [100 / 285] Batch Time: 0.1480 (0.1613) Data Time: 0.0156 (0.0277) Average Loss: 0.8619 (0.7074) Average CE Loss (Source):  0.8619 ( 0.7074) Learning Rate: 0.1000 (0.1000) Top1_base: 76.5625 (80.0156) Top1_base_per_class: 78.7798 (80.3521) 
Training Epoch: [173/1000] Step: [110 / 285] Batch Time: 0.1961 (0.1615) Data Time: 0.0625 (0.0279) Average Loss: 0.8870 (0.7157) Average CE Loss (Source):  0.8870 ( 0.7157) Learning Rate: 0.1000 (0.1000) Top1_base: 72.6562 (79.6804) Top1_base_per_class: 73.7202 (80.1235) 
Training Epoch: [173/1000] Step: [120 / 285] Batch Time: 0.1478 (0.1611) Data Time: 0.0121 (0.0275) Average Loss: 0.5948 (0.7141) Average CE Loss (Source):  0.5948 ( 0.7141) Learning Rate: 0.1000 (0.1000) Top1_base: 85.1562 (79.8372) Top1_base_per_class: 82.3446 (80.2742) 
Training Epoch: [173/1000] Step: [130 / 285] Batch Time: 0.1538 (0.1603) Data Time: 0.0227 (0.0267) Average Loss: 0.5820 (0.7132) Average CE Loss (Source):  0.5820 ( 0.7132) Learning Rate: 0.1000 (0.1000) Top1_base: 85.1562 (79.8618) Top1_base_per_class: 81.3690 (80.2347) 
Training Epoch: [173/1000] Step: [140 / 285] Batch Time: 0.1472 (0.1593) Data Time: 0.0123 (0.0258) Average Loss: 0.4857 (0.7176) Average CE Loss (Source):  0.4857 ( 0.7176) Learning Rate: 0.1000 (0.1000) Top1_base: 85.1562 (79.7321) Top1_base_per_class: 84.3939 (80.0786) 
Training Epoch: [173/1000] Step: [150 / 285] Batch Time: 0.1858 (0.1593) Data Time: 0.0527 (0.0258) Average Loss: 0.5571 (0.7144) Average CE Loss (Source):  0.5571 ( 0.7144) Learning Rate: 0.1000 (0.1000) Top1_base: 82.0312 (79.8073) Top1_base_per_class: 81.6975 (80.1479) 
Training Epoch: [173/1000] Step: [160 / 285] Batch Time: 0.1536 (0.1589) Data Time: 0.0196 (0.0253) Average Loss: 0.5544 (0.7129) Average CE Loss (Source):  0.5544 ( 0.7129) Learning Rate: 0.1000 (0.1000) Top1_base: 82.8125 (79.8193) Top1_base_per_class: 81.9940 (80.1313) 
Training Epoch: [173/1000] Step: [170 / 285] Batch Time: 0.1494 (0.1585) Data Time: 0.0164 (0.0249) Average Loss: 0.7754 (0.7163) Average CE Loss (Source):  0.7754 ( 0.7163) Learning Rate: 0.1000 (0.1000) Top1_base: 79.6875 (79.7243) Top1_base_per_class: 81.4815 (80.0771) 
Training Epoch: [173/1000] Step: [180 / 285] Batch Time: 0.1484 (0.1581) Data Time: 0.0174 (0.0246) Average Loss: 0.6701 (0.7179) Average CE Loss (Source):  0.6701 ( 0.7179) Learning Rate: 0.1000 (0.1000) Top1_base: 82.8125 (79.6918) Top1_base_per_class: 85.5930 (80.1311) 
Training Epoch: [173/1000] Step: [190 / 285] Batch Time: 0.1893 (0.1582) Data Time: 0.0563 (0.0246) Average Loss: 0.8242 (0.7204) Average CE Loss (Source):  0.8242 ( 0.7204) Learning Rate: 0.1000 (0.1000) Top1_base: 71.8750 (79.6340) Top1_base_per_class: 71.5833 (80.0737) 
Training Epoch: [173/1000] Step: [200 / 285] Batch Time: 0.1440 (0.1579) Data Time: 0.0130 (0.0244) Average Loss: 0.6255 (0.7174) Average CE Loss (Source):  0.6255 ( 0.7174) Learning Rate: 0.1000 (0.1000) Top1_base: 82.0312 (79.6797) Top1_base_per_class: 82.0192 (80.1215) 
Training Epoch: [173/1000] Step: [210 / 285] Batch Time: 0.1945 (0.1579) Data Time: 0.0636 (0.0244) Average Loss: 0.7273 (0.7188) Average CE Loss (Source):  0.7273 ( 0.7188) Learning Rate: 0.1000 (0.1000) Top1_base: 80.4688 (79.6987) Top1_base_per_class: 79.1975 (80.1368) 
Training Epoch: [173/1000] Step: [220 / 285] Batch Time: 0.1452 (0.1577) Data Time: 0.0107 (0.0242) Average Loss: 0.6483 (0.7197) Average CE Loss (Source):  0.6483 ( 0.7197) Learning Rate: 0.1000 (0.1000) Top1_base: 78.9062 (79.6946) Top1_base_per_class: 77.4546 (80.1390) 
Training Epoch: [173/1000] Step: [230 / 285] Batch Time: 0.2073 (0.1578) Data Time: 0.0745 (0.0245) Average Loss: 0.6936 (0.7220) Average CE Loss (Source):  0.6936 ( 0.7220) Learning Rate: 0.1000 (0.1000) Top1_base: 77.3438 (79.5924) Top1_base_per_class: 77.9167 (80.0739) 
Training Epoch: [173/1000] Step: [240 / 285] Batch Time: 0.1498 (0.1577) Data Time: 0.0147 (0.0244) Average Loss: 0.6165 (0.7209) Average CE Loss (Source):  0.6165 ( 0.7209) Learning Rate: 0.1000 (0.1000) Top1_base: 82.8125 (79.6615) Top1_base_per_class: 86.0000 (80.1558) 
Training Epoch: [173/1000] Step: [250 / 285] Batch Time: 0.1844 (0.1577) Data Time: 0.0489 (0.0244) Average Loss: 0.8446 (0.7245) Average CE Loss (Source):  0.8446 ( 0.7245) Learning Rate: 0.1000 (0.1000) Top1_base: 75.0000 (79.5781) Top1_base_per_class: 78.4503 (80.0824) 
Training Epoch: [173/1000] Step: [260 / 285] Batch Time: 0.1436 (0.1574) Data Time: 0.0125 (0.0241) Average Loss: 0.7663 (0.7249) Average CE Loss (Source):  0.7663 ( 0.7249) Learning Rate: 0.1000 (0.1000) Top1_base: 77.3438 (79.5433) Top1_base_per_class: 75.9748 (80.0494) 
Training Epoch: [173/1000] Step: [270 / 285] Batch Time: 0.1704 (0.1581) Data Time: 0.0380 (0.0248) Average Loss: 0.8832 (0.7269) Average CE Loss (Source):  0.8832 ( 0.7269) Learning Rate: 0.1000 (0.1000) Top1_base: 73.4375 (79.4531) Top1_base_per_class: 67.2121 (79.9273) 
Training Epoch: [173/1000] Step: [280 / 285] Batch Time: 0.1438 (0.1580) Data Time: 0.0121 (0.0247) Average Loss: 0.7588 (0.7298) Average CE Loss (Source):  0.7588 ( 0.7298) Learning Rate: 0.1000 (0.1000) Top1_base: 75.7812 (79.3917) Top1_base_per_class: 78.0173 (79.8722) 
Training Epoch: [174/1000] Step: [0] Batch Time: 0.1442 (0.1578) Data Time: 0.0114 (0.0246) Average Loss: 0.7182 (0.7308) Average CE Loss (Source):  0.7182 ( 0.7308) Learning Rate: 0.1000 (0.1000) Top1_base: 80.4688 (79.3695) Top1_base_per_class: 81.6667 (79.8617) 
 17%|█▋        | 174/1000 [2:15:16<10:43:37, 46.75s/it] 18%|█▊        | 175/1000 [2:16:01<10:34:22, 46.14s/it]Training Epoch: [174/1000] Step: [10 / 285] Batch Time: 0.1447 (0.2318) Data Time: 0.0145 (0.0993) Average Loss: 0.7998 (0.7201) Average CE Loss (Source):  0.7998 ( 0.7201) Learning Rate: 0.1000 (0.1000) Top1_base: 78.1250 (80.0781) Top1_base_per_class: 77.5298 (80.7583) 
Training Epoch: [174/1000] Step: [20 / 285] Batch Time: 0.1455 (0.1917) Data Time: 0.0110 (0.0588) Average Loss: 0.5867 (0.6991) Average CE Loss (Source):  0.5867 ( 0.6991) Learning Rate: 0.1000 (0.1000) Top1_base: 78.9062 (80.0000) Top1_base_per_class: 76.1818 (80.5025) 
Training Epoch: [174/1000] Step: [30 / 285] Batch Time: 0.1449 (0.1815) Data Time: 0.0124 (0.0485) Average Loss: 0.6210 (0.6906) Average CE Loss (Source):  0.6210 ( 0.6906) Learning Rate: 0.1000 (0.1000) Top1_base: 77.3438 (80.0781) Top1_base_per_class: 76.6061 (80.4525) 
Training Epoch: [174/1000] Step: [40 / 285] Batch Time: 0.1463 (0.1736) Data Time: 0.0108 (0.0404) Average Loss: 0.7684 (0.6896) Average CE Loss (Source):  0.7684 ( 0.6896) Learning Rate: 0.1000 (0.1000) Top1_base: 78.1250 (80.2930) Top1_base_per_class: 76.6667 (80.7122) 
Training Epoch: [174/1000] Step: [50 / 285] Batch Time: 0.1461 (0.1722) Data Time: 0.0142 (0.0390) Average Loss: 0.6081 (0.6799) Average CE Loss (Source):  0.6081 ( 0.6799) Learning Rate: 0.1000 (0.1000) Top1_base: 78.9062 (80.5156) Top1_base_per_class: 78.6207 (80.9240) 
Training Epoch: [174/1000] Step: [60 / 285] Batch Time: 0.1473 (0.1705) Data Time: 0.0127 (0.0372) Average Loss: 0.9327 (0.6895) Average CE Loss (Source):  0.9327 ( 0.6895) Learning Rate: 0.1000 (0.1000) Top1_base: 77.3438 (80.4948) Top1_base_per_class: 74.9091 (80.8767) 
Training Epoch: [174/1000] Step: [70 / 285] Batch Time: 0.1726 (0.1680) Data Time: 0.0357 (0.0346) Average Loss: 0.5820 (0.6896) Average CE Loss (Source):  0.5820 ( 0.6896) Learning Rate: 0.1000 (0.1000) Top1_base: 84.3750 (80.6696) Top1_base_per_class: 86.1494 (80.8372) 
Training Epoch: [174/1000] Step: [80 / 285] Batch Time: 0.1490 (0.1676) Data Time: 0.0114 (0.0339) Average Loss: 0.5645 (0.6888) Average CE Loss (Source):  0.5645 ( 0.6888) Learning Rate: 0.1000 (0.1000) Top1_base: 85.9375 (80.8105) Top1_base_per_class: 83.4226 (80.9868) 
Training Epoch: [174/1000] Step: [90 / 285] Batch Time: 0.1513 (0.1666) Data Time: 0.0167 (0.0326) Average Loss: 0.6794 (0.6918) Average CE Loss (Source):  0.6794 ( 0.6918) Learning Rate: 0.1000 (0.1000) Top1_base: 80.4688 (80.6944) Top1_base_per_class: 80.0303 (80.8792) 
Training Epoch: [174/1000] Step: [100 / 285] Batch Time: 0.1486 (0.1675) Data Time: 0.0108 (0.0334) Average Loss: 0.6637 (0.6941) Average CE Loss (Source):  0.6637 ( 0.6941) Learning Rate: 0.1000 (0.1000) Top1_base: 82.0312 (80.6094) Top1_base_per_class: 84.9123 (80.7243) 
Training Epoch: [174/1000] Step: [110 / 285] Batch Time: 0.1765 (0.1667) Data Time: 0.0441 (0.0325) Average Loss: 0.8921 (0.6999) Average CE Loss (Source):  0.8921 ( 0.6999) Learning Rate: 0.1000 (0.1000) Top1_base: 73.4375 (80.4119) Top1_base_per_class: 76.8269 (80.5513) 
Training Epoch: [174/1000] Step: [120 / 285] Batch Time: 0.1480 (0.1656) Data Time: 0.0106 (0.0313) Average Loss: 0.7171 (0.6996) Average CE Loss (Source):  0.7171 ( 0.6996) Learning Rate: 0.1000 (0.1000) Top1_base: 82.8125 (80.5078) Top1_base_per_class: 85.5172 (80.6785) 
Training Epoch: [174/1000] Step: [130 / 285] Batch Time: 0.1768 (0.1650) Data Time: 0.0437 (0.0306) Average Loss: 0.8493 (0.7026) Average CE Loss (Source):  0.8493 ( 0.7026) Learning Rate: 0.1000 (0.1000) Top1_base: 77.3438 (80.4567) Top1_base_per_class: 77.7879 (80.5940) 
Training Epoch: [174/1000] Step: [140 / 285] Batch Time: 0.1454 (0.1637) Data Time: 0.0112 (0.0293) Average Loss: 0.6139 (0.6995) Average CE Loss (Source):  0.6139 ( 0.6995) Learning Rate: 0.1000 (0.1000) Top1_base: 80.4688 (80.5357) Top1_base_per_class: 80.5449 (80.7039) 
Training Epoch: [174/1000] Step: [150 / 285] Batch Time: 0.1515 (0.1635) Data Time: 0.0177 (0.0293) Average Loss: 0.6943 (0.6997) Average CE Loss (Source):  0.6943 ( 0.6997) Learning Rate: 0.1000 (0.1000) Top1_base: 82.0312 (80.5365) Top1_base_per_class: 77.3856 (80.7636) 
Training Epoch: [174/1000] Step: [160 / 285] Batch Time: 0.1468 (0.1625) Data Time: 0.0110 (0.0283) Average Loss: 0.7665 (0.7004) Average CE Loss (Source):  0.7665 ( 0.7004) Learning Rate: 0.1000 (0.1000) Top1_base: 79.6875 (80.5127) Top1_base_per_class: 79.4828 (80.7399) 
Training Epoch: [174/1000] Step: [170 / 285] Batch Time: 0.1515 (0.1618) Data Time: 0.0188 (0.0276) Average Loss: 0.8380 (0.7072) Average CE Loss (Source):  0.8380 ( 0.7072) Learning Rate: 0.1000 (0.1000) Top1_base: 76.5625 (80.3355) Top1_base_per_class: 77.9310 (80.5708) 
Training Epoch: [174/1000] Step: [180 / 285] Batch Time: 0.1452 (0.1611) Data Time: 0.0106 (0.0270) Average Loss: 0.8342 (0.7074) Average CE Loss (Source):  0.8342 ( 0.7074) Learning Rate: 0.1000 (0.1000) Top1_base: 78.1250 (80.3689) Top1_base_per_class: 73.7273 (80.5917) 
Training Epoch: [174/1000] Step: [190 / 285] Batch Time: 0.1496 (0.1605) Data Time: 0.0178 (0.0265) Average Loss: 0.7587 (0.7103) Average CE Loss (Source):  0.7587 ( 0.7103) Learning Rate: 0.1000 (0.1000) Top1_base: 78.9062 (80.2179) Top1_base_per_class: 78.6607 (80.4477) 
Training Epoch: [174/1000] Step: [200 / 285] Batch Time: 0.1438 (0.1603) Data Time: 0.0106 (0.0263) Average Loss: 0.5184 (0.7099) Average CE Loss (Source):  0.5184 ( 0.7099) Learning Rate: 0.1000 (0.1000) Top1_base: 85.1562 (80.2344) Top1_base_per_class: 86.9872 (80.4941) 
Training Epoch: [174/1000] Step: [210 / 285] Batch Time: 0.1483 (0.1600) Data Time: 0.0174 (0.0260) Average Loss: 0.7447 (0.7145) Average CE Loss (Source):  0.7447 ( 0.7145) Learning Rate: 0.1000 (0.1000) Top1_base: 81.2500 (80.1376) Top1_base_per_class: 81.2302 (80.4267) 
Training Epoch: [174/1000] Step: [220 / 285] Batch Time: 0.1446 (0.1595) Data Time: 0.0111 (0.0257) Average Loss: 0.7758 (0.7167) Average CE Loss (Source):  0.7758 ( 0.7167) Learning Rate: 0.1000 (0.1000) Top1_base: 81.2500 (80.0533) Top1_base_per_class: 82.5893 (80.3564) 
Training Epoch: [174/1000] Step: [230 / 285] Batch Time: 0.1459 (0.1590) Data Time: 0.0160 (0.0252) Average Loss: 0.9300 (0.7191) Average CE Loss (Source):  0.9300 ( 0.7191) Learning Rate: 0.1000 (0.1000) Top1_base: 72.6562 (79.9592) Top1_base_per_class: 74.2810 (80.3251) 
Training Epoch: [174/1000] Step: [240 / 285] Batch Time: 0.1445 (0.1585) Data Time: 0.0112 (0.0247) Average Loss: 0.5863 (0.7182) Average CE Loss (Source):  0.5863 ( 0.7182) Learning Rate: 0.1000 (0.1000) Top1_base: 83.5938 (79.9740) Top1_base_per_class: 85.7310 (80.3516) 
Training Epoch: [174/1000] Step: [250 / 285] Batch Time: 0.1460 (0.1580) Data Time: 0.0158 (0.0242) Average Loss: 0.5935 (0.7179) Average CE Loss (Source):  0.5935 ( 0.7179) Learning Rate: 0.1000 (0.1000) Top1_base: 85.1562 (80.0062) Top1_base_per_class: 85.0000 (80.3955) 
Training Epoch: [174/1000] Step: [260 / 285] Batch Time: 0.1472 (0.1575) Data Time: 0.0156 (0.0238) Average Loss: 0.5984 (0.7170) Average CE Loss (Source):  0.5984 ( 0.7170) Learning Rate: 0.1000 (0.1000) Top1_base: 82.0312 (79.9910) Top1_base_per_class: 82.1384 (80.4123) 
Training Epoch: [174/1000] Step: [270 / 285] Batch Time: 0.1461 (0.1571) Data Time: 0.0137 (0.0234) Average Loss: 0.6599 (0.7180) Average CE Loss (Source):  0.6599 ( 0.7180) Learning Rate: 0.1000 (0.1000) Top1_base: 82.0312 (80.0145) Top1_base_per_class: 83.8983 (80.4251) 
Training Epoch: [174/1000] Step: [280 / 285] Batch Time: 0.1457 (0.1567) Data Time: 0.0115 (0.0231) Average Loss: 0.4900 (0.7190) Average CE Loss (Source):  0.4900 ( 0.7190) Learning Rate: 0.1000 (0.1000) Top1_base: 83.5938 (79.9833) Top1_base_per_class: 87.6061 (80.4133) 
Training Epoch: [175/1000] Step: [0] Batch Time: 0.1455 (0.1566) Data Time: 0.0136 (0.0230) Average Loss: 0.6532 (0.7192) Average CE Loss (Source):  0.6532 ( 0.7192) Learning Rate: 0.1000 (0.1000) Top1_base: 84.3750 (79.9890) Top1_base_per_class: 85.8268 (80.4275) 
Training Epoch: [175/1000] Step: [10 / 285] Batch Time: 0.1435 (0.2369) Data Time: 0.0120 (0.1036) Average Loss: 0.7472 (0.6870) Average CE Loss (Source):  0.7472 ( 0.6870) Learning Rate: 0.1000 (0.1000) Top1_base: 76.5625 (80.0781) Top1_base_per_class: 78.2502 (81.1331) 
Training Epoch: [175/1000] Step: [20 / 285] Batch Time: 0.1414 (0.1913) Data Time: 0.0113 (0.0584) Average Loss: 0.5607 (0.6696) Average CE Loss (Source):  0.5607 ( 0.6696) Learning Rate: 0.1000 (0.1000) Top1_base: 82.8125 (80.5078) Top1_base_per_class: 83.1548 (81.3474) 
Training Epoch: [175/1000] Step: [30 / 285] Batch Time: 0.1470 (0.1839) Data Time: 0.0150 (0.0511) Average Loss: 0.5251 (0.6618) Average CE Loss (Source):  0.5251 ( 0.6618) Learning Rate: 0.1000 (0.1000) Top1_base: 81.2500 (80.9635) Top1_base_per_class: 80.8479 (81.1706) 
Training Epoch: [175/1000] Step: [40 / 285] Batch Time: 0.1428 (0.1752) Data Time: 0.0123 (0.0426) Average Loss: 0.8695 (0.6606) Average CE Loss (Source):  0.8695 ( 0.6606) Learning Rate: 0.1000 (0.1000) Top1_base: 79.6875 (81.1719) Top1_base_per_class: 81.6981 (81.4146) 
Training Epoch: [175/1000] Step: [50 / 285] Batch Time: 0.1453 (0.1718) Data Time: 0.0138 (0.0391) Average Loss: 0.6594 (0.6723) Average CE Loss (Source):  0.6594 ( 0.6723) Learning Rate: 0.1000 (0.1000) Top1_base: 84.3750 (81.0156) Top1_base_per_class: 84.1520 (81.3568) 
Training Epoch: [175/1000] Step: [60 / 285] Batch Time: 0.1450 (0.1704) Data Time: 0.0124 (0.0375) Average Loss: 0.6676 (0.6764) Average CE Loss (Source):  0.6676 ( 0.6764) Learning Rate: 0.1000 (0.1000) Top1_base: 78.1250 (81.0547) Top1_base_per_class: 81.0734 (81.5089) 
Training Epoch: [175/1000] Step: [70 / 285] Batch Time: 0.1513 (0.1673) Data Time: 0.0155 (0.0342) Average Loss: 0.6681 (0.6849) Average CE Loss (Source):  0.6681 ( 0.6849) Learning Rate: 0.1000 (0.1000) Top1_base: 78.9062 (80.7701) Top1_base_per_class: 78.4524 (81.1229) 
Training Epoch: [175/1000] Step: [80 / 285] Batch Time: 0.1473 (0.1658) Data Time: 0.0123 (0.0324) Average Loss: 0.6546 (0.6926) Average CE Loss (Source):  0.6546 ( 0.6926) Learning Rate: 0.1000 (0.1000) Top1_base: 82.0312 (80.5859) Top1_base_per_class: 84.6726 (80.9621) 
Training Epoch: [175/1000] Step: [90 / 285] Batch Time: 0.1500 (0.1639) Data Time: 0.0161 (0.0303) Average Loss: 0.4661 (0.6935) Average CE Loss (Source):  0.4661 ( 0.6935) Learning Rate: 0.1000 (0.1000) Top1_base: 89.0625 (80.6076) Top1_base_per_class: 88.4503 (80.8659) 
Training Epoch: [175/1000] Step: [100 / 285] Batch Time: 0.1467 (0.1623) Data Time: 0.0126 (0.0286) Average Loss: 0.8888 (0.6939) Average CE Loss (Source):  0.8888 ( 0.6939) Learning Rate: 0.1000 (0.1000) Top1_base: 76.5625 (80.5547) Top1_base_per_class: 77.2667 (80.8737) 
Training Epoch: [175/1000] Step: [110 / 285] Batch Time: 0.1509 (0.1612) Data Time: 0.0177 (0.0274) Average Loss: 0.8533 (0.6915) Average CE Loss (Source):  0.8533 ( 0.6915) Learning Rate: 0.1000 (0.1000) Top1_base: 78.1250 (80.6179) Top1_base_per_class: 78.8462 (80.8771) 
Training Epoch: [175/1000] Step: [120 / 285] Batch Time: 0.1426 (0.1601) Data Time: 0.0110 (0.0262) Average Loss: 0.8682 (0.6936) Average CE Loss (Source):  0.8682 ( 0.6936) Learning Rate: 0.1000 (0.1000) Top1_base: 77.3438 (80.4753) Top1_base_per_class: 79.1667 (80.6804) 
Training Epoch: [175/1000] Step: [130 / 285] Batch Time: 0.1509 (0.1594) Data Time: 0.0172 (0.0255) Average Loss: 0.7697 (0.6953) Average CE Loss (Source):  0.7697 ( 0.6953) Learning Rate: 0.1000 (0.1000) Top1_base: 80.4688 (80.4567) Top1_base_per_class: 84.6839 (80.6799) 
Training Epoch: [175/1000] Step: [140 / 285] Batch Time: 0.1482 (0.1588) Data Time: 0.0128 (0.0248) Average Loss: 0.9106 (0.7026) Average CE Loss (Source):  0.9106 ( 0.7026) Learning Rate: 0.1000 (0.1000) Top1_base: 73.4375 (80.1786) Top1_base_per_class: 78.4445 (80.5156) 
Training Epoch: [175/1000] Step: [150 / 285] Batch Time: 0.2056 (0.1585) Data Time: 0.0718 (0.0244) Average Loss: 0.6341 (0.7038) Average CE Loss (Source):  0.6341 ( 0.7038) Learning Rate: 0.1000 (0.1000) Top1_base: 82.0312 (80.1510) Top1_base_per_class: 81.0234 (80.5264) 
Training Epoch: [175/1000] Step: [160 / 285] Batch Time: 0.1485 (0.1578) Data Time: 0.0143 (0.0237) Average Loss: 0.9516 (0.7094) Average CE Loss (Source):  0.9516 ( 0.7094) Learning Rate: 0.1000 (0.1000) Top1_base: 78.1250 (80.0732) Top1_base_per_class: 78.4848 (80.4924) 
Training Epoch: [175/1000] Step: [170 / 285] Batch Time: 0.1561 (0.1573) Data Time: 0.0240 (0.0232) Average Loss: 0.4546 (0.7078) Average CE Loss (Source):  0.4546 ( 0.7078) Learning Rate: 0.1000 (0.1000) Top1_base: 87.5000 (80.1103) Top1_base_per_class: 91.5748 (80.5189) 
Training Epoch: [175/1000] Step: [180 / 285] Batch Time: 0.1457 (0.1570) Data Time: 0.0141 (0.0230) Average Loss: 0.8913 (0.7109) Average CE Loss (Source):  0.8913 ( 0.7109) Learning Rate: 0.1000 (0.1000) Top1_base: 75.0000 (80.0651) Top1_base_per_class: 73.7853 (80.4760) 
Training Epoch: [175/1000] Step: [190 / 285] Batch Time: 0.2559 (0.1578) Data Time: 0.1237 (0.0239) Average Loss: 0.6262 (0.7068) Average CE Loss (Source):  0.6262 ( 0.7068) Learning Rate: 0.1000 (0.1000) Top1_base: 82.0312 (80.1069) Top1_base_per_class: 84.3531 (80.5780) 
Training Epoch: [175/1000] Step: [200 / 285] Batch Time: 0.1489 (0.1574) Data Time: 0.0167 (0.0235) Average Loss: 0.6539 (0.7073) Average CE Loss (Source):  0.6539 ( 0.7073) Learning Rate: 0.1000 (0.1000) Top1_base: 79.6875 (80.0703) Top1_base_per_class: 78.9394 (80.5656) 
Training Epoch: [175/1000] Step: [210 / 285] Batch Time: 0.1471 (0.1573) Data Time: 0.0153 (0.0235) Average Loss: 0.8103 (0.7075) Average CE Loss (Source):  0.8103 ( 0.7075) Learning Rate: 0.1000 (0.1000) Top1_base: 78.9062 (80.0446) Top1_base_per_class: 78.6706 (80.5457) 
Training Epoch: [175/1000] Step: [220 / 285] Batch Time: 0.1778 (0.1572) Data Time: 0.0455 (0.0234) Average Loss: 0.6815 (0.7077) Average CE Loss (Source):  0.6815 ( 0.7077) Learning Rate: 0.1000 (0.1000) Top1_base: 82.8125 (79.9929) Top1_base_per_class: 81.8750 (80.4730) 
Training Epoch: [175/1000] Step: [230 / 285] Batch Time: 0.1473 (0.1571) Data Time: 0.0159 (0.0233) Average Loss: 0.7400 (0.7073) Average CE Loss (Source):  0.7400 ( 0.7073) Learning Rate: 0.1000 (0.1000) Top1_base: 82.0312 (80.0068) Top1_base_per_class: 80.0000 (80.5099) 
Training Epoch: [175/1000] Step: [240 / 285] Batch Time: 0.1481 (0.1569) Data Time: 0.0155 (0.0232) Average Loss: 0.7402 (0.7082) Average CE Loss (Source):  0.7402 ( 0.7082) Learning Rate: 0.1000 (0.1000) Top1_base: 77.3438 (79.9805) Top1_base_per_class: 78.1515 (80.4725) 
Training Epoch: [175/1000] Step: [250 / 285] Batch Time: 0.1736 (0.1569) Data Time: 0.0423 (0.0232) Average Loss: 0.5963 (0.7098) Average CE Loss (Source):  0.5963 ( 0.7098) Learning Rate: 0.1000 (0.1000) Top1_base: 85.1562 (79.9313) Top1_base_per_class: 82.8788 (80.4579) 
Training Epoch: [175/1000] Step: [260 / 285] Batch Time: 0.1492 (0.1567) Data Time: 0.0166 (0.0231) Average Loss: 0.6383 (0.7111) Average CE Loss (Source):  0.6383 ( 0.7111) Learning Rate: 0.1000 (0.1000) Top1_base: 82.8125 (79.9099) Top1_base_per_class: 81.1782 (80.4248) 
Training Epoch: [175/1000] Step: [270 / 285] Batch Time: 0.1492 (0.1565) Data Time: 0.0167 (0.0228) Average Loss: 0.6235 (0.7126) Average CE Loss (Source):  0.6235 ( 0.7126) Learning Rate: 0.1000 (0.1000) Top1_base: 83.5938 (79.8987) Top1_base_per_class: 84.3400 (80.3853) 
Training Epoch: [175/1000] Step: [280 / 285] Batch Time: 0.1813 (0.1565) Data Time: 0.0491 (0.0228) Average Loss: 0.7601 (0.7121) Average CE Loss (Source):  0.7601 ( 0.7121) Learning Rate: 0.1000 (0.1000) Top1_base: 82.8125 (79.8940) Top1_base_per_class: 84.8810 (80.4067) 
Training Epoch: [176/1000] Step: [0] Batch Time: 0.1454 (0.1563) Data Time: 0.0115 (0.0226) Average Loss: 0.7196 (0.7114) Average CE Loss (Source):  0.7196 ( 0.7114) Learning Rate: 0.1000 (0.1000) Top1_base: 77.3438 (79.9068) Top1_base_per_class: 79.4340 (80.4312) 
 18%|█▊        | 176/1000 [2:16:48<10:38:37, 46.50s/it] 18%|█▊        | 177/1000 [2:17:33<10:30:48, 45.99s/it]Training Epoch: [176/1000] Step: [10 / 285] Batch Time: 0.1451 (0.2287) Data Time: 0.0105 (0.0954) Average Loss: 0.8522 (0.7449) Average CE Loss (Source):  0.8522 ( 0.7449) Learning Rate: 0.1000 (0.1000) Top1_base: 75.0000 (78.7500) Top1_base_per_class: 73.7202 (79.7023) 
Training Epoch: [176/1000] Step: [20 / 285] Batch Time: 0.1445 (0.1922) Data Time: 0.0140 (0.0591) Average Loss: 0.7700 (0.7094) Average CE Loss (Source):  0.7700 ( 0.7094) Learning Rate: 0.1000 (0.1000) Top1_base: 78.9062 (80.5469) Top1_base_per_class: 77.7026 (81.1593) 
Training Epoch: [176/1000] Step: [30 / 285] Batch Time: 0.1444 (0.1791) Data Time: 0.0133 (0.0466) Average Loss: 0.8446 (0.6945) Average CE Loss (Source):  0.8446 ( 0.6945) Learning Rate: 0.1000 (0.1000) Top1_base: 78.1250 (80.8333) Top1_base_per_class: 77.7381 (81.0505) 
Training Epoch: [176/1000] Step: [40 / 285] Batch Time: 0.1463 (0.1712) Data Time: 0.0122 (0.0386) Average Loss: 0.6710 (0.6899) Average CE Loss (Source):  0.6710 ( 0.6899) Learning Rate: 0.1000 (0.1000) Top1_base: 78.9062 (80.6836) Top1_base_per_class: 80.0862 (80.9822) 
Training Epoch: [176/1000] Step: [50 / 285] Batch Time: 0.1495 (0.1689) Data Time: 0.0152 (0.0363) Average Loss: 0.5674 (0.6755) Average CE Loss (Source):  0.5674 ( 0.6755) Learning Rate: 0.1000 (0.1000) Top1_base: 85.1562 (81.1875) Top1_base_per_class: 86.1310 (81.4945) 
Training Epoch: [176/1000] Step: [60 / 285] Batch Time: 0.1446 (0.1661) Data Time: 0.0114 (0.0335) Average Loss: 0.7204 (0.6758) Average CE Loss (Source):  0.7204 ( 0.6758) Learning Rate: 0.1000 (0.1000) Top1_base: 79.6875 (81.1068) Top1_base_per_class: 79.4805 (81.2326) 
Training Epoch: [176/1000] Step: [70 / 285] Batch Time: 0.1477 (0.1645) Data Time: 0.0133 (0.0318) Average Loss: 0.6532 (0.6798) Average CE Loss (Source):  0.6532 ( 0.6798) Learning Rate: 0.1000 (0.1000) Top1_base: 79.6875 (81.0826) Top1_base_per_class: 83.4295 (81.3155) 
Training Epoch: [176/1000] Step: [80 / 285] Batch Time: 0.1450 (0.1626) Data Time: 0.0119 (0.0299) Average Loss: 0.5486 (0.6749) Average CE Loss (Source):  0.5486 ( 0.6749) Learning Rate: 0.1000 (0.1000) Top1_base: 84.3750 (81.0645) Top1_base_per_class: 81.6038 (81.1094) 
Training Epoch: [176/1000] Step: [90 / 285] Batch Time: 0.1453 (0.1623) Data Time: 0.0103 (0.0297) Average Loss: 0.8370 (0.6805) Average CE Loss (Source):  0.8370 ( 0.6805) Learning Rate: 0.1000 (0.1000) Top1_base: 79.6875 (80.9722) Top1_base_per_class: 79.8742 (81.1296) 
Training Epoch: [176/1000] Step: [100 / 285] Batch Time: 0.1463 (0.1618) Data Time: 0.0123 (0.0292) Average Loss: 0.9142 (0.6823) Average CE Loss (Source):  0.9142 ( 0.6823) Learning Rate: 0.1000 (0.1000) Top1_base: 75.0000 (81.0000) Top1_base_per_class: 78.2790 (81.1936) 
Training Epoch: [176/1000] Step: [110 / 285] Batch Time: 0.1448 (0.1625) Data Time: 0.0104 (0.0298) Average Loss: 0.6869 (0.6872) Average CE Loss (Source):  0.6869 ( 0.6872) Learning Rate: 0.1000 (0.1000) Top1_base: 82.0312 (80.9091) Top1_base_per_class: 83.0655 (81.1361) 
Training Epoch: [176/1000] Step: [120 / 285] Batch Time: 0.1495 (0.1626) Data Time: 0.0126 (0.0299) Average Loss: 0.7571 (0.6912) Average CE Loss (Source):  0.7571 ( 0.6912) Learning Rate: 0.1000 (0.1000) Top1_base: 80.4688 (80.8529) Top1_base_per_class: 83.8580 (81.1859) 
Training Epoch: [176/1000] Step: [130 / 285] Batch Time: 0.1458 (0.1616) Data Time: 0.0108 (0.0287) Average Loss: 0.7338 (0.6924) Average CE Loss (Source):  0.7338 ( 0.6924) Learning Rate: 0.1000 (0.1000) Top1_base: 79.6875 (80.7993) Top1_base_per_class: 82.0909 (81.1861) 
Training Epoch: [176/1000] Step: [140 / 285] Batch Time: 0.1462 (0.1607) Data Time: 0.0103 (0.0278) Average Loss: 0.7802 (0.6926) Average CE Loss (Source):  0.7802 ( 0.6926) Learning Rate: 0.1000 (0.1000) Top1_base: 80.4688 (80.7924) Top1_base_per_class: 80.9434 (81.1928) 
Training Epoch: [176/1000] Step: [150 / 285] Batch Time: 0.1464 (0.1600) Data Time: 0.0113 (0.0271) Average Loss: 0.5941 (0.6963) Average CE Loss (Source):  0.5941 ( 0.6963) Learning Rate: 0.1000 (0.1000) Top1_base: 84.3750 (80.7135) Top1_base_per_class: 82.4561 (81.1440) 
Training Epoch: [176/1000] Step: [160 / 285] Batch Time: 0.1477 (0.1593) Data Time: 0.0114 (0.0264) Average Loss: 0.6289 (0.7016) Average CE Loss (Source):  0.6289 ( 0.7016) Learning Rate: 0.1000 (0.1000) Top1_base: 82.0312 (80.5615) Top1_base_per_class: 84.7024 (81.0085) 
Training Epoch: [176/1000] Step: [170 / 285] Batch Time: 0.1462 (0.1587) Data Time: 0.0103 (0.0256) Average Loss: 0.8755 (0.7006) Average CE Loss (Source):  0.8755 ( 0.7006) Learning Rate: 0.1000 (0.1000) Top1_base: 71.8750 (80.5836) Top1_base_per_class: 74.9339 (81.0934) 
Training Epoch: [176/1000] Step: [180 / 285] Batch Time: 0.1481 (0.1581) Data Time: 0.0112 (0.0250) Average Loss: 0.8476 (0.7031) Average CE Loss (Source):  0.8476 ( 0.7031) Learning Rate: 0.1000 (0.1000) Top1_base: 77.3438 (80.5035) Top1_base_per_class: 78.8333 (80.9977) 
Training Epoch: [176/1000] Step: [190 / 285] Batch Time: 0.1440 (0.1582) Data Time: 0.0125 (0.0250) Average Loss: 0.8624 (0.7032) Average CE Loss (Source):  0.8624 ( 0.7032) Learning Rate: 0.1000 (0.1000) Top1_base: 75.0000 (80.5263) Top1_base_per_class: 74.5071 (81.0442) 
Training Epoch: [176/1000] Step: [200 / 285] Batch Time: 0.1428 (0.1576) Data Time: 0.0123 (0.0245) Average Loss: 0.7962 (0.7049) Average CE Loss (Source):  0.7962 ( 0.7049) Learning Rate: 0.1000 (0.1000) Top1_base: 79.6875 (80.4844) Top1_base_per_class: 79.1818 (81.0337) 
Training Epoch: [176/1000] Step: [210 / 285] Batch Time: 0.1434 (0.1579) Data Time: 0.0101 (0.0249) Average Loss: 0.7841 (0.7086) Average CE Loss (Source):  0.7841 ( 0.7086) Learning Rate: 0.1000 (0.1000) Top1_base: 77.3438 (80.3385) Top1_base_per_class: 79.1515 (80.8903) 
Training Epoch: [176/1000] Step: [220 / 285] Batch Time: 0.1443 (0.1576) Data Time: 0.0137 (0.0246) Average Loss: 0.8847 (0.7117) Average CE Loss (Source):  0.8847 ( 0.7117) Learning Rate: 0.1000 (0.1000) Top1_base: 78.1250 (80.2450) Top1_base_per_class: 80.3846 (80.8166) 
Training Epoch: [176/1000] Step: [230 / 285] Batch Time: 0.1441 (0.1575) Data Time: 0.0128 (0.0245) Average Loss: 0.7467 (0.7145) Average CE Loss (Source):  0.7467 ( 0.7145) Learning Rate: 0.1000 (0.1000) Top1_base: 76.5625 (80.0985) Top1_base_per_class: 69.4848 (80.6231) 
Training Epoch: [176/1000] Step: [240 / 285] Batch Time: 0.1471 (0.1573) Data Time: 0.0115 (0.0243) Average Loss: 0.9349 (0.7167) Average CE Loss (Source):  0.9349 ( 0.7167) Learning Rate: 0.1000 (0.1000) Top1_base: 72.6562 (80.0195) Top1_base_per_class: 72.5309 (80.5319) 
Training Epoch: [176/1000] Step: [250 / 285] Batch Time: 0.1476 (0.1571) Data Time: 0.0116 (0.0241) Average Loss: 0.5713 (0.7160) Average CE Loss (Source):  0.5713 ( 0.7160) Learning Rate: 0.1000 (0.1000) Top1_base: 84.3750 (80.0500) Top1_base_per_class: 86.0692 (80.5372) 
Training Epoch: [176/1000] Step: [260 / 285] Batch Time: 0.1457 (0.1576) Data Time: 0.0134 (0.0245) Average Loss: 0.8331 (0.7177) Average CE Loss (Source):  0.8331 ( 0.7177) Learning Rate: 0.1000 (0.1000) Top1_base: 72.6562 (79.9970) Top1_base_per_class: 73.1372 (80.4495) 
Training Epoch: [176/1000] Step: [270 / 285] Batch Time: 0.1439 (0.1574) Data Time: 0.0106 (0.0244) Average Loss: 0.6212 (0.7194) Average CE Loss (Source):  0.6212 ( 0.7194) Learning Rate: 0.1000 (0.1000) Top1_base: 79.6875 (79.9595) Top1_base_per_class: 80.0877 (80.4017) 
Training Epoch: [176/1000] Step: [280 / 285] Batch Time: 0.1452 (0.1570) Data Time: 0.0105 (0.0240) Average Loss: 0.8163 (0.7199) Average CE Loss (Source):  0.8163 ( 0.7199) Learning Rate: 0.1000 (0.1000) Top1_base: 76.5625 (79.8996) Top1_base_per_class: 74.8974 (80.3071) 
Training Epoch: [177/1000] Step: [0] Batch Time: 0.1418 (0.1569) Data Time: 0.0112 (0.0239) Average Loss: 0.7680 (0.7195) Average CE Loss (Source):  0.7680 ( 0.7195) Learning Rate: 0.1000 (0.1000) Top1_base: 78.1250 (79.9041) Top1_base_per_class: 81.8899 (80.2936) 
Training Epoch: [177/1000] Step: [10 / 285] Batch Time: 0.2171 (0.2317) Data Time: 0.0835 (0.0980) Average Loss: 0.4864 (0.6562) Average CE Loss (Source):  0.4864 ( 0.6562) Learning Rate: 0.1000 (0.1000) Top1_base: 85.9375 (81.4844) Top1_base_per_class: 89.3294 (83.2976) 
Training Epoch: [177/1000] Step: [20 / 285] Batch Time: 0.1444 (0.2018) Data Time: 0.0116 (0.0686) Average Loss: 0.6296 (0.6737) Average CE Loss (Source):  0.6296 ( 0.6737) Learning Rate: 0.1000 (0.1000) Top1_base: 82.0312 (81.0547) Top1_base_per_class: 80.1130 (82.1278) 
Training Epoch: [177/1000] Step: [30 / 285] Batch Time: 0.2479 (0.1925) Data Time: 0.1167 (0.0594) Average Loss: 0.9016 (0.6895) Average CE Loss (Source):  0.9016 ( 0.6895) Learning Rate: 0.1000 (0.1000) Top1_base: 72.6562 (80.5990) Top1_base_per_class: 71.8868 (81.4074) 
Training Epoch: [177/1000] Step: [40 / 285] Batch Time: 0.1440 (0.1827) Data Time: 0.0102 (0.0498) Average Loss: 0.5743 (0.6988) Average CE Loss (Source):  0.5743 ( 0.6988) Learning Rate: 0.1000 (0.1000) Top1_base: 83.5938 (80.0977) Top1_base_per_class: 88.9711 (81.0809) 
Training Epoch: [177/1000] Step: [50 / 285] Batch Time: 0.1586 (0.1767) Data Time: 0.0270 (0.0438) Average Loss: 0.6408 (0.6942) Average CE Loss (Source):  0.6408 ( 0.6942) Learning Rate: 0.1000 (0.1000) Top1_base: 82.0312 (80.2500) Top1_base_per_class: 84.2121 (81.0866) 
Training Epoch: [177/1000] Step: [60 / 285] Batch Time: 0.1447 (0.1732) Data Time: 0.0109 (0.0404) Average Loss: 0.5544 (0.6828) Average CE Loss (Source):  0.5544 ( 0.6828) Learning Rate: 0.1000 (0.1000) Top1_base: 82.8125 (80.4688) Top1_base_per_class: 82.5758 (81.3432) 
Training Epoch: [177/1000] Step: [70 / 285] Batch Time: 0.2123 (0.1718) Data Time: 0.0794 (0.0390) Average Loss: 0.6263 (0.6790) Average CE Loss (Source):  0.6263 ( 0.6790) Learning Rate: 0.1000 (0.1000) Top1_base: 84.3750 (80.6808) Top1_base_per_class: 86.2802 (81.6936) 
Training Epoch: [177/1000] Step: [80 / 285] Batch Time: 0.1413 (0.1684) Data Time: 0.0112 (0.0358) Average Loss: 0.5570 (0.6762) Average CE Loss (Source):  0.5570 ( 0.6762) Learning Rate: 0.1000 (0.1000) Top1_base: 82.0312 (80.7520) Top1_base_per_class: 82.2531 (81.7105) 
Training Epoch: [177/1000] Step: [90 / 285] Batch Time: 0.1774 (0.1679) Data Time: 0.0460 (0.0353) Average Loss: 0.7257 (0.6760) Average CE Loss (Source):  0.7257 ( 0.6760) Learning Rate: 0.1000 (0.1000) Top1_base: 82.8125 (80.8333) Top1_base_per_class: 84.8693 (81.7629) 
Training Epoch: [177/1000] Step: [100 / 285] Batch Time: 0.1419 (0.1658) Data Time: 0.0112 (0.0333) Average Loss: 0.7002 (0.6749) Average CE Loss (Source):  0.7002 ( 0.6749) Learning Rate: 0.1000 (0.1000) Top1_base: 79.6875 (80.8672) Top1_base_per_class: 81.6102 (81.8004) 
Training Epoch: [177/1000] Step: [110 / 285] Batch Time: 0.1968 (0.1663) Data Time: 0.0614 (0.0338) Average Loss: 1.0980 (0.6807) Average CE Loss (Source):  1.0980 ( 0.6807) Learning Rate: 0.1000 (0.1000) Top1_base: 74.2188 (80.7528) Top1_base_per_class: 75.7978 (81.6745) 
Training Epoch: [177/1000] Step: [120 / 285] Batch Time: 0.1443 (0.1652) Data Time: 0.0108 (0.0326) Average Loss: 0.8172 (0.6866) Average CE Loss (Source):  0.8172 ( 0.6866) Learning Rate: 0.1000 (0.1000) Top1_base: 78.1250 (80.5599) Top1_base_per_class: 78.0093 (81.4310) 
Training Epoch: [177/1000] Step: [130 / 285] Batch Time: 0.1485 (0.1645) Data Time: 0.0172 (0.0319) Average Loss: 0.6662 (0.6865) Average CE Loss (Source):  0.6662 ( 0.6865) Learning Rate: 0.1000 (0.1000) Top1_base: 82.8125 (80.6550) Top1_base_per_class: 81.1515 (81.4144) 
Training Epoch: [177/1000] Step: [140 / 285] Batch Time: 0.1445 (0.1631) Data Time: 0.0108 (0.0305) Average Loss: 0.7958 (0.6875) Average CE Loss (Source):  0.7958 ( 0.6875) Learning Rate: 0.1000 (0.1000) Top1_base: 78.9062 (80.6027) Top1_base_per_class: 76.7116 (81.3249) 
Training Epoch: [177/1000] Step: [150 / 285] Batch Time: 0.1487 (0.1620) Data Time: 0.0176 (0.0294) Average Loss: 0.6744 (0.6881) Average CE Loss (Source):  0.6744 ( 0.6881) Learning Rate: 0.1000 (0.1000) Top1_base: 78.9062 (80.5625) Top1_base_per_class: 79.0017 (81.2588) 
Training Epoch: [177/1000] Step: [160 / 285] Batch Time: 0.1423 (0.1609) Data Time: 0.0122 (0.0284) Average Loss: 0.8631 (0.6932) Average CE Loss (Source):  0.8631 ( 0.6932) Learning Rate: 0.1000 (0.1000) Top1_base: 78.1250 (80.3711) Top1_base_per_class: 78.9697 (81.0461) 
Training Epoch: [177/1000] Step: [170 / 285] Batch Time: 0.1454 (0.1600) Data Time: 0.0144 (0.0275) Average Loss: 0.9066 (0.6984) Average CE Loss (Source):  0.9066 ( 0.6984) Learning Rate: 0.1000 (0.1000) Top1_base: 75.0000 (80.2252) Top1_base_per_class: 74.3750 (80.8752) 
Training Epoch: [177/1000] Step: [180 / 285] Batch Time: 0.1440 (0.1592) Data Time: 0.0101 (0.0267) Average Loss: 0.6217 (0.6989) Average CE Loss (Source):  0.6217 ( 0.6989) Learning Rate: 0.1000 (0.1000) Top1_base: 82.0312 (80.2604) Top1_base_per_class: 83.7500 (80.9274) 
Training Epoch: [177/1000] Step: [190 / 285] Batch Time: 0.1464 (0.1585) Data Time: 0.0147 (0.0260) Average Loss: 0.8664 (0.6960) Average CE Loss (Source):  0.8664 ( 0.6960) Learning Rate: 0.1000 (0.1000) Top1_base: 75.7812 (80.3413) Top1_base_per_class: 77.0909 (80.9695) 
Training Epoch: [177/1000] Step: [200 / 285] Batch Time: 0.1428 (0.1580) Data Time: 0.0115 (0.0255) Average Loss: 0.7037 (0.6972) Average CE Loss (Source):  0.7037 ( 0.6972) Learning Rate: 0.1000 (0.1000) Top1_base: 80.4688 (80.2930) Top1_base_per_class: 77.2956 (80.9383) 
Training Epoch: [177/1000] Step: [210 / 285] Batch Time: 0.1464 (0.1581) Data Time: 0.0153 (0.0255) Average Loss: 0.5094 (0.6985) Average CE Loss (Source):  0.5094 ( 0.6985) Learning Rate: 0.1000 (0.1000) Top1_base: 85.9375 (80.2307) Top1_base_per_class: 87.5000 (80.8948) 
Training Epoch: [177/1000] Step: [220 / 285] Batch Time: 0.1445 (0.1586) Data Time: 0.0106 (0.0260) Average Loss: 0.8234 (0.6986) Average CE Loss (Source):  0.8234 ( 0.6986) Learning Rate: 0.1000 (0.1000) Top1_base: 78.9062 (80.2237) Top1_base_per_class: 75.6970 (80.8537) 
Training Epoch: [177/1000] Step: [230 / 285] Batch Time: 0.1470 (0.1583) Data Time: 0.0135 (0.0257) Average Loss: 0.4597 (0.6982) Average CE Loss (Source):  0.4597 ( 0.6982) Learning Rate: 0.1000 (0.1000) Top1_base: 89.0625 (80.2446) Top1_base_per_class: 90.0909 (80.9059) 
Training Epoch: [177/1000] Step: [240 / 285] Batch Time: 0.1436 (0.1578) Data Time: 0.0106 (0.0252) Average Loss: 0.6324 (0.6996) Average CE Loss (Source):  0.6324 ( 0.6996) Learning Rate: 0.1000 (0.1000) Top1_base: 85.1562 (80.2181) Top1_base_per_class: 86.9753 (80.8889) 
Training Epoch: [177/1000] Step: [250 / 285] Batch Time: 0.1442 (0.1574) Data Time: 0.0140 (0.0249) Average Loss: 0.7392 (0.7018) Average CE Loss (Source):  0.7392 ( 0.7018) Learning Rate: 0.1000 (0.1000) Top1_base: 78.1250 (80.1406) Top1_base_per_class: 77.9938 (80.8468) 
Training Epoch: [177/1000] Step: [260 / 285] Batch Time: 0.1452 (0.1573) Data Time: 0.0113 (0.0248) Average Loss: 0.6251 (0.7034) Average CE Loss (Source):  0.6251 ( 0.7034) Learning Rate: 0.1000 (0.1000) Top1_base: 84.3750 (80.1112) Top1_base_per_class: 86.0417 (80.7966) 
Training Epoch: [177/1000] Step: [270 / 285] Batch Time: 0.1433 (0.1570) Data Time: 0.0106 (0.0246) Average Loss: 0.4994 (0.7043) Average CE Loss (Source):  0.4994 ( 0.7043) Learning Rate: 0.1000 (0.1000) Top1_base: 86.7188 (80.1100) Top1_base_per_class: 86.2963 (80.7842) 
Training Epoch: [177/1000] Step: [280 / 285] Batch Time: 0.1480 (0.1566) Data Time: 0.0120 (0.0242) Average Loss: 0.9034 (0.7061) Average CE Loss (Source):  0.9034 ( 0.7061) Learning Rate: 0.1000 (0.1000) Top1_base: 78.1250 (80.1200) Top1_base_per_class: 82.8182 (80.8186) 
Training Epoch: [178/1000] Step: [0] Batch Time: 0.1459 (0.1565) Data Time: 0.0116 (0.0240) Average Loss: 0.6839 (0.7062) Average CE Loss (Source):  0.6839 ( 0.7062) Learning Rate: 0.1000 (0.1000) Top1_base: 79.6875 (80.1288) Top1_base_per_class: 79.8538 (80.8334) 
 18%|█▊        | 178/1000 [2:18:20<10:35:48, 46.41s/it] 18%|█▊        | 179/1000 [2:19:05<10:28:38, 45.94s/it]Training Epoch: [178/1000] Step: [10 / 285] Batch Time: 0.1494 (0.2327) Data Time: 0.0146 (0.0994) Average Loss: 0.8055 (0.6998) Average CE Loss (Source):  0.8055 ( 0.6998) Learning Rate: 0.1000 (0.1000) Top1_base: 75.0000 (80.9375) Top1_base_per_class: 74.6667 (81.5517) 
Training Epoch: [178/1000] Step: [20 / 285] Batch Time: 0.1456 (0.1967) Data Time: 0.0126 (0.0636) Average Loss: 0.6166 (0.6736) Average CE Loss (Source):  0.6166 ( 0.6736) Learning Rate: 0.1000 (0.1000) Top1_base: 80.4688 (81.0156) Top1_base_per_class: 78.1445 (81.0238) 
Training Epoch: [178/1000] Step: [30 / 285] Batch Time: 0.1479 (0.1851) Data Time: 0.0126 (0.0519) Average Loss: 0.7422 (0.6808) Average CE Loss (Source):  0.7422 ( 0.6808) Learning Rate: 0.1000 (0.1000) Top1_base: 78.9062 (81.0156) Top1_base_per_class: 78.4195 (80.8756) 
Training Epoch: [178/1000] Step: [40 / 285] Batch Time: 0.1455 (0.1782) Data Time: 0.0109 (0.0450) Average Loss: 0.7405 (0.6969) Average CE Loss (Source):  0.7405 ( 0.6969) Learning Rate: 0.1000 (0.1000) Top1_base: 77.3438 (80.5859) Top1_base_per_class: 79.2949 (80.6212) 
Training Epoch: [178/1000] Step: [50 / 285] Batch Time: 0.1477 (0.1735) Data Time: 0.0114 (0.0401) Average Loss: 0.7238 (0.6921) Average CE Loss (Source):  0.7238 ( 0.6921) Learning Rate: 0.1000 (0.1000) Top1_base: 78.9062 (80.5469) Top1_base_per_class: 74.9057 (80.7100) 
Training Epoch: [178/1000] Step: [60 / 285] Batch Time: 0.1438 (0.1693) Data Time: 0.0113 (0.0360) Average Loss: 0.8360 (0.7068) Average CE Loss (Source):  0.8360 ( 0.7068) Learning Rate: 0.1000 (0.1000) Top1_base: 78.1250 (80.1823) Top1_base_per_class: 82.2316 (80.5443) 
Training Epoch: [178/1000] Step: [70 / 285] Batch Time: 0.1449 (0.1691) Data Time: 0.0140 (0.0357) Average Loss: 0.6865 (0.7079) Average CE Loss (Source):  0.6865 ( 0.7079) Learning Rate: 0.1000 (0.1000) Top1_base: 82.0312 (80.1897) Top1_base_per_class: 83.0655 (80.5529) 
Training Epoch: [178/1000] Step: [80 / 285] Batch Time: 0.1471 (0.1678) Data Time: 0.0131 (0.0344) Average Loss: 0.6561 (0.7095) Average CE Loss (Source):  0.6561 ( 0.7095) Learning Rate: 0.1000 (0.1000) Top1_base: 82.0312 (80.1270) Top1_base_per_class: 77.7193 (80.5036) 
Training Epoch: [178/1000] Step: [90 / 285] Batch Time: 0.1483 (0.1662) Data Time: 0.0118 (0.0326) Average Loss: 0.6614 (0.7035) Average CE Loss (Source):  0.6614 ( 0.7035) Learning Rate: 0.1000 (0.1000) Top1_base: 76.5625 (80.2951) Top1_base_per_class: 75.0000 (80.6102) 
Training Epoch: [178/1000] Step: [100 / 285] Batch Time: 0.1484 (0.1647) Data Time: 0.0134 (0.0309) Average Loss: 0.7861 (0.7027) Average CE Loss (Source):  0.7861 ( 0.7027) Learning Rate: 0.1000 (0.1000) Top1_base: 78.1250 (80.3906) Top1_base_per_class: 76.9253 (80.7195) 
Training Epoch: [178/1000] Step: [110 / 285] Batch Time: 0.1489 (0.1641) Data Time: 0.0119 (0.0301) Average Loss: 0.8368 (0.7038) Average CE Loss (Source):  0.8368 ( 0.7038) Learning Rate: 0.1000 (0.1000) Top1_base: 80.4688 (80.3551) Top1_base_per_class: 81.4081 (80.6988) 
Training Epoch: [178/1000] Step: [120 / 285] Batch Time: 0.1501 (0.1635) Data Time: 0.0119 (0.0295) Average Loss: 0.5615 (0.7021) Average CE Loss (Source):  0.5615 ( 0.7021) Learning Rate: 0.1000 (0.1000) Top1_base: 84.3750 (80.4362) Top1_base_per_class: 84.9415 (80.8768) 
Training Epoch: [178/1000] Step: [130 / 285] Batch Time: 0.1443 (0.1631) Data Time: 0.0135 (0.0291) Average Loss: 0.7490 (0.7042) Average CE Loss (Source):  0.7490 ( 0.7042) Learning Rate: 0.1000 (0.1000) Top1_base: 80.4688 (80.3546) Top1_base_per_class: 82.5397 (80.8039) 
Training Epoch: [178/1000] Step: [140 / 285] Batch Time: 0.1446 (0.1623) Data Time: 0.0138 (0.0283) Average Loss: 0.6446 (0.7001) Average CE Loss (Source):  0.6446 ( 0.7001) Learning Rate: 0.1000 (0.1000) Top1_base: 81.2500 (80.4855) Top1_base_per_class: 79.4545 (80.9346) 
Training Epoch: [178/1000] Step: [150 / 285] Batch Time: 0.1494 (0.1614) Data Time: 0.0116 (0.0276) Average Loss: 0.6614 (0.6985) Average CE Loss (Source):  0.6614 ( 0.6985) Learning Rate: 0.1000 (0.1000) Top1_base: 82.8125 (80.5938) Top1_base_per_class: 82.3030 (81.0617) 
Training Epoch: [178/1000] Step: [160 / 285] Batch Time: 0.1458 (0.1605) Data Time: 0.0141 (0.0267) Average Loss: 0.7310 (0.6995) Average CE Loss (Source):  0.7310 ( 0.6995) Learning Rate: 0.1000 (0.1000) Top1_base: 77.3438 (80.5371) Top1_base_per_class: 77.1472 (80.9723) 
Training Epoch: [178/1000] Step: [170 / 285] Batch Time: 0.1511 (0.1597) Data Time: 0.0158 (0.0259) Average Loss: 0.8134 (0.7001) Average CE Loss (Source):  0.8134 ( 0.7001) Learning Rate: 0.1000 (0.1000) Top1_base: 75.0000 (80.5377) Top1_base_per_class: 78.6012 (80.9924) 
Training Epoch: [178/1000] Step: [180 / 285] Batch Time: 0.1473 (0.1590) Data Time: 0.0127 (0.0253) Average Loss: 0.5577 (0.6992) Average CE Loss (Source):  0.5577 ( 0.6992) Learning Rate: 0.1000 (0.1000) Top1_base: 83.5938 (80.5642) Top1_base_per_class: 83.3333 (81.0272) 
Training Epoch: [178/1000] Step: [190 / 285] Batch Time: 0.1446 (0.1583) Data Time: 0.0140 (0.0247) Average Loss: 0.7591 (0.7014) Average CE Loss (Source):  0.7591 ( 0.7014) Learning Rate: 0.1000 (0.1000) Top1_base: 78.9062 (80.5345) Top1_base_per_class: 79.1612 (80.9367) 
Training Epoch: [178/1000] Step: [200 / 285] Batch Time: 0.1451 (0.1580) Data Time: 0.0115 (0.0244) Average Loss: 0.5391 (0.7019) Average CE Loss (Source):  0.5391 ( 0.7019) Learning Rate: 0.1000 (0.1000) Top1_base: 84.3750 (80.4805) Top1_base_per_class: 84.0643 (80.9096) 
Training Epoch: [178/1000] Step: [210 / 285] Batch Time: 0.1452 (0.1576) Data Time: 0.0139 (0.0240) Average Loss: 0.5501 (0.7055) Average CE Loss (Source):  0.5501 ( 0.7055) Learning Rate: 0.1000 (0.1000) Top1_base: 83.5938 (80.3460) Top1_base_per_class: 83.3974 (80.8080) 
Training Epoch: [178/1000] Step: [220 / 285] Batch Time: 0.1454 (0.1571) Data Time: 0.0114 (0.0235) Average Loss: 0.8655 (0.7088) Average CE Loss (Source):  0.8655 ( 0.7088) Learning Rate: 0.1000 (0.1000) Top1_base: 76.5625 (80.2699) Top1_base_per_class: 75.5263 (80.7533) 
Training Epoch: [178/1000] Step: [230 / 285] Batch Time: 0.1446 (0.1578) Data Time: 0.0114 (0.0242) Average Loss: 0.7509 (0.7120) Average CE Loss (Source):  0.7509 ( 0.7120) Learning Rate: 0.1000 (0.1000) Top1_base: 82.0312 (80.2276) Top1_base_per_class: 83.8889 (80.7160) 
Training Epoch: [178/1000] Step: [240 / 285] Batch Time: 0.1442 (0.1574) Data Time: 0.0107 (0.0239) Average Loss: 0.7958 (0.7127) Average CE Loss (Source):  0.7958 ( 0.7127) Learning Rate: 0.1000 (0.1000) Top1_base: 79.6875 (80.1660) Top1_base_per_class: 77.9023 (80.6308) 
Training Epoch: [178/1000] Step: [250 / 285] Batch Time: 0.1443 (0.1578) Data Time: 0.0105 (0.0243) Average Loss: 0.8307 (0.7157) Average CE Loss (Source):  0.8307 ( 0.7157) Learning Rate: 0.1000 (0.1000) Top1_base: 79.6875 (80.0969) Top1_base_per_class: 81.7296 (80.5460) 
Training Epoch: [178/1000] Step: [260 / 285] Batch Time: 0.1480 (0.1577) Data Time: 0.0118 (0.0242) Average Loss: 0.7631 (0.7150) Average CE Loss (Source):  0.7631 ( 0.7150) Learning Rate: 0.1000 (0.1000) Top1_base: 77.3438 (80.0751) Top1_base_per_class: 77.4107 (80.5135) 
Training Epoch: [178/1000] Step: [270 / 285] Batch Time: 0.1437 (0.1576) Data Time: 0.0119 (0.0241) Average Loss: 0.8794 (0.7172) Average CE Loss (Source):  0.8794 ( 0.7172) Learning Rate: 0.1000 (0.1000) Top1_base: 75.0000 (80.0434) Top1_base_per_class: 75.5758 (80.5065) 
Training Epoch: [178/1000] Step: [280 / 285] Batch Time: 0.1478 (0.1573) Data Time: 0.0115 (0.0238) Average Loss: 0.7972 (0.7208) Average CE Loss (Source):  0.7972 ( 0.7208) Learning Rate: 0.1000 (0.1000) Top1_base: 77.3438 (79.9693) Top1_base_per_class: 76.8713 (80.4292) 
Training Epoch: [179/1000] Step: [0] Batch Time: 0.1476 (0.1572) Data Time: 0.0157 (0.0236) Average Loss: 0.7137 (0.7208) Average CE Loss (Source):  0.7137 ( 0.7208) Learning Rate: 0.1000 (0.1000) Top1_base: 78.9062 (79.9698) Top1_base_per_class: 79.9697 (80.4295) 
Training Epoch: [179/1000] Step: [10 / 285] Batch Time: 0.1446 (0.2279) Data Time: 0.0133 (0.0955) Average Loss: 0.8191 (0.7495) Average CE Loss (Source):  0.8191 ( 0.7495) Learning Rate: 0.1000 (0.1000) Top1_base: 78.1250 (79.2188) Top1_base_per_class: 81.5909 (79.8031) 
Training Epoch: [179/1000] Step: [20 / 285] Batch Time: 0.1450 (0.1984) Data Time: 0.0114 (0.0656) Average Loss: 0.7236 (0.7417) Average CE Loss (Source):  0.7236 ( 0.7417) Learning Rate: 0.1000 (0.1000) Top1_base: 82.8125 (79.0625) Top1_base_per_class: 86.7836 (79.3160) 
Training Epoch: [179/1000] Step: [30 / 285] Batch Time: 0.2160 (0.1880) Data Time: 0.0836 (0.0553) Average Loss: 0.6860 (0.7316) Average CE Loss (Source):  0.6860 ( 0.7316) Learning Rate: 0.1000 (0.1000) Top1_base: 83.5938 (79.7135) Top1_base_per_class: 84.0774 (80.4898) 
Training Epoch: [179/1000] Step: [40 / 285] Batch Time: 0.1446 (0.1802) Data Time: 0.0105 (0.0475) Average Loss: 0.6559 (0.7211) Average CE Loss (Source):  0.6559 ( 0.7211) Learning Rate: 0.1000 (0.1000) Top1_base: 81.2500 (79.8438) Top1_base_per_class: 81.3072 (80.5134) 
Training Epoch: [179/1000] Step: [50 / 285] Batch Time: 0.1478 (0.1745) Data Time: 0.0162 (0.0416) Average Loss: 0.6013 (0.7207) Average CE Loss (Source):  0.6013 ( 0.7207) Learning Rate: 0.1000 (0.1000) Top1_base: 84.3750 (79.7656) Top1_base_per_class: 84.7273 (80.4986) 
Training Epoch: [179/1000] Step: [60 / 285] Batch Time: 0.1430 (0.1734) Data Time: 0.0102 (0.0405) Average Loss: 0.7368 (0.7213) Average CE Loss (Source):  0.7368 ( 0.7213) Learning Rate: 0.1000 (0.1000) Top1_base: 78.1250 (79.6354) Top1_base_per_class: 80.2721 (80.3437) 
Training Epoch: [179/1000] Step: [70 / 285] Batch Time: 0.1485 (0.1709) Data Time: 0.0158 (0.0379) Average Loss: 0.6054 (0.7145) Average CE Loss (Source):  0.6054 ( 0.7145) Learning Rate: 0.1000 (0.1000) Top1_base: 82.0312 (79.8103) Top1_base_per_class: 85.8688 (80.4617) 
Training Epoch: [179/1000] Step: [80 / 285] Batch Time: 0.1452 (0.1685) Data Time: 0.0104 (0.0355) Average Loss: 0.7938 (0.7049) Average CE Loss (Source):  0.7938 ( 0.7049) Learning Rate: 0.1000 (0.1000) Top1_base: 76.5625 (80.1953) Top1_base_per_class: 81.8240 (80.7262) 
Training Epoch: [179/1000] Step: [90 / 285] Batch Time: 0.1468 (0.1663) Data Time: 0.0135 (0.0333) Average Loss: 0.7790 (0.7017) Average CE Loss (Source):  0.7790 ( 0.7017) Learning Rate: 0.1000 (0.1000) Top1_base: 77.3438 (80.3993) Top1_base_per_class: 74.1195 (80.8829) 
Training Epoch: [179/1000] Step: [100 / 285] Batch Time: 0.1440 (0.1647) Data Time: 0.0103 (0.0318) Average Loss: 0.7089 (0.7011) Average CE Loss (Source):  0.7089 ( 0.7011) Learning Rate: 0.1000 (0.1000) Top1_base: 77.3438 (80.3750) Top1_base_per_class: 78.0994 (80.8940) 
Training Epoch: [179/1000] Step: [110 / 285] Batch Time: 0.1466 (0.1643) Data Time: 0.0135 (0.0314) Average Loss: 0.7528 (0.7005) Average CE Loss (Source):  0.7528 ( 0.7005) Learning Rate: 0.1000 (0.1000) Top1_base: 78.1250 (80.3906) Top1_base_per_class: 78.2554 (80.9130) 
Training Epoch: [179/1000] Step: [120 / 285] Batch Time: 0.1462 (0.1634) Data Time: 0.0109 (0.0304) Average Loss: 0.9083 (0.7017) Average CE Loss (Source):  0.9083 ( 0.7017) Learning Rate: 0.1000 (0.1000) Top1_base: 74.2188 (80.3190) Top1_base_per_class: 75.4762 (80.9415) 
Training Epoch: [179/1000] Step: [130 / 285] Batch Time: 0.1437 (0.1630) Data Time: 0.0124 (0.0300) Average Loss: 0.8641 (0.7045) Average CE Loss (Source):  0.8641 ( 0.7045) Learning Rate: 0.1000 (0.1000) Top1_base: 76.5625 (80.2584) Top1_base_per_class: 79.4242 (80.9261) 
Training Epoch: [179/1000] Step: [140 / 285] Batch Time: 0.1440 (0.1623) Data Time: 0.0102 (0.0294) Average Loss: 0.6771 (0.7061) Average CE Loss (Source):  0.6771 ( 0.7061) Learning Rate: 0.1000 (0.1000) Top1_base: 82.0312 (80.3125) Top1_base_per_class: 81.3636 (80.9269) 
Training Epoch: [179/1000] Step: [150 / 285] Batch Time: 0.1429 (0.1618) Data Time: 0.0107 (0.0289) Average Loss: 0.7149 (0.7074) Average CE Loss (Source):  0.7149 ( 0.7074) Learning Rate: 0.1000 (0.1000) Top1_base: 80.4688 (80.2552) Top1_base_per_class: 80.3395 (80.8594) 
Training Epoch: [179/1000] Step: [160 / 285] Batch Time: 0.1440 (0.1616) Data Time: 0.0117 (0.0288) Average Loss: 0.8891 (0.7082) Average CE Loss (Source):  0.8891 ( 0.7082) Learning Rate: 0.1000 (0.1000) Top1_base: 79.6875 (80.3076) Top1_base_per_class: 81.0374 (80.9051) 
Training Epoch: [179/1000] Step: [170 / 285] Batch Time: 0.1443 (0.1612) Data Time: 0.0128 (0.0284) Average Loss: 0.6045 (0.7082) Average CE Loss (Source):  0.6045 ( 0.7082) Learning Rate: 0.1000 (0.1000) Top1_base: 85.1562 (80.3079) Top1_base_per_class: 86.6049 (80.8386) 
Training Epoch: [179/1000] Step: [180 / 285] Batch Time: 0.1427 (0.1605) Data Time: 0.0117 (0.0277) Average Loss: 0.7293 (0.7078) Average CE Loss (Source):  0.7293 ( 0.7078) Learning Rate: 0.1000 (0.1000) Top1_base: 80.4688 (80.3342) Top1_base_per_class: 78.5714 (80.8897) 
Training Epoch: [179/1000] Step: [190 / 285] Batch Time: 0.1456 (0.1597) Data Time: 0.0137 (0.0269) Average Loss: 0.7561 (0.7102) Average CE Loss (Source):  0.7561 ( 0.7102) Learning Rate: 0.1000 (0.1000) Top1_base: 78.9062 (80.2385) Top1_base_per_class: 80.8182 (80.8260) 
Training Epoch: [179/1000] Step: [200 / 285] Batch Time: 0.1402 (0.1590) Data Time: 0.0114 (0.0264) Average Loss: 0.6832 (0.7120) Average CE Loss (Source):  0.6832 ( 0.7120) Learning Rate: 0.1000 (0.1000) Top1_base: 82.0312 (80.1484) Top1_base_per_class: 84.1755 (80.7463) 
Training Epoch: [179/1000] Step: [210 / 285] Batch Time: 0.1479 (0.1586) Data Time: 0.0133 (0.0259) Average Loss: 0.6202 (0.7127) Average CE Loss (Source):  0.6202 ( 0.7127) Learning Rate: 0.1000 (0.1000) Top1_base: 82.0312 (80.1265) Top1_base_per_class: 81.1309 (80.7575) 
Training Epoch: [179/1000] Step: [220 / 285] Batch Time: 0.1445 (0.1584) Data Time: 0.0105 (0.0257) Average Loss: 0.8811 (0.7168) Average CE Loss (Source):  0.8811 ( 0.7168) Learning Rate: 0.1000 (0.1000) Top1_base: 75.7812 (80.0142) Top1_base_per_class: 76.8767 (80.6491) 
Training Epoch: [179/1000] Step: [230 / 285] Batch Time: 0.1492 (0.1580) Data Time: 0.0166 (0.0252) Average Loss: 0.9238 (0.7190) Average CE Loss (Source):  0.9238 ( 0.7190) Learning Rate: 0.1000 (0.1000) Top1_base: 79.6875 (79.9898) Top1_base_per_class: 78.6158 (80.6016) 
Training Epoch: [179/1000] Step: [240 / 285] Batch Time: 0.1469 (0.1576) Data Time: 0.0120 (0.0248) Average Loss: 0.6739 (0.7219) Average CE Loss (Source):  0.6739 ( 0.7219) Learning Rate: 0.1000 (0.1000) Top1_base: 76.5625 (79.9023) Top1_base_per_class: 77.8788 (80.4944) 
Training Epoch: [179/1000] Step: [250 / 285] Batch Time: 0.1482 (0.1572) Data Time: 0.0154 (0.0244) Average Loss: 0.6792 (0.7230) Average CE Loss (Source):  0.6792 ( 0.7230) Learning Rate: 0.1000 (0.1000) Top1_base: 78.1250 (79.7781) Top1_base_per_class: 79.7619 (80.3328) 
Training Epoch: [179/1000] Step: [260 / 285] Batch Time: 0.1453 (0.1575) Data Time: 0.0105 (0.0246) Average Loss: 0.7474 (0.7247) Average CE Loss (Source):  0.7474 ( 0.7247) Learning Rate: 0.1000 (0.1000) Top1_base: 82.0312 (79.6995) Top1_base_per_class: 81.8362 (80.2875) 
Training Epoch: [179/1000] Step: [270 / 285] Batch Time: 0.1470 (0.1572) Data Time: 0.0129 (0.0243) Average Loss: 0.8507 (0.7258) Average CE Loss (Source):  0.8507 ( 0.7258) Learning Rate: 0.1000 (0.1000) Top1_base: 76.5625 (79.6759) Top1_base_per_class: 74.0385 (80.2104) 
Training Epoch: [179/1000] Step: [280 / 285] Batch Time: 0.1444 (0.1574) Data Time: 0.0103 (0.0245) Average Loss: 0.7516 (0.7263) Average CE Loss (Source):  0.7516 ( 0.7263) Learning Rate: 0.1000 (0.1000) Top1_base: 78.9062 (79.6233) Top1_base_per_class: 79.4855 (80.1265) 
Training Epoch: [180/1000] Step: [0] Batch Time: 0.1438 (0.1572) Data Time: 0.0124 (0.0243) Average Loss: 0.7792 (0.7272) Average CE Loss (Source):  0.7792 ( 0.7272) Learning Rate: 0.1000 (0.1000) Top1_base: 75.0000 (79.5943) Top1_base_per_class: 74.9248 (80.0996) 
 18%|█▊        | 180/1000 [2:19:53<10:34:34, 46.43s/it] 18%|█▊        | 181/1000 [2:20:37<10:24:40, 45.76s/it]Training Epoch: [180/1000] Step: [10 / 285] Batch Time: 0.1440 (0.2529) Data Time: 0.0119 (0.1208) Average Loss: 0.4985 (0.7194) Average CE Loss (Source):  0.4985 ( 0.7194) Learning Rate: 0.1000 (0.1000) Top1_base: 88.2812 (78.5156) Top1_base_per_class: 88.1090 (78.8630) 
Training Epoch: [180/1000] Step: [20 / 285] Batch Time: 0.1462 (0.2093) Data Time: 0.0127 (0.0769) Average Loss: 0.6603 (0.6806) Average CE Loss (Source):  0.6603 ( 0.6806) Learning Rate: 0.1000 (0.1000) Top1_base: 80.4688 (80.3906) Top1_base_per_class: 81.4481 (80.8842) 
Training Epoch: [180/1000] Step: [30 / 285] Batch Time: 0.1440 (0.1935) Data Time: 0.0107 (0.0613) Average Loss: 0.5511 (0.6762) Average CE Loss (Source):  0.5511 ( 0.6762) Learning Rate: 0.1000 (0.1000) Top1_base: 87.5000 (80.8333) Top1_base_per_class: 89.0351 (81.3589) 
Training Epoch: [180/1000] Step: [40 / 285] Batch Time: 0.1482 (0.1830) Data Time: 0.0141 (0.0499) Average Loss: 0.7088 (0.6821) Average CE Loss (Source):  0.7088 ( 0.6821) Learning Rate: 0.1000 (0.1000) Top1_base: 78.1250 (80.5469) Top1_base_per_class: 81.1111 (81.0443) 
Training Epoch: [180/1000] Step: [50 / 285] Batch Time: 0.1427 (0.1763) Data Time: 0.0113 (0.0427) Average Loss: 0.6314 (0.6808) Average CE Loss (Source):  0.6314 ( 0.6808) Learning Rate: 0.1000 (0.1000) Top1_base: 81.2500 (80.6250) Top1_base_per_class: 79.6429 (81.1226) 
Training Epoch: [180/1000] Step: [60 / 285] Batch Time: 0.1447 (0.1736) Data Time: 0.0131 (0.0402) Average Loss: 0.7135 (0.6728) Average CE Loss (Source):  0.7135 ( 0.6728) Learning Rate: 0.1000 (0.1000) Top1_base: 81.2500 (80.8203) Top1_base_per_class: 82.6970 (81.3245) 
Training Epoch: [180/1000] Step: [70 / 285] Batch Time: 0.1438 (0.1707) Data Time: 0.0128 (0.0371) Average Loss: 0.9904 (0.6808) Average CE Loss (Source):  0.9904 ( 0.6808) Learning Rate: 0.1000 (0.1000) Top1_base: 76.5625 (80.7701) Top1_base_per_class: 82.5724 (81.3296) 
Training Epoch: [180/1000] Step: [80 / 285] Batch Time: 0.1461 (0.1676) Data Time: 0.0143 (0.0342) Average Loss: 0.6240 (0.6818) Average CE Loss (Source):  0.6240 ( 0.6818) Learning Rate: 0.1000 (0.1000) Top1_base: 82.0312 (80.7520) Top1_base_per_class: 84.0566 (81.2034) 
Training Epoch: [180/1000] Step: [90 / 285] Batch Time: 0.1463 (0.1668) Data Time: 0.0121 (0.0334) Average Loss: 0.9798 (0.6876) Average CE Loss (Source):  0.9798 ( 0.6876) Learning Rate: 0.1000 (0.1000) Top1_base: 74.2188 (80.6771) Top1_base_per_class: 76.0897 (81.1499) 
Training Epoch: [180/1000] Step: [100 / 285] Batch Time: 0.1453 (0.1651) Data Time: 0.0122 (0.0316) Average Loss: 0.6572 (0.6872) Average CE Loss (Source):  0.6572 ( 0.6872) Learning Rate: 0.1000 (0.1000) Top1_base: 82.8125 (80.6797) Top1_base_per_class: 82.6603 (81.1984) 
Training Epoch: [180/1000] Step: [110 / 285] Batch Time: 0.1458 (0.1637) Data Time: 0.0148 (0.0303) Average Loss: 0.6908 (0.6829) Average CE Loss (Source):  0.6908 ( 0.6829) Learning Rate: 0.1000 (0.1000) Top1_base: 79.6875 (80.8026) Top1_base_per_class: 78.3648 (81.3133) 
Training Epoch: [180/1000] Step: [120 / 285] Batch Time: 0.1451 (0.1627) Data Time: 0.0120 (0.0292) Average Loss: 0.9350 (0.6836) Average CE Loss (Source):  0.9350 ( 0.6836) Learning Rate: 0.1000 (0.1000) Top1_base: 75.0000 (80.7812) Top1_base_per_class: 73.0278 (81.2370) 
Training Epoch: [180/1000] Step: [130 / 285] Batch Time: 0.1491 (0.1619) Data Time: 0.0129 (0.0281) Average Loss: 0.7280 (0.6813) Average CE Loss (Source):  0.7280 ( 0.6813) Learning Rate: 0.1000 (0.1000) Top1_base: 75.7812 (80.7692) Top1_base_per_class: 77.2619 (81.2303) 
Training Epoch: [180/1000] Step: [140 / 285] Batch Time: 0.1470 (0.1610) Data Time: 0.0150 (0.0271) Average Loss: 0.6073 (0.6869) Average CE Loss (Source):  0.6073 ( 0.6869) Learning Rate: 0.1000 (0.1000) Top1_base: 82.0312 (80.6250) Top1_base_per_class: 83.9744 (81.1359) 
Training Epoch: [180/1000] Step: [150 / 285] Batch Time: 0.1450 (0.1601) Data Time: 0.0118 (0.0263) Average Loss: 0.6974 (0.6903) Average CE Loss (Source):  0.6974 ( 0.6903) Learning Rate: 0.1000 (0.1000) Top1_base: 78.1250 (80.5156) Top1_base_per_class: 78.1173 (81.0700) 
Training Epoch: [180/1000] Step: [160 / 285] Batch Time: 0.1445 (0.1592) Data Time: 0.0135 (0.0255) Average Loss: 0.6495 (0.6968) Average CE Loss (Source):  0.6495 ( 0.6968) Learning Rate: 0.1000 (0.1000) Top1_base: 82.8125 (80.3516) Top1_base_per_class: 78.5152 (80.8778) 
Training Epoch: [180/1000] Step: [170 / 285] Batch Time: 0.1446 (0.1584) Data Time: 0.0123 (0.0247) Average Loss: 0.5771 (0.6956) Average CE Loss (Source):  0.5771 ( 0.6956) Learning Rate: 0.1000 (0.1000) Top1_base: 80.4688 (80.3401) Top1_base_per_class: 79.8397 (80.8514) 
Training Epoch: [180/1000] Step: [180 / 285] Batch Time: 0.1462 (0.1578) Data Time: 0.0149 (0.0241) Average Loss: 0.6522 (0.6969) Average CE Loss (Source):  0.6522 ( 0.6969) Learning Rate: 0.1000 (0.1000) Top1_base: 81.2500 (80.3125) Top1_base_per_class: 80.8908 (80.8426) 
Training Epoch: [180/1000] Step: [190 / 285] Batch Time: 0.1491 (0.1573) Data Time: 0.0160 (0.0237) Average Loss: 0.7467 (0.7009) Average CE Loss (Source):  0.7467 ( 0.7009) Learning Rate: 0.1000 (0.1000) Top1_base: 77.3438 (80.1604) Top1_base_per_class: 76.6667 (80.7394) 
Training Epoch: [180/1000] Step: [200 / 285] Batch Time: 0.1452 (0.1569) Data Time: 0.0129 (0.0233) Average Loss: 0.7939 (0.7007) Average CE Loss (Source):  0.7939 ( 0.7007) Learning Rate: 0.1000 (0.1000) Top1_base: 75.7812 (80.1641) Top1_base_per_class: 77.4214 (80.7447) 
Training Epoch: [180/1000] Step: [210 / 285] Batch Time: 0.1455 (0.1565) Data Time: 0.0117 (0.0230) Average Loss: 0.6887 (0.7032) Average CE Loss (Source):  0.6887 ( 0.7032) Learning Rate: 0.1000 (0.1000) Top1_base: 81.2500 (80.0930) Top1_base_per_class: 84.8560 (80.7465) 
Training Epoch: [180/1000] Step: [220 / 285] Batch Time: 0.1457 (0.1561) Data Time: 0.0133 (0.0226) Average Loss: 0.6737 (0.7052) Average CE Loss (Source):  0.6737 ( 0.7052) Learning Rate: 0.1000 (0.1000) Top1_base: 80.4688 (80.0142) Top1_base_per_class: 85.9120 (80.6626) 
Training Epoch: [180/1000] Step: [230 / 285] Batch Time: 0.1441 (0.1560) Data Time: 0.0134 (0.0225) Average Loss: 0.7330 (0.7069) Average CE Loss (Source):  0.7330 ( 0.7069) Learning Rate: 0.1000 (0.1000) Top1_base: 76.5625 (79.9558) Top1_base_per_class: 76.5027 (80.5746) 
Training Epoch: [180/1000] Step: [240 / 285] Batch Time: 0.1494 (0.1560) Data Time: 0.0162 (0.0225) Average Loss: 0.6483 (0.7072) Average CE Loss (Source):  0.6483 ( 0.7072) Learning Rate: 0.1000 (0.1000) Top1_base: 81.2500 (79.9089) Top1_base_per_class: 82.8161 (80.4654) 
Training Epoch: [180/1000] Step: [250 / 285] Batch Time: 0.1426 (0.1557) Data Time: 0.0119 (0.0222) Average Loss: 0.5569 (0.7058) Average CE Loss (Source):  0.5569 ( 0.7058) Learning Rate: 0.1000 (0.1000) Top1_base: 79.6875 (79.9031) Top1_base_per_class: 81.9665 (80.4478) 
Training Epoch: [180/1000] Step: [260 / 285] Batch Time: 0.1476 (0.1553) Data Time: 0.0139 (0.0219) Average Loss: 0.7313 (0.7052) Average CE Loss (Source):  0.7313 ( 0.7052) Learning Rate: 0.1000 (0.1000) Top1_base: 78.9062 (79.9940) Top1_base_per_class: 78.3036 (80.5270) 
Training Epoch: [180/1000] Step: [270 / 285] Batch Time: 0.1449 (0.1550) Data Time: 0.0138 (0.0216) Average Loss: 0.8999 (0.7072) Average CE Loss (Source):  0.8999 ( 0.7072) Learning Rate: 0.1000 (0.1000) Top1_base: 78.9062 (79.9971) Top1_base_per_class: 77.5758 (80.5071) 
Training Epoch: [180/1000] Step: [280 / 285] Batch Time: 0.2147 (0.1550) Data Time: 0.0822 (0.0217) Average Loss: 0.8561 (0.7085) Average CE Loss (Source):  0.8561 ( 0.7085) Learning Rate: 0.1000 (0.1000) Top1_base: 75.0000 (80.0195) Top1_base_per_class: 76.8707 (80.5343) 
Training Epoch: [181/1000] Step: [0] Batch Time: 0.1444 (0.1549) Data Time: 0.0137 (0.0215) Average Loss: 0.8817 (0.7092) Average CE Loss (Source):  0.8817 ( 0.7092) Learning Rate: 0.1000 (0.1000) Top1_base: 75.0000 (79.9973) Top1_base_per_class: 78.3041 (80.5550) 
Training Epoch: [181/1000] Step: [10 / 285] Batch Time: 0.1438 (0.2513) Data Time: 0.0102 (0.1185) Average Loss: 0.6808 (0.6744) Average CE Loss (Source):  0.6808 ( 0.6744) Learning Rate: 0.0500 (0.0500) Top1_base: 81.2500 (81.2500) Top1_base_per_class: 81.9941 (81.9885) 
Training Epoch: [181/1000] Step: [20 / 285] Batch Time: 0.1425 (0.2065) Data Time: 0.0108 (0.0737) Average Loss: 0.5637 (0.6302) Average CE Loss (Source):  0.5637 ( 0.6302) Learning Rate: 0.0500 (0.0500) Top1_base: 82.8125 (82.8906) Top1_base_per_class: 84.2424 (83.5140) 
Training Epoch: [181/1000] Step: [30 / 285] Batch Time: 0.1430 (0.1914) Data Time: 0.0116 (0.0588) Average Loss: 0.6983 (0.6214) Average CE Loss (Source):  0.6983 ( 0.6214) Learning Rate: 0.0500 (0.0500) Top1_base: 78.9062 (83.1510) Top1_base_per_class: 82.1930 (83.9262) 
Training Epoch: [181/1000] Step: [40 / 285] Batch Time: 0.1435 (0.1825) Data Time: 0.0120 (0.0500) Average Loss: 0.5127 (0.6183) Average CE Loss (Source):  0.5127 ( 0.6183) Learning Rate: 0.0500 (0.0500) Top1_base: 85.1562 (83.2812) Top1_base_per_class: 86.1310 (84.0969) 
Training Epoch: [181/1000] Step: [50 / 285] Batch Time: 0.1446 (0.1784) Data Time: 0.0101 (0.0459) Average Loss: 0.6941 (0.6113) Average CE Loss (Source):  0.6941 ( 0.6113) Learning Rate: 0.0500 (0.0500) Top1_base: 81.2500 (83.2656) Top1_base_per_class: 81.6220 (83.9971) 
Training Epoch: [181/1000] Step: [60 / 285] Batch Time: 0.1457 (0.1731) Data Time: 0.0133 (0.0407) Average Loss: 0.5866 (0.6067) Average CE Loss (Source):  0.5866 ( 0.6067) Learning Rate: 0.0500 (0.0500) Top1_base: 85.1562 (83.5938) Top1_base_per_class: 86.0909 (84.1198) 
Training Epoch: [181/1000] Step: [70 / 285] Batch Time: 0.1455 (0.1702) Data Time: 0.0116 (0.0377) Average Loss: 0.4937 (0.6116) Average CE Loss (Source):  0.4937 ( 0.6116) Learning Rate: 0.0500 (0.0500) Top1_base: 85.1562 (83.4040) Top1_base_per_class: 81.9697 (84.0674) 
Training Epoch: [181/1000] Step: [80 / 285] Batch Time: 0.1496 (0.1675) Data Time: 0.0156 (0.0350) Average Loss: 0.3191 (0.6041) Average CE Loss (Source):  0.3191 ( 0.6041) Learning Rate: 0.0500 (0.0500) Top1_base: 89.8438 (83.4961) Top1_base_per_class: 91.0714 (84.1202) 
Training Epoch: [181/1000] Step: [90 / 285] Batch Time: 0.1469 (0.1653) Data Time: 0.0109 (0.0326) Average Loss: 0.4971 (0.5908) Average CE Loss (Source):  0.4971 ( 0.5908) Learning Rate: 0.0500 (0.0500) Top1_base: 82.8125 (83.7413) Top1_base_per_class: 81.2713 (84.2942) 
Training Epoch: [181/1000] Step: [100 / 285] Batch Time: 0.1459 (0.1637) Data Time: 0.0130 (0.0307) Average Loss: 0.6279 (0.5893) Average CE Loss (Source):  0.6279 ( 0.5893) Learning Rate: 0.0500 (0.0500) Top1_base: 81.2500 (83.7891) Top1_base_per_class: 84.7934 (84.4109) 
Training Epoch: [181/1000] Step: [110 / 285] Batch Time: 0.1424 (0.1621) Data Time: 0.0113 (0.0290) Average Loss: 0.6202 (0.5856) Average CE Loss (Source):  0.6202 ( 0.5856) Learning Rate: 0.0500 (0.0500) Top1_base: 81.2500 (83.8210) Top1_base_per_class: 80.3774 (84.3912) 
Training Epoch: [181/1000] Step: [120 / 285] Batch Time: 0.1451 (0.1607) Data Time: 0.0132 (0.0277) Average Loss: 0.4955 (0.5822) Average CE Loss (Source):  0.4955 ( 0.5822) Learning Rate: 0.0500 (0.0500) Top1_base: 84.3750 (83.8997) Top1_base_per_class: 84.0476 (84.4644) 
Training Epoch: [181/1000] Step: [130 / 285] Batch Time: 0.1418 (0.1611) Data Time: 0.0112 (0.0282) Average Loss: 0.5441 (0.5822) Average CE Loss (Source):  0.5441 ( 0.5822) Learning Rate: 0.0500 (0.0500) Top1_base: 83.5938 (83.8882) Top1_base_per_class: 83.3416 (84.3921) 
Training Epoch: [181/1000] Step: [140 / 285] Batch Time: 0.1458 (0.1604) Data Time: 0.0130 (0.0275) Average Loss: 0.4856 (0.5822) Average CE Loss (Source):  0.4856 ( 0.5822) Learning Rate: 0.0500 (0.0500) Top1_base: 87.5000 (83.9509) Top1_base_per_class: 85.7441 (84.4701) 
Training Epoch: [181/1000] Step: [150 / 285] Batch Time: 0.1447 (0.1600) Data Time: 0.0107 (0.0271) Average Loss: 0.4761 (0.5801) Average CE Loss (Source):  0.4761 ( 0.5801) Learning Rate: 0.0500 (0.0500) Top1_base: 89.0625 (84.0208) Top1_base_per_class: 89.9394 (84.5344) 
Training Epoch: [181/1000] Step: [160 / 285] Batch Time: 0.1450 (0.1604) Data Time: 0.0120 (0.0275) Average Loss: 0.4440 (0.5757) Average CE Loss (Source):  0.4440 ( 0.5757) Learning Rate: 0.0500 (0.0500) Top1_base: 85.9375 (84.0918) Top1_base_per_class: 87.5731 (84.6046) 
Training Epoch: [181/1000] Step: [170 / 285] Batch Time: 0.1434 (0.1600) Data Time: 0.0117 (0.0271) Average Loss: 0.5718 (0.5686) Average CE Loss (Source):  0.5718 ( 0.5686) Learning Rate: 0.0500 (0.0500) Top1_base: 85.9375 (84.3474) Top1_base_per_class: 87.5553 (84.8391) 
Training Epoch: [181/1000] Step: [180 / 285] Batch Time: 0.1434 (0.1594) Data Time: 0.0119 (0.0265) Average Loss: 0.5485 (0.5656) Average CE Loss (Source):  0.5485 ( 0.5656) Learning Rate: 0.0500 (0.0500) Top1_base: 82.8125 (84.4097) Top1_base_per_class: 84.6810 (84.9518) 
Training Epoch: [181/1000] Step: [190 / 285] Batch Time: 0.1452 (0.1591) Data Time: 0.0109 (0.0262) Average Loss: 0.4739 (0.5597) Average CE Loss (Source):  0.4739 ( 0.5597) Learning Rate: 0.0500 (0.0500) Top1_base: 89.8438 (84.5559) Top1_base_per_class: 90.7879 (85.0534) 
Training Epoch: [181/1000] Step: [200 / 285] Batch Time: 0.1419 (0.1586) Data Time: 0.0121 (0.0257) Average Loss: 0.4601 (0.5592) Average CE Loss (Source):  0.4601 ( 0.5592) Learning Rate: 0.0500 (0.0500) Top1_base: 89.0625 (84.5781) Top1_base_per_class: 88.7582 (85.0409) 
Training Epoch: [181/1000] Step: [210 / 285] Batch Time: 0.1468 (0.1583) Data Time: 0.0109 (0.0253) Average Loss: 0.6083 (0.5582) Average CE Loss (Source):  0.6083 ( 0.5582) Learning Rate: 0.0500 (0.0500) Top1_base: 83.5938 (84.6019) Top1_base_per_class: 86.7084 (85.1204) 
Training Epoch: [181/1000] Step: [220 / 285] Batch Time: 0.1460 (0.1579) Data Time: 0.0117 (0.0250) Average Loss: 0.5646 (0.5575) Average CE Loss (Source):  0.5646 ( 0.5575) Learning Rate: 0.0500 (0.0500) Top1_base: 84.3750 (84.6058) Top1_base_per_class: 85.1616 (85.0943) 
Training Epoch: [181/1000] Step: [230 / 285] Batch Time: 0.1420 (0.1580) Data Time: 0.0117 (0.0250) Average Loss: 0.4117 (0.5558) Average CE Loss (Source):  0.4117 ( 0.5558) Learning Rate: 0.0500 (0.0500) Top1_base: 89.8438 (84.6569) Top1_base_per_class: 89.7756 (85.1399) 
Training Epoch: [181/1000] Step: [240 / 285] Batch Time: 0.1462 (0.1576) Data Time: 0.0132 (0.0246) Average Loss: 0.4535 (0.5524) Average CE Loss (Source):  0.4535 ( 0.5524) Learning Rate: 0.0500 (0.0500) Top1_base: 85.9375 (84.7233) Top1_base_per_class: 88.9654 (85.1900) 
Training Epoch: [181/1000] Step: [250 / 285] Batch Time: 0.1457 (0.1572) Data Time: 0.0114 (0.0242) Average Loss: 0.4444 (0.5517) Average CE Loss (Source):  0.4444 ( 0.5517) Learning Rate: 0.0500 (0.0500) Top1_base: 86.7188 (84.7094) Top1_base_per_class: 87.0115 (85.1535) 
Training Epoch: [181/1000] Step: [260 / 285] Batch Time: 0.1470 (0.1568) Data Time: 0.0139 (0.0238) Average Loss: 0.3820 (0.5498) Average CE Loss (Source):  0.3820 ( 0.5498) Learning Rate: 0.0500 (0.0500) Top1_base: 88.2812 (84.7566) Top1_base_per_class: 92.1981 (85.2173) 
Training Epoch: [181/1000] Step: [270 / 285] Batch Time: 0.1472 (0.1565) Data Time: 0.0115 (0.0235) Average Loss: 0.5182 (0.5475) Average CE Loss (Source):  0.5182 ( 0.5475) Learning Rate: 0.0500 (0.0500) Top1_base: 84.3750 (84.8264) Top1_base_per_class: 88.1548 (85.2672) 
Training Epoch: [181/1000] Step: [280 / 285] Batch Time: 0.1454 (0.1561) Data Time: 0.0132 (0.0231) Average Loss: 0.4331 (0.5470) Average CE Loss (Source):  0.4331 ( 0.5470) Learning Rate: 0.0500 (0.0500) Top1_base: 89.0625 (84.8493) Top1_base_per_class: 88.0952 (85.3244) 
Training Epoch: [182/1000] Step: [0] Batch Time: 0.1817 (0.1560) Data Time: 0.0492 (0.0230) Average Loss: 0.4897 (0.5468) Average CE Loss (Source):  0.4897 ( 0.5468) Learning Rate: 0.0500 (0.0500) Top1_base: 82.8125 (84.8465) Top1_base_per_class: 80.2976 (85.2951) 
 18%|█▊        | 182/1000 [2:21:24<10:30:23, 46.24s/it] 18%|█▊        | 183/1000 [2:22:08<10:20:51, 45.60s/it]Training Epoch: [182/1000] Step: [10 / 285] Batch Time: 0.1482 (0.2327) Data Time: 0.0162 (0.1005) Average Loss: 0.4030 (0.4398) Average CE Loss (Source):  0.4030 ( 0.4398) Learning Rate: 0.0500 (0.0500) Top1_base: 92.1875 (87.5781) Top1_base_per_class: 92.9167 (87.2632) 
Training Epoch: [182/1000] Step: [20 / 285] Batch Time: 0.1447 (0.1957) Data Time: 0.0122 (0.0633) Average Loss: 0.5677 (0.4696) Average CE Loss (Source):  0.5677 ( 0.4696) Learning Rate: 0.0500 (0.0500) Top1_base: 85.1562 (87.1875) Top1_base_per_class: 85.2724 (86.9510) 
Training Epoch: [182/1000] Step: [30 / 285] Batch Time: 0.1444 (0.1870) Data Time: 0.0104 (0.0544) Average Loss: 0.2682 (0.4785) Average CE Loss (Source):  0.2682 ( 0.4785) Learning Rate: 0.0500 (0.0500) Top1_base: 93.7500 (86.9792) Top1_base_per_class: 95.4310 (87.2079) 
Training Epoch: [182/1000] Step: [40 / 285] Batch Time: 0.1433 (0.1826) Data Time: 0.0104 (0.0500) Average Loss: 0.5594 (0.4719) Average CE Loss (Source):  0.5594 ( 0.4719) Learning Rate: 0.0500 (0.0500) Top1_base: 85.1562 (87.2461) Top1_base_per_class: 85.4938 (87.3933) 
Training Epoch: [182/1000] Step: [50 / 285] Batch Time: 0.1446 (0.1767) Data Time: 0.0109 (0.0441) Average Loss: 0.4157 (0.4835) Average CE Loss (Source):  0.4157 ( 0.4835) Learning Rate: 0.0500 (0.0500) Top1_base: 90.6250 (86.9062) Top1_base_per_class: 89.4915 (87.0666) 
Training Epoch: [182/1000] Step: [60 / 285] Batch Time: 0.1467 (0.1723) Data Time: 0.0112 (0.0395) Average Loss: 0.5536 (0.4892) Average CE Loss (Source):  0.5536 ( 0.4892) Learning Rate: 0.0500 (0.0500) Top1_base: 84.3750 (86.7708) Top1_base_per_class: 85.0000 (87.1032) 
Training Epoch: [182/1000] Step: [70 / 285] Batch Time: 0.1472 (0.1689) Data Time: 0.0110 (0.0358) Average Loss: 0.4139 (0.4824) Average CE Loss (Source):  0.4139 ( 0.4824) Learning Rate: 0.0500 (0.0500) Top1_base: 89.0625 (86.8638) Top1_base_per_class: 89.2284 (87.3310) 
Training Epoch: [182/1000] Step: [80 / 285] Batch Time: 0.1423 (0.1660) Data Time: 0.0119 (0.0330) Average Loss: 0.5751 (0.4824) Average CE Loss (Source):  0.5751 ( 0.4824) Learning Rate: 0.0500 (0.0500) Top1_base: 83.5938 (86.7676) Top1_base_per_class: 85.6731 (87.3281) 
Training Epoch: [182/1000] Step: [90 / 285] Batch Time: 0.1435 (0.1637) Data Time: 0.0125 (0.0308) Average Loss: 0.5788 (0.4811) Average CE Loss (Source):  0.5788 ( 0.4811) Learning Rate: 0.0500 (0.0500) Top1_base: 84.3750 (86.8316) Top1_base_per_class: 83.1090 (87.3720) 
Training Epoch: [182/1000] Step: [100 / 285] Batch Time: 0.1476 (0.1634) Data Time: 0.0113 (0.0305) Average Loss: 0.4560 (0.4763) Average CE Loss (Source):  0.4560 ( 0.4763) Learning Rate: 0.0500 (0.0500) Top1_base: 89.0625 (86.9141) Top1_base_per_class: 91.3580 (87.4601) 
Training Epoch: [182/1000] Step: [110 / 285] Batch Time: 0.1412 (0.1619) Data Time: 0.0113 (0.0289) Average Loss: 0.4718 (0.4806) Average CE Loss (Source):  0.4718 ( 0.4806) Learning Rate: 0.0500 (0.0500) Top1_base: 87.5000 (86.7756) Top1_base_per_class: 88.7346 (87.3621) 
Training Epoch: [182/1000] Step: [120 / 285] Batch Time: 0.1429 (0.1608) Data Time: 0.0129 (0.0279) Average Loss: 0.6854 (0.4837) Average CE Loss (Source):  0.6854 ( 0.4837) Learning Rate: 0.0500 (0.0500) Top1_base: 80.4688 (86.6081) Top1_base_per_class: 82.5893 (87.2382) 
Training Epoch: [182/1000] Step: [130 / 285] Batch Time: 0.1439 (0.1597) Data Time: 0.0129 (0.0270) Average Loss: 0.5516 (0.4841) Average CE Loss (Source):  0.5516 ( 0.4841) Learning Rate: 0.0500 (0.0500) Top1_base: 82.8125 (86.6166) Top1_base_per_class: 81.1782 (87.1620) 
Training Epoch: [182/1000] Step: [140 / 285] Batch Time: 0.1431 (0.1589) Data Time: 0.0124 (0.0263) Average Loss: 0.4693 (0.4821) Average CE Loss (Source):  0.4693 ( 0.4821) Learning Rate: 0.0500 (0.0500) Top1_base: 86.7188 (86.6406) Top1_base_per_class: 86.4197 (87.1301) 
Training Epoch: [182/1000] Step: [150 / 285] Batch Time: 0.1460 (0.1581) Data Time: 0.0156 (0.0255) Average Loss: 0.5646 (0.4840) Average CE Loss (Source):  0.5646 ( 0.4840) Learning Rate: 0.0500 (0.0500) Top1_base: 84.3750 (86.5625) Top1_base_per_class: 82.8947 (87.0556) 
Training Epoch: [182/1000] Step: [160 / 285] Batch Time: 0.1494 (0.1573) Data Time: 0.0125 (0.0248) Average Loss: 0.5040 (0.4849) Average CE Loss (Source):  0.5040 ( 0.4849) Learning Rate: 0.0500 (0.0500) Top1_base: 87.5000 (86.5625) Top1_base_per_class: 89.7953 (87.0572) 
Training Epoch: [182/1000] Step: [170 / 285] Batch Time: 0.1443 (0.1569) Data Time: 0.0143 (0.0245) Average Loss: 0.6325 (0.4869) Average CE Loss (Source):  0.6325 ( 0.4869) Learning Rate: 0.0500 (0.0500) Top1_base: 82.8125 (86.5533) Top1_base_per_class: 81.5385 (87.0566) 
Training Epoch: [182/1000] Step: [180 / 285] Batch Time: 0.1433 (0.1568) Data Time: 0.0107 (0.0243) Average Loss: 0.5664 (0.4878) Average CE Loss (Source):  0.5664 ( 0.4878) Learning Rate: 0.0500 (0.0500) Top1_base: 83.5938 (86.5234) Top1_base_per_class: 82.7244 (86.9727) 
Training Epoch: [182/1000] Step: [190 / 285] Batch Time: 0.1453 (0.1567) Data Time: 0.0113 (0.0242) Average Loss: 0.6931 (0.4896) Average CE Loss (Source):  0.6931 ( 0.4896) Learning Rate: 0.0500 (0.0500) Top1_base: 81.2500 (86.5049) Top1_base_per_class: 84.0017 (86.9775) 
Training Epoch: [182/1000] Step: [200 / 285] Batch Time: 0.1416 (0.1563) Data Time: 0.0118 (0.0238) Average Loss: 0.6036 (0.4931) Average CE Loss (Source):  0.6036 ( 0.4931) Learning Rate: 0.0500 (0.0500) Top1_base: 82.8125 (86.4023) Top1_base_per_class: 82.9487 (86.8490) 
Training Epoch: [182/1000] Step: [210 / 285] Batch Time: 0.1435 (0.1557) Data Time: 0.0129 (0.0232) Average Loss: 0.5835 (0.4933) Average CE Loss (Source):  0.5835 ( 0.4933) Learning Rate: 0.0500 (0.0500) Top1_base: 84.3750 (86.3616) Top1_base_per_class: 81.6959 (86.7959) 
Training Epoch: [182/1000] Step: [220 / 285] Batch Time: 0.1483 (0.1552) Data Time: 0.0119 (0.0228) Average Loss: 0.5732 (0.4929) Average CE Loss (Source):  0.5732 ( 0.4929) Learning Rate: 0.0500 (0.0500) Top1_base: 85.1562 (86.4382) Top1_base_per_class: 84.9691 (86.8795) 
Training Epoch: [182/1000] Step: [230 / 285] Batch Time: 0.1483 (0.1549) Data Time: 0.0113 (0.0223) Average Loss: 0.3929 (0.4918) Average CE Loss (Source):  0.3929 ( 0.4918) Learning Rate: 0.0500 (0.0500) Top1_base: 89.8438 (86.4674) Top1_base_per_class: 93.6097 (86.8991) 
Training Epoch: [182/1000] Step: [240 / 285] Batch Time: 0.1473 (0.1547) Data Time: 0.0114 (0.0220) Average Loss: 0.4831 (0.4916) Average CE Loss (Source):  0.4831 ( 0.4916) Learning Rate: 0.0500 (0.0500) Top1_base: 86.7188 (86.5039) Top1_base_per_class: 88.1731 (86.9581) 
Training Epoch: [182/1000] Step: [250 / 285] Batch Time: 0.1511 (0.1543) Data Time: 0.0125 (0.0216) Average Loss: 0.3984 (0.4916) Average CE Loss (Source):  0.3984 ( 0.4916) Learning Rate: 0.0500 (0.0500) Top1_base: 88.2812 (86.4719) Top1_base_per_class: 89.8512 (86.9257) 
Training Epoch: [182/1000] Step: [260 / 285] Batch Time: 0.1494 (0.1541) Data Time: 0.0115 (0.0213) Average Loss: 0.4931 (0.4916) Average CE Loss (Source):  0.4931 ( 0.4916) Learning Rate: 0.0500 (0.0500) Top1_base: 86.7188 (86.4363) Top1_base_per_class: 86.0169 (86.8780) 
Training Epoch: [182/1000] Step: [270 / 285] Batch Time: 0.1701 (0.1548) Data Time: 0.0336 (0.0219) Average Loss: 0.5873 (0.4918) Average CE Loss (Source):  0.5873 ( 0.4918) Learning Rate: 0.0500 (0.0500) Top1_base: 83.5938 (86.4091) Top1_base_per_class: 82.9762 (86.8315) 
Training Epoch: [182/1000] Step: [280 / 285] Batch Time: 0.1490 (0.1546) Data Time: 0.0122 (0.0217) Average Loss: 0.5330 (0.4918) Average CE Loss (Source):  0.5330 ( 0.4918) Learning Rate: 0.0500 (0.0500) Top1_base: 84.3750 (86.3979) Top1_base_per_class: 84.9359 (86.7827) 
Training Epoch: [183/1000] Step: [0] Batch Time: 0.1434 (0.1545) Data Time: 0.0127 (0.0215) Average Loss: 0.5869 (0.4935) Average CE Loss (Source):  0.5869 ( 0.4935) Learning Rate: 0.0500 (0.0500) Top1_base: 84.3750 (86.3542) Top1_base_per_class: 84.1061 (86.7505) 
Training Epoch: [183/1000] Step: [10 / 285] Batch Time: 0.1420 (0.2486) Data Time: 0.0128 (0.1160) Average Loss: 0.2854 (0.4973) Average CE Loss (Source):  0.2854 ( 0.4973) Learning Rate: 0.0500 (0.0500) Top1_base: 93.7500 (86.9531) Top1_base_per_class: 94.3396 (87.2898) 
Training Epoch: [183/1000] Step: [20 / 285] Batch Time: 0.1482 (0.2032) Data Time: 0.0114 (0.0697) Average Loss: 0.4623 (0.4877) Average CE Loss (Source):  0.4623 ( 0.4877) Learning Rate: 0.0500 (0.0500) Top1_base: 87.5000 (86.8750) Top1_base_per_class: 88.3459 (87.7431) 
Training Epoch: [183/1000] Step: [30 / 285] Batch Time: 0.1433 (0.1867) Data Time: 0.0108 (0.0527) Average Loss: 0.2296 (0.4626) Average CE Loss (Source):  0.2296 ( 0.4626) Learning Rate: 0.0500 (0.0500) Top1_base: 96.0938 (87.6302) Top1_base_per_class: 96.9811 (88.4826) 
Training Epoch: [183/1000] Step: [40 / 285] Batch Time: 0.1404 (0.1775) Data Time: 0.0117 (0.0441) Average Loss: 0.5295 (0.4644) Average CE Loss (Source):  0.5295 ( 0.4644) Learning Rate: 0.0500 (0.0500) Top1_base: 87.5000 (87.5391) Top1_base_per_class: 86.1538 (88.3416) 
Training Epoch: [183/1000] Step: [50 / 285] Batch Time: 0.1455 (0.1717) Data Time: 0.0117 (0.0385) Average Loss: 0.6479 (0.4687) Average CE Loss (Source):  0.6479 ( 0.4687) Learning Rate: 0.0500 (0.0500) Top1_base: 83.5938 (87.6250) Top1_base_per_class: 84.0604 (88.3944) 
Training Epoch: [183/1000] Step: [60 / 285] Batch Time: 0.1482 (0.1679) Data Time: 0.0118 (0.0345) Average Loss: 0.3688 (0.4651) Average CE Loss (Source):  0.3688 ( 0.4651) Learning Rate: 0.0500 (0.0500) Top1_base: 92.9688 (87.7214) Top1_base_per_class: 95.0777 (88.3276) 
Training Epoch: [183/1000] Step: [70 / 285] Batch Time: 0.1478 (0.1652) Data Time: 0.0157 (0.0320) Average Loss: 0.4375 (0.4661) Average CE Loss (Source):  0.4375 ( 0.4661) Learning Rate: 0.0500 (0.0500) Top1_base: 89.0625 (87.7121) Top1_base_per_class: 88.2456 (88.3467) 
Training Epoch: [183/1000] Step: [80 / 285] Batch Time: 0.1422 (0.1633) Data Time: 0.0108 (0.0303) Average Loss: 0.5463 (0.4658) Average CE Loss (Source):  0.5463 ( 0.4658) Learning Rate: 0.0500 (0.0500) Top1_base: 85.1562 (87.6855) Top1_base_per_class: 82.7485 (88.2717) 
Training Epoch: [183/1000] Step: [90 / 285] Batch Time: 0.1427 (0.1617) Data Time: 0.0125 (0.0287) Average Loss: 0.4802 (0.4707) Average CE Loss (Source):  0.4802 ( 0.4707) Learning Rate: 0.0500 (0.0500) Top1_base: 86.7188 (87.4740) Top1_base_per_class: 88.6859 (88.0613) 
Training Epoch: [183/1000] Step: [100 / 285] Batch Time: 0.1474 (0.1612) Data Time: 0.0124 (0.0282) Average Loss: 0.5192 (0.4775) Average CE Loss (Source):  0.5192 ( 0.4775) Learning Rate: 0.0500 (0.0500) Top1_base: 85.1562 (87.2266) Top1_base_per_class: 82.8869 (87.7791) 
Training Epoch: [183/1000] Step: [110 / 285] Batch Time: 0.1553 (0.1608) Data Time: 0.0245 (0.0278) Average Loss: 0.5227 (0.4763) Average CE Loss (Source):  0.5227 ( 0.4763) Learning Rate: 0.0500 (0.0500) Top1_base: 85.1562 (87.1875) Top1_base_per_class: 86.5790 (87.7341) 
Training Epoch: [183/1000] Step: [120 / 285] Batch Time: 0.1459 (0.1611) Data Time: 0.0120 (0.0281) Average Loss: 0.3677 (0.4758) Average CE Loss (Source):  0.3677 ( 0.4758) Learning Rate: 0.0500 (0.0500) Top1_base: 89.0625 (87.1484) Top1_base_per_class: 89.8506 (87.6689) 
Training Epoch: [183/1000] Step: [130 / 285] Batch Time: 0.2236 (0.1609) Data Time: 0.0917 (0.0279) Average Loss: 0.5561 (0.4710) Average CE Loss (Source):  0.5561 ( 0.4710) Learning Rate: 0.0500 (0.0500) Top1_base: 84.3750 (87.2776) Top1_base_per_class: 87.3099 (87.8143) 
Training Epoch: [183/1000] Step: [140 / 285] Batch Time: 0.1445 (0.1607) Data Time: 0.0126 (0.0277) Average Loss: 0.5001 (0.4718) Average CE Loss (Source):  0.5001 ( 0.4718) Learning Rate: 0.0500 (0.0500) Top1_base: 90.6250 (87.3382) Top1_base_per_class: 91.6049 (87.8591) 
Training Epoch: [183/1000] Step: [150 / 285] Batch Time: 0.1506 (0.1599) Data Time: 0.0211 (0.0270) Average Loss: 0.5673 (0.4732) Average CE Loss (Source):  0.5673 ( 0.4732) Learning Rate: 0.0500 (0.0500) Top1_base: 84.3750 (87.2552) Top1_base_per_class: 85.9171 (87.7122) 
Training Epoch: [183/1000] Step: [160 / 285] Batch Time: 0.1467 (0.1593) Data Time: 0.0136 (0.0263) Average Loss: 0.5069 (0.4745) Average CE Loss (Source):  0.5069 ( 0.4745) Learning Rate: 0.0500 (0.0500) Top1_base: 87.5000 (87.2314) Top1_base_per_class: 88.2121 (87.6759) 
Training Epoch: [183/1000] Step: [170 / 285] Batch Time: 0.2322 (0.1594) Data Time: 0.0983 (0.0265) Average Loss: 0.4271 (0.4761) Average CE Loss (Source):  0.4271 ( 0.4761) Learning Rate: 0.0500 (0.0500) Top1_base: 89.8438 (87.1232) Top1_base_per_class: 87.3937 (87.5042) 
Training Epoch: [183/1000] Step: [180 / 285] Batch Time: 0.1485 (0.1589) Data Time: 0.0120 (0.0258) Average Loss: 0.5588 (0.4764) Average CE Loss (Source):  0.5588 ( 0.4764) Learning Rate: 0.0500 (0.0500) Top1_base: 86.7188 (87.1354) Top1_base_per_class: 86.1012 (87.5482) 
Training Epoch: [183/1000] Step: [190 / 285] Batch Time: 0.1504 (0.1585) Data Time: 0.0190 (0.0254) Average Loss: 0.5409 (0.4787) Average CE Loss (Source):  0.5409 ( 0.4787) Learning Rate: 0.0500 (0.0500) Top1_base: 83.5938 (87.0559) Top1_base_per_class: 82.7469 (87.4961) 
Training Epoch: [183/1000] Step: [200 / 285] Batch Time: 0.1421 (0.1579) Data Time: 0.0111 (0.0248) Average Loss: 0.4832 (0.4795) Average CE Loss (Source):  0.4832 ( 0.4795) Learning Rate: 0.0500 (0.0500) Top1_base: 86.7188 (87.0156) Top1_base_per_class: 86.6450 (87.4368) 
Training Epoch: [183/1000] Step: [210 / 285] Batch Time: 0.1638 (0.1577) Data Time: 0.0300 (0.0247) Average Loss: 0.4779 (0.4805) Average CE Loss (Source):  0.4779 ( 0.4805) Learning Rate: 0.0500 (0.0500) Top1_base: 85.9375 (86.9606) Top1_base_per_class: 87.5893 (87.4053) 
Training Epoch: [183/1000] Step: [220 / 285] Batch Time: 0.1506 (0.1573) Data Time: 0.0124 (0.0241) Average Loss: 0.3837 (0.4808) Average CE Loss (Source):  0.3837 ( 0.4808) Learning Rate: 0.0500 (0.0500) Top1_base: 90.6250 (86.9318) Top1_base_per_class: 90.0433 (87.3730) 
Training Epoch: [183/1000] Step: [230 / 285] Batch Time: 0.1494 (0.1570) Data Time: 0.0174 (0.0238) Average Loss: 0.4875 (0.4820) Average CE Loss (Source):  0.4875 ( 0.4820) Learning Rate: 0.0500 (0.0500) Top1_base: 85.1562 (86.9022) Top1_base_per_class: 86.8182 (87.3738) 
Training Epoch: [183/1000] Step: [240 / 285] Batch Time: 0.1404 (0.1567) Data Time: 0.0105 (0.0235) Average Loss: 0.6629 (0.4831) Average CE Loss (Source):  0.6629 ( 0.4831) Learning Rate: 0.0500 (0.0500) Top1_base: 78.9062 (86.8457) Top1_base_per_class: 81.1348 (87.2986) 
Training Epoch: [183/1000] Step: [250 / 285] Batch Time: 0.2203 (0.1566) Data Time: 0.0888 (0.0234) Average Loss: 0.5001 (0.4828) Average CE Loss (Source):  0.5001 ( 0.4828) Learning Rate: 0.0500 (0.0500) Top1_base: 83.5938 (86.8500) Top1_base_per_class: 83.8223 (87.3398) 
Training Epoch: [183/1000] Step: [260 / 285] Batch Time: 0.1427 (0.1564) Data Time: 0.0120 (0.0232) Average Loss: 0.2972 (0.4850) Average CE Loss (Source):  0.2972 ( 0.4850) Learning Rate: 0.0500 (0.0500) Top1_base: 91.4062 (86.7548) Top1_base_per_class: 91.4035 (87.1919) 
Training Epoch: [183/1000] Step: [270 / 285] Batch Time: 0.1486 (0.1562) Data Time: 0.0162 (0.0231) Average Loss: 0.5905 (0.4858) Average CE Loss (Source):  0.5905 ( 0.4858) Learning Rate: 0.0500 (0.0500) Top1_base: 84.3750 (86.7564) Top1_base_per_class: 84.8246 (87.1774) 
Training Epoch: [183/1000] Step: [280 / 285] Batch Time: 0.1487 (0.1559) Data Time: 0.0119 (0.0227) Average Loss: 0.6292 (0.4865) Average CE Loss (Source):  0.6292 ( 0.4865) Learning Rate: 0.0500 (0.0500) Top1_base: 78.1250 (86.7494) Top1_base_per_class: 80.2885 (87.1980) 
Training Epoch: [184/1000] Step: [0] Batch Time: 0.1473 (0.1557) Data Time: 0.0114 (0.0225) Average Loss: 0.5984 (0.4864) Average CE Loss (Source):  0.5984 ( 0.4864) Learning Rate: 0.0500 (0.0500) Top1_base: 82.0312 (86.7544) Top1_base_per_class: 82.1930 (87.1795) 
 18%|█▊        | 184/1000 [2:22:56<10:26:25, 46.06s/it] 18%|█▊        | 185/1000 [2:23:41<10:22:57, 45.86s/it]Training Epoch: [184/1000] Step: [10 / 285] Batch Time: 0.1430 (0.2444) Data Time: 0.0103 (0.1129) Average Loss: 0.3786 (0.4608) Average CE Loss (Source):  0.3786 ( 0.4608) Learning Rate: 0.0500 (0.0500) Top1_base: 92.9688 (88.1250) Top1_base_per_class: 93.5009 (88.1819) 
Training Epoch: [184/1000] Step: [20 / 285] Batch Time: 0.1441 (0.2007) Data Time: 0.0122 (0.0685) Average Loss: 0.4611 (0.4865) Average CE Loss (Source):  0.4611 ( 0.4865) Learning Rate: 0.0500 (0.0500) Top1_base: 86.7188 (87.1094) Top1_base_per_class: 88.4294 (87.4939) 
Training Epoch: [184/1000] Step: [30 / 285] Batch Time: 0.1434 (0.1865) Data Time: 0.0101 (0.0544) Average Loss: 0.3530 (0.4786) Average CE Loss (Source):  0.3530 ( 0.4786) Learning Rate: 0.0500 (0.0500) Top1_base: 89.0625 (87.1875) Top1_base_per_class: 87.8571 (87.4680) 
Training Epoch: [184/1000] Step: [40 / 285] Batch Time: 0.1439 (0.1837) Data Time: 0.0117 (0.0511) Average Loss: 0.3224 (0.4778) Average CE Loss (Source):  0.3224 ( 0.4778) Learning Rate: 0.0500 (0.0500) Top1_base: 90.6250 (87.0312) Top1_base_per_class: 87.3512 (87.3719) 
Training Epoch: [184/1000] Step: [50 / 285] Batch Time: 0.1432 (0.1811) Data Time: 0.0114 (0.0485) Average Loss: 0.5513 (0.4913) Average CE Loss (Source):  0.5513 ( 0.4913) Learning Rate: 0.0500 (0.0500) Top1_base: 85.9375 (86.7969) Top1_base_per_class: 83.3939 (87.0863) 
Training Epoch: [184/1000] Step: [60 / 285] Batch Time: 0.1442 (0.1783) Data Time: 0.0111 (0.0454) Average Loss: 0.4775 (0.4966) Average CE Loss (Source):  0.4775 ( 0.4966) Learning Rate: 0.0500 (0.0500) Top1_base: 88.2812 (86.7839) Top1_base_per_class: 89.9107 (87.2044) 
Training Epoch: [184/1000] Step: [70 / 285] Batch Time: 0.1429 (0.1760) Data Time: 0.0116 (0.0430) Average Loss: 0.4901 (0.4897) Average CE Loss (Source):  0.4901 ( 0.4897) Learning Rate: 0.0500 (0.0500) Top1_base: 85.9375 (86.9420) Top1_base_per_class: 84.6405 (87.2962) 
Training Epoch: [184/1000] Step: [80 / 285] Batch Time: 0.1434 (0.1738) Data Time: 0.0128 (0.0409) Average Loss: 0.4722 (0.4851) Average CE Loss (Source):  0.4722 ( 0.4851) Learning Rate: 0.0500 (0.0500) Top1_base: 86.7188 (87.0215) Top1_base_per_class: 83.8095 (87.2490) 
Training Epoch: [184/1000] Step: [90 / 285] Batch Time: 0.1439 (0.1712) Data Time: 0.0103 (0.0383) Average Loss: 0.4301 (0.4870) Average CE Loss (Source):  0.4301 ( 0.4870) Learning Rate: 0.0500 (0.0500) Top1_base: 88.2812 (86.8924) Top1_base_per_class: 87.3765 (87.0060) 
Training Epoch: [184/1000] Step: [100 / 285] Batch Time: 0.1414 (0.1693) Data Time: 0.0103 (0.0365) Average Loss: 0.4948 (0.4930) Average CE Loss (Source):  0.4948 ( 0.4930) Learning Rate: 0.0500 (0.0500) Top1_base: 85.9375 (86.6953) Top1_base_per_class: 83.0189 (86.8780) 
Training Epoch: [184/1000] Step: [110 / 285] Batch Time: 0.1436 (0.1683) Data Time: 0.0110 (0.0355) Average Loss: 0.4062 (0.4903) Average CE Loss (Source):  0.4062 ( 0.4903) Learning Rate: 0.0500 (0.0500) Top1_base: 91.4062 (86.8111) Top1_base_per_class: 90.0654 (87.0398) 
Training Epoch: [184/1000] Step: [120 / 285] Batch Time: 0.1450 (0.1672) Data Time: 0.0127 (0.0344) Average Loss: 0.4876 (0.4874) Average CE Loss (Source):  0.4876 ( 0.4874) Learning Rate: 0.0500 (0.0500) Top1_base: 85.1562 (86.8945) Top1_base_per_class: 83.2727 (87.1397) 
Training Epoch: [184/1000] Step: [130 / 285] Batch Time: 0.1455 (0.1661) Data Time: 0.0111 (0.0332) Average Loss: 0.5501 (0.4905) Average CE Loss (Source):  0.5501 ( 0.4905) Learning Rate: 0.0500 (0.0500) Top1_base: 85.9375 (86.7788) Top1_base_per_class: 86.5826 (87.0420) 
Training Epoch: [184/1000] Step: [140 / 285] Batch Time: 0.1443 (0.1650) Data Time: 0.0126 (0.0322) Average Loss: 0.5266 (0.4913) Average CE Loss (Source):  0.5266 ( 0.4913) Learning Rate: 0.0500 (0.0500) Top1_base: 86.7188 (86.7411) Top1_base_per_class: 87.9091 (87.0720) 
Training Epoch: [184/1000] Step: [150 / 285] Batch Time: 0.1442 (0.1642) Data Time: 0.0105 (0.0314) Average Loss: 0.5313 (0.4917) Average CE Loss (Source):  0.5313 ( 0.4917) Learning Rate: 0.0500 (0.0500) Top1_base: 84.3750 (86.7083) Top1_base_per_class: 87.2424 (86.9974) 
Training Epoch: [184/1000] Step: [160 / 285] Batch Time: 0.1441 (0.1635) Data Time: 0.0116 (0.0306) Average Loss: 0.3167 (0.4897) Average CE Loss (Source):  0.3167 ( 0.4897) Learning Rate: 0.0500 (0.0500) Top1_base: 89.8438 (86.7090) Top1_base_per_class: 90.7568 (87.0730) 
Training Epoch: [184/1000] Step: [170 / 285] Batch Time: 0.1444 (0.1632) Data Time: 0.0118 (0.0303) Average Loss: 0.4497 (0.4899) Average CE Loss (Source):  0.4497 ( 0.4899) Learning Rate: 0.0500 (0.0500) Top1_base: 89.0625 (86.6544) Top1_base_per_class: 85.0000 (87.0120) 
Training Epoch: [184/1000] Step: [180 / 285] Batch Time: 0.1445 (0.1628) Data Time: 0.0105 (0.0299) Average Loss: 0.4597 (0.4912) Average CE Loss (Source):  0.4597 ( 0.4912) Learning Rate: 0.0500 (0.0500) Top1_base: 89.0625 (86.6623) Top1_base_per_class: 89.1358 (87.0235) 
Training Epoch: [184/1000] Step: [190 / 285] Batch Time: 0.1433 (0.1631) Data Time: 0.0114 (0.0302) Average Loss: 0.5258 (0.4911) Average CE Loss (Source):  0.5258 ( 0.4911) Learning Rate: 0.0500 (0.0500) Top1_base: 83.5938 (86.6735) Top1_base_per_class: 82.8407 (87.0661) 
Training Epoch: [184/1000] Step: [200 / 285] Batch Time: 0.1455 (0.1626) Data Time: 0.0108 (0.0297) Average Loss: 0.4890 (0.4901) Average CE Loss (Source):  0.4890 ( 0.4901) Learning Rate: 0.0500 (0.0500) Top1_base: 88.2812 (86.6797) Top1_base_per_class: 91.1818 (87.0928) 
Training Epoch: [184/1000] Step: [210 / 285] Batch Time: 0.1425 (0.1624) Data Time: 0.0112 (0.0296) Average Loss: 0.5194 (0.4914) Average CE Loss (Source):  0.5194 ( 0.4914) Learning Rate: 0.0500 (0.0500) Top1_base: 85.9375 (86.6071) Top1_base_per_class: 84.4872 (86.9893) 
Training Epoch: [184/1000] Step: [220 / 285] Batch Time: 0.1459 (0.1618) Data Time: 0.0123 (0.0291) Average Loss: 0.5145 (0.4924) Average CE Loss (Source):  0.5145 ( 0.4924) Learning Rate: 0.0500 (0.0500) Top1_base: 84.3750 (86.5732) Top1_base_per_class: 83.9181 (86.9284) 
Training Epoch: [184/1000] Step: [230 / 285] Batch Time: 0.1434 (0.1612) Data Time: 0.0113 (0.0285) Average Loss: 0.5731 (0.4918) Average CE Loss (Source):  0.5731 ( 0.4918) Learning Rate: 0.0500 (0.0500) Top1_base: 85.9375 (86.5659) Top1_base_per_class: 85.6173 (86.9678) 
Training Epoch: [184/1000] Step: [240 / 285] Batch Time: 0.1468 (0.1611) Data Time: 0.0118 (0.0283) Average Loss: 0.4601 (0.4910) Average CE Loss (Source):  0.4601 ( 0.4910) Learning Rate: 0.0500 (0.0500) Top1_base: 90.6250 (86.6016) Top1_base_per_class: 89.4643 (87.0093) 
Training Epoch: [184/1000] Step: [250 / 285] Batch Time: 0.1434 (0.1605) Data Time: 0.0104 (0.0277) Average Loss: 0.3401 (0.4880) Average CE Loss (Source):  0.3401 ( 0.4880) Learning Rate: 0.0500 (0.0500) Top1_base: 90.6250 (86.7094) Top1_base_per_class: 89.9123 (87.1179) 
Training Epoch: [184/1000] Step: [260 / 285] Batch Time: 0.1489 (0.1599) Data Time: 0.0175 (0.0272) Average Loss: 0.4296 (0.4894) Average CE Loss (Source):  0.4296 ( 0.4894) Learning Rate: 0.0500 (0.0500) Top1_base: 88.2812 (86.7007) Top1_base_per_class: 89.0936 (87.1468) 
Training Epoch: [184/1000] Step: [270 / 285] Batch Time: 0.1440 (0.1594) Data Time: 0.0102 (0.0267) Average Loss: 0.4881 (0.4914) Average CE Loss (Source):  0.4881 ( 0.4914) Learning Rate: 0.0500 (0.0500) Top1_base: 86.7188 (86.6262) Top1_base_per_class: 89.2105 (87.1019) 
Training Epoch: [184/1000] Step: [280 / 285] Batch Time: 0.1439 (0.1591) Data Time: 0.0143 (0.0264) Average Loss: 0.5190 (0.4913) Average CE Loss (Source):  0.5190 ( 0.4913) Learning Rate: 0.0500 (0.0500) Top1_base: 85.9375 (86.6044) Top1_base_per_class: 88.4568 (87.1056) 
Training Epoch: [185/1000] Step: [0] Batch Time: 0.1904 (0.1591) Data Time: 0.0605 (0.0264) Average Loss: 0.3211 (0.4909) Average CE Loss (Source):  0.3211 ( 0.4909) Learning Rate: 0.0500 (0.0500) Top1_base: 91.4062 (86.6064) Top1_base_per_class: 92.7381 (87.1051) 
Training Epoch: [185/1000] Step: [10 / 285] Batch Time: 0.1429 (0.2372) Data Time: 0.0105 (0.1043) Average Loss: 0.4150 (0.4338) Average CE Loss (Source):  0.4150 ( 0.4338) Learning Rate: 0.0500 (0.0500) Top1_base: 91.4062 (88.0469) Top1_base_per_class: 92.7193 (89.0488) 
Training Epoch: [185/1000] Step: [20 / 285] Batch Time: 0.1470 (0.1991) Data Time: 0.0141 (0.0664) Average Loss: 0.3509 (0.4650) Average CE Loss (Source):  0.3509 ( 0.4650) Learning Rate: 0.0500 (0.0500) Top1_base: 91.4062 (87.3438) Top1_base_per_class: 92.5151 (87.9992) 
Training Epoch: [185/1000] Step: [30 / 285] Batch Time: 0.1404 (0.1910) Data Time: 0.0095 (0.0582) Average Loss: 0.5076 (0.4585) Average CE Loss (Source):  0.5076 ( 0.4585) Learning Rate: 0.0500 (0.0500) Top1_base: 86.7188 (87.5521) Top1_base_per_class: 86.6374 (87.9521) 
Training Epoch: [185/1000] Step: [40 / 285] Batch Time: 0.1491 (0.1818) Data Time: 0.0150 (0.0490) Average Loss: 0.5401 (0.4583) Average CE Loss (Source):  0.5401 ( 0.4583) Learning Rate: 0.0500 (0.0500) Top1_base: 86.7188 (87.5000) Top1_base_per_class: 86.5454 (87.8674) 
Training Epoch: [185/1000] Step: [50 / 285] Batch Time: 0.1453 (0.1782) Data Time: 0.0117 (0.0454) Average Loss: 0.4100 (0.4526) Average CE Loss (Source):  0.4100 ( 0.4526) Learning Rate: 0.0500 (0.0500) Top1_base: 92.1875 (87.6562) Top1_base_per_class: 93.3041 (88.0646) 
Training Epoch: [185/1000] Step: [60 / 285] Batch Time: 0.1450 (0.1740) Data Time: 0.0142 (0.0414) Average Loss: 0.3907 (0.4575) Average CE Loss (Source):  0.3907 ( 0.4575) Learning Rate: 0.0500 (0.0500) Top1_base: 87.5000 (87.4870) Top1_base_per_class: 90.4762 (87.9664) 
Training Epoch: [185/1000] Step: [70 / 285] Batch Time: 0.1428 (0.1718) Data Time: 0.0104 (0.0391) Average Loss: 0.3149 (0.4525) Average CE Loss (Source):  0.3149 ( 0.4525) Learning Rate: 0.0500 (0.0500) Top1_base: 92.9688 (87.6674) Top1_base_per_class: 94.9057 (88.2783) 
Training Epoch: [185/1000] Step: [80 / 285] Batch Time: 0.1467 (0.1696) Data Time: 0.0120 (0.0368) Average Loss: 0.5657 (0.4561) Average CE Loss (Source):  0.5657 ( 0.4561) Learning Rate: 0.0500 (0.0500) Top1_base: 82.8125 (87.6074) Top1_base_per_class: 82.1069 (88.1956) 
Training Epoch: [185/1000] Step: [90 / 285] Batch Time: 0.1430 (0.1689) Data Time: 0.0106 (0.0361) Average Loss: 0.3645 (0.4592) Average CE Loss (Source):  0.3645 ( 0.4592) Learning Rate: 0.0500 (0.0500) Top1_base: 88.2812 (87.3958) Top1_base_per_class: 89.5115 (87.9464) 
Training Epoch: [185/1000] Step: [100 / 285] Batch Time: 0.1478 (0.1678) Data Time: 0.0141 (0.0349) Average Loss: 0.5868 (0.4612) Average CE Loss (Source):  0.5868 ( 0.4612) Learning Rate: 0.0500 (0.0500) Top1_base: 80.4688 (87.2891) Top1_base_per_class: 76.9394 (87.7684) 
Training Epoch: [185/1000] Step: [110 / 285] Batch Time: 0.1438 (0.1674) Data Time: 0.0125 (0.0346) Average Loss: 0.5703 (0.4653) Average CE Loss (Source):  0.5703 ( 0.4653) Learning Rate: 0.0500 (0.0500) Top1_base: 82.0312 (87.1662) Top1_base_per_class: 83.7356 (87.6647) 
Training Epoch: [185/1000] Step: [120 / 285] Batch Time: 0.1448 (0.1662) Data Time: 0.0123 (0.0334) Average Loss: 0.4008 (0.4656) Average CE Loss (Source):  0.4008 ( 0.4656) Learning Rate: 0.0500 (0.0500) Top1_base: 88.2812 (87.1615) Top1_base_per_class: 88.1685 (87.6651) 
Training Epoch: [185/1000] Step: [130 / 285] Batch Time: 0.1491 (0.1655) Data Time: 0.0152 (0.0326) Average Loss: 0.4874 (0.4662) Average CE Loss (Source):  0.4874 ( 0.4662) Learning Rate: 0.0500 (0.0500) Top1_base: 86.7188 (87.1394) Top1_base_per_class: 88.8889 (87.6493) 
Training Epoch: [185/1000] Step: [140 / 285] Batch Time: 0.1422 (0.1651) Data Time: 0.0118 (0.0323) Average Loss: 0.4267 (0.4687) Average CE Loss (Source):  0.4267 ( 0.4687) Learning Rate: 0.0500 (0.0500) Top1_base: 90.6250 (87.1261) Top1_base_per_class: 89.6364 (87.6383) 
Training Epoch: [185/1000] Step: [150 / 285] Batch Time: 0.1424 (0.1644) Data Time: 0.0119 (0.0317) Average Loss: 0.5191 (0.4684) Average CE Loss (Source):  0.5191 ( 0.4684) Learning Rate: 0.0500 (0.0500) Top1_base: 82.8125 (87.1042) Top1_base_per_class: 84.4872 (87.5918) 
Training Epoch: [185/1000] Step: [160 / 285] Batch Time: 0.1447 (0.1635) Data Time: 0.0122 (0.0308) Average Loss: 0.3905 (0.4697) Average CE Loss (Source):  0.3905 ( 0.4697) Learning Rate: 0.0500 (0.0500) Top1_base: 89.0625 (87.0654) Top1_base_per_class: 92.4383 (87.5709) 
Training Epoch: [185/1000] Step: [170 / 285] Batch Time: 0.1465 (0.1634) Data Time: 0.0126 (0.0305) Average Loss: 0.5538 (0.4695) Average CE Loss (Source):  0.5538 ( 0.4695) Learning Rate: 0.0500 (0.0500) Top1_base: 85.9375 (87.0956) Top1_base_per_class: 85.7879 (87.5295) 
Training Epoch: [185/1000] Step: [180 / 285] Batch Time: 0.1406 (0.1627) Data Time: 0.0107 (0.0298) Average Loss: 0.6277 (0.4732) Average CE Loss (Source):  0.6277 ( 0.4732) Learning Rate: 0.0500 (0.0500) Top1_base: 82.0312 (86.9358) Top1_base_per_class: 82.1637 (87.3674) 
Training Epoch: [185/1000] Step: [190 / 285] Batch Time: 0.1477 (0.1621) Data Time: 0.0125 (0.0292) Average Loss: 0.4403 (0.4750) Average CE Loss (Source):  0.4403 ( 0.4750) Learning Rate: 0.0500 (0.0500) Top1_base: 89.0625 (86.9038) Top1_base_per_class: 92.9957 (87.4075) 
Training Epoch: [185/1000] Step: [200 / 285] Batch Time: 0.1496 (0.1614) Data Time: 0.0126 (0.0284) Average Loss: 0.5010 (0.4780) Average CE Loss (Source):  0.5010 ( 0.4780) Learning Rate: 0.0500 (0.0500) Top1_base: 85.9375 (86.8086) Top1_base_per_class: 85.8642 (87.3167) 
Training Epoch: [185/1000] Step: [210 / 285] Batch Time: 0.1468 (0.1611) Data Time: 0.0121 (0.0279) Average Loss: 0.4759 (0.4767) Average CE Loss (Source):  0.4759 ( 0.4767) Learning Rate: 0.0500 (0.0500) Top1_base: 88.2812 (86.8973) Top1_base_per_class: 88.3918 (87.4523) 
Training Epoch: [185/1000] Step: [220 / 285] Batch Time: 0.1404 (0.1607) Data Time: 0.0112 (0.0275) Average Loss: 0.4265 (0.4775) Average CE Loss (Source):  0.4265 ( 0.4775) Learning Rate: 0.0500 (0.0500) Top1_base: 88.2812 (86.8750) Top1_base_per_class: 89.3210 (87.4871) 
Training Epoch: [185/1000] Step: [230 / 285] Batch Time: 0.1487 (0.1608) Data Time: 0.0158 (0.0276) Average Loss: 0.7147 (0.4795) Average CE Loss (Source):  0.7147 ( 0.4795) Learning Rate: 0.0500 (0.0500) Top1_base: 82.8125 (86.8037) Top1_base_per_class: 87.0748 (87.3828) 
Training Epoch: [185/1000] Step: [240 / 285] Batch Time: 0.1424 (0.1605) Data Time: 0.0108 (0.0273) Average Loss: 0.5230 (0.4792) Average CE Loss (Source):  0.5230 ( 0.4792) Learning Rate: 0.0500 (0.0500) Top1_base: 86.7188 (86.8262) Top1_base_per_class: 85.1437 (87.3819) 
Training Epoch: [185/1000] Step: [250 / 285] Batch Time: 0.1483 (0.1603) Data Time: 0.0152 (0.0272) Average Loss: 0.4990 (0.4787) Average CE Loss (Source):  0.4990 ( 0.4787) Learning Rate: 0.0500 (0.0500) Top1_base: 85.1562 (86.8187) Top1_base_per_class: 88.4167 (87.3398) 
Training Epoch: [185/1000] Step: [260 / 285] Batch Time: 0.1501 (0.1598) Data Time: 0.0119 (0.0266) Average Loss: 0.4518 (0.4812) Average CE Loss (Source):  0.4518 ( 0.4812) Learning Rate: 0.0500 (0.0500) Top1_base: 84.3750 (86.7338) Top1_base_per_class: 86.2644 (87.2525) 
Training Epoch: [185/1000] Step: [270 / 285] Batch Time: 0.1470 (0.1594) Data Time: 0.0128 (0.0261) Average Loss: 0.4573 (0.4815) Average CE Loss (Source):  0.4573 ( 0.4815) Learning Rate: 0.0500 (0.0500) Top1_base: 87.5000 (86.7014) Top1_base_per_class: 89.8397 (87.2152) 
Training Epoch: [185/1000] Step: [280 / 285] Batch Time: 0.1468 (0.1591) Data Time: 0.0138 (0.0258) Average Loss: 0.4836 (0.4806) Average CE Loss (Source):  0.4836 ( 0.4806) Learning Rate: 0.0500 (0.0500) Top1_base: 87.5000 (86.7383) Top1_base_per_class: 85.5975 (87.2485) 
Training Epoch: [186/1000] Step: [0] Batch Time: 0.2165 (0.1592) Data Time: 0.0830 (0.0259) Average Loss: 0.5284 (0.4808) Average CE Loss (Source):  0.5284 ( 0.4808) Learning Rate: 0.0500 (0.0500) Top1_base: 86.7188 (86.7379) Top1_base_per_class: 90.2121 (87.2763) 
 19%|█▊        | 186/1000 [2:24:29<10:31:43, 46.56s/it] 19%|█▊        | 187/1000 [2:25:14<10:22:51, 45.97s/it]Training Epoch: [186/1000] Step: [10 / 285] Batch Time: 0.1484 (0.2353) Data Time: 0.0140 (0.1024) Average Loss: 0.5519 (0.4839) Average CE Loss (Source):  0.5519 ( 0.4839) Learning Rate: 0.0500 (0.0500) Top1_base: 85.9375 (86.7969) Top1_base_per_class: 88.6119 (86.6699) 
Training Epoch: [186/1000] Step: [20 / 285] Batch Time: 0.1481 (0.1997) Data Time: 0.0148 (0.0666) Average Loss: 0.4587 (0.4831) Average CE Loss (Source):  0.4587 ( 0.4831) Learning Rate: 0.0500 (0.0500) Top1_base: 87.5000 (86.5234) Top1_base_per_class: 88.3929 (86.4820) 
Training Epoch: [186/1000] Step: [30 / 285] Batch Time: 0.1448 (0.1869) Data Time: 0.0123 (0.0540) Average Loss: 0.5870 (0.5006) Average CE Loss (Source):  0.5870 ( 0.5006) Learning Rate: 0.0500 (0.0500) Top1_base: 81.2500 (85.7552) Top1_base_per_class: 82.0330 (86.1074) 
Training Epoch: [186/1000] Step: [40 / 285] Batch Time: 0.1446 (0.1808) Data Time: 0.0120 (0.0480) Average Loss: 0.6189 (0.4978) Average CE Loss (Source):  0.6189 ( 0.4978) Learning Rate: 0.0500 (0.0500) Top1_base: 82.0312 (85.8984) Top1_base_per_class: 81.0847 (86.1721) 
Training Epoch: [186/1000] Step: [50 / 285] Batch Time: 0.1453 (0.1748) Data Time: 0.0135 (0.0420) Average Loss: 0.4447 (0.4973) Average CE Loss (Source):  0.4447 ( 0.4973) Learning Rate: 0.0500 (0.0500) Top1_base: 88.2812 (86.0781) Top1_base_per_class: 89.9008 (86.4325) 
Training Epoch: [186/1000] Step: [60 / 285] Batch Time: 0.1444 (0.1713) Data Time: 0.0130 (0.0386) Average Loss: 0.6042 (0.4874) Average CE Loss (Source):  0.6042 ( 0.4874) Learning Rate: 0.0500 (0.0500) Top1_base: 86.7188 (86.4714) Top1_base_per_class: 87.8526 (86.7156) 
Training Epoch: [186/1000] Step: [70 / 285] Batch Time: 0.1450 (0.1709) Data Time: 0.0144 (0.0382) Average Loss: 0.3554 (0.4885) Average CE Loss (Source):  0.3554 ( 0.4885) Learning Rate: 0.0500 (0.0500) Top1_base: 92.1875 (86.5625) Top1_base_per_class: 93.1761 (86.7929) 
Training Epoch: [186/1000] Step: [80 / 285] Batch Time: 0.1437 (0.1681) Data Time: 0.0110 (0.0354) Average Loss: 0.6553 (0.4861) Average CE Loss (Source):  0.6553 ( 0.4861) Learning Rate: 0.0500 (0.0500) Top1_base: 85.1562 (86.6113) Top1_base_per_class: 87.1818 (86.9190) 
Training Epoch: [186/1000] Step: [90 / 285] Batch Time: 0.1431 (0.1660) Data Time: 0.0124 (0.0333) Average Loss: 0.4160 (0.4877) Average CE Loss (Source):  0.4160 ( 0.4877) Learning Rate: 0.0500 (0.0500) Top1_base: 89.8438 (86.6406) Top1_base_per_class: 92.1154 (87.0463) 
Training Epoch: [186/1000] Step: [100 / 285] Batch Time: 0.1449 (0.1644) Data Time: 0.0114 (0.0316) Average Loss: 0.5206 (0.4870) Average CE Loss (Source):  0.5206 ( 0.4870) Learning Rate: 0.0500 (0.0500) Top1_base: 85.9375 (86.6250) Top1_base_per_class: 82.5000 (87.0552) 
Training Epoch: [186/1000] Step: [110 / 285] Batch Time: 0.1781 (0.1631) Data Time: 0.0466 (0.0304) Average Loss: 0.3884 (0.4903) Average CE Loss (Source):  0.3884 ( 0.4903) Learning Rate: 0.0500 (0.0500) Top1_base: 89.8438 (86.5696) Top1_base_per_class: 86.2037 (86.9581) 
Training Epoch: [186/1000] Step: [120 / 285] Batch Time: 0.1436 (0.1621) Data Time: 0.0130 (0.0294) Average Loss: 0.6909 (0.4922) Average CE Loss (Source):  0.6909 ( 0.4922) Learning Rate: 0.0500 (0.0500) Top1_base: 82.0312 (86.5104) Top1_base_per_class: 81.5409 (86.9015) 
Training Epoch: [186/1000] Step: [130 / 285] Batch Time: 0.1526 (0.1612) Data Time: 0.0176 (0.0284) Average Loss: 0.3822 (0.4888) Average CE Loss (Source):  0.3822 ( 0.4888) Learning Rate: 0.0500 (0.0500) Top1_base: 91.4062 (86.6106) Top1_base_per_class: 89.8397 (86.9136) 
Training Epoch: [186/1000] Step: [140 / 285] Batch Time: 0.1470 (0.1604) Data Time: 0.0127 (0.0274) Average Loss: 0.4040 (0.4888) Average CE Loss (Source):  0.4040 ( 0.4888) Learning Rate: 0.0500 (0.0500) Top1_base: 85.9375 (86.5346) Top1_base_per_class: 87.3529 (86.8263) 
Training Epoch: [186/1000] Step: [150 / 285] Batch Time: 0.1501 (0.1596) Data Time: 0.0144 (0.0264) Average Loss: 0.3193 (0.4861) Average CE Loss (Source):  0.3193 ( 0.4861) Learning Rate: 0.0500 (0.0500) Top1_base: 90.6250 (86.5573) Top1_base_per_class: 92.1667 (86.8754) 
Training Epoch: [186/1000] Step: [160 / 285] Batch Time: 0.1444 (0.1589) Data Time: 0.0113 (0.0257) Average Loss: 0.3205 (0.4831) Average CE Loss (Source):  0.3205 ( 0.4831) Learning Rate: 0.0500 (0.0500) Top1_base: 92.9688 (86.5967) Top1_base_per_class: 92.2327 (86.9352) 
Training Epoch: [186/1000] Step: [170 / 285] Batch Time: 0.1470 (0.1584) Data Time: 0.0141 (0.0251) Average Loss: 0.4811 (0.4854) Average CE Loss (Source):  0.4811 ( 0.4854) Learning Rate: 0.0500 (0.0500) Top1_base: 82.8125 (86.4936) Top1_base_per_class: 81.5094 (86.8711) 
Training Epoch: [186/1000] Step: [180 / 285] Batch Time: 0.1442 (0.1583) Data Time: 0.0113 (0.0250) Average Loss: 0.4532 (0.4855) Average CE Loss (Source):  0.4532 ( 0.4855) Learning Rate: 0.0500 (0.0500) Top1_base: 88.2812 (86.5278) Top1_base_per_class: 88.4722 (86.9103) 
Training Epoch: [186/1000] Step: [190 / 285] Batch Time: 0.1497 (0.1578) Data Time: 0.0155 (0.0246) Average Loss: 0.4319 (0.4845) Average CE Loss (Source):  0.4319 ( 0.4845) Learning Rate: 0.0500 (0.0500) Top1_base: 85.1562 (86.5090) Top1_base_per_class: 87.5455 (86.8940) 
Training Epoch: [186/1000] Step: [200 / 285] Batch Time: 0.1488 (0.1577) Data Time: 0.0143 (0.0243) Average Loss: 0.4995 (0.4829) Average CE Loss (Source):  0.4995 ( 0.4829) Learning Rate: 0.0500 (0.0500) Top1_base: 85.1562 (86.5430) Top1_base_per_class: 81.7529 (86.8993) 
Training Epoch: [186/1000] Step: [210 / 285] Batch Time: 0.1464 (0.1578) Data Time: 0.0126 (0.0244) Average Loss: 0.4267 (0.4823) Average CE Loss (Source):  0.4267 ( 0.4823) Learning Rate: 0.0500 (0.0500) Top1_base: 86.7188 (86.6109) Top1_base_per_class: 88.6728 (87.0144) 
Training Epoch: [186/1000] Step: [220 / 285] Batch Time: 0.1487 (0.1573) Data Time: 0.0114 (0.0238) Average Loss: 0.4463 (0.4818) Average CE Loss (Source):  0.4463 ( 0.4818) Learning Rate: 0.0500 (0.0500) Top1_base: 86.7188 (86.6016) Top1_base_per_class: 90.1420 (86.9807) 
Training Epoch: [186/1000] Step: [230 / 285] Batch Time: 0.1469 (0.1574) Data Time: 0.0129 (0.0239) Average Loss: 0.4052 (0.4842) Average CE Loss (Source):  0.4052 ( 0.4842) Learning Rate: 0.0500 (0.0500) Top1_base: 87.5000 (86.5285) Top1_base_per_class: 86.9753 (86.8968) 
Training Epoch: [186/1000] Step: [240 / 285] Batch Time: 0.1439 (0.1570) Data Time: 0.0119 (0.0235) Average Loss: 0.4984 (0.4838) Average CE Loss (Source):  0.4984 ( 0.4838) Learning Rate: 0.0500 (0.0500) Top1_base: 88.2812 (86.5039) Top1_base_per_class: 86.4151 (86.9173) 
Training Epoch: [186/1000] Step: [250 / 285] Batch Time: 0.1464 (0.1568) Data Time: 0.0134 (0.0233) Average Loss: 0.5798 (0.4833) Average CE Loss (Source):  0.5798 ( 0.4833) Learning Rate: 0.0500 (0.0500) Top1_base: 82.8125 (86.5250) Top1_base_per_class: 83.4936 (86.9509) 
Training Epoch: [186/1000] Step: [260 / 285] Batch Time: 0.1474 (0.1565) Data Time: 0.0132 (0.0229) Average Loss: 0.3954 (0.4825) Average CE Loss (Source):  0.3954 ( 0.4825) Learning Rate: 0.0500 (0.0500) Top1_base: 87.5000 (86.5595) Top1_base_per_class: 88.7093 (86.9491) 
Training Epoch: [186/1000] Step: [270 / 285] Batch Time: 0.1445 (0.1564) Data Time: 0.0113 (0.0227) Average Loss: 0.3332 (0.4824) Average CE Loss (Source):  0.3332 ( 0.4824) Learning Rate: 0.0500 (0.0500) Top1_base: 91.4062 (86.6030) Top1_base_per_class: 91.3559 (86.9756) 
Training Epoch: [186/1000] Step: [280 / 285] Batch Time: 0.1455 (0.1563) Data Time: 0.0139 (0.0227) Average Loss: 0.4831 (0.4844) Average CE Loss (Source):  0.4831 ( 0.4844) Learning Rate: 0.0500 (0.0500) Top1_base: 89.0625 (86.5792) Top1_base_per_class: 87.2951 (86.9574) 
Training Epoch: [187/1000] Step: [0] Batch Time: 0.1427 (0.1562) Data Time: 0.0103 (0.0226) Average Loss: 0.4838 (0.4840) Average CE Loss (Source):  0.4838 ( 0.4840) Learning Rate: 0.0500 (0.0500) Top1_base: 88.2812 (86.5981) Top1_base_per_class: 87.2573 (86.9645) 
Training Epoch: [187/1000] Step: [10 / 285] Batch Time: 0.1811 (0.2325) Data Time: 0.0441 (0.0978) Average Loss: 0.3077 (0.4384) Average CE Loss (Source):  0.3077 ( 0.4384) Learning Rate: 0.0500 (0.0500) Top1_base: 89.8438 (87.2656) Top1_base_per_class: 88.5058 (87.9444) 
Training Epoch: [187/1000] Step: [20 / 285] Batch Time: 0.1439 (0.1984) Data Time: 0.0111 (0.0644) Average Loss: 0.5256 (0.4645) Average CE Loss (Source):  0.5256 ( 0.4645) Learning Rate: 0.0500 (0.0500) Top1_base: 85.1562 (86.9141) Top1_base_per_class: 87.7425 (87.4761) 
Training Epoch: [187/1000] Step: [30 / 285] Batch Time: 0.1592 (0.1849) Data Time: 0.0258 (0.0517) Average Loss: 0.3557 (0.4512) Average CE Loss (Source):  0.3557 ( 0.4512) Learning Rate: 0.0500 (0.0500) Top1_base: 89.8438 (87.3438) Top1_base_per_class: 89.2500 (87.5651) 
Training Epoch: [187/1000] Step: [40 / 285] Batch Time: 0.1455 (0.1762) Data Time: 0.0114 (0.0423) Average Loss: 0.5428 (0.4673) Average CE Loss (Source):  0.5428 ( 0.4673) Learning Rate: 0.0500 (0.0500) Top1_base: 86.7188 (86.9922) Top1_base_per_class: 87.1131 (87.4489) 
Training Epoch: [187/1000] Step: [50 / 285] Batch Time: 0.2111 (0.1720) Data Time: 0.0761 (0.0378) Average Loss: 0.4544 (0.4601) Average CE Loss (Source):  0.4544 ( 0.4601) Learning Rate: 0.0500 (0.0500) Top1_base: 87.5000 (87.2656) Top1_base_per_class: 85.8036 (87.6066) 
Training Epoch: [187/1000] Step: [60 / 285] Batch Time: 0.1465 (0.1690) Data Time: 0.0105 (0.0345) Average Loss: 0.5158 (0.4653) Average CE Loss (Source):  0.5158 ( 0.4653) Learning Rate: 0.0500 (0.0500) Top1_base: 86.7188 (87.2005) Top1_base_per_class: 87.7469 (87.5566) 
Training Epoch: [187/1000] Step: [70 / 285] Batch Time: 0.1471 (0.1669) Data Time: 0.0134 (0.0323) Average Loss: 0.3446 (0.4608) Average CE Loss (Source):  0.3446 ( 0.4608) Learning Rate: 0.0500 (0.0500) Top1_base: 90.6250 (87.3661) Top1_base_per_class: 89.6914 (87.7017) 
Training Epoch: [187/1000] Step: [80 / 285] Batch Time: 0.1476 (0.1649) Data Time: 0.0128 (0.0304) Average Loss: 0.3925 (0.4594) Average CE Loss (Source):  0.3925 ( 0.4594) Learning Rate: 0.0500 (0.0500) Top1_base: 89.0625 (87.3242) Top1_base_per_class: 86.7836 (87.7155) 
Training Epoch: [187/1000] Step: [90 / 285] Batch Time: 0.1671 (0.1636) Data Time: 0.0333 (0.0290) Average Loss: 0.4336 (0.4575) Average CE Loss (Source):  0.4336 ( 0.4575) Learning Rate: 0.0500 (0.0500) Top1_base: 88.2812 (87.3090) Top1_base_per_class: 89.5536 (87.7039) 
Training Epoch: [187/1000] Step: [100 / 285] Batch Time: 0.1482 (0.1619) Data Time: 0.0154 (0.0274) Average Loss: 0.4772 (0.4580) Average CE Loss (Source):  0.4772 ( 0.4580) Learning Rate: 0.0500 (0.0500) Top1_base: 85.1562 (87.2031) Top1_base_per_class: 83.4795 (87.6285) 
Training Epoch: [187/1000] Step: [110 / 285] Batch Time: 0.1525 (0.1607) Data Time: 0.0159 (0.0262) Average Loss: 0.5214 (0.4586) Average CE Loss (Source):  0.5214 ( 0.4586) Learning Rate: 0.0500 (0.0500) Top1_base: 82.8125 (87.1307) Top1_base_per_class: 83.1034 (87.4535) 
Training Epoch: [187/1000] Step: [120 / 285] Batch Time: 0.1499 (0.1598) Data Time: 0.0162 (0.0252) Average Loss: 0.4892 (0.4612) Average CE Loss (Source):  0.4892 ( 0.4612) Learning Rate: 0.0500 (0.0500) Top1_base: 85.9375 (87.1289) Top1_base_per_class: 86.6667 (87.4348) 
Training Epoch: [187/1000] Step: [130 / 285] Batch Time: 0.1501 (0.1590) Data Time: 0.0139 (0.0243) Average Loss: 0.4899 (0.4631) Average CE Loss (Source):  0.4899 ( 0.4631) Learning Rate: 0.0500 (0.0500) Top1_base: 85.1562 (87.0433) Top1_base_per_class: 87.5706 (87.3192) 
Training Epoch: [187/1000] Step: [140 / 285] Batch Time: 0.1515 (0.1584) Data Time: 0.0165 (0.0236) Average Loss: 0.5587 (0.4650) Average CE Loss (Source):  0.5587 ( 0.4650) Learning Rate: 0.0500 (0.0500) Top1_base: 83.5938 (86.9587) Top1_base_per_class: 87.8773 (87.2584) 
Training Epoch: [187/1000] Step: [150 / 285] Batch Time: 0.1488 (0.1578) Data Time: 0.0139 (0.0229) Average Loss: 0.5244 (0.4687) Average CE Loss (Source):  0.5244 ( 0.4687) Learning Rate: 0.0500 (0.0500) Top1_base: 85.9375 (86.8646) Top1_base_per_class: 82.3636 (87.1642) 
Training Epoch: [187/1000] Step: [160 / 285] Batch Time: 0.1429 (0.1574) Data Time: 0.0108 (0.0227) Average Loss: 0.4599 (0.4699) Average CE Loss (Source):  0.4599 ( 0.4699) Learning Rate: 0.0500 (0.0500) Top1_base: 88.2812 (86.8555) Top1_base_per_class: 87.6730 (87.1302) 
Training Epoch: [187/1000] Step: [170 / 285] Batch Time: 0.1491 (0.1574) Data Time: 0.0139 (0.0229) Average Loss: 0.4775 (0.4714) Average CE Loss (Source):  0.4775 ( 0.4714) Learning Rate: 0.0500 (0.0500) Top1_base: 89.0625 (86.8244) Top1_base_per_class: 89.4152 (87.1218) 
Training Epoch: [187/1000] Step: [180 / 285] Batch Time: 0.1435 (0.1569) Data Time: 0.0111 (0.0224) Average Loss: 0.5100 (0.4756) Average CE Loss (Source):  0.5100 ( 0.4756) Learning Rate: 0.0500 (0.0500) Top1_base: 85.1562 (86.7361) Top1_base_per_class: 83.3333 (87.0717) 
Training Epoch: [187/1000] Step: [190 / 285] Batch Time: 0.1726 (0.1567) Data Time: 0.0409 (0.0224) Average Loss: 0.4991 (0.4766) Average CE Loss (Source):  0.4991 ( 0.4766) Learning Rate: 0.0500 (0.0500) Top1_base: 83.5938 (86.7475) Top1_base_per_class: 85.4358 (87.1063) 
Training Epoch: [187/1000] Step: [200 / 285] Batch Time: 0.1470 (0.1566) Data Time: 0.0127 (0.0224) Average Loss: 0.3085 (0.4804) Average CE Loss (Source):  0.3085 ( 0.4804) Learning Rate: 0.0500 (0.0500) Top1_base: 91.4062 (86.6719) Top1_base_per_class: 93.3041 (87.0136) 
Training Epoch: [187/1000] Step: [210 / 285] Batch Time: 0.1818 (0.1569) Data Time: 0.0478 (0.0227) Average Loss: 0.5180 (0.4820) Average CE Loss (Source):  0.5180 ( 0.4820) Learning Rate: 0.0500 (0.0500) Top1_base: 84.3750 (86.6146) Top1_base_per_class: 89.2262 (87.0321) 
Training Epoch: [187/1000] Step: [220 / 285] Batch Time: 0.1449 (0.1567) Data Time: 0.0112 (0.0226) Average Loss: 0.6280 (0.4816) Average CE Loss (Source):  0.6280 ( 0.4816) Learning Rate: 0.0500 (0.0500) Top1_base: 82.0312 (86.5767) Top1_base_per_class: 86.7347 (86.9897) 
Training Epoch: [187/1000] Step: [230 / 285] Batch Time: 0.1714 (0.1564) Data Time: 0.0380 (0.0223) Average Loss: 0.4951 (0.4826) Average CE Loss (Source):  0.4951 ( 0.4826) Learning Rate: 0.0500 (0.0500) Top1_base: 85.1562 (86.5183) Top1_base_per_class: 85.8929 (86.9354) 
Training Epoch: [187/1000] Step: [240 / 285] Batch Time: 0.1460 (0.1559) Data Time: 0.0115 (0.0219) Average Loss: 0.3312 (0.4815) Average CE Loss (Source):  0.3312 ( 0.4815) Learning Rate: 0.0500 (0.0500) Top1_base: 92.1875 (86.5397) Top1_base_per_class: 92.0909 (86.9859) 
Training Epoch: [187/1000] Step: [250 / 285] Batch Time: 0.2746 (0.1568) Data Time: 0.1398 (0.0229) Average Loss: 0.7492 (0.4823) Average CE Loss (Source):  0.7492 ( 0.4823) Learning Rate: 0.0500 (0.0500) Top1_base: 82.8125 (86.5219) Top1_base_per_class: 82.6852 (86.9341) 
Training Epoch: [187/1000] Step: [260 / 285] Batch Time: 0.1452 (0.1565) Data Time: 0.0110 (0.0227) Average Loss: 0.4218 (0.4806) Average CE Loss (Source):  0.4218 ( 0.4806) Learning Rate: 0.0500 (0.0500) Top1_base: 90.6250 (86.5505) Top1_base_per_class: 89.8830 (86.9457) 
Training Epoch: [187/1000] Step: [270 / 285] Batch Time: 0.2683 (0.1570) Data Time: 0.1340 (0.0231) Average Loss: 0.5916 (0.4801) Average CE Loss (Source):  0.5916 ( 0.4801) Learning Rate: 0.0500 (0.0500) Top1_base: 81.2500 (86.5712) Top1_base_per_class: 82.0278 (86.9681) 
Training Epoch: [187/1000] Step: [280 / 285] Batch Time: 0.1456 (0.1569) Data Time: 0.0149 (0.0231) Average Loss: 0.6313 (0.4801) Average CE Loss (Source):  0.6313 ( 0.4801) Learning Rate: 0.0500 (0.0500) Top1_base: 85.1562 (86.5876) Top1_base_per_class: 90.0000 (86.9941) 
Training Epoch: [188/1000] Step: [0] Batch Time: 0.1404 (0.1568) Data Time: 0.0099 (0.0231) Average Loss: 0.6636 (0.4807) Average CE Loss (Source):  0.6636 ( 0.4807) Learning Rate: 0.0500 (0.0500) Top1_base: 83.5938 (86.5872) Top1_base_per_class: 84.8182 (86.9819) 
 19%|█▉        | 188/1000 [2:26:01<10:28:10, 46.42s/it] 19%|█▉        | 189/1000 [2:26:46<10:19:17, 45.82s/it]Training Epoch: [188/1000] Step: [10 / 285] Batch Time: 0.1483 (0.2376) Data Time: 0.0146 (0.1060) Average Loss: 0.4086 (0.4477) Average CE Loss (Source):  0.4086 ( 0.4477) Learning Rate: 0.0500 (0.0500) Top1_base: 89.8438 (87.7344) Top1_base_per_class: 92.1345 (88.9348) 
Training Epoch: [188/1000] Step: [20 / 285] Batch Time: 0.1425 (0.1962) Data Time: 0.0117 (0.0641) Average Loss: 0.3563 (0.4387) Average CE Loss (Source):  0.3563 ( 0.4387) Learning Rate: 0.0500 (0.0500) Top1_base: 92.9688 (87.6953) Top1_base_per_class: 95.4971 (89.1522) 
Training Epoch: [188/1000] Step: [30 / 285] Batch Time: 0.1466 (0.1855) Data Time: 0.0147 (0.0532) Average Loss: 0.6363 (0.4384) Average CE Loss (Source):  0.6363 ( 0.4384) Learning Rate: 0.0500 (0.0500) Top1_base: 83.5938 (87.7604) Top1_base_per_class: 84.6429 (88.9356) 
Training Epoch: [188/1000] Step: [40 / 285] Batch Time: 0.1481 (0.1771) Data Time: 0.0129 (0.0447) Average Loss: 0.4561 (0.4526) Average CE Loss (Source):  0.4561 ( 0.4526) Learning Rate: 0.0500 (0.0500) Top1_base: 85.1562 (87.2852) Top1_base_per_class: 88.0864 (88.2366) 
Training Epoch: [188/1000] Step: [50 / 285] Batch Time: 0.1441 (0.1729) Data Time: 0.0124 (0.0403) Average Loss: 0.4031 (0.4462) Average CE Loss (Source):  0.4031 ( 0.4462) Learning Rate: 0.0500 (0.0500) Top1_base: 88.2812 (87.4531) Top1_base_per_class: 90.0000 (88.4431) 
Training Epoch: [188/1000] Step: [60 / 285] Batch Time: 0.1527 (0.1699) Data Time: 0.0157 (0.0369) Average Loss: 0.4395 (0.4417) Average CE Loss (Source):  0.4395 ( 0.4417) Learning Rate: 0.0500 (0.0500) Top1_base: 89.0625 (87.5781) Top1_base_per_class: 90.0764 (88.4939) 
Training Epoch: [188/1000] Step: [70 / 285] Batch Time: 0.2174 (0.1680) Data Time: 0.0827 (0.0346) Average Loss: 0.4554 (0.4421) Average CE Loss (Source):  0.4554 ( 0.4421) Learning Rate: 0.0500 (0.0500) Top1_base: 84.3750 (87.5446) Top1_base_per_class: 81.7815 (88.3329) 
Training Epoch: [188/1000] Step: [80 / 285] Batch Time: 0.1519 (0.1658) Data Time: 0.0157 (0.0320) Average Loss: 0.2955 (0.4462) Average CE Loss (Source):  0.2955 ( 0.4462) Learning Rate: 0.0500 (0.0500) Top1_base: 91.4062 (87.4512) Top1_base_per_class: 91.2424 (88.1826) 
Training Epoch: [188/1000] Step: [90 / 285] Batch Time: 0.1496 (0.1640) Data Time: 0.0129 (0.0301) Average Loss: 0.4547 (0.4463) Average CE Loss (Source):  0.4547 ( 0.4463) Learning Rate: 0.0500 (0.0500) Top1_base: 87.5000 (87.5174) Top1_base_per_class: 89.1987 (88.2467) 
Training Epoch: [188/1000] Step: [100 / 285] Batch Time: 0.1525 (0.1626) Data Time: 0.0143 (0.0284) Average Loss: 0.1833 (0.4472) Average CE Loss (Source):  0.1833 ( 0.4472) Learning Rate: 0.0500 (0.0500) Top1_base: 94.5312 (87.4766) Top1_base_per_class: 95.3672 (88.1970) 
Training Epoch: [188/1000] Step: [110 / 285] Batch Time: 0.1469 (0.1614) Data Time: 0.0133 (0.0271) Average Loss: 0.4978 (0.4465) Average CE Loss (Source):  0.4978 ( 0.4465) Learning Rate: 0.0500 (0.0500) Top1_base: 82.8125 (87.5071) Top1_base_per_class: 82.7011 (88.2394) 
Training Epoch: [188/1000] Step: [120 / 285] Batch Time: 0.1441 (0.1601) Data Time: 0.0129 (0.0259) Average Loss: 0.6151 (0.4519) Average CE Loss (Source):  0.6151 ( 0.4519) Learning Rate: 0.0500 (0.0500) Top1_base: 83.5938 (87.4674) Top1_base_per_class: 86.0505 (88.2364) 
Training Epoch: [188/1000] Step: [130 / 285] Batch Time: 0.1500 (0.1592) Data Time: 0.0169 (0.0250) Average Loss: 0.6345 (0.4584) Average CE Loss (Source):  0.6345 ( 0.4584) Learning Rate: 0.0500 (0.0500) Top1_base: 81.2500 (87.2536) Top1_base_per_class: 76.2213 (87.9381) 
Training Epoch: [188/1000] Step: [140 / 285] Batch Time: 0.1506 (0.1583) Data Time: 0.0139 (0.0242) Average Loss: 0.5118 (0.4596) Average CE Loss (Source):  0.5118 ( 0.4596) Learning Rate: 0.0500 (0.0500) Top1_base: 83.5938 (87.1931) Top1_base_per_class: 83.7654 (87.8924) 
Training Epoch: [188/1000] Step: [150 / 285] Batch Time: 0.1449 (0.1578) Data Time: 0.0122 (0.0236) Average Loss: 0.3633 (0.4626) Average CE Loss (Source):  0.3633 ( 0.4626) Learning Rate: 0.0500 (0.0500) Top1_base: 92.1875 (87.0573) Top1_base_per_class: 89.7879 (87.7278) 
Training Epoch: [188/1000] Step: [160 / 285] Batch Time: 0.1461 (0.1571) Data Time: 0.0142 (0.0230) Average Loss: 0.5912 (0.4658) Average CE Loss (Source):  0.5912 ( 0.4658) Learning Rate: 0.0500 (0.0500) Top1_base: 81.2500 (86.9727) Top1_base_per_class: 82.5000 (87.6509) 
Training Epoch: [188/1000] Step: [170 / 285] Batch Time: 0.1453 (0.1565) Data Time: 0.0145 (0.0225) Average Loss: 0.4654 (0.4667) Average CE Loss (Source):  0.4654 ( 0.4667) Learning Rate: 0.0500 (0.0500) Top1_base: 85.1562 (86.9347) Top1_base_per_class: 84.9415 (87.6012) 
Training Epoch: [188/1000] Step: [180 / 285] Batch Time: 0.1527 (0.1562) Data Time: 0.0175 (0.0222) Average Loss: 0.5185 (0.4700) Average CE Loss (Source):  0.5185 ( 0.4700) Learning Rate: 0.0500 (0.0500) Top1_base: 84.3750 (86.8403) Top1_base_per_class: 84.5536 (87.4843) 
Training Epoch: [188/1000] Step: [190 / 285] Batch Time: 0.1461 (0.1564) Data Time: 0.0132 (0.0224) Average Loss: 0.5755 (0.4702) Average CE Loss (Source):  0.5755 ( 0.4702) Learning Rate: 0.0500 (0.0500) Top1_base: 83.5938 (86.8421) Top1_base_per_class: 84.0566 (87.4986) 
Training Epoch: [188/1000] Step: [200 / 285] Batch Time: 0.1457 (0.1564) Data Time: 0.0140 (0.0225) Average Loss: 0.3752 (0.4717) Average CE Loss (Source):  0.3752 ( 0.4717) Learning Rate: 0.0500 (0.0500) Top1_base: 89.8438 (86.8086) Top1_base_per_class: 89.4118 (87.4573) 
Training Epoch: [188/1000] Step: [210 / 285] Batch Time: 0.1470 (0.1563) Data Time: 0.0130 (0.0224) Average Loss: 0.6553 (0.4739) Average CE Loss (Source):  0.6553 ( 0.4739) Learning Rate: 0.0500 (0.0500) Top1_base: 82.0312 (86.7522) Top1_base_per_class: 85.7602 (87.4212) 
Training Epoch: [188/1000] Step: [220 / 285] Batch Time: 0.1493 (0.1562) Data Time: 0.0120 (0.0223) Average Loss: 0.5400 (0.4743) Average CE Loss (Source):  0.5400 ( 0.4743) Learning Rate: 0.0500 (0.0500) Top1_base: 85.9375 (86.7756) Top1_base_per_class: 87.7381 (87.4566) 
Training Epoch: [188/1000] Step: [230 / 285] Batch Time: 0.1442 (0.1560) Data Time: 0.0132 (0.0222) Average Loss: 0.4846 (0.4742) Average CE Loss (Source):  0.4846 ( 0.4742) Learning Rate: 0.0500 (0.0500) Top1_base: 88.2812 (86.7799) Top1_base_per_class: 90.7547 (87.4818) 
Training Epoch: [188/1000] Step: [240 / 285] Batch Time: 0.1502 (0.1560) Data Time: 0.0155 (0.0222) Average Loss: 0.4333 (0.4767) Average CE Loss (Source):  0.4333 ( 0.4767) Learning Rate: 0.0500 (0.0500) Top1_base: 88.2812 (86.7383) Top1_base_per_class: 87.2640 (87.3955) 
Training Epoch: [188/1000] Step: [250 / 285] Batch Time: 0.1482 (0.1561) Data Time: 0.0145 (0.0223) Average Loss: 0.7505 (0.4790) Average CE Loss (Source):  0.7505 ( 0.4790) Learning Rate: 0.0500 (0.0500) Top1_base: 81.2500 (86.6719) Top1_base_per_class: 81.3333 (87.2993) 
Training Epoch: [188/1000] Step: [260 / 285] Batch Time: 0.1434 (0.1560) Data Time: 0.0131 (0.0222) Average Loss: 0.3341 (0.4793) Average CE Loss (Source):  0.3341 ( 0.4793) Learning Rate: 0.0500 (0.0500) Top1_base: 89.8438 (86.6737) Top1_base_per_class: 88.1286 (87.2285) 
Training Epoch: [188/1000] Step: [270 / 285] Batch Time: 0.1439 (0.1559) Data Time: 0.0124 (0.0222) Average Loss: 0.5561 (0.4808) Average CE Loss (Source):  0.5561 ( 0.4808) Learning Rate: 0.0500 (0.0500) Top1_base: 83.5938 (86.5828) Top1_base_per_class: 81.3218 (87.1493) 
Training Epoch: [188/1000] Step: [280 / 285] Batch Time: 0.1496 (0.1558) Data Time: 0.0137 (0.0221) Average Loss: 0.5297 (0.4825) Average CE Loss (Source):  0.5297 ( 0.4825) Learning Rate: 0.0500 (0.0500) Top1_base: 87.5000 (86.5262) Top1_base_per_class: 89.1369 (87.0603) 
Training Epoch: [189/1000] Step: [0] Batch Time: 0.1450 (0.1556) Data Time: 0.0148 (0.0220) Average Loss: 0.5035 (0.4831) Average CE Loss (Source):  0.5035 ( 0.4831) Learning Rate: 0.0500 (0.0500) Top1_base: 86.7188 (86.5104) Top1_base_per_class: 87.8056 (87.0329) 
Training Epoch: [189/1000] Step: [10 / 285] Batch Time: 0.1478 (0.2407) Data Time: 0.0112 (0.1059) Average Loss: 0.3075 (0.4412) Average CE Loss (Source):  0.3075 ( 0.4412) Learning Rate: 0.0500 (0.0500) Top1_base: 94.5312 (87.5000) Top1_base_per_class: 93.2727 (87.4449) 
Training Epoch: [189/1000] Step: [20 / 285] Batch Time: 0.1450 (0.2020) Data Time: 0.0103 (0.0669) Average Loss: 0.4158 (0.4555) Average CE Loss (Source):  0.4158 ( 0.4555) Learning Rate: 0.0500 (0.0500) Top1_base: 89.8438 (87.3438) Top1_base_per_class: 91.0556 (87.3251) 
Training Epoch: [189/1000] Step: [30 / 285] Batch Time: 0.1481 (0.1844) Data Time: 0.0102 (0.0492) Average Loss: 0.4643 (0.4577) Average CE Loss (Source):  0.4643 ( 0.4577) Learning Rate: 0.0500 (0.0500) Top1_base: 89.8438 (87.6823) Top1_base_per_class: 90.9649 (87.9145) 
Training Epoch: [189/1000] Step: [40 / 285] Batch Time: 0.1473 (0.1752) Data Time: 0.0122 (0.0403) Average Loss: 0.3615 (0.4647) Average CE Loss (Source):  0.3615 ( 0.4647) Learning Rate: 0.0500 (0.0500) Top1_base: 92.1875 (87.6172) Top1_base_per_class: 91.7778 (87.8328) 
Training Epoch: [189/1000] Step: [50 / 285] Batch Time: 0.1448 (0.1712) Data Time: 0.0133 (0.0369) Average Loss: 0.4280 (0.4726) Average CE Loss (Source):  0.4280 ( 0.4726) Learning Rate: 0.0500 (0.0500) Top1_base: 86.7188 (87.3438) Top1_base_per_class: 85.2874 (87.7293) 
Training Epoch: [189/1000] Step: [60 / 285] Batch Time: 0.1444 (0.1679) Data Time: 0.0108 (0.0339) Average Loss: 0.3907 (0.4673) Average CE Loss (Source):  0.3907 ( 0.4673) Learning Rate: 0.0500 (0.0500) Top1_base: 90.6250 (87.5130) Top1_base_per_class: 91.7377 (87.9566) 
Training Epoch: [189/1000] Step: [70 / 285] Batch Time: 0.1432 (0.1661) Data Time: 0.0129 (0.0321) Average Loss: 0.4714 (0.4641) Average CE Loss (Source):  0.4714 ( 0.4641) Learning Rate: 0.0500 (0.0500) Top1_base: 88.2812 (87.5335) Top1_base_per_class: 91.3988 (88.0028) 
Training Epoch: [189/1000] Step: [80 / 285] Batch Time: 0.1468 (0.1636) Data Time: 0.0121 (0.0297) Average Loss: 0.5737 (0.4672) Average CE Loss (Source):  0.5737 ( 0.4672) Learning Rate: 0.0500 (0.0500) Top1_base: 86.7188 (87.5977) Top1_base_per_class: 87.7381 (88.0705) 
Training Epoch: [189/1000] Step: [90 / 285] Batch Time: 0.1496 (0.1630) Data Time: 0.0119 (0.0288) Average Loss: 0.4257 (0.4695) Average CE Loss (Source):  0.4257 ( 0.4695) Learning Rate: 0.0500 (0.0500) Top1_base: 87.5000 (87.4913) Top1_base_per_class: 89.3333 (87.9419) 
Training Epoch: [189/1000] Step: [100 / 285] Batch Time: 0.1443 (0.1620) Data Time: 0.0107 (0.0278) Average Loss: 0.6351 (0.4706) Average CE Loss (Source):  0.6351 ( 0.4706) Learning Rate: 0.0500 (0.0500) Top1_base: 82.0312 (87.3672) Top1_base_per_class: 81.3218 (87.7984) 
Training Epoch: [189/1000] Step: [110 / 285] Batch Time: 0.1444 (0.1605) Data Time: 0.0152 (0.0265) Average Loss: 0.5928 (0.4750) Average CE Loss (Source):  0.5928 ( 0.4750) Learning Rate: 0.0500 (0.0500) Top1_base: 84.3750 (87.1804) Top1_base_per_class: 86.2121 (87.4618) 
Training Epoch: [189/1000] Step: [120 / 285] Batch Time: 0.1475 (0.1595) Data Time: 0.0146 (0.0256) Average Loss: 0.6495 (0.4725) Average CE Loss (Source):  0.6495 ( 0.4725) Learning Rate: 0.0500 (0.0500) Top1_base: 85.9375 (87.3242) Top1_base_per_class: 84.2816 (87.6256) 
Training Epoch: [189/1000] Step: [130 / 285] Batch Time: 0.1446 (0.1593) Data Time: 0.0145 (0.0255) Average Loss: 0.6353 (0.4738) Average CE Loss (Source):  0.6353 ( 0.4738) Learning Rate: 0.0500 (0.0500) Top1_base: 83.5938 (87.2897) Top1_base_per_class: 85.8642 (87.5824) 
Training Epoch: [189/1000] Step: [140 / 285] Batch Time: 0.1473 (0.1587) Data Time: 0.0115 (0.0251) Average Loss: 0.5324 (0.4726) Average CE Loss (Source):  0.5324 ( 0.4726) Learning Rate: 0.0500 (0.0500) Top1_base: 85.1562 (87.3158) Top1_base_per_class: 84.8485 (87.5849) 
Training Epoch: [189/1000] Step: [150 / 285] Batch Time: 0.1523 (0.1581) Data Time: 0.0144 (0.0244) Average Loss: 0.4842 (0.4732) Average CE Loss (Source):  0.4842 ( 0.4732) Learning Rate: 0.0500 (0.0500) Top1_base: 88.2812 (87.3281) Top1_base_per_class: 89.7661 (87.6210) 
Training Epoch: [189/1000] Step: [160 / 285] Batch Time: 0.1451 (0.1574) Data Time: 0.0126 (0.0237) Average Loss: 0.4224 (0.4764) Average CE Loss (Source):  0.4224 ( 0.4764) Learning Rate: 0.0500 (0.0500) Top1_base: 89.8438 (87.2070) Top1_base_per_class: 90.5411 (87.5134) 
Training Epoch: [189/1000] Step: [170 / 285] Batch Time: 0.1518 (0.1568) Data Time: 0.0144 (0.0231) Average Loss: 0.4319 (0.4772) Average CE Loss (Source):  0.4319 ( 0.4772) Learning Rate: 0.0500 (0.0500) Top1_base: 88.2812 (87.1094) Top1_base_per_class: 86.5544 (87.3758) 
Training Epoch: [189/1000] Step: [180 / 285] Batch Time: 0.1503 (0.1566) Data Time: 0.0146 (0.0229) Average Loss: 0.5274 (0.4782) Average CE Loss (Source):  0.5274 ( 0.4782) Learning Rate: 0.0500 (0.0500) Top1_base: 86.7188 (87.0530) Top1_base_per_class: 87.3030 (87.3444) 
Training Epoch: [189/1000] Step: [190 / 285] Batch Time: 0.1489 (0.1563) Data Time: 0.0120 (0.0225) Average Loss: 0.5627 (0.4805) Average CE Loss (Source):  0.5627 ( 0.4805) Learning Rate: 0.0500 (0.0500) Top1_base: 85.1562 (87.0025) Top1_base_per_class: 87.6970 (87.3186) 
Training Epoch: [189/1000] Step: [200 / 285] Batch Time: 0.1532 (0.1560) Data Time: 0.0165 (0.0220) Average Loss: 0.5666 (0.4812) Average CE Loss (Source):  0.5666 ( 0.4812) Learning Rate: 0.0500 (0.0500) Top1_base: 82.8125 (86.9648) Top1_base_per_class: 84.1061 (87.3173) 
Training Epoch: [189/1000] Step: [210 / 285] Batch Time: 0.1437 (0.1558) Data Time: 0.0132 (0.0218) Average Loss: 0.4950 (0.4804) Average CE Loss (Source):  0.4950 ( 0.4804) Learning Rate: 0.0500 (0.0500) Top1_base: 85.9375 (86.9940) Top1_base_per_class: 86.2037 (87.3520) 
Training Epoch: [189/1000] Step: [220 / 285] Batch Time: 0.2156 (0.1558) Data Time: 0.0831 (0.0219) Average Loss: 0.4285 (0.4812) Average CE Loss (Source):  0.4285 ( 0.4812) Learning Rate: 0.0500 (0.0500) Top1_base: 88.2812 (86.9496) Top1_base_per_class: 85.8929 (87.3212) 
Training Epoch: [189/1000] Step: [230 / 285] Batch Time: 0.1443 (0.1554) Data Time: 0.0137 (0.0215) Average Loss: 0.4554 (0.4817) Average CE Loss (Source):  0.4554 ( 0.4817) Learning Rate: 0.0500 (0.0500) Top1_base: 85.1562 (86.9260) Top1_base_per_class: 87.5758 (87.3239) 
Training Epoch: [189/1000] Step: [240 / 285] Batch Time: 0.1508 (0.1553) Data Time: 0.0196 (0.0215) Average Loss: 0.3365 (0.4797) Average CE Loss (Source):  0.3365 ( 0.4797) Learning Rate: 0.0500 (0.0500) Top1_base: 91.4062 (86.9368) Top1_base_per_class: 90.0617 (87.3390) 
Training Epoch: [189/1000] Step: [250 / 285] Batch Time: 0.1467 (0.1553) Data Time: 0.0118 (0.0215) Average Loss: 0.3388 (0.4803) Average CE Loss (Source):  0.3388 ( 0.4803) Learning Rate: 0.0500 (0.0500) Top1_base: 89.8438 (86.9062) Top1_base_per_class: 89.7321 (87.3080) 
Training Epoch: [189/1000] Step: [260 / 285] Batch Time: 0.2237 (0.1559) Data Time: 0.0896 (0.0220) Average Loss: 0.6517 (0.4822) Average CE Loss (Source):  0.6517 ( 0.4822) Learning Rate: 0.0500 (0.0500) Top1_base: 82.0312 (86.8600) Top1_base_per_class: 80.1515 (87.2918) 
Training Epoch: [189/1000] Step: [270 / 285] Batch Time: 0.1484 (0.1557) Data Time: 0.0119 (0.0217) Average Loss: 0.4324 (0.4813) Average CE Loss (Source):  0.4324 ( 0.4813) Learning Rate: 0.0500 (0.0500) Top1_base: 91.4062 (86.8924) Top1_base_per_class: 93.4906 (87.3313) 
Training Epoch: [189/1000] Step: [280 / 285] Batch Time: 0.1480 (0.1553) Data Time: 0.0157 (0.0214) Average Loss: 0.3435 (0.4806) Average CE Loss (Source):  0.3435 ( 0.4806) Learning Rate: 0.0500 (0.0500) Top1_base: 93.7500 (86.9252) Top1_base_per_class: 93.3333 (87.3505) 
Training Epoch: [190/1000] Step: [0] Batch Time: 0.1425 (0.1552) Data Time: 0.0105 (0.0214) Average Loss: 0.5946 (0.4807) Average CE Loss (Source):  0.5946 ( 0.4807) Learning Rate: 0.0500 (0.0500) Top1_base: 85.1562 (86.9435) Top1_base_per_class: 86.8750 (87.3701) 
 19%|█▉        | 190/1000 [2:27:33<10:23:28, 46.18s/it] 19%|█▉        | 191/1000 [2:28:18<10:18:48, 45.89s/it]Training Epoch: [190/1000] Step: [10 / 285] Batch Time: 0.1449 (0.2304) Data Time: 0.0125 (0.0974) Average Loss: 0.5640 (0.5027) Average CE Loss (Source):  0.5640 ( 0.5027) Learning Rate: 0.0500 (0.0500) Top1_base: 85.1562 (87.1875) Top1_base_per_class: 86.2500 (87.1365) 
Training Epoch: [190/1000] Step: [20 / 285] Batch Time: 0.1480 (0.1954) Data Time: 0.0126 (0.0623) Average Loss: 0.2937 (0.4816) Average CE Loss (Source):  0.2937 ( 0.4816) Learning Rate: 0.0500 (0.0500) Top1_base: 91.4062 (87.5391) Top1_base_per_class: 92.3446 (88.0140) 
Training Epoch: [190/1000] Step: [30 / 285] Batch Time: 0.1667 (0.1808) Data Time: 0.0358 (0.0478) Average Loss: 0.4779 (0.4721) Average CE Loss (Source):  0.4779 ( 0.4721) Learning Rate: 0.0500 (0.0500) Top1_base: 89.0625 (87.5781) Top1_base_per_class: 90.6609 (87.9325) 
Training Epoch: [190/1000] Step: [40 / 285] Batch Time: 0.1467 (0.1732) Data Time: 0.0107 (0.0401) Average Loss: 0.4869 (0.4625) Average CE Loss (Source):  0.4869 ( 0.4625) Learning Rate: 0.0500 (0.0500) Top1_base: 88.2812 (87.8320) Top1_base_per_class: 86.6038 (88.1085) 
Training Epoch: [190/1000] Step: [50 / 285] Batch Time: 0.1489 (0.1721) Data Time: 0.0141 (0.0389) Average Loss: 0.4227 (0.4570) Average CE Loss (Source):  0.4227 ( 0.4570) Learning Rate: 0.0500 (0.0500) Top1_base: 89.8438 (87.8750) Top1_base_per_class: 89.6552 (88.0927) 
Training Epoch: [190/1000] Step: [60 / 285] Batch Time: 0.1435 (0.1701) Data Time: 0.0104 (0.0369) Average Loss: 0.4555 (0.4593) Average CE Loss (Source):  0.4555 ( 0.4593) Learning Rate: 0.0500 (0.0500) Top1_base: 86.7188 (87.8516) Top1_base_per_class: 87.9091 (88.0133) 
Training Epoch: [190/1000] Step: [70 / 285] Batch Time: 0.1491 (0.1672) Data Time: 0.0160 (0.0339) Average Loss: 0.6012 (0.4632) Average CE Loss (Source):  0.6012 ( 0.4632) Learning Rate: 0.0500 (0.0500) Top1_base: 89.0625 (87.7232) Top1_base_per_class: 87.5731 (87.7883) 
Training Epoch: [190/1000] Step: [80 / 285] Batch Time: 0.1441 (0.1662) Data Time: 0.0117 (0.0329) Average Loss: 0.5786 (0.4673) Average CE Loss (Source):  0.5786 ( 0.4673) Learning Rate: 0.0500 (0.0500) Top1_base: 82.8125 (87.5098) Top1_base_per_class: 82.8704 (87.7189) 
Training Epoch: [190/1000] Step: [90 / 285] Batch Time: 0.1498 (0.1645) Data Time: 0.0152 (0.0312) Average Loss: 0.6712 (0.4767) Average CE Loss (Source):  0.6712 ( 0.4767) Learning Rate: 0.0500 (0.0500) Top1_base: 82.0312 (87.2743) Top1_base_per_class: 82.3895 (87.4833) 
Training Epoch: [190/1000] Step: [100 / 285] Batch Time: 0.1439 (0.1632) Data Time: 0.0117 (0.0299) Average Loss: 0.5868 (0.4762) Average CE Loss (Source):  0.5868 ( 0.4762) Learning Rate: 0.0500 (0.0500) Top1_base: 83.5938 (87.2344) Top1_base_per_class: 84.8830 (87.4194) 
Training Epoch: [190/1000] Step: [110 / 285] Batch Time: 0.1475 (0.1626) Data Time: 0.0125 (0.0293) Average Loss: 0.4800 (0.4751) Average CE Loss (Source):  0.4800 ( 0.4751) Learning Rate: 0.0500 (0.0500) Top1_base: 87.5000 (87.1520) Top1_base_per_class: 89.6296 (87.4089) 
Training Epoch: [190/1000] Step: [120 / 285] Batch Time: 0.1428 (0.1614) Data Time: 0.0115 (0.0282) Average Loss: 0.4460 (0.4744) Average CE Loss (Source):  0.4460 ( 0.4744) Learning Rate: 0.0500 (0.0500) Top1_base: 89.8438 (87.1419) Top1_base_per_class: 89.0643 (87.4969) 
Training Epoch: [190/1000] Step: [130 / 285] Batch Time: 0.1475 (0.1603) Data Time: 0.0149 (0.0271) Average Loss: 0.5287 (0.4785) Average CE Loss (Source):  0.5287 ( 0.4785) Learning Rate: 0.0500 (0.0500) Top1_base: 83.5938 (86.9712) Top1_base_per_class: 82.7576 (87.3066) 
Training Epoch: [190/1000] Step: [140 / 285] Batch Time: 0.1454 (0.1604) Data Time: 0.0106 (0.0272) Average Loss: 0.4727 (0.4775) Average CE Loss (Source):  0.4727 ( 0.4775) Learning Rate: 0.0500 (0.0500) Top1_base: 87.5000 (87.0480) Top1_base_per_class: 89.8851 (87.3428) 
Training Epoch: [190/1000] Step: [150 / 285] Batch Time: 0.1447 (0.1609) Data Time: 0.0119 (0.0277) Average Loss: 0.4533 (0.4779) Average CE Loss (Source):  0.4533 ( 0.4779) Learning Rate: 0.0500 (0.0500) Top1_base: 89.0625 (86.9740) Top1_base_per_class: 89.6675 (87.2866) 
Training Epoch: [190/1000] Step: [160 / 285] Batch Time: 0.1443 (0.1604) Data Time: 0.0104 (0.0272) Average Loss: 0.5940 (0.4769) Average CE Loss (Source):  0.5940 ( 0.4769) Learning Rate: 0.0500 (0.0500) Top1_base: 83.5938 (86.9580) Top1_base_per_class: 82.2121 (87.2638) 
Training Epoch: [190/1000] Step: [170 / 285] Batch Time: 0.1467 (0.1600) Data Time: 0.0145 (0.0268) Average Loss: 0.3865 (0.4762) Average CE Loss (Source):  0.3865 ( 0.4762) Learning Rate: 0.0500 (0.0500) Top1_base: 89.0625 (86.9853) Top1_base_per_class: 88.5965 (87.3388) 
Training Epoch: [190/1000] Step: [180 / 285] Batch Time: 0.1426 (0.1603) Data Time: 0.0101 (0.0271) Average Loss: 0.5994 (0.4751) Average CE Loss (Source):  0.5994 ( 0.4751) Learning Rate: 0.0500 (0.0500) Top1_base: 81.2500 (87.0182) Top1_base_per_class: 78.7000 (87.4054) 
Training Epoch: [190/1000] Step: [190 / 285] Batch Time: 0.1467 (0.1596) Data Time: 0.0143 (0.0264) Average Loss: 0.4009 (0.4749) Average CE Loss (Source):  0.4009 ( 0.4749) Learning Rate: 0.0500 (0.0500) Top1_base: 85.9375 (86.9942) Top1_base_per_class: 88.7427 (87.3615) 
Training Epoch: [190/1000] Step: [200 / 285] Batch Time: 0.1426 (0.1594) Data Time: 0.0118 (0.0261) Average Loss: 0.5636 (0.4754) Average CE Loss (Source):  0.5636 ( 0.4754) Learning Rate: 0.0500 (0.0500) Top1_base: 86.7188 (87.0117) Top1_base_per_class: 87.7244 (87.3801) 
Training Epoch: [190/1000] Step: [210 / 285] Batch Time: 0.1470 (0.1590) Data Time: 0.0128 (0.0257) Average Loss: 0.4153 (0.4769) Average CE Loss (Source):  0.4153 ( 0.4769) Learning Rate: 0.0500 (0.0500) Top1_base: 85.1562 (86.9829) Top1_base_per_class: 86.0119 (87.3628) 
Training Epoch: [190/1000] Step: [220 / 285] Batch Time: 0.1439 (0.1600) Data Time: 0.0103 (0.0267) Average Loss: 0.4900 (0.4768) Average CE Loss (Source):  0.4900 ( 0.4768) Learning Rate: 0.0500 (0.0500) Top1_base: 86.7188 (86.9744) Top1_base_per_class: 88.2680 (87.3616) 
Training Epoch: [190/1000] Step: [230 / 285] Batch Time: 0.1469 (0.1597) Data Time: 0.0119 (0.0265) Average Loss: 0.5641 (0.4767) Average CE Loss (Source):  0.5641 ( 0.4767) Learning Rate: 0.0500 (0.0500) Top1_base: 86.7188 (87.0041) Top1_base_per_class: 87.3896 (87.3708) 
Training Epoch: [190/1000] Step: [240 / 285] Batch Time: 0.1452 (0.1595) Data Time: 0.0106 (0.0263) Average Loss: 0.5846 (0.4781) Average CE Loss (Source):  0.5846 ( 0.4781) Learning Rate: 0.0500 (0.0500) Top1_base: 82.0312 (86.9206) Top1_base_per_class: 82.1121 (87.2687) 
Training Epoch: [190/1000] Step: [250 / 285] Batch Time: 0.1464 (0.1595) Data Time: 0.0147 (0.0263) Average Loss: 0.4081 (0.4788) Average CE Loss (Source):  0.4081 ( 0.4788) Learning Rate: 0.0500 (0.0500) Top1_base: 88.2812 (86.8969) Top1_base_per_class: 88.4259 (87.2673) 
Training Epoch: [190/1000] Step: [260 / 285] Batch Time: 0.1449 (0.1593) Data Time: 0.0102 (0.0260) Average Loss: 0.5527 (0.4794) Average CE Loss (Source):  0.5527 ( 0.4794) Learning Rate: 0.0500 (0.0500) Top1_base: 82.8125 (86.8570) Top1_base_per_class: 81.1782 (87.1926) 
Training Epoch: [190/1000] Step: [270 / 285] Batch Time: 0.1476 (0.1589) Data Time: 0.0153 (0.0257) Average Loss: 0.4879 (0.4796) Average CE Loss (Source):  0.4879 ( 0.4796) Learning Rate: 0.0500 (0.0500) Top1_base: 87.5000 (86.7853) Top1_base_per_class: 87.4528 (87.0874) 
Training Epoch: [190/1000] Step: [280 / 285] Batch Time: 0.1480 (0.1587) Data Time: 0.0124 (0.0254) Average Loss: 0.4418 (0.4828) Average CE Loss (Source):  0.4418 ( 0.4828) Learning Rate: 0.0500 (0.0500) Top1_base: 86.7188 (86.6853) Top1_base_per_class: 87.7586 (87.0081) 
Training Epoch: [191/1000] Step: [0] Batch Time: 0.1434 (0.1585) Data Time: 0.0120 (0.0252) Average Loss: 0.5001 (0.4828) Average CE Loss (Source):  0.5001 ( 0.4828) Learning Rate: 0.0500 (0.0500) Top1_base: 86.7188 (86.6804) Top1_base_per_class: 83.9506 (86.9925) 
Training Epoch: [191/1000] Step: [10 / 285] Batch Time: 0.1455 (0.2304) Data Time: 0.0121 (0.0965) Average Loss: 0.6198 (0.4745) Average CE Loss (Source):  0.6198 ( 0.4745) Learning Rate: 0.0500 (0.0500) Top1_base: 82.8125 (86.2500) Top1_base_per_class: 85.3594 (87.0769) 
Training Epoch: [191/1000] Step: [20 / 285] Batch Time: 0.1441 (0.1942) Data Time: 0.0110 (0.0602) Average Loss: 0.4999 (0.4864) Average CE Loss (Source):  0.4999 ( 0.4864) Learning Rate: 0.0500 (0.0500) Top1_base: 85.1562 (85.9766) Top1_base_per_class: 86.1905 (85.8498) 
Training Epoch: [191/1000] Step: [30 / 285] Batch Time: 0.1417 (0.1920) Data Time: 0.0106 (0.0589) Average Loss: 0.4643 (0.4985) Average CE Loss (Source):  0.4643 ( 0.4985) Learning Rate: 0.0500 (0.0500) Top1_base: 85.9375 (85.7292) Top1_base_per_class: 86.3095 (86.0437) 
Training Epoch: [191/1000] Step: [40 / 285] Batch Time: 0.1456 (0.1811) Data Time: 0.0148 (0.0482) Average Loss: 0.5070 (0.4896) Average CE Loss (Source):  0.5070 ( 0.4896) Learning Rate: 0.0500 (0.0500) Top1_base: 85.1562 (86.0547) Top1_base_per_class: 83.4242 (86.5555) 
Training Epoch: [191/1000] Step: [50 / 285] Batch Time: 0.1462 (0.1767) Data Time: 0.0128 (0.0438) Average Loss: 0.3690 (0.4866) Average CE Loss (Source):  0.3690 ( 0.4866) Learning Rate: 0.0500 (0.0500) Top1_base: 90.6250 (86.0781) Top1_base_per_class: 93.6017 (86.6100) 
Training Epoch: [191/1000] Step: [60 / 285] Batch Time: 0.1455 (0.1743) Data Time: 0.0124 (0.0414) Average Loss: 0.5351 (0.4874) Average CE Loss (Source):  0.5351 ( 0.4874) Learning Rate: 0.0500 (0.0500) Top1_base: 82.0312 (85.9635) Top1_base_per_class: 83.3626 (86.4494) 
Training Epoch: [191/1000] Step: [70 / 285] Batch Time: 0.1459 (0.1734) Data Time: 0.0103 (0.0405) Average Loss: 0.5493 (0.4879) Average CE Loss (Source):  0.5493 ( 0.4879) Learning Rate: 0.0500 (0.0500) Top1_base: 83.5938 (86.0491) Top1_base_per_class: 84.3519 (86.5840) 
Training Epoch: [191/1000] Step: [80 / 285] Batch Time: 0.1435 (0.1708) Data Time: 0.0104 (0.0380) Average Loss: 0.5086 (0.4892) Average CE Loss (Source):  0.5086 ( 0.4892) Learning Rate: 0.0500 (0.0500) Top1_base: 86.7188 (86.1035) Top1_base_per_class: 89.2560 (86.6133) 
Training Epoch: [191/1000] Step: [90 / 285] Batch Time: 0.1429 (0.1684) Data Time: 0.0115 (0.0358) Average Loss: 0.4743 (0.4830) Average CE Loss (Source):  0.4743 ( 0.4830) Learning Rate: 0.0500 (0.0500) Top1_base: 86.7188 (86.2847) Top1_base_per_class: 85.2632 (86.7290) 
Training Epoch: [191/1000] Step: [100 / 285] Batch Time: 0.1454 (0.1666) Data Time: 0.0130 (0.0339) Average Loss: 0.6114 (0.4845) Average CE Loss (Source):  0.6114 ( 0.4845) Learning Rate: 0.0500 (0.0500) Top1_base: 84.3750 (86.3438) Top1_base_per_class: 84.2064 (86.7476) 
Training Epoch: [191/1000] Step: [110 / 285] Batch Time: 0.1436 (0.1667) Data Time: 0.0116 (0.0340) Average Loss: 0.4602 (0.4848) Average CE Loss (Source):  0.4602 ( 0.4848) Learning Rate: 0.0500 (0.0500) Top1_base: 86.7188 (86.4276) Top1_base_per_class: 90.4088 (86.8417) 
Training Epoch: [191/1000] Step: [120 / 285] Batch Time: 0.1430 (0.1659) Data Time: 0.0112 (0.0332) Average Loss: 0.4907 (0.4841) Average CE Loss (Source):  0.4907 ( 0.4841) Learning Rate: 0.0500 (0.0500) Top1_base: 86.7188 (86.4193) Top1_base_per_class: 88.3019 (86.8427) 
Training Epoch: [191/1000] Step: [130 / 285] Batch Time: 0.1448 (0.1653) Data Time: 0.0106 (0.0326) Average Loss: 0.3938 (0.4837) Average CE Loss (Source):  0.3938 ( 0.4837) Learning Rate: 0.0500 (0.0500) Top1_base: 88.2812 (86.4844) Top1_base_per_class: 88.3036 (86.9070) 
Training Epoch: [191/1000] Step: [140 / 285] Batch Time: 0.1432 (0.1644) Data Time: 0.0110 (0.0317) Average Loss: 0.5305 (0.4854) Average CE Loss (Source):  0.5305 ( 0.4854) Learning Rate: 0.0500 (0.0500) Top1_base: 82.8125 (86.4900) Top1_base_per_class: 83.0655 (86.9586) 
Training Epoch: [191/1000] Step: [150 / 285] Batch Time: 0.1412 (0.1639) Data Time: 0.0111 (0.0313) Average Loss: 0.5185 (0.4835) Average CE Loss (Source):  0.5185 ( 0.4835) Learning Rate: 0.0500 (0.0500) Top1_base: 85.1562 (86.4844) Top1_base_per_class: 83.7798 (86.9077) 
Training Epoch: [191/1000] Step: [160 / 285] Batch Time: 0.1430 (0.1629) Data Time: 0.0104 (0.0303) Average Loss: 0.5268 (0.4853) Average CE Loss (Source):  0.5268 ( 0.4853) Learning Rate: 0.0500 (0.0500) Top1_base: 85.9375 (86.4502) Top1_base_per_class: 87.2829 (86.8428) 
Training Epoch: [191/1000] Step: [170 / 285] Batch Time: 0.1445 (0.1621) Data Time: 0.0102 (0.0296) Average Loss: 0.6421 (0.4874) Average CE Loss (Source):  0.6421 ( 0.4874) Learning Rate: 0.0500 (0.0500) Top1_base: 82.0312 (86.4614) Top1_base_per_class: 84.1515 (86.8405) 
Training Epoch: [191/1000] Step: [180 / 285] Batch Time: 0.1409 (0.1621) Data Time: 0.0109 (0.0295) Average Loss: 0.4511 (0.4857) Average CE Loss (Source):  0.4511 ( 0.4857) Learning Rate: 0.0500 (0.0500) Top1_base: 88.2812 (86.4844) Top1_base_per_class: 85.5503 (86.8350) 
Training Epoch: [191/1000] Step: [190 / 285] Batch Time: 0.1464 (0.1620) Data Time: 0.0114 (0.0294) Average Loss: 0.5699 (0.4851) Average CE Loss (Source):  0.5699 ( 0.4851) Learning Rate: 0.0500 (0.0500) Top1_base: 85.1562 (86.5419) Top1_base_per_class: 87.9874 (86.9022) 
Training Epoch: [191/1000] Step: [200 / 285] Batch Time: 0.1450 (0.1617) Data Time: 0.0121 (0.0290) Average Loss: 0.3834 (0.4860) Average CE Loss (Source):  0.3834 ( 0.4860) Learning Rate: 0.0500 (0.0500) Top1_base: 89.0625 (86.5000) Top1_base_per_class: 89.6226 (86.9303) 
Training Epoch: [191/1000] Step: [210 / 285] Batch Time: 0.1446 (0.1614) Data Time: 0.0105 (0.0287) Average Loss: 0.5990 (0.4862) Average CE Loss (Source):  0.5990 ( 0.4862) Learning Rate: 0.0500 (0.0500) Top1_base: 83.5938 (86.5030) Top1_base_per_class: 86.1667 (86.9628) 
Training Epoch: [191/1000] Step: [220 / 285] Batch Time: 0.1434 (0.1608) Data Time: 0.0117 (0.0280) Average Loss: 0.4785 (0.4877) Average CE Loss (Source):  0.4785 ( 0.4877) Learning Rate: 0.0500 (0.0500) Top1_base: 86.7188 (86.4276) Top1_base_per_class: 84.6515 (86.9187) 
Training Epoch: [191/1000] Step: [230 / 285] Batch Time: 0.1470 (0.1606) Data Time: 0.0105 (0.0278) Average Loss: 0.5586 (0.4877) Average CE Loss (Source):  0.5586 ( 0.4877) Learning Rate: 0.0500 (0.0500) Top1_base: 85.1562 (86.4266) Top1_base_per_class: 79.5493 (86.8699) 
Training Epoch: [191/1000] Step: [240 / 285] Batch Time: 0.1437 (0.1603) Data Time: 0.0115 (0.0275) Average Loss: 0.4053 (0.4854) Average CE Loss (Source):  0.4053 ( 0.4854) Learning Rate: 0.0500 (0.0500) Top1_base: 88.2812 (86.4681) Top1_base_per_class: 88.4849 (86.9018) 
Training Epoch: [191/1000] Step: [250 / 285] Batch Time: 0.1467 (0.1598) Data Time: 0.0108 (0.0271) Average Loss: 0.6489 (0.4850) Average CE Loss (Source):  0.6489 ( 0.4850) Learning Rate: 0.0500 (0.0500) Top1_base: 81.2500 (86.4844) Top1_base_per_class: 83.0702 (86.9177) 
Training Epoch: [191/1000] Step: [260 / 285] Batch Time: 0.1432 (0.1596) Data Time: 0.0114 (0.0268) Average Loss: 0.4169 (0.4839) Average CE Loss (Source):  0.4169 ( 0.4839) Learning Rate: 0.0500 (0.0500) Top1_base: 86.7188 (86.5114) Top1_base_per_class: 86.0000 (86.9233) 
Training Epoch: [191/1000] Step: [270 / 285] Batch Time: 0.1427 (0.1594) Data Time: 0.0116 (0.0266) Average Loss: 0.3627 (0.4829) Average CE Loss (Source):  0.3627 ( 0.4829) Learning Rate: 0.0500 (0.0500) Top1_base: 88.2812 (86.5191) Top1_base_per_class: 89.2727 (86.9289) 
Training Epoch: [191/1000] Step: [280 / 285] Batch Time: 0.1422 (0.1591) Data Time: 0.0101 (0.0264) Average Loss: 0.5441 (0.4843) Average CE Loss (Source):  0.5441 ( 0.4843) Learning Rate: 0.0500 (0.0500) Top1_base: 84.3750 (86.4955) Top1_base_per_class: 86.0827 (86.8958) 
Training Epoch: [192/1000] Step: [0] Batch Time: 0.1777 (0.1589) Data Time: 0.0478 (0.0263) Average Loss: 0.4904 (0.4845) Average CE Loss (Source):  0.4904 ( 0.4845) Learning Rate: 0.0500 (0.0500) Top1_base: 85.9375 (86.4857) Top1_base_per_class: 86.1404 (86.8884) 
 19%|█▉        | 192/1000 [2:29:06<10:26:50, 46.55s/it] 19%|█▉        | 193/1000 [2:29:50<10:15:51, 45.79s/it]Training Epoch: [192/1000] Step: [10 / 285] Batch Time: 0.1503 (0.2229) Data Time: 0.0159 (0.0894) Average Loss: 0.3474 (0.4514) Average CE Loss (Source):  0.3474 ( 0.4514) Learning Rate: 0.0500 (0.0500) Top1_base: 90.6250 (87.8906) Top1_base_per_class: 91.9643 (87.9432) 
Training Epoch: [192/1000] Step: [20 / 285] Batch Time: 0.1455 (0.1877) Data Time: 0.0123 (0.0548) Average Loss: 0.5291 (0.4697) Average CE Loss (Source):  0.5291 ( 0.4697) Learning Rate: 0.0500 (0.0500) Top1_base: 85.1562 (86.9922) Top1_base_per_class: 82.6389 (86.8744) 
Training Epoch: [192/1000] Step: [30 / 285] Batch Time: 0.1601 (0.1756) Data Time: 0.0299 (0.0430) Average Loss: 0.3225 (0.4641) Average CE Loss (Source):  0.3225 ( 0.4641) Learning Rate: 0.0500 (0.0500) Top1_base: 90.6250 (87.0312) Top1_base_per_class: 91.5033 (86.9729) 
Training Epoch: [192/1000] Step: [40 / 285] Batch Time: 0.1458 (0.1692) Data Time: 0.0108 (0.0364) Average Loss: 0.4888 (0.4575) Average CE Loss (Source):  0.4888 ( 0.4575) Learning Rate: 0.0500 (0.0500) Top1_base: 89.0625 (87.4023) Top1_base_per_class: 89.0591 (87.3834) 
Training Epoch: [192/1000] Step: [50 / 285] Batch Time: 0.1508 (0.1656) Data Time: 0.0150 (0.0322) Average Loss: 0.3960 (0.4544) Average CE Loss (Source):  0.3960 ( 0.4544) Learning Rate: 0.0500 (0.0500) Top1_base: 90.6250 (87.4219) Top1_base_per_class: 93.5108 (87.6937) 
Training Epoch: [192/1000] Step: [60 / 285] Batch Time: 0.1439 (0.1635) Data Time: 0.0113 (0.0298) Average Loss: 0.6718 (0.4595) Average CE Loss (Source):  0.6718 ( 0.4595) Learning Rate: 0.0500 (0.0500) Top1_base: 75.7812 (87.1615) Top1_base_per_class: 80.9286 (87.5009) 
Training Epoch: [192/1000] Step: [70 / 285] Batch Time: 0.1430 (0.1621) Data Time: 0.0127 (0.0284) Average Loss: 0.3906 (0.4592) Average CE Loss (Source):  0.3906 ( 0.4592) Learning Rate: 0.0500 (0.0500) Top1_base: 88.2812 (87.0759) Top1_base_per_class: 90.5017 (87.4832) 
Training Epoch: [192/1000] Step: [80 / 285] Batch Time: 0.1453 (0.1602) Data Time: 0.0132 (0.0265) Average Loss: 0.4325 (0.4655) Average CE Loss (Source):  0.4325 ( 0.4655) Learning Rate: 0.0500 (0.0500) Top1_base: 88.2812 (86.9434) Top1_base_per_class: 91.7468 (87.3224) 
Training Epoch: [192/1000] Step: [90 / 285] Batch Time: 0.1507 (0.1600) Data Time: 0.0150 (0.0264) Average Loss: 0.5860 (0.4690) Average CE Loss (Source):  0.5860 ( 0.4690) Learning Rate: 0.0500 (0.0500) Top1_base: 85.1562 (86.8229) Top1_base_per_class: 85.3395 (87.2374) 
Training Epoch: [192/1000] Step: [100 / 285] Batch Time: 0.1453 (0.1587) Data Time: 0.0109 (0.0250) Average Loss: 0.4973 (0.4722) Average CE Loss (Source):  0.4973 ( 0.4722) Learning Rate: 0.0500 (0.0500) Top1_base: 85.9375 (86.7578) Top1_base_per_class: 86.0652 (87.1730) 
Training Epoch: [192/1000] Step: [110 / 285] Batch Time: 0.1485 (0.1590) Data Time: 0.0183 (0.0252) Average Loss: 0.4956 (0.4706) Average CE Loss (Source):  0.4956 ( 0.4706) Learning Rate: 0.0500 (0.0500) Top1_base: 88.2812 (86.7969) Top1_base_per_class: 87.6437 (87.2343) 
Training Epoch: [192/1000] Step: [120 / 285] Batch Time: 0.1459 (0.1586) Data Time: 0.0108 (0.0249) Average Loss: 0.4847 (0.4714) Average CE Loss (Source):  0.4847 ( 0.4714) Learning Rate: 0.0500 (0.0500) Top1_base: 85.9375 (86.8555) Top1_base_per_class: 86.0526 (87.2475) 
Training Epoch: [192/1000] Step: [130 / 285] Batch Time: 0.1468 (0.1578) Data Time: 0.0162 (0.0240) Average Loss: 0.5424 (0.4770) Average CE Loss (Source):  0.5424 ( 0.4770) Learning Rate: 0.0500 (0.0500) Top1_base: 84.3750 (86.7608) Top1_base_per_class: 86.1728 (87.1414) 
Training Epoch: [192/1000] Step: [140 / 285] Batch Time: 0.1470 (0.1569) Data Time: 0.0125 (0.0233) Average Loss: 0.5336 (0.4770) Average CE Loss (Source):  0.5336 ( 0.4770) Learning Rate: 0.0500 (0.0500) Top1_base: 85.9375 (86.7020) Top1_base_per_class: 85.1923 (87.0449) 
Training Epoch: [192/1000] Step: [150 / 285] Batch Time: 0.1520 (0.1574) Data Time: 0.0128 (0.0236) Average Loss: 0.3986 (0.4757) Average CE Loss (Source):  0.3986 ( 0.4757) Learning Rate: 0.0500 (0.0500) Top1_base: 89.0625 (86.7240) Top1_base_per_class: 91.5705 (87.1069) 
Training Epoch: [192/1000] Step: [160 / 285] Batch Time: 0.1461 (0.1571) Data Time: 0.0115 (0.0231) Average Loss: 0.4442 (0.4742) Average CE Loss (Source):  0.4442 ( 0.4742) Learning Rate: 0.0500 (0.0500) Top1_base: 89.8438 (86.7334) Top1_base_per_class: 89.8457 (87.1288) 
Training Epoch: [192/1000] Step: [170 / 285] Batch Time: 0.1416 (0.1567) Data Time: 0.0111 (0.0229) Average Loss: 0.5805 (0.4739) Average CE Loss (Source):  0.5805 ( 0.4739) Learning Rate: 0.0500 (0.0500) Top1_base: 83.5938 (86.7463) Top1_base_per_class: 84.2424 (87.1308) 
Training Epoch: [192/1000] Step: [180 / 285] Batch Time: 0.1460 (0.1563) Data Time: 0.0115 (0.0224) Average Loss: 0.4068 (0.4748) Average CE Loss (Source):  0.4068 ( 0.4748) Learning Rate: 0.0500 (0.0500) Top1_base: 88.2812 (86.7318) Top1_base_per_class: 90.1639 (87.1304) 
Training Epoch: [192/1000] Step: [190 / 285] Batch Time: 0.1411 (0.1560) Data Time: 0.0106 (0.0222) Average Loss: 0.4239 (0.4773) Average CE Loss (Source):  0.4239 ( 0.4773) Learning Rate: 0.0500 (0.0500) Top1_base: 88.2812 (86.6694) Top1_base_per_class: 89.2857 (87.0464) 
Training Epoch: [192/1000] Step: [200 / 285] Batch Time: 0.1497 (0.1556) Data Time: 0.0142 (0.0218) Average Loss: 0.4781 (0.4742) Average CE Loss (Source):  0.4781 ( 0.4742) Learning Rate: 0.0500 (0.0500) Top1_base: 84.3750 (86.7656) Top1_base_per_class: 87.8274 (87.1413) 
Training Epoch: [192/1000] Step: [210 / 285] Batch Time: 0.1490 (0.1552) Data Time: 0.0121 (0.0214) Average Loss: 0.5981 (0.4745) Average CE Loss (Source):  0.5981 ( 0.4745) Learning Rate: 0.0500 (0.0500) Top1_base: 83.5938 (86.7560) Top1_base_per_class: 84.5763 (87.1269) 
Training Epoch: [192/1000] Step: [220 / 285] Batch Time: 0.1498 (0.1550) Data Time: 0.0128 (0.0212) Average Loss: 0.4779 (0.4739) Average CE Loss (Source):  0.4779 ( 0.4739) Learning Rate: 0.0500 (0.0500) Top1_base: 85.1562 (86.7223) Top1_base_per_class: 84.3182 (87.0824) 
Training Epoch: [192/1000] Step: [230 / 285] Batch Time: 0.1524 (0.1547) Data Time: 0.0157 (0.0209) Average Loss: 0.3925 (0.4723) Average CE Loss (Source):  0.3925 ( 0.4723) Learning Rate: 0.0500 (0.0500) Top1_base: 89.0625 (86.7120) Top1_base_per_class: 88.3621 (87.0576) 
Training Epoch: [192/1000] Step: [240 / 285] Batch Time: 0.1468 (0.1547) Data Time: 0.0122 (0.0208) Average Loss: 0.4310 (0.4746) Average CE Loss (Source):  0.4310 ( 0.4746) Learning Rate: 0.0500 (0.0500) Top1_base: 87.5000 (86.6667) Top1_base_per_class: 88.5417 (87.0309) 
Training Epoch: [192/1000] Step: [250 / 285] Batch Time: 0.1461 (0.1549) Data Time: 0.0123 (0.0210) Average Loss: 0.4809 (0.4741) Average CE Loss (Source):  0.4809 ( 0.4741) Learning Rate: 0.0500 (0.0500) Top1_base: 82.8125 (86.6813) Top1_base_per_class: 83.6699 (87.0143) 
Training Epoch: [192/1000] Step: [260 / 285] Batch Time: 0.1422 (0.1547) Data Time: 0.0107 (0.0209) Average Loss: 0.4473 (0.4733) Average CE Loss (Source):  0.4473 ( 0.4733) Learning Rate: 0.0500 (0.0500) Top1_base: 85.1562 (86.6737) Top1_base_per_class: 87.0238 (87.0255) 
Training Epoch: [192/1000] Step: [270 / 285] Batch Time: 0.1469 (0.1546) Data Time: 0.0122 (0.0208) Average Loss: 0.3396 (0.4731) Average CE Loss (Source):  0.3396 ( 0.4731) Learning Rate: 0.0500 (0.0500) Top1_base: 89.8438 (86.6985) Top1_base_per_class: 88.5798 (87.0386) 
Training Epoch: [192/1000] Step: [280 / 285] Batch Time: 0.1422 (0.1544) Data Time: 0.0103 (0.0207) Average Loss: 0.5503 (0.4733) Average CE Loss (Source):  0.5503 ( 0.4733) Learning Rate: 0.0500 (0.0500) Top1_base: 82.8125 (86.6881) Top1_base_per_class: 83.8889 (87.0375) 
Training Epoch: [193/1000] Step: [0] Batch Time: 0.1421 (0.1542) Data Time: 0.0101 (0.0205) Average Loss: 0.4914 (0.4735) Average CE Loss (Source):  0.4914 ( 0.4735) Learning Rate: 0.0500 (0.0500) Top1_base: 85.9375 (86.6776) Top1_base_per_class: 87.5786 (87.0557) 
Training Epoch: [193/1000] Step: [10 / 285] Batch Time: 0.1466 (0.2306) Data Time: 0.0163 (0.0974) Average Loss: 0.4461 (0.4378) Average CE Loss (Source):  0.4461 ( 0.4378) Learning Rate: 0.0500 (0.0500) Top1_base: 89.0625 (88.5938) Top1_base_per_class: 88.9869 (89.6403) 
Training Epoch: [193/1000] Step: [20 / 285] Batch Time: 0.1461 (0.1978) Data Time: 0.0141 (0.0652) Average Loss: 0.3652 (0.4790) Average CE Loss (Source):  0.3652 ( 0.4790) Learning Rate: 0.0500 (0.0500) Top1_base: 90.6250 (87.1094) Top1_base_per_class: 92.1212 (88.3321) 
Training Epoch: [193/1000] Step: [30 / 285] Batch Time: 0.1704 (0.1836) Data Time: 0.0364 (0.0510) Average Loss: 0.4089 (0.4735) Average CE Loss (Source):  0.4089 ( 0.4735) Learning Rate: 0.0500 (0.0500) Top1_base: 89.0625 (87.2917) Top1_base_per_class: 89.0123 (88.5296) 
Training Epoch: [193/1000] Step: [40 / 285] Batch Time: 0.1472 (0.1755) Data Time: 0.0119 (0.0429) Average Loss: 0.4226 (0.4896) Average CE Loss (Source):  0.4226 ( 0.4896) Learning Rate: 0.0500 (0.0500) Top1_base: 85.1562 (86.6992) Top1_base_per_class: 85.2251 (87.3799) 
Training Epoch: [193/1000] Step: [50 / 285] Batch Time: 0.1447 (0.1732) Data Time: 0.0110 (0.0404) Average Loss: 0.5357 (0.4831) Average CE Loss (Source):  0.5357 ( 0.4831) Learning Rate: 0.0500 (0.0500) Top1_base: 85.1562 (86.9375) Top1_base_per_class: 85.8187 (87.5966) 
Training Epoch: [193/1000] Step: [60 / 285] Batch Time: 0.1438 (0.1701) Data Time: 0.0133 (0.0371) Average Loss: 0.5550 (0.4746) Average CE Loss (Source):  0.5550 ( 0.4746) Learning Rate: 0.0500 (0.0500) Top1_base: 82.0312 (87.1224) Top1_base_per_class: 86.3636 (87.8375) 
Training Epoch: [193/1000] Step: [70 / 285] Batch Time: 0.1458 (0.1677) Data Time: 0.0109 (0.0348) Average Loss: 0.4516 (0.4727) Average CE Loss (Source):  0.4516 ( 0.4727) Learning Rate: 0.0500 (0.0500) Top1_base: 87.5000 (87.1429) Top1_base_per_class: 89.2857 (87.8130) 
Training Epoch: [193/1000] Step: [80 / 285] Batch Time: 0.1489 (0.1655) Data Time: 0.0116 (0.0323) Average Loss: 0.2709 (0.4694) Average CE Loss (Source):  0.2709 ( 0.4694) Learning Rate: 0.0500 (0.0500) Top1_base: 92.1875 (87.2070) Top1_base_per_class: 93.7879 (87.8525) 
Training Epoch: [193/1000] Step: [90 / 285] Batch Time: 0.1503 (0.1641) Data Time: 0.0161 (0.0305) Average Loss: 0.5564 (0.4695) Average CE Loss (Source):  0.5564 ( 0.4695) Learning Rate: 0.0500 (0.0500) Top1_base: 84.3750 (87.1875) Top1_base_per_class: 84.6685 (87.8287) 
Training Epoch: [193/1000] Step: [100 / 285] Batch Time: 0.1476 (0.1625) Data Time: 0.0142 (0.0288) Average Loss: 0.3218 (0.4648) Average CE Loss (Source):  0.3218 ( 0.4648) Learning Rate: 0.0500 (0.0500) Top1_base: 92.1875 (87.3438) Top1_base_per_class: 93.9881 (87.8914) 
Training Epoch: [193/1000] Step: [110 / 285] Batch Time: 0.1534 (0.1614) Data Time: 0.0169 (0.0275) Average Loss: 0.5567 (0.4683) Average CE Loss (Source):  0.5567 ( 0.4683) Learning Rate: 0.0500 (0.0500) Top1_base: 82.8125 (87.1165) Top1_base_per_class: 83.3051 (87.6177) 
Training Epoch: [193/1000] Step: [120 / 285] Batch Time: 0.1503 (0.1610) Data Time: 0.0123 (0.0270) Average Loss: 0.4440 (0.4693) Average CE Loss (Source):  0.4440 ( 0.4693) Learning Rate: 0.0500 (0.0500) Top1_base: 86.7188 (86.9531) Top1_base_per_class: 86.6072 (87.4482) 
Training Epoch: [193/1000] Step: [130 / 285] Batch Time: 0.2672 (0.1616) Data Time: 0.1357 (0.0276) Average Loss: 0.4571 (0.4711) Average CE Loss (Source):  0.4571 ( 0.4711) Learning Rate: 0.0500 (0.0500) Top1_base: 87.5000 (86.9832) Top1_base_per_class: 89.9394 (87.5292) 
Training Epoch: [193/1000] Step: [140 / 285] Batch Time: 0.1437 (0.1617) Data Time: 0.0118 (0.0277) Average Loss: 0.6487 (0.4762) Average CE Loss (Source):  0.6487 ( 0.4762) Learning Rate: 0.0500 (0.0500) Top1_base: 82.8125 (86.8527) Top1_base_per_class: 87.1131 (87.4319) 
Training Epoch: [193/1000] Step: [150 / 285] Batch Time: 0.1504 (0.1610) Data Time: 0.0149 (0.0271) Average Loss: 0.4432 (0.4748) Average CE Loss (Source):  0.4432 ( 0.4748) Learning Rate: 0.0500 (0.0500) Top1_base: 89.0625 (86.8854) Top1_base_per_class: 91.3333 (87.4303) 
Training Epoch: [193/1000] Step: [160 / 285] Batch Time: 0.1474 (0.1603) Data Time: 0.0114 (0.0264) Average Loss: 0.4695 (0.4764) Average CE Loss (Source):  0.4695 ( 0.4764) Learning Rate: 0.0500 (0.0500) Top1_base: 85.1562 (86.7969) Top1_base_per_class: 83.4722 (87.2933) 
Training Epoch: [193/1000] Step: [170 / 285] Batch Time: 0.1492 (0.1597) Data Time: 0.0150 (0.0257) Average Loss: 0.4496 (0.4748) Average CE Loss (Source):  0.4496 ( 0.4748) Learning Rate: 0.0500 (0.0500) Top1_base: 85.9375 (86.8244) Top1_base_per_class: 88.8506 (87.3004) 
Training Epoch: [193/1000] Step: [180 / 285] Batch Time: 0.1473 (0.1595) Data Time: 0.0111 (0.0254) Average Loss: 0.3779 (0.4746) Average CE Loss (Source):  0.3779 ( 0.4746) Learning Rate: 0.0500 (0.0500) Top1_base: 90.6250 (86.8924) Top1_base_per_class: 90.4237 (87.3610) 
Training Epoch: [193/1000] Step: [190 / 285] Batch Time: 0.1856 (0.1594) Data Time: 0.0497 (0.0252) Average Loss: 0.3520 (0.4743) Average CE Loss (Source):  0.3520 ( 0.4743) Learning Rate: 0.0500 (0.0500) Top1_base: 87.5000 (86.9202) Top1_base_per_class: 87.7485 (87.3719) 
Training Epoch: [193/1000] Step: [200 / 285] Batch Time: 0.1503 (0.1590) Data Time: 0.0122 (0.0247) Average Loss: 0.4271 (0.4765) Average CE Loss (Source):  0.4271 ( 0.4765) Learning Rate: 0.0500 (0.0500) Top1_base: 88.2812 (86.8477) Top1_base_per_class: 86.9445 (87.2870) 
Training Epoch: [193/1000] Step: [210 / 285] Batch Time: 0.1511 (0.1584) Data Time: 0.0157 (0.0242) Average Loss: 0.4764 (0.4770) Average CE Loss (Source):  0.4764 ( 0.4770) Learning Rate: 0.0500 (0.0500) Top1_base: 86.7188 (86.8750) Top1_base_per_class: 86.4368 (87.2908) 
Training Epoch: [193/1000] Step: [220 / 285] Batch Time: 0.1485 (0.1579) Data Time: 0.0111 (0.0237) Average Loss: 0.4006 (0.4782) Average CE Loss (Source):  0.4006 ( 0.4782) Learning Rate: 0.0500 (0.0500) Top1_base: 86.7188 (86.8466) Top1_base_per_class: 88.7427 (87.2725) 
Training Epoch: [193/1000] Step: [230 / 285] Batch Time: 0.1549 (0.1575) Data Time: 0.0235 (0.0234) Average Loss: 0.4634 (0.4805) Average CE Loss (Source):  0.4634 ( 0.4805) Learning Rate: 0.0500 (0.0500) Top1_base: 87.5000 (86.7697) Top1_base_per_class: 90.5128 (87.2308) 
Training Epoch: [193/1000] Step: [240 / 285] Batch Time: 0.1462 (0.1573) Data Time: 0.0124 (0.0232) Average Loss: 0.4539 (0.4811) Average CE Loss (Source):  0.4539 ( 0.4811) Learning Rate: 0.0500 (0.0500) Top1_base: 86.7188 (86.7806) Top1_base_per_class: 87.9091 (87.2283) 
Training Epoch: [193/1000] Step: [250 / 285] Batch Time: 0.1564 (0.1571) Data Time: 0.0212 (0.0230) Average Loss: 0.4812 (0.4817) Average CE Loss (Source):  0.4812 ( 0.4817) Learning Rate: 0.0500 (0.0500) Top1_base: 87.5000 (86.7687) Top1_base_per_class: 89.3452 (87.2203) 
Training Epoch: [193/1000] Step: [260 / 285] Batch Time: 0.1468 (0.1573) Data Time: 0.0111 (0.0231) Average Loss: 0.6692 (0.4824) Average CE Loss (Source):  0.6692 ( 0.4824) Learning Rate: 0.0500 (0.0500) Top1_base: 79.6875 (86.7488) Top1_base_per_class: 80.4971 (87.1959) 
Training Epoch: [193/1000] Step: [270 / 285] Batch Time: 0.1471 (0.1570) Data Time: 0.0156 (0.0227) Average Loss: 0.3511 (0.4822) Average CE Loss (Source):  0.3511 ( 0.4822) Learning Rate: 0.0500 (0.0500) Top1_base: 88.2812 (86.7361) Top1_base_per_class: 88.7798 (87.1627) 
Training Epoch: [193/1000] Step: [280 / 285] Batch Time: 0.1459 (0.1566) Data Time: 0.0122 (0.0224) Average Loss: 0.4875 (0.4812) Average CE Loss (Source):  0.4875 ( 0.4812) Learning Rate: 0.0500 (0.0500) Top1_base: 89.0625 (86.7439) Top1_base_per_class: 90.0000 (87.1406) 
Training Epoch: [194/1000] Step: [0] Batch Time: 0.1386 (0.1564) Data Time: 0.0106 (0.0223) Average Loss: 0.5004 (0.4820) Average CE Loss (Source):  0.5004 ( 0.4820) Learning Rate: 0.0500 (0.0500) Top1_base: 82.8125 (86.7050) Top1_base_per_class: 82.9012 (87.1070) 
 19%|█▉        | 194/1000 [2:30:37<10:21:31, 46.27s/it] 20%|█▉        | 195/1000 [2:31:22<10:12:35, 45.66s/it]Training Epoch: [194/1000] Step: [10 / 285] Batch Time: 0.1437 (0.2376) Data Time: 0.0124 (0.1050) Average Loss: 0.4645 (0.3636) Average CE Loss (Source):  0.4645 ( 0.3636) Learning Rate: 0.0500 (0.0500) Top1_base: 88.2812 (89.6875) Top1_base_per_class: 89.4025 (89.3694) 
Training Epoch: [194/1000] Step: [20 / 285] Batch Time: 0.1447 (0.2004) Data Time: 0.0114 (0.0676) Average Loss: 0.4971 (0.4067) Average CE Loss (Source):  0.4971 ( 0.4067) Learning Rate: 0.0500 (0.0500) Top1_base: 85.9375 (88.5938) Top1_base_per_class: 88.9368 (88.7766) 
Training Epoch: [194/1000] Step: [30 / 285] Batch Time: 0.1456 (0.1843) Data Time: 0.0115 (0.0518) Average Loss: 0.3743 (0.4210) Average CE Loss (Source):  0.3743 ( 0.4210) Learning Rate: 0.0500 (0.0500) Top1_base: 89.8438 (88.1250) Top1_base_per_class: 91.8269 (88.5639) 
Training Epoch: [194/1000] Step: [40 / 285] Batch Time: 0.1465 (0.1756) Data Time: 0.0113 (0.0427) Average Loss: 0.4995 (0.4336) Average CE Loss (Source):  0.4995 ( 0.4336) Learning Rate: 0.0500 (0.0500) Top1_base: 83.5938 (87.6562) Top1_base_per_class: 83.0009 (88.2225) 
Training Epoch: [194/1000] Step: [50 / 285] Batch Time: 0.1450 (0.1723) Data Time: 0.0128 (0.0394) Average Loss: 0.3676 (0.4382) Average CE Loss (Source):  0.3676 ( 0.4382) Learning Rate: 0.0500 (0.0500) Top1_base: 86.7188 (87.6875) Top1_base_per_class: 89.1071 (88.1996) 
Training Epoch: [194/1000] Step: [60 / 285] Batch Time: 0.1477 (0.1684) Data Time: 0.0105 (0.0352) Average Loss: 0.4737 (0.4391) Average CE Loss (Source):  0.4737 ( 0.4391) Learning Rate: 0.0500 (0.0500) Top1_base: 85.9375 (87.5781) Top1_base_per_class: 88.1699 (88.0867) 
Training Epoch: [194/1000] Step: [70 / 285] Batch Time: 0.1499 (0.1661) Data Time: 0.0132 (0.0326) Average Loss: 0.4385 (0.4407) Average CE Loss (Source):  0.4385 ( 0.4407) Learning Rate: 0.0500 (0.0500) Top1_base: 88.2812 (87.5558) Top1_base_per_class: 89.2593 (88.0979) 
Training Epoch: [194/1000] Step: [80 / 285] Batch Time: 0.1463 (0.1646) Data Time: 0.0104 (0.0308) Average Loss: 0.4985 (0.4401) Average CE Loss (Source):  0.4985 ( 0.4401) Learning Rate: 0.0500 (0.0500) Top1_base: 83.5938 (87.5977) Top1_base_per_class: 84.5152 (88.1699) 
Training Epoch: [194/1000] Step: [90 / 285] Batch Time: 0.1473 (0.1637) Data Time: 0.0113 (0.0297) Average Loss: 0.5529 (0.4423) Average CE Loss (Source):  0.5529 ( 0.4423) Learning Rate: 0.0500 (0.0500) Top1_base: 87.5000 (87.5347) Top1_base_per_class: 88.0409 (88.1176) 
Training Epoch: [194/1000] Step: [100 / 285] Batch Time: 0.1483 (0.1632) Data Time: 0.0104 (0.0291) Average Loss: 0.4586 (0.4467) Average CE Loss (Source):  0.4586 ( 0.4467) Learning Rate: 0.0500 (0.0500) Top1_base: 87.5000 (87.4297) Top1_base_per_class: 88.7798 (87.9866) 
Training Epoch: [194/1000] Step: [110 / 285] Batch Time: 0.1467 (0.1628) Data Time: 0.0109 (0.0285) Average Loss: 0.5888 (0.4566) Average CE Loss (Source):  0.5888 ( 0.4566) Learning Rate: 0.0500 (0.0500) Top1_base: 86.7188 (87.2798) Top1_base_per_class: 86.9091 (87.8440) 
Training Epoch: [194/1000] Step: [120 / 285] Batch Time: 0.1444 (0.1616) Data Time: 0.0104 (0.0273) Average Loss: 0.3650 (0.4570) Average CE Loss (Source):  0.3650 ( 0.4570) Learning Rate: 0.0500 (0.0500) Top1_base: 89.8438 (87.2461) Top1_base_per_class: 90.1389 (87.7701) 
Training Epoch: [194/1000] Step: [130 / 285] Batch Time: 0.1489 (0.1612) Data Time: 0.0106 (0.0271) Average Loss: 0.5120 (0.4604) Average CE Loss (Source):  0.5120 ( 0.4604) Learning Rate: 0.0500 (0.0500) Top1_base: 85.9375 (87.0913) Top1_base_per_class: 87.8869 (87.6239) 
Training Epoch: [194/1000] Step: [140 / 285] Batch Time: 0.1470 (0.1607) Data Time: 0.0108 (0.0264) Average Loss: 0.3823 (0.4614) Average CE Loss (Source):  0.3823 ( 0.4614) Learning Rate: 0.0500 (0.0500) Top1_base: 88.2812 (87.0647) Top1_base_per_class: 86.1012 (87.5717) 
Training Epoch: [194/1000] Step: [150 / 285] Batch Time: 0.1441 (0.1601) Data Time: 0.0129 (0.0259) Average Loss: 0.4054 (0.4646) Average CE Loss (Source):  0.4054 ( 0.4646) Learning Rate: 0.0500 (0.0500) Top1_base: 89.0625 (86.9896) Top1_base_per_class: 89.9702 (87.5026) 
Training Epoch: [194/1000] Step: [160 / 285] Batch Time: 0.1459 (0.1596) Data Time: 0.0109 (0.0255) Average Loss: 0.2776 (0.4642) Average CE Loss (Source):  0.2776 ( 0.4642) Learning Rate: 0.0500 (0.0500) Top1_base: 92.9688 (86.9482) Top1_base_per_class: 95.1342 (87.4654) 
Training Epoch: [194/1000] Step: [170 / 285] Batch Time: 0.1453 (0.1592) Data Time: 0.0105 (0.0251) Average Loss: 0.5615 (0.4674) Average CE Loss (Source):  0.5615 ( 0.4674) Learning Rate: 0.0500 (0.0500) Top1_base: 82.8125 (86.9164) Top1_base_per_class: 85.5655 (87.4358) 
Training Epoch: [194/1000] Step: [180 / 285] Batch Time: 0.1423 (0.1586) Data Time: 0.0124 (0.0246) Average Loss: 0.6143 (0.4695) Average CE Loss (Source):  0.6143 ( 0.4695) Learning Rate: 0.0500 (0.0500) Top1_base: 83.5938 (86.8750) Top1_base_per_class: 85.9877 (87.3762) 
Training Epoch: [194/1000] Step: [190 / 285] Batch Time: 0.1422 (0.1584) Data Time: 0.0119 (0.0246) Average Loss: 0.4651 (0.4703) Average CE Loss (Source):  0.4651 ( 0.4703) Learning Rate: 0.0500 (0.0500) Top1_base: 86.7188 (86.8668) Top1_base_per_class: 89.7531 (87.3357) 
Training Epoch: [194/1000] Step: [200 / 285] Batch Time: 0.1484 (0.1578) Data Time: 0.0114 (0.0240) Average Loss: 0.4723 (0.4711) Average CE Loss (Source):  0.4723 ( 0.4711) Learning Rate: 0.0500 (0.0500) Top1_base: 84.3750 (86.8164) Top1_base_per_class: 85.2679 (87.3023) 
Training Epoch: [194/1000] Step: [210 / 285] Batch Time: 0.1476 (0.1574) Data Time: 0.0112 (0.0235) Average Loss: 0.6243 (0.4724) Average CE Loss (Source):  0.6243 ( 0.4724) Learning Rate: 0.0500 (0.0500) Top1_base: 81.2500 (86.7671) Top1_base_per_class: 79.1169 (87.2260) 
Training Epoch: [194/1000] Step: [220 / 285] Batch Time: 0.1478 (0.1570) Data Time: 0.0117 (0.0230) Average Loss: 0.6606 (0.4730) Average CE Loss (Source):  0.6606 ( 0.4730) Learning Rate: 0.0500 (0.0500) Top1_base: 81.2500 (86.7294) Top1_base_per_class: 85.4938 (87.1795) 
Training Epoch: [194/1000] Step: [230 / 285] Batch Time: 0.1467 (0.1570) Data Time: 0.0130 (0.0231) Average Loss: 0.4801 (0.4720) Average CE Loss (Source):  0.4801 ( 0.4720) Learning Rate: 0.0500 (0.0500) Top1_base: 85.1562 (86.7527) Top1_base_per_class: 86.0417 (87.2297) 
Training Epoch: [194/1000] Step: [240 / 285] Batch Time: 0.1479 (0.1566) Data Time: 0.0118 (0.0226) Average Loss: 0.5235 (0.4725) Average CE Loss (Source):  0.5235 ( 0.4725) Learning Rate: 0.0500 (0.0500) Top1_base: 86.7188 (86.7383) Top1_base_per_class: 87.1345 (87.1829) 
Training Epoch: [194/1000] Step: [250 / 285] Batch Time: 0.1468 (0.1562) Data Time: 0.0121 (0.0223) Average Loss: 0.5008 (0.4734) Average CE Loss (Source):  0.5008 ( 0.4734) Learning Rate: 0.0500 (0.0500) Top1_base: 84.3750 (86.6906) Top1_base_per_class: 83.7107 (87.1547) 
Training Epoch: [194/1000] Step: [260 / 285] Batch Time: 0.1471 (0.1558) Data Time: 0.0124 (0.0219) Average Loss: 0.5327 (0.4752) Average CE Loss (Source):  0.5327 ( 0.4752) Learning Rate: 0.0500 (0.0500) Top1_base: 85.9375 (86.6436) Top1_base_per_class: 84.7701 (87.1032) 
Training Epoch: [194/1000] Step: [270 / 285] Batch Time: 0.1496 (0.1555) Data Time: 0.0119 (0.0216) Average Loss: 0.3888 (0.4768) Average CE Loss (Source):  0.3888 ( 0.4768) Learning Rate: 0.0500 (0.0500) Top1_base: 88.2812 (86.6088) Top1_base_per_class: 90.3395 (87.0870) 
Training Epoch: [194/1000] Step: [280 / 285] Batch Time: 0.1431 (0.1552) Data Time: 0.0129 (0.0213) Average Loss: 0.4054 (0.4778) Average CE Loss (Source):  0.4054 ( 0.4778) Learning Rate: 0.0500 (0.0500) Top1_base: 86.7188 (86.5597) Top1_base_per_class: 88.2680 (87.0355) 
Training Epoch: [195/1000] Step: [0] Batch Time: 0.1425 (0.1550) Data Time: 0.0128 (0.0212) Average Loss: 0.3578 (0.4780) Average CE Loss (Source):  0.3578 ( 0.4780) Learning Rate: 0.0500 (0.0500) Top1_base: 90.6250 (86.5598) Top1_base_per_class: 90.6173 (87.0419) 
Training Epoch: [195/1000] Step: [10 / 285] Batch Time: 0.1456 (0.2556) Data Time: 0.0122 (0.1235) Average Loss: 0.3663 (0.4309) Average CE Loss (Source):  0.3663 ( 0.4309) Learning Rate: 0.0500 (0.0500) Top1_base: 89.0625 (88.7500) Top1_base_per_class: 90.3161 (88.8557) 
Training Epoch: [195/1000] Step: [20 / 285] Batch Time: 0.1467 (0.2030) Data Time: 0.0136 (0.0702) Average Loss: 0.5191 (0.4399) Average CE Loss (Source):  0.5191 ( 0.4399) Learning Rate: 0.0500 (0.0500) Top1_base: 84.3750 (87.8906) Top1_base_per_class: 85.9195 (88.4865) 
Training Epoch: [195/1000] Step: [30 / 285] Batch Time: 0.1478 (0.1892) Data Time: 0.0117 (0.0564) Average Loss: 0.4772 (0.4417) Average CE Loss (Source):  0.4772 ( 0.4417) Learning Rate: 0.0500 (0.0500) Top1_base: 85.9375 (87.5260) Top1_base_per_class: 84.1327 (87.8883) 
Training Epoch: [195/1000] Step: [40 / 285] Batch Time: 0.1465 (0.1794) Data Time: 0.0113 (0.0466) Average Loss: 0.5644 (0.4567) Average CE Loss (Source):  0.5644 ( 0.4567) Learning Rate: 0.0500 (0.0500) Top1_base: 82.8125 (87.0703) Top1_base_per_class: 84.9405 (87.5905) 
Training Epoch: [195/1000] Step: [50 / 285] Batch Time: 0.1432 (0.1738) Data Time: 0.0114 (0.0408) Average Loss: 0.4707 (0.4765) Average CE Loss (Source):  0.4707 ( 0.4765) Learning Rate: 0.0500 (0.0500) Top1_base: 88.2812 (86.6875) Top1_base_per_class: 87.9167 (87.2480) 
Training Epoch: [195/1000] Step: [60 / 285] Batch Time: 0.1460 (0.1705) Data Time: 0.0116 (0.0375) Average Loss: 0.5936 (0.4730) Average CE Loss (Source):  0.5936 ( 0.4730) Learning Rate: 0.0500 (0.0500) Top1_base: 86.7188 (86.9141) Top1_base_per_class: 87.5128 (87.4022) 
Training Epoch: [195/1000] Step: [70 / 285] Batch Time: 0.1465 (0.1678) Data Time: 0.0150 (0.0348) Average Loss: 0.5664 (0.4762) Average CE Loss (Source):  0.5664 ( 0.4762) Learning Rate: 0.0500 (0.0500) Top1_base: 86.7188 (86.8973) Top1_base_per_class: 88.5220 (87.4772) 
Training Epoch: [195/1000] Step: [80 / 285] Batch Time: 0.1503 (0.1672) Data Time: 0.0165 (0.0341) Average Loss: 0.6844 (0.4800) Average CE Loss (Source):  0.6844 ( 0.4800) Learning Rate: 0.0500 (0.0500) Top1_base: 83.5938 (86.8457) Top1_base_per_class: 82.5000 (87.2954) 
Training Epoch: [195/1000] Step: [90 / 285] Batch Time: 0.1432 (0.1658) Data Time: 0.0106 (0.0328) Average Loss: 0.4464 (0.4772) Average CE Loss (Source):  0.4464 ( 0.4772) Learning Rate: 0.0500 (0.0500) Top1_base: 85.1562 (86.8837) Top1_base_per_class: 84.7126 (87.3282) 
Training Epoch: [195/1000] Step: [100 / 285] Batch Time: 0.1467 (0.1649) Data Time: 0.0127 (0.0318) Average Loss: 0.6314 (0.4792) Average CE Loss (Source):  0.6314 ( 0.4792) Learning Rate: 0.0500 (0.0500) Top1_base: 80.4688 (86.7422) Top1_base_per_class: 82.9310 (87.2814) 
Training Epoch: [195/1000] Step: [110 / 285] Batch Time: 0.1443 (0.1640) Data Time: 0.0127 (0.0309) Average Loss: 0.5620 (0.4824) Average CE Loss (Source):  0.5620 ( 0.4824) Learning Rate: 0.0500 (0.0500) Top1_base: 83.5938 (86.6903) Top1_base_per_class: 85.3509 (87.1957) 
Training Epoch: [195/1000] Step: [120 / 285] Batch Time: 0.1488 (0.1628) Data Time: 0.0144 (0.0298) Average Loss: 0.4865 (0.4855) Average CE Loss (Source):  0.4865 ( 0.4855) Learning Rate: 0.0500 (0.0500) Top1_base: 86.7188 (86.6146) Top1_base_per_class: 86.9591 (87.1462) 
Training Epoch: [195/1000] Step: [130 / 285] Batch Time: 0.1458 (0.1621) Data Time: 0.0152 (0.0292) Average Loss: 0.4371 (0.4846) Average CE Loss (Source):  0.4371 ( 0.4846) Learning Rate: 0.0500 (0.0500) Top1_base: 85.1562 (86.6346) Top1_base_per_class: 84.3910 (87.2028) 
Training Epoch: [195/1000] Step: [140 / 285] Batch Time: 0.1492 (0.1613) Data Time: 0.0139 (0.0283) Average Loss: 0.6090 (0.4844) Average CE Loss (Source):  0.6090 ( 0.4844) Learning Rate: 0.0500 (0.0500) Top1_base: 84.3750 (86.5848) Top1_base_per_class: 86.5659 (87.1820) 
Training Epoch: [195/1000] Step: [150 / 285] Batch Time: 0.1778 (0.1611) Data Time: 0.0466 (0.0282) Average Loss: 0.5397 (0.4840) Average CE Loss (Source):  0.5397 ( 0.4840) Learning Rate: 0.0500 (0.0500) Top1_base: 84.3750 (86.6406) Top1_base_per_class: 82.7469 (87.2312) 
Training Epoch: [195/1000] Step: [160 / 285] Batch Time: 0.1487 (0.1606) Data Time: 0.0133 (0.0276) Average Loss: 0.6861 (0.4837) Average CE Loss (Source):  0.6861 ( 0.4837) Learning Rate: 0.0500 (0.0500) Top1_base: 80.4688 (86.6455) Top1_base_per_class: 79.5098 (87.1903) 
Training Epoch: [195/1000] Step: [170 / 285] Batch Time: 0.1730 (0.1602) Data Time: 0.0418 (0.0272) Average Loss: 0.5386 (0.4857) Average CE Loss (Source):  0.5386 ( 0.4857) Learning Rate: 0.0500 (0.0500) Top1_base: 85.1562 (86.6085) Top1_base_per_class: 85.3571 (87.1114) 
Training Epoch: [195/1000] Step: [180 / 285] Batch Time: 0.1424 (0.1596) Data Time: 0.0122 (0.0267) Average Loss: 0.6242 (0.4866) Average CE Loss (Source):  0.6242 ( 0.4866) Learning Rate: 0.0500 (0.0500) Top1_base: 79.6875 (86.6189) Top1_base_per_class: 79.1369 (87.1207) 
Training Epoch: [195/1000] Step: [190 / 285] Batch Time: 0.1475 (0.1599) Data Time: 0.0135 (0.0269) Average Loss: 0.4793 (0.4872) Average CE Loss (Source):  0.4793 ( 0.4872) Learning Rate: 0.0500 (0.0500) Top1_base: 88.2812 (86.6077) Top1_base_per_class: 89.1515 (87.1010) 
Training Epoch: [195/1000] Step: [200 / 285] Batch Time: 0.1469 (0.1595) Data Time: 0.0140 (0.0264) Average Loss: 0.5676 (0.4875) Average CE Loss (Source):  0.5676 ( 0.4875) Learning Rate: 0.0500 (0.0500) Top1_base: 85.1562 (86.6445) Top1_base_per_class: 86.6450 (87.1353) 
Training Epoch: [195/1000] Step: [210 / 285] Batch Time: 0.1434 (0.1590) Data Time: 0.0108 (0.0260) Average Loss: 0.5551 (0.4874) Average CE Loss (Source):  0.5551 ( 0.4874) Learning Rate: 0.0500 (0.0500) Top1_base: 87.5000 (86.6481) Top1_base_per_class: 87.5893 (87.1070) 
Training Epoch: [195/1000] Step: [220 / 285] Batch Time: 0.1427 (0.1588) Data Time: 0.0119 (0.0258) Average Loss: 0.4431 (0.4861) Average CE Loss (Source):  0.4431 ( 0.4861) Learning Rate: 0.0500 (0.0500) Top1_base: 88.2812 (86.6974) Top1_base_per_class: 88.9286 (87.1256) 
Training Epoch: [195/1000] Step: [230 / 285] Batch Time: 0.1429 (0.1588) Data Time: 0.0107 (0.0257) Average Loss: 0.4769 (0.4874) Average CE Loss (Source):  0.4769 ( 0.4874) Learning Rate: 0.0500 (0.0500) Top1_base: 83.5938 (86.6440) Top1_base_per_class: 82.8437 (87.0713) 
Training Epoch: [195/1000] Step: [240 / 285] Batch Time: 0.1492 (0.1585) Data Time: 0.0149 (0.0254) Average Loss: 0.3576 (0.4872) Average CE Loss (Source):  0.3576 ( 0.4872) Learning Rate: 0.0500 (0.0500) Top1_base: 91.4062 (86.6602) Top1_base_per_class: 91.7424 (87.0796) 
Training Epoch: [195/1000] Step: [250 / 285] Batch Time: 0.1464 (0.1581) Data Time: 0.0122 (0.0250) Average Loss: 0.4668 (0.4853) Average CE Loss (Source):  0.4668 ( 0.4853) Learning Rate: 0.0500 (0.0500) Top1_base: 87.5000 (86.6813) Top1_base_per_class: 84.5758 (87.1032) 
Training Epoch: [195/1000] Step: [260 / 285] Batch Time: 0.1506 (0.1578) Data Time: 0.0127 (0.0246) Average Loss: 0.4016 (0.4857) Average CE Loss (Source):  0.4016 ( 0.4857) Learning Rate: 0.0500 (0.0500) Top1_base: 85.1562 (86.6767) Top1_base_per_class: 87.8070 (87.0928) 
Training Epoch: [195/1000] Step: [270 / 285] Batch Time: 0.1454 (0.1575) Data Time: 0.0104 (0.0242) Average Loss: 0.6433 (0.4858) Average CE Loss (Source):  0.6433 ( 0.4858) Learning Rate: 0.0500 (0.0500) Top1_base: 80.4688 (86.6146) Top1_base_per_class: 83.9286 (87.0239) 
Training Epoch: [195/1000] Step: [280 / 285] Batch Time: 0.1493 (0.1572) Data Time: 0.0158 (0.0239) Average Loss: 0.4945 (0.4862) Average CE Loss (Source):  0.4945 ( 0.4862) Learning Rate: 0.0500 (0.0500) Top1_base: 86.7188 (86.6434) Top1_base_per_class: 85.7602 (87.0679) 
Training Epoch: [196/1000] Step: [0] Batch Time: 0.1426 (0.1570) Data Time: 0.0110 (0.0236) Average Loss: 0.6672 (0.4876) Average CE Loss (Source):  0.6672 ( 0.4876) Learning Rate: 0.0500 (0.0500) Top1_base: 81.2500 (86.5954) Top1_base_per_class: 82.1131 (87.0239) 
 20%|█▉        | 196/1000 [2:32:09<10:19:46, 46.25s/it] 20%|█▉        | 197/1000 [2:32:55<10:15:20, 45.98s/it]Training Epoch: [196/1000] Step: [10 / 285] Batch Time: 0.1466 (0.2340) Data Time: 0.0102 (0.1016) Average Loss: 0.8239 (0.5245) Average CE Loss (Source):  0.8239 ( 0.5245) Learning Rate: 0.0500 (0.0500) Top1_base: 77.3438 (86.3281) Top1_base_per_class: 78.1897 (86.6179) 
Training Epoch: [196/1000] Step: [20 / 285] Batch Time: 0.1452 (0.1948) Data Time: 0.0123 (0.0626) Average Loss: 0.4625 (0.5082) Average CE Loss (Source):  0.4625 ( 0.5082) Learning Rate: 0.0500 (0.0500) Top1_base: 87.5000 (86.0156) Top1_base_per_class: 86.7593 (86.5587) 
Training Epoch: [196/1000] Step: [30 / 285] Batch Time: 0.1470 (0.1839) Data Time: 0.0125 (0.0513) Average Loss: 0.5430 (0.4988) Average CE Loss (Source):  0.5430 ( 0.4988) Learning Rate: 0.0500 (0.0500) Top1_base: 81.2500 (86.0677) Top1_base_per_class: 82.1131 (86.7387) 
Training Epoch: [196/1000] Step: [40 / 285] Batch Time: 0.1443 (0.1753) Data Time: 0.0123 (0.0427) Average Loss: 0.6210 (0.4947) Average CE Loss (Source):  0.6210 ( 0.4947) Learning Rate: 0.0500 (0.0500) Top1_base: 81.2500 (86.2500) Top1_base_per_class: 83.6607 (87.0849) 
Training Epoch: [196/1000] Step: [50 / 285] Batch Time: 0.1449 (0.1714) Data Time: 0.0117 (0.0388) Average Loss: 0.5369 (0.4947) Average CE Loss (Source):  0.5369 ( 0.4947) Learning Rate: 0.0500 (0.0500) Top1_base: 83.5938 (86.1562) Top1_base_per_class: 79.5679 (86.8781) 
Training Epoch: [196/1000] Step: [60 / 285] Batch Time: 0.1452 (0.1692) Data Time: 0.0138 (0.0365) Average Loss: 0.5113 (0.4821) Average CE Loss (Source):  0.5113 ( 0.4821) Learning Rate: 0.0500 (0.0500) Top1_base: 84.3750 (86.5365) Top1_base_per_class: 83.3117 (87.2051) 
Training Epoch: [196/1000] Step: [70 / 285] Batch Time: 0.1434 (0.1688) Data Time: 0.0105 (0.0362) Average Loss: 0.5408 (0.4829) Average CE Loss (Source):  0.5408 ( 0.4829) Learning Rate: 0.0500 (0.0500) Top1_base: 85.1562 (86.4844) Top1_base_per_class: 83.2716 (86.9467) 
Training Epoch: [196/1000] Step: [80 / 285] Batch Time: 0.1433 (0.1661) Data Time: 0.0114 (0.0335) Average Loss: 0.5171 (0.4805) Average CE Loss (Source):  0.5171 ( 0.4805) Learning Rate: 0.0500 (0.0500) Top1_base: 83.5938 (86.4746) Top1_base_per_class: 84.1369 (86.9957) 
Training Epoch: [196/1000] Step: [90 / 285] Batch Time: 0.1449 (0.1645) Data Time: 0.0105 (0.0318) Average Loss: 0.7460 (0.4851) Average CE Loss (Source):  0.7460 ( 0.4851) Learning Rate: 0.0500 (0.0500) Top1_base: 78.9062 (86.3628) Top1_base_per_class: 82.9012 (86.8628) 
Training Epoch: [196/1000] Step: [100 / 285] Batch Time: 0.1426 (0.1644) Data Time: 0.0116 (0.0317) Average Loss: 0.6341 (0.4905) Average CE Loss (Source):  0.6341 ( 0.4905) Learning Rate: 0.0500 (0.0500) Top1_base: 82.0312 (86.2266) Top1_base_per_class: 84.9435 (86.7815) 
Training Epoch: [196/1000] Step: [110 / 285] Batch Time: 0.1454 (0.1642) Data Time: 0.0101 (0.0315) Average Loss: 0.4255 (0.4903) Average CE Loss (Source):  0.4255 ( 0.4903) Learning Rate: 0.0500 (0.0500) Top1_base: 89.8438 (86.2287) Top1_base_per_class: 88.9766 (86.7713) 
Training Epoch: [196/1000] Step: [120 / 285] Batch Time: 0.1477 (0.1636) Data Time: 0.0149 (0.0308) Average Loss: 0.4445 (0.4883) Average CE Loss (Source):  0.4445 ( 0.4883) Learning Rate: 0.0500 (0.0500) Top1_base: 89.8438 (86.2891) Top1_base_per_class: 88.9198 (86.7676) 
Training Epoch: [196/1000] Step: [130 / 285] Batch Time: 0.1447 (0.1629) Data Time: 0.0107 (0.0300) Average Loss: 0.5686 (0.4884) Average CE Loss (Source):  0.5686 ( 0.4884) Learning Rate: 0.0500 (0.0500) Top1_base: 84.3750 (86.3161) Top1_base_per_class: 83.9943 (86.7569) 
Training Epoch: [196/1000] Step: [140 / 285] Batch Time: 0.1432 (0.1623) Data Time: 0.0122 (0.0295) Average Loss: 0.4728 (0.4894) Average CE Loss (Source):  0.4728 ( 0.4894) Learning Rate: 0.0500 (0.0500) Top1_base: 87.5000 (86.3337) Top1_base_per_class: 85.9477 (86.7771) 
Training Epoch: [196/1000] Step: [150 / 285] Batch Time: 0.1446 (0.1623) Data Time: 0.0124 (0.0295) Average Loss: 0.4688 (0.4888) Average CE Loss (Source):  0.4688 ( 0.4888) Learning Rate: 0.0500 (0.0500) Top1_base: 83.5938 (86.3646) Top1_base_per_class: 83.9286 (86.8192) 
Training Epoch: [196/1000] Step: [160 / 285] Batch Time: 0.1465 (0.1618) Data Time: 0.0133 (0.0289) Average Loss: 0.4002 (0.4875) Average CE Loss (Source):  0.4002 ( 0.4875) Learning Rate: 0.0500 (0.0500) Top1_base: 89.0625 (86.4111) Top1_base_per_class: 90.2160 (86.8633) 
Training Epoch: [196/1000] Step: [170 / 285] Batch Time: 0.1462 (0.1617) Data Time: 0.0114 (0.0288) Average Loss: 0.4591 (0.4848) Average CE Loss (Source):  0.4591 ( 0.4848) Learning Rate: 0.0500 (0.0500) Top1_base: 87.5000 (86.5257) Top1_base_per_class: 89.4231 (86.9892) 
Training Epoch: [196/1000] Step: [180 / 285] Batch Time: 0.1461 (0.1609) Data Time: 0.0127 (0.0280) Average Loss: 0.4564 (0.4822) Average CE Loss (Source):  0.4564 ( 0.4822) Learning Rate: 0.0500 (0.0500) Top1_base: 88.2812 (86.5929) Top1_base_per_class: 90.7692 (87.0991) 
Training Epoch: [196/1000] Step: [190 / 285] Batch Time: 0.1455 (0.1603) Data Time: 0.0104 (0.0274) Average Loss: 0.4946 (0.4816) Average CE Loss (Source):  0.4946 ( 0.4816) Learning Rate: 0.0500 (0.0500) Top1_base: 86.7188 (86.5831) Top1_base_per_class: 83.9102 (87.0837) 
Training Epoch: [196/1000] Step: [200 / 285] Batch Time: 0.1483 (0.1602) Data Time: 0.0155 (0.0272) Average Loss: 0.4734 (0.4841) Average CE Loss (Source):  0.4734 ( 0.4841) Learning Rate: 0.0500 (0.0500) Top1_base: 88.2812 (86.5000) Top1_base_per_class: 86.7560 (87.0245) 
Training Epoch: [196/1000] Step: [210 / 285] Batch Time: 0.1459 (0.1601) Data Time: 0.0111 (0.0271) Average Loss: 0.5647 (0.4849) Average CE Loss (Source):  0.5647 ( 0.4849) Learning Rate: 0.0500 (0.0500) Top1_base: 87.5000 (86.4695) Top1_base_per_class: 87.0440 (86.9855) 
Training Epoch: [196/1000] Step: [220 / 285] Batch Time: 0.2977 (0.1603) Data Time: 0.1663 (0.0274) Average Loss: 0.4778 (0.4857) Average CE Loss (Source):  0.4778 ( 0.4857) Learning Rate: 0.0500 (0.0500) Top1_base: 86.7188 (86.4062) Top1_base_per_class: 84.2098 (86.9213) 
Training Epoch: [196/1000] Step: [230 / 285] Batch Time: 0.1450 (0.1598) Data Time: 0.0136 (0.0269) Average Loss: 0.4846 (0.4853) Average CE Loss (Source):  0.4846 ( 0.4853) Learning Rate: 0.0500 (0.0500) Top1_base: 89.8438 (86.4504) Top1_base_per_class: 91.6667 (86.9865) 
Training Epoch: [196/1000] Step: [240 / 285] Batch Time: 0.1764 (0.1598) Data Time: 0.0445 (0.0269) Average Loss: 0.4133 (0.4864) Average CE Loss (Source):  0.4133 ( 0.4864) Learning Rate: 0.0500 (0.0500) Top1_base: 85.9375 (86.4290) Top1_base_per_class: 87.6099 (86.9952) 
Training Epoch: [196/1000] Step: [250 / 285] Batch Time: 0.1451 (0.1594) Data Time: 0.0140 (0.0265) Average Loss: 0.4417 (0.4871) Average CE Loss (Source):  0.4417 ( 0.4871) Learning Rate: 0.0500 (0.0500) Top1_base: 85.9375 (86.4156) Top1_base_per_class: 85.2632 (86.9539) 
Training Epoch: [196/1000] Step: [260 / 285] Batch Time: 0.1739 (0.1593) Data Time: 0.0418 (0.0264) Average Loss: 0.4970 (0.4896) Average CE Loss (Source):  0.4970 ( 0.4896) Learning Rate: 0.0500 (0.0500) Top1_base: 86.7188 (86.3522) Top1_base_per_class: 87.2727 (86.8860) 
Training Epoch: [196/1000] Step: [270 / 285] Batch Time: 0.1446 (0.1593) Data Time: 0.0107 (0.0264) Average Loss: 0.5980 (0.4915) Average CE Loss (Source):  0.5980 ( 0.4915) Learning Rate: 0.0500 (0.0500) Top1_base: 83.5938 (86.2789) Top1_base_per_class: 86.7925 (86.7975) 
Training Epoch: [196/1000] Step: [280 / 285] Batch Time: 0.1585 (0.1590) Data Time: 0.0266 (0.0262) Average Loss: 0.6455 (0.4936) Average CE Loss (Source):  0.6455 ( 0.4936) Learning Rate: 0.0500 (0.0500) Top1_base: 80.4688 (86.2612) Top1_base_per_class: 80.3509 (86.7485) 
Training Epoch: [197/1000] Step: [0] Batch Time: 0.1413 (0.1589) Data Time: 0.0105 (0.0260) Average Loss: 0.6763 (0.4949) Average CE Loss (Source):  0.6763 ( 0.4949) Learning Rate: 0.0500 (0.0500) Top1_base: 80.4688 (86.2171) Top1_base_per_class: 79.6726 (86.7210) 
Training Epoch: [197/1000] Step: [10 / 285] Batch Time: 0.1449 (0.2453) Data Time: 0.0112 (0.1120) Average Loss: 0.5957 (0.4919) Average CE Loss (Source):  0.5957 ( 0.4919) Learning Rate: 0.0500 (0.0500) Top1_base: 82.8125 (87.3438) Top1_base_per_class: 82.8931 (87.1167) 
Training Epoch: [197/1000] Step: [20 / 285] Batch Time: 0.1470 (0.2049) Data Time: 0.0115 (0.0714) Average Loss: 0.3135 (0.4675) Average CE Loss (Source):  0.3135 ( 0.4675) Learning Rate: 0.0500 (0.0500) Top1_base: 91.4062 (87.8516) Top1_base_per_class: 90.6433 (87.6621) 
Training Epoch: [197/1000] Step: [30 / 285] Batch Time: 0.1474 (0.1873) Data Time: 0.0110 (0.0538) Average Loss: 0.4997 (0.4872) Average CE Loss (Source):  0.4997 ( 0.4872) Learning Rate: 0.0500 (0.0500) Top1_base: 85.1562 (87.2917) Top1_base_per_class: 85.5758 (87.2323) 
Training Epoch: [197/1000] Step: [40 / 285] Batch Time: 0.1444 (0.1790) Data Time: 0.0108 (0.0455) Average Loss: 0.4968 (0.4922) Average CE Loss (Source):  0.4968 ( 0.4922) Learning Rate: 0.0500 (0.0500) Top1_base: 85.9375 (86.9922) Top1_base_per_class: 90.1923 (87.0931) 
Training Epoch: [197/1000] Step: [50 / 285] Batch Time: 0.1458 (0.1732) Data Time: 0.0111 (0.0397) Average Loss: 0.4731 (0.4944) Average CE Loss (Source):  0.4731 ( 0.4944) Learning Rate: 0.0500 (0.0500) Top1_base: 88.2812 (86.7656) Top1_base_per_class: 87.4214 (86.9761) 
Training Epoch: [197/1000] Step: [60 / 285] Batch Time: 0.1440 (0.1695) Data Time: 0.0108 (0.0361) Average Loss: 0.4225 (0.4947) Average CE Loss (Source):  0.4225 ( 0.4947) Learning Rate: 0.0500 (0.0500) Top1_base: 86.7188 (86.7057) Top1_base_per_class: 86.7320 (86.9177) 
Training Epoch: [197/1000] Step: [70 / 285] Batch Time: 0.1442 (0.1668) Data Time: 0.0126 (0.0336) Average Loss: 0.4142 (0.4884) Average CE Loss (Source):  0.4142 ( 0.4884) Learning Rate: 0.0500 (0.0500) Top1_base: 86.7188 (86.7522) Top1_base_per_class: 87.5926 (86.8948) 
Training Epoch: [197/1000] Step: [80 / 285] Batch Time: 0.1456 (0.1662) Data Time: 0.0110 (0.0330) Average Loss: 0.5292 (0.4852) Average CE Loss (Source):  0.5292 ( 0.4852) Learning Rate: 0.0500 (0.0500) Top1_base: 86.7188 (86.8750) Top1_base_per_class: 86.7273 (87.0362) 
Training Epoch: [197/1000] Step: [90 / 285] Batch Time: 0.1461 (0.1647) Data Time: 0.0104 (0.0315) Average Loss: 0.5197 (0.4792) Average CE Loss (Source):  0.5197 ( 0.4792) Learning Rate: 0.0500 (0.0500) Top1_base: 84.3750 (87.0226) Top1_base_per_class: 87.0175 (87.1272) 
Training Epoch: [197/1000] Step: [100 / 285] Batch Time: 0.1462 (0.1665) Data Time: 0.0115 (0.0332) Average Loss: 0.3693 (0.4766) Average CE Loss (Source):  0.3693 ( 0.4766) Learning Rate: 0.0500 (0.0500) Top1_base: 87.5000 (87.1172) Top1_base_per_class: 87.5821 (87.3470) 
Training Epoch: [197/1000] Step: [110 / 285] Batch Time: 0.1420 (0.1655) Data Time: 0.0113 (0.0324) Average Loss: 0.5330 (0.4825) Average CE Loss (Source):  0.5330 ( 0.4825) Learning Rate: 0.0500 (0.0500) Top1_base: 82.8125 (86.8537) Top1_base_per_class: 85.9649 (87.1457) 
Training Epoch: [197/1000] Step: [120 / 285] Batch Time: 0.1455 (0.1647) Data Time: 0.0104 (0.0316) Average Loss: 0.5597 (0.4801) Average CE Loss (Source):  0.5597 ( 0.4801) Learning Rate: 0.0500 (0.0500) Top1_base: 85.1562 (86.8750) Top1_base_per_class: 85.8442 (87.1762) 
Training Epoch: [197/1000] Step: [130 / 285] Batch Time: 0.1457 (0.1636) Data Time: 0.0108 (0.0305) Average Loss: 0.4387 (0.4802) Average CE Loss (Source):  0.4387 ( 0.4802) Learning Rate: 0.0500 (0.0500) Top1_base: 85.9375 (86.8329) Top1_base_per_class: 87.2127 (87.1823) 
Training Epoch: [197/1000] Step: [140 / 285] Batch Time: 0.1422 (0.1634) Data Time: 0.0104 (0.0304) Average Loss: 0.5081 (0.4801) Average CE Loss (Source):  0.5081 ( 0.4801) Learning Rate: 0.0500 (0.0500) Top1_base: 85.1562 (86.7801) Top1_base_per_class: 86.6379 (87.0881) 
Training Epoch: [197/1000] Step: [150 / 285] Batch Time: 0.1445 (0.1629) Data Time: 0.0107 (0.0299) Average Loss: 0.5798 (0.4833) Average CE Loss (Source):  0.5798 ( 0.4833) Learning Rate: 0.0500 (0.0500) Top1_base: 83.5938 (86.7240) Top1_base_per_class: 81.1111 (87.0300) 
Training Epoch: [197/1000] Step: [160 / 285] Batch Time: 0.1435 (0.1628) Data Time: 0.0117 (0.0298) Average Loss: 0.4855 (0.4849) Average CE Loss (Source):  0.4855 ( 0.4849) Learning Rate: 0.0500 (0.0500) Top1_base: 83.5938 (86.7041) Top1_base_per_class: 83.2440 (87.0311) 
Training Epoch: [197/1000] Step: [170 / 285] Batch Time: 0.1446 (0.1621) Data Time: 0.0129 (0.0291) Average Loss: 0.5336 (0.4826) Average CE Loss (Source):  0.5336 ( 0.4826) Learning Rate: 0.0500 (0.0500) Top1_base: 84.3750 (86.7601) Top1_base_per_class: 84.1530 (87.0937) 
Training Epoch: [197/1000] Step: [180 / 285] Batch Time: 0.1448 (0.1612) Data Time: 0.0111 (0.0282) Average Loss: 0.4809 (0.4848) Average CE Loss (Source):  0.4809 ( 0.4848) Learning Rate: 0.0500 (0.0500) Top1_base: 84.3750 (86.6884) Top1_base_per_class: 83.3333 (87.0247) 
Training Epoch: [197/1000] Step: [190 / 285] Batch Time: 0.1447 (0.1604) Data Time: 0.0106 (0.0275) Average Loss: 0.3830 (0.4852) Average CE Loss (Source):  0.3830 ( 0.4852) Learning Rate: 0.0500 (0.0500) Top1_base: 92.1875 (86.6859) Top1_base_per_class: 92.8571 (86.9801) 
Training Epoch: [197/1000] Step: [200 / 285] Batch Time: 0.1443 (0.1600) Data Time: 0.0104 (0.0271) Average Loss: 0.5490 (0.4850) Average CE Loss (Source):  0.5490 ( 0.4850) Learning Rate: 0.0500 (0.0500) Top1_base: 83.5938 (86.7109) Top1_base_per_class: 87.7778 (87.0581) 
Training Epoch: [197/1000] Step: [210 / 285] Batch Time: 0.1456 (0.1595) Data Time: 0.0108 (0.0266) Average Loss: 0.4258 (0.4837) Average CE Loss (Source):  0.4258 ( 0.4837) Learning Rate: 0.0500 (0.0500) Top1_base: 88.2812 (86.7485) Top1_base_per_class: 91.3580 (87.1277) 
Training Epoch: [197/1000] Step: [220 / 285] Batch Time: 0.1444 (0.1596) Data Time: 0.0128 (0.0267) Average Loss: 0.6638 (0.4862) Average CE Loss (Source):  0.6638 ( 0.4862) Learning Rate: 0.0500 (0.0500) Top1_base: 80.4688 (86.6832) Top1_base_per_class: 80.5060 (87.0431) 
Training Epoch: [197/1000] Step: [230 / 285] Batch Time: 0.1426 (0.1594) Data Time: 0.0116 (0.0265) Average Loss: 0.7052 (0.4873) Average CE Loss (Source):  0.7052 ( 0.4873) Learning Rate: 0.0500 (0.0500) Top1_base: 80.4688 (86.6168) Top1_base_per_class: 81.9136 (86.9983) 
Training Epoch: [197/1000] Step: [240 / 285] Batch Time: 0.1436 (0.1591) Data Time: 0.0119 (0.0262) Average Loss: 0.5875 (0.4896) Average CE Loss (Source):  0.5875 ( 0.4896) Learning Rate: 0.0500 (0.0500) Top1_base: 81.2500 (86.5234) Top1_base_per_class: 82.9825 (86.9029) 
Training Epoch: [197/1000] Step: [250 / 285] Batch Time: 0.1475 (0.1586) Data Time: 0.0111 (0.0257) Average Loss: 0.4676 (0.4894) Average CE Loss (Source):  0.4676 ( 0.4894) Learning Rate: 0.0500 (0.0500) Top1_base: 85.9375 (86.5187) Top1_base_per_class: 87.5893 (86.8944) 
Training Epoch: [197/1000] Step: [260 / 285] Batch Time: 0.1483 (0.1587) Data Time: 0.0115 (0.0257) Average Loss: 0.5575 (0.4881) Average CE Loss (Source):  0.5575 ( 0.4881) Learning Rate: 0.0500 (0.0500) Top1_base: 85.9375 (86.5445) Top1_base_per_class: 82.1212 (86.9059) 
Training Epoch: [197/1000] Step: [270 / 285] Batch Time: 0.1433 (0.1584) Data Time: 0.0116 (0.0253) Average Loss: 0.5005 (0.4908) Average CE Loss (Source):  0.5005 ( 0.4908) Learning Rate: 0.0500 (0.0500) Top1_base: 88.2812 (86.4844) Top1_base_per_class: 87.5287 (86.8639) 
Training Epoch: [197/1000] Step: [280 / 285] Batch Time: 0.1486 (0.1581) Data Time: 0.0106 (0.0250) Average Loss: 0.4146 (0.4913) Average CE Loss (Source):  0.4146 ( 0.4913) Learning Rate: 0.0500 (0.0500) Top1_base: 87.5000 (86.4425) Top1_base_per_class: 86.3463 (86.8035) 
Training Epoch: [198/1000] Step: [0] Batch Time: 0.1459 (0.1582) Data Time: 0.0122 (0.0251) Average Loss: 0.6150 (0.4909) Average CE Loss (Source):  0.6150 ( 0.4909) Learning Rate: 0.0500 (0.0500) Top1_base: 82.8125 (86.4419) Top1_base_per_class: 84.8214 (86.8022) 
 20%|█▉        | 198/1000 [2:33:42<10:22:09, 46.54s/it] 20%|█▉        | 199/1000 [2:34:28<10:18:35, 46.34s/it]Training Epoch: [198/1000] Step: [10 / 285] Batch Time: 0.1427 (0.2237) Data Time: 0.0125 (0.0911) Average Loss: 0.5758 (0.5164) Average CE Loss (Source):  0.5758 ( 0.5164) Learning Rate: 0.0500 (0.0500) Top1_base: 86.7188 (85.6250) Top1_base_per_class: 82.2917 (86.0266) 
Training Epoch: [198/1000] Step: [20 / 285] Batch Time: 0.1465 (0.1891) Data Time: 0.0114 (0.0565) Average Loss: 0.4745 (0.4971) Average CE Loss (Source):  0.4745 ( 0.4971) Learning Rate: 0.0500 (0.0500) Top1_base: 89.0625 (86.0938) Top1_base_per_class: 91.2568 (86.6501) 
Training Epoch: [198/1000] Step: [30 / 285] Batch Time: 0.1818 (0.1810) Data Time: 0.0524 (0.0484) Average Loss: 0.3682 (0.4850) Average CE Loss (Source):  0.3682 ( 0.4850) Learning Rate: 0.0500 (0.0500) Top1_base: 90.6250 (86.3802) Top1_base_per_class: 90.7233 (87.0035) 
Training Epoch: [198/1000] Step: [40 / 285] Batch Time: 0.1436 (0.1767) Data Time: 0.0121 (0.0441) Average Loss: 0.3752 (0.4691) Average CE Loss (Source):  0.3752 ( 0.4691) Learning Rate: 0.0500 (0.0500) Top1_base: 90.6250 (87.0117) Top1_base_per_class: 93.3025 (87.4367) 
Training Epoch: [198/1000] Step: [50 / 285] Batch Time: 0.2514 (0.1751) Data Time: 0.1190 (0.0423) Average Loss: 0.5104 (0.4668) Average CE Loss (Source):  0.5104 ( 0.4668) Learning Rate: 0.0500 (0.0500) Top1_base: 83.5938 (87.1875) Top1_base_per_class: 85.7377 (87.7663) 
Training Epoch: [198/1000] Step: [60 / 285] Batch Time: 0.1505 (0.1718) Data Time: 0.0137 (0.0389) Average Loss: 0.4280 (0.4733) Average CE Loss (Source):  0.4280 ( 0.4733) Learning Rate: 0.0500 (0.0500) Top1_base: 88.2812 (87.0182) Top1_base_per_class: 90.4971 (87.6618) 
Training Epoch: [198/1000] Step: [70 / 285] Batch Time: 0.2280 (0.1702) Data Time: 0.0956 (0.0371) Average Loss: 0.5526 (0.4757) Average CE Loss (Source):  0.5526 ( 0.4757) Learning Rate: 0.0500 (0.0500) Top1_base: 84.3750 (86.9643) Top1_base_per_class: 86.0526 (87.6494) 
Training Epoch: [198/1000] Step: [80 / 285] Batch Time: 0.1495 (0.1698) Data Time: 0.0124 (0.0366) Average Loss: 0.4498 (0.4823) Average CE Loss (Source):  0.4498 ( 0.4823) Learning Rate: 0.0500 (0.0500) Top1_base: 84.3750 (86.7383) Top1_base_per_class: 85.3571 (87.4031) 
Training Epoch: [198/1000] Step: [90 / 285] Batch Time: 0.1456 (0.1686) Data Time: 0.0135 (0.0354) Average Loss: 0.4307 (0.4808) Average CE Loss (Source):  0.4307 ( 0.4808) Learning Rate: 0.0500 (0.0500) Top1_base: 86.7188 (86.7622) Top1_base_per_class: 88.1609 (87.3997) 
Training Epoch: [198/1000] Step: [100 / 285] Batch Time: 0.1447 (0.1670) Data Time: 0.0121 (0.0339) Average Loss: 0.3094 (0.4774) Average CE Loss (Source):  0.3094 ( 0.4774) Learning Rate: 0.0500 (0.0500) Top1_base: 92.9688 (86.8281) Top1_base_per_class: 91.5152 (87.4597) 
Training Epoch: [198/1000] Step: [110 / 285] Batch Time: 0.1471 (0.1662) Data Time: 0.0144 (0.0330) Average Loss: 0.4005 (0.4758) Average CE Loss (Source):  0.4005 ( 0.4758) Learning Rate: 0.0500 (0.0500) Top1_base: 89.0625 (86.8537) Top1_base_per_class: 86.7836 (87.4887) 
Training Epoch: [198/1000] Step: [120 / 285] Batch Time: 0.1496 (0.1650) Data Time: 0.0149 (0.0318) Average Loss: 0.5691 (0.4794) Average CE Loss (Source):  0.5691 ( 0.4794) Learning Rate: 0.0500 (0.0500) Top1_base: 85.1562 (86.6992) Top1_base_per_class: 85.7440 (87.3027) 
Training Epoch: [198/1000] Step: [130 / 285] Batch Time: 0.1446 (0.1650) Data Time: 0.0127 (0.0318) Average Loss: 0.6101 (0.4807) Average CE Loss (Source):  0.6101 ( 0.4807) Learning Rate: 0.0500 (0.0500) Top1_base: 82.0312 (86.6647) Top1_base_per_class: 81.5758 (87.2551) 
Training Epoch: [198/1000] Step: [140 / 285] Batch Time: 0.1507 (0.1645) Data Time: 0.0163 (0.0313) Average Loss: 0.4886 (0.4841) Average CE Loss (Source):  0.4886 ( 0.4841) Learning Rate: 0.0500 (0.0500) Top1_base: 85.1562 (86.6406) Top1_base_per_class: 81.7252 (87.1903) 
Training Epoch: [198/1000] Step: [150 / 285] Batch Time: 0.1457 (0.1640) Data Time: 0.0132 (0.0309) Average Loss: 0.3891 (0.4872) Average CE Loss (Source):  0.3891 ( 0.4872) Learning Rate: 0.0500 (0.0500) Top1_base: 89.8438 (86.5990) Top1_base_per_class: 89.8587 (87.1359) 
Training Epoch: [198/1000] Step: [160 / 285] Batch Time: 0.1444 (0.1629) Data Time: 0.0111 (0.0298) Average Loss: 0.5425 (0.4880) Average CE Loss (Source):  0.5425 ( 0.4880) Learning Rate: 0.0500 (0.0500) Top1_base: 85.1562 (86.5771) Top1_base_per_class: 88.7644 (87.1064) 
Training Epoch: [198/1000] Step: [170 / 285] Batch Time: 0.1425 (0.1624) Data Time: 0.0104 (0.0294) Average Loss: 0.4934 (0.4864) Average CE Loss (Source):  0.4934 ( 0.4864) Learning Rate: 0.0500 (0.0500) Top1_base: 88.2812 (86.6452) Top1_base_per_class: 89.5238 (87.1323) 
Training Epoch: [198/1000] Step: [180 / 285] Batch Time: 0.1494 (0.1622) Data Time: 0.0158 (0.0291) Average Loss: 0.3977 (0.4845) Average CE Loss (Source):  0.3977 ( 0.4845) Learning Rate: 0.0500 (0.0500) Top1_base: 86.7188 (86.7144) Top1_base_per_class: 87.6730 (87.2048) 
Training Epoch: [198/1000] Step: [190 / 285] Batch Time: 0.1426 (0.1624) Data Time: 0.0106 (0.0293) Average Loss: 0.5927 (0.4866) Average CE Loss (Source):  0.5927 ( 0.4866) Learning Rate: 0.0500 (0.0500) Top1_base: 83.5938 (86.6571) Top1_base_per_class: 83.3621 (87.1247) 
Training Epoch: [198/1000] Step: [200 / 285] Batch Time: 0.1522 (0.1618) Data Time: 0.0161 (0.0287) Average Loss: 0.5252 (0.4829) Average CE Loss (Source):  0.5252 ( 0.4829) Learning Rate: 0.0500 (0.0500) Top1_base: 87.5000 (86.7695) Top1_base_per_class: 87.8869 (87.2459) 
Training Epoch: [198/1000] Step: [210 / 285] Batch Time: 0.1423 (0.1618) Data Time: 0.0110 (0.0286) Average Loss: 0.3866 (0.4809) Average CE Loss (Source):  0.3866 ( 0.4809) Learning Rate: 0.0500 (0.0500) Top1_base: 88.2812 (86.8155) Top1_base_per_class: 88.2738 (87.3045) 
Training Epoch: [198/1000] Step: [220 / 285] Batch Time: 0.1520 (0.1613) Data Time: 0.0150 (0.0282) Average Loss: 0.4671 (0.4815) Average CE Loss (Source):  0.4671 ( 0.4815) Learning Rate: 0.0500 (0.0500) Top1_base: 87.5000 (86.8501) Top1_base_per_class: 87.2321 (87.3415) 
Training Epoch: [198/1000] Step: [230 / 285] Batch Time: 0.1423 (0.1615) Data Time: 0.0108 (0.0283) Average Loss: 0.7290 (0.4838) Average CE Loss (Source):  0.7290 ( 0.4838) Learning Rate: 0.0500 (0.0500) Top1_base: 82.0312 (86.8139) Top1_base_per_class: 81.5497 (87.2855) 
Training Epoch: [198/1000] Step: [240 / 285] Batch Time: 0.1512 (0.1615) Data Time: 0.0156 (0.0283) Average Loss: 0.5031 (0.4834) Average CE Loss (Source):  0.5031 ( 0.4834) Learning Rate: 0.0500 (0.0500) Top1_base: 82.8125 (86.8164) Top1_base_per_class: 83.9286 (87.3006) 
Training Epoch: [198/1000] Step: [250 / 285] Batch Time: 0.1426 (0.1614) Data Time: 0.0113 (0.0282) Average Loss: 0.6185 (0.4846) Average CE Loss (Source):  0.6185 ( 0.4846) Learning Rate: 0.0500 (0.0500) Top1_base: 82.0312 (86.7812) Top1_base_per_class: 85.2632 (87.2524) 
Training Epoch: [198/1000] Step: [260 / 285] Batch Time: 0.1431 (0.1610) Data Time: 0.0110 (0.0279) Average Loss: 0.5017 (0.4854) Average CE Loss (Source):  0.5017 ( 0.4854) Learning Rate: 0.0500 (0.0500) Top1_base: 87.5000 (86.7368) Top1_base_per_class: 85.9568 (87.1789) 
Training Epoch: [198/1000] Step: [270 / 285] Batch Time: 0.1449 (0.1609) Data Time: 0.0109 (0.0277) Average Loss: 0.4459 (0.4846) Average CE Loss (Source):  0.4459 ( 0.4846) Learning Rate: 0.0500 (0.0500) Top1_base: 88.2812 (86.7650) Top1_base_per_class: 87.5309 (87.2066) 
Training Epoch: [198/1000] Step: [280 / 285] Batch Time: 0.1456 (0.1609) Data Time: 0.0130 (0.0276) Average Loss: 0.5065 (0.4867) Average CE Loss (Source):  0.5065 ( 0.4867) Learning Rate: 0.0500 (0.0500) Top1_base: 82.0312 (86.7048) Top1_base_per_class: 79.1374 (87.1128) 
Training Epoch: [199/1000] Step: [0] Batch Time: 0.1416 (0.1606) Data Time: 0.0104 (0.0274) Average Loss: 0.5552 (0.4878) Average CE Loss (Source):  0.5552 ( 0.4878) Learning Rate: 0.0500 (0.0500) Top1_base: 82.8125 (86.6584) Top1_base_per_class: 83.8690 (87.0739) 
Training Epoch: [199/1000] Step: [10 / 285] Batch Time: 0.1438 (0.2279) Data Time: 0.0112 (0.0956) Average Loss: 0.4276 (0.4699) Average CE Loss (Source):  0.4276 ( 0.4699) Learning Rate: 0.0500 (0.0500) Top1_base: 87.5000 (86.1719) Top1_base_per_class: 87.4425 (85.8294) 
Training Epoch: [199/1000] Step: [20 / 285] Batch Time: 0.1467 (0.1903) Data Time: 0.0106 (0.0575) Average Loss: 0.4887 (0.4620) Average CE Loss (Source):  0.4887 ( 0.4620) Learning Rate: 0.0500 (0.0500) Top1_base: 88.2812 (86.9141) Top1_base_per_class: 87.7485 (86.7274) 
Training Epoch: [199/1000] Step: [30 / 285] Batch Time: 0.1549 (0.1804) Data Time: 0.0246 (0.0478) Average Loss: 0.4853 (0.4713) Average CE Loss (Source):  0.4853 ( 0.4713) Learning Rate: 0.0500 (0.0500) Top1_base: 85.9375 (86.6927) Top1_base_per_class: 86.7857 (86.6978) 
Training Epoch: [199/1000] Step: [40 / 285] Batch Time: 0.1444 (0.1745) Data Time: 0.0113 (0.0418) Average Loss: 0.5596 (0.4679) Average CE Loss (Source):  0.5596 ( 0.4679) Learning Rate: 0.0500 (0.0500) Top1_base: 86.7188 (86.8945) Top1_base_per_class: 88.2471 (87.1758) 
Training Epoch: [199/1000] Step: [50 / 285] Batch Time: 0.2999 (0.1737) Data Time: 0.1669 (0.0411) Average Loss: 0.5713 (0.4791) Average CE Loss (Source):  0.5713 ( 0.4791) Learning Rate: 0.0500 (0.0500) Top1_base: 85.9375 (86.5781) Top1_base_per_class: 84.1497 (87.0094) 
Training Epoch: [199/1000] Step: [60 / 285] Batch Time: 0.1452 (0.1693) Data Time: 0.0130 (0.0367) Average Loss: 0.4458 (0.4825) Average CE Loss (Source):  0.4458 ( 0.4825) Learning Rate: 0.0500 (0.0500) Top1_base: 86.7188 (86.3151) Top1_base_per_class: 85.7407 (86.7613) 
Training Epoch: [199/1000] Step: [70 / 285] Batch Time: 0.2270 (0.1693) Data Time: 0.0963 (0.0368) Average Loss: 0.4325 (0.4818) Average CE Loss (Source):  0.4325 ( 0.4818) Learning Rate: 0.0500 (0.0500) Top1_base: 87.5000 (86.2946) Top1_base_per_class: 88.0071 (86.7298) 
Training Epoch: [199/1000] Step: [80 / 285] Batch Time: 0.1451 (0.1673) Data Time: 0.0144 (0.0349) Average Loss: 0.3700 (0.4813) Average CE Loss (Source):  0.3700 ( 0.4813) Learning Rate: 0.0500 (0.0500) Top1_base: 92.1875 (86.3770) Top1_base_per_class: 92.6913 (86.7555) 
Training Epoch: [199/1000] Step: [90 / 285] Batch Time: 0.2845 (0.1683) Data Time: 0.1526 (0.0360) Average Loss: 0.5389 (0.4754) Average CE Loss (Source):  0.5389 ( 0.4754) Learning Rate: 0.0500 (0.0500) Top1_base: 83.5938 (86.5799) Top1_base_per_class: 84.3396 (86.9126) 
Training Epoch: [199/1000] Step: [100 / 285] Batch Time: 0.1475 (0.1667) Data Time: 0.0156 (0.0344) Average Loss: 0.4641 (0.4740) Average CE Loss (Source):  0.4641 ( 0.4740) Learning Rate: 0.0500 (0.0500) Top1_base: 85.9375 (86.7422) Top1_base_per_class: 86.9345 (87.1524) 
Training Epoch: [199/1000] Step: [110 / 285] Batch Time: 0.2005 (0.1661) Data Time: 0.0657 (0.0337) Average Loss: 0.5810 (0.4716) Average CE Loss (Source):  0.5810 ( 0.4716) Learning Rate: 0.0500 (0.0500) Top1_base: 82.8125 (86.7614) Top1_base_per_class: 82.0303 (87.1468) 
Training Epoch: [199/1000] Step: [120 / 285] Batch Time: 0.1502 (0.1650) Data Time: 0.0144 (0.0325) Average Loss: 0.5367 (0.4724) Average CE Loss (Source):  0.5367 ( 0.4724) Learning Rate: 0.0500 (0.0500) Top1_base: 83.5938 (86.7448) Top1_base_per_class: 83.5153 (87.1442) 
Training Epoch: [199/1000] Step: [130 / 285] Batch Time: 0.1931 (0.1649) Data Time: 0.0615 (0.0324) Average Loss: 0.6589 (0.4754) Average CE Loss (Source):  0.6589 ( 0.4754) Learning Rate: 0.0500 (0.0500) Top1_base: 82.0312 (86.7188) Top1_base_per_class: 83.1851 (87.1787) 
Training Epoch: [199/1000] Step: [140 / 285] Batch Time: 0.1448 (0.1642) Data Time: 0.0106 (0.0316) Average Loss: 0.3991 (0.4761) Average CE Loss (Source):  0.3991 ( 0.4761) Learning Rate: 0.0500 (0.0500) Top1_base: 88.2812 (86.7522) Top1_base_per_class: 85.4717 (87.1766) 
Training Epoch: [199/1000] Step: [150 / 285] Batch Time: 0.1688 (0.1639) Data Time: 0.0372 (0.0313) Average Loss: 0.4036 (0.4785) Average CE Loss (Source):  0.4036 ( 0.4785) Learning Rate: 0.0500 (0.0500) Top1_base: 90.6250 (86.6979) Top1_base_per_class: 91.7610 (87.1424) 
Training Epoch: [199/1000] Step: [160 / 285] Batch Time: 0.1446 (0.1630) Data Time: 0.0107 (0.0304) Average Loss: 0.4849 (0.4797) Average CE Loss (Source):  0.4849 ( 0.4797) Learning Rate: 0.0500 (0.0500) Top1_base: 85.1562 (86.6211) Top1_base_per_class: 86.0452 (87.0594) 
Training Epoch: [199/1000] Step: [170 / 285] Batch Time: 0.1911 (0.1635) Data Time: 0.0577 (0.0308) Average Loss: 0.4325 (0.4776) Average CE Loss (Source):  0.4325 ( 0.4776) Learning Rate: 0.0500 (0.0500) Top1_base: 87.5000 (86.6452) Top1_base_per_class: 88.4545 (87.0459) 
Training Epoch: [199/1000] Step: [180 / 285] Batch Time: 0.1438 (0.1632) Data Time: 0.0121 (0.0305) Average Loss: 0.5857 (0.4796) Average CE Loss (Source):  0.5857 ( 0.4796) Learning Rate: 0.0500 (0.0500) Top1_base: 82.8125 (86.5495) Top1_base_per_class: 83.1921 (87.0066) 
Training Epoch: [199/1000] Step: [190 / 285] Batch Time: 0.2122 (0.1630) Data Time: 0.0786 (0.0302) Average Loss: 0.4996 (0.4784) Average CE Loss (Source):  0.4996 ( 0.4784) Learning Rate: 0.0500 (0.0500) Top1_base: 87.5000 (86.6530) Top1_base_per_class: 84.3391 (87.1024) 
Training Epoch: [199/1000] Step: [200 / 285] Batch Time: 0.1443 (0.1623) Data Time: 0.0106 (0.0295) Average Loss: 0.4555 (0.4786) Average CE Loss (Source):  0.4555 ( 0.4786) Learning Rate: 0.0500 (0.0500) Top1_base: 89.8438 (86.5898) Top1_base_per_class: 91.3277 (87.1024) 
Training Epoch: [199/1000] Step: [210 / 285] Batch Time: 0.1695 (0.1619) Data Time: 0.0368 (0.0291) Average Loss: 0.4176 (0.4786) Average CE Loss (Source):  0.4176 ( 0.4786) Learning Rate: 0.0500 (0.0500) Top1_base: 88.2812 (86.5885) Top1_base_per_class: 88.4153 (87.0743) 
Training Epoch: [199/1000] Step: [220 / 285] Batch Time: 0.1450 (0.1615) Data Time: 0.0110 (0.0286) Average Loss: 0.4466 (0.4803) Average CE Loss (Source):  0.4466 ( 0.4803) Learning Rate: 0.0500 (0.0500) Top1_base: 87.5000 (86.5732) Top1_base_per_class: 85.0292 (87.0467) 
Training Epoch: [199/1000] Step: [230 / 285] Batch Time: 0.1479 (0.1611) Data Time: 0.0155 (0.0283) Average Loss: 0.5424 (0.4804) Average CE Loss (Source):  0.5424 ( 0.4804) Learning Rate: 0.0500 (0.0500) Top1_base: 85.1562 (86.5523) Top1_base_per_class: 84.5887 (86.9982) 
Training Epoch: [199/1000] Step: [240 / 285] Batch Time: 0.1459 (0.1608) Data Time: 0.0106 (0.0279) Average Loss: 0.4184 (0.4825) Average CE Loss (Source):  0.4184 ( 0.4825) Learning Rate: 0.0500 (0.0500) Top1_base: 87.5000 (86.4421) Top1_base_per_class: 90.5454 (86.8646) 
Training Epoch: [199/1000] Step: [250 / 285] Batch Time: 0.1543 (0.1607) Data Time: 0.0223 (0.0278) Average Loss: 0.4646 (0.4852) Average CE Loss (Source):  0.4646 ( 0.4852) Learning Rate: 0.0500 (0.0500) Top1_base: 85.9375 (86.3656) Top1_base_per_class: 86.8210 (86.7560) 
Training Epoch: [199/1000] Step: [260 / 285] Batch Time: 0.1469 (0.1603) Data Time: 0.0117 (0.0274) Average Loss: 0.5097 (0.4873) Average CE Loss (Source):  0.5097 ( 0.4873) Learning Rate: 0.0500 (0.0500) Top1_base: 86.7188 (86.3281) Top1_base_per_class: 85.6739 (86.6573) 
Training Epoch: [199/1000] Step: [270 / 285] Batch Time: 0.1513 (0.1601) Data Time: 0.0180 (0.0273) Average Loss: 0.5619 (0.4877) Average CE Loss (Source):  0.5619 ( 0.4877) Learning Rate: 0.0500 (0.0500) Top1_base: 85.1562 (86.3166) Top1_base_per_class: 82.2327 (86.6367) 
Training Epoch: [199/1000] Step: [280 / 285] Batch Time: 0.1418 (0.1599) Data Time: 0.0121 (0.0270) Average Loss: 0.4083 (0.4884) Average CE Loss (Source):  0.4083 ( 0.4884) Learning Rate: 0.0500 (0.0500) Top1_base: 88.2812 (86.2695) Top1_base_per_class: 90.7879 (86.6224) 
Training Epoch: [200/1000] Step: [0] Batch Time: 0.1388 (0.1596) Data Time: 0.0106 (0.0268) Average Loss: 0.4665 (0.4887) Average CE Loss (Source):  0.4665 ( 0.4887) Learning Rate: 0.0500 (0.0500) Top1_base: 86.7188 (86.2610) Top1_base_per_class: 86.6667 (86.6157) 
 20%|██        | 200/1000 [2:35:17<10:25:48, 46.94s/it] 20%|██        | 201/1000 [2:36:02<10:16:43, 46.31s/it]Training Epoch: [200/1000] Step: [10 / 285] Batch Time: 0.1412 (0.2355) Data Time: 0.0106 (0.1041) Average Loss: 0.3333 (0.4882) Average CE Loss (Source):  0.3333 ( 0.4882) Learning Rate: 0.0500 (0.0500) Top1_base: 92.1875 (87.1875) Top1_base_per_class: 91.4583 (86.6092) 
Training Epoch: [200/1000] Step: [20 / 285] Batch Time: 0.1456 (0.1955) Data Time: 0.0150 (0.0640) Average Loss: 0.5064 (0.4924) Average CE Loss (Source):  0.5064 ( 0.4924) Learning Rate: 0.0500 (0.0500) Top1_base: 85.9375 (86.4453) Top1_base_per_class: 87.5000 (86.9013) 
Training Epoch: [200/1000] Step: [30 / 285] Batch Time: 0.1506 (0.1879) Data Time: 0.0114 (0.0553) Average Loss: 0.4119 (0.4880) Average CE Loss (Source):  0.4119 ( 0.4880) Learning Rate: 0.0500 (0.0500) Top1_base: 90.6250 (86.7448) Top1_base_per_class: 90.4762 (87.0968) 
Training Epoch: [200/1000] Step: [40 / 285] Batch Time: 0.1485 (0.1796) Data Time: 0.0108 (0.0464) Average Loss: 0.5750 (0.4830) Average CE Loss (Source):  0.5750 ( 0.4830) Learning Rate: 0.0500 (0.0500) Top1_base: 87.5000 (86.9727) Top1_base_per_class: 89.0643 (87.2483) 
Training Epoch: [200/1000] Step: [50 / 285] Batch Time: 0.1524 (0.1753) Data Time: 0.0149 (0.0414) Average Loss: 0.4032 (0.4864) Average CE Loss (Source):  0.4032 ( 0.4864) Learning Rate: 0.0500 (0.0500) Top1_base: 90.6250 (87.0312) Top1_base_per_class: 89.6610 (87.2064) 
Training Epoch: [200/1000] Step: [60 / 285] Batch Time: 0.1481 (0.1709) Data Time: 0.0113 (0.0367) Average Loss: 0.5242 (0.4921) Average CE Loss (Source):  0.5242 ( 0.4921) Learning Rate: 0.0500 (0.0500) Top1_base: 87.5000 (86.9531) Top1_base_per_class: 90.0000 (87.2330) 
Training Epoch: [200/1000] Step: [70 / 285] Batch Time: 0.1511 (0.1682) Data Time: 0.0136 (0.0337) Average Loss: 0.4784 (0.4886) Average CE Loss (Source):  0.4784 ( 0.4886) Learning Rate: 0.0500 (0.0500) Top1_base: 84.3750 (86.9308) Top1_base_per_class: 88.0993 (87.2760) 
Training Epoch: [200/1000] Step: [80 / 285] Batch Time: 0.1467 (0.1657) Data Time: 0.0109 (0.0312) Average Loss: 0.5289 (0.4888) Average CE Loss (Source):  0.5289 ( 0.4888) Learning Rate: 0.0500 (0.0500) Top1_base: 85.1562 (87.0117) Top1_base_per_class: 85.8951 (87.3817) 
Training Epoch: [200/1000] Step: [90 / 285] Batch Time: 0.1486 (0.1658) Data Time: 0.0117 (0.0312) Average Loss: 0.6235 (0.4864) Average CE Loss (Source):  0.6235 ( 0.4864) Learning Rate: 0.0500 (0.0500) Top1_base: 84.3750 (87.1441) Top1_base_per_class: 81.0606 (87.3299) 
Training Epoch: [200/1000] Step: [100 / 285] Batch Time: 0.1468 (0.1645) Data Time: 0.0107 (0.0298) Average Loss: 0.2901 (0.4885) Average CE Loss (Source):  0.2901 ( 0.4885) Learning Rate: 0.0500 (0.0500) Top1_base: 93.7500 (86.9375) Top1_base_per_class: 93.9815 (87.1779) 
Training Epoch: [200/1000] Step: [110 / 285] Batch Time: 0.1488 (0.1639) Data Time: 0.0105 (0.0291) Average Loss: 0.3423 (0.4850) Average CE Loss (Source):  0.3423 ( 0.4850) Learning Rate: 0.0500 (0.0500) Top1_base: 89.8438 (86.9744) Top1_base_per_class: 85.8187 (87.1193) 
Training Epoch: [200/1000] Step: [120 / 285] Batch Time: 0.1471 (0.1632) Data Time: 0.0114 (0.0283) Average Loss: 0.4375 (0.4805) Average CE Loss (Source):  0.4375 ( 0.4805) Learning Rate: 0.0500 (0.0500) Top1_base: 89.0625 (87.0443) Top1_base_per_class: 87.5000 (87.1965) 
Training Epoch: [200/1000] Step: [130 / 285] Batch Time: 0.1488 (0.1622) Data Time: 0.0110 (0.0272) Average Loss: 0.3335 (0.4839) Average CE Loss (Source):  0.3335 ( 0.4839) Learning Rate: 0.0500 (0.0500) Top1_base: 92.1875 (86.8870) Top1_base_per_class: 94.0566 (87.0488) 
Training Epoch: [200/1000] Step: [140 / 285] Batch Time: 0.1479 (0.1613) Data Time: 0.0119 (0.0263) Average Loss: 0.5839 (0.4853) Average CE Loss (Source):  0.5839 ( 0.4853) Learning Rate: 0.0500 (0.0500) Top1_base: 85.1562 (86.7801) Top1_base_per_class: 87.5472 (86.9851) 
Training Epoch: [200/1000] Step: [150 / 285] Batch Time: 0.1499 (0.1605) Data Time: 0.0106 (0.0254) Average Loss: 0.5663 (0.4876) Average CE Loss (Source):  0.5663 ( 0.4876) Learning Rate: 0.0500 (0.0500) Top1_base: 83.5938 (86.7188) Top1_base_per_class: 83.8889 (86.9393) 
Training Epoch: [200/1000] Step: [160 / 285] Batch Time: 0.1474 (0.1600) Data Time: 0.0110 (0.0248) Average Loss: 0.4009 (0.4877) Average CE Loss (Source):  0.4009 ( 0.4877) Learning Rate: 0.0500 (0.0500) Top1_base: 89.8438 (86.6748) Top1_base_per_class: 92.5000 (86.8910) 
Training Epoch: [200/1000] Step: [170 / 285] Batch Time: 0.1475 (0.1593) Data Time: 0.0114 (0.0242) Average Loss: 0.5657 (0.4873) Average CE Loss (Source):  0.5657 ( 0.4873) Learning Rate: 0.0500 (0.0500) Top1_base: 81.2500 (86.6406) Top1_base_per_class: 81.6667 (86.8331) 
Training Epoch: [200/1000] Step: [180 / 285] Batch Time: 0.1476 (0.1588) Data Time: 0.0110 (0.0236) Average Loss: 0.5435 (0.4860) Average CE Loss (Source):  0.5435 ( 0.4860) Learning Rate: 0.0500 (0.0500) Top1_base: 83.5938 (86.6580) Top1_base_per_class: 85.1754 (86.8318) 
Training Epoch: [200/1000] Step: [190 / 285] Batch Time: 0.1477 (0.1583) Data Time: 0.0107 (0.0231) Average Loss: 0.4046 (0.4836) Average CE Loss (Source):  0.4046 ( 0.4836) Learning Rate: 0.0500 (0.0500) Top1_base: 90.6250 (86.6982) Top1_base_per_class: 89.1818 (86.8631) 
Training Epoch: [200/1000] Step: [200 / 285] Batch Time: 0.1463 (0.1580) Data Time: 0.0109 (0.0228) Average Loss: 0.3765 (0.4817) Average CE Loss (Source):  0.3765 ( 0.4817) Learning Rate: 0.0500 (0.0500) Top1_base: 88.2812 (86.7578) Top1_base_per_class: 86.3072 (86.9143) 
Training Epoch: [200/1000] Step: [210 / 285] Batch Time: 0.1456 (0.1580) Data Time: 0.0110 (0.0228) Average Loss: 0.3690 (0.4823) Average CE Loss (Source):  0.3690 ( 0.4823) Learning Rate: 0.0500 (0.0500) Top1_base: 88.2812 (86.7299) Top1_base_per_class: 90.9568 (86.8833) 
Training Epoch: [200/1000] Step: [220 / 285] Batch Time: 0.1457 (0.1582) Data Time: 0.0106 (0.0232) Average Loss: 0.5940 (0.4831) Average CE Loss (Source):  0.5940 ( 0.4831) Learning Rate: 0.0500 (0.0500) Top1_base: 84.3750 (86.6726) Top1_base_per_class: 85.1818 (86.8691) 
Training Epoch: [200/1000] Step: [230 / 285] Batch Time: 0.1457 (0.1585) Data Time: 0.0106 (0.0235) Average Loss: 0.3805 (0.4811) Average CE Loss (Source):  0.3805 ( 0.4811) Learning Rate: 0.0500 (0.0500) Top1_base: 89.8438 (86.7018) Top1_base_per_class: 88.6364 (86.9115) 
Training Epoch: [200/1000] Step: [240 / 285] Batch Time: 0.1455 (0.1580) Data Time: 0.0115 (0.0231) Average Loss: 0.5896 (0.4839) Average CE Loss (Source):  0.5896 ( 0.4839) Learning Rate: 0.0500 (0.0500) Top1_base: 82.8125 (86.6602) Top1_base_per_class: 83.3648 (86.8894) 
Training Epoch: [200/1000] Step: [250 / 285] Batch Time: 0.1471 (0.1579) Data Time: 0.0112 (0.0230) Average Loss: 0.5787 (0.4849) Average CE Loss (Source):  0.5787 ( 0.4849) Learning Rate: 0.0500 (0.0500) Top1_base: 82.8125 (86.6188) Top1_base_per_class: 83.6728 (86.8349) 
Training Epoch: [200/1000] Step: [260 / 285] Batch Time: 0.1457 (0.1575) Data Time: 0.0107 (0.0226) Average Loss: 0.5224 (0.4862) Average CE Loss (Source):  0.5224 ( 0.4862) Learning Rate: 0.0500 (0.0500) Top1_base: 88.2812 (86.5865) Top1_base_per_class: 91.9298 (86.8301) 
Training Epoch: [200/1000] Step: [270 / 285] Batch Time: 0.1456 (0.1573) Data Time: 0.0127 (0.0226) Average Loss: 0.6120 (0.4873) Average CE Loss (Source):  0.6120 ( 0.4873) Learning Rate: 0.0500 (0.0500) Top1_base: 82.0312 (86.5509) Top1_base_per_class: 82.9085 (86.8075) 
Training Epoch: [200/1000] Step: [280 / 285] Batch Time: 0.1454 (0.1572) Data Time: 0.0110 (0.0224) Average Loss: 0.7006 (0.4871) Average CE Loss (Source):  0.7006 ( 0.4871) Learning Rate: 0.0500 (0.0500) Top1_base: 80.4688 (86.5095) Top1_base_per_class: 81.9136 (86.7922) 
Training Epoch: [201/1000] Step: [0] Batch Time: 0.1461 (0.1572) Data Time: 0.0138 (0.0225) Average Loss: 0.4392 (0.4868) Average CE Loss (Source):  0.4392 ( 0.4868) Learning Rate: 0.0500 (0.0500) Top1_base: 85.1562 (86.5104) Top1_base_per_class: 82.4074 (86.7715) 
Training Epoch: [201/1000] Step: [10 / 285] Batch Time: 0.1435 (0.2391) Data Time: 0.0117 (0.1068) Average Loss: 0.5875 (0.4656) Average CE Loss (Source):  0.5875 ( 0.4656) Learning Rate: 0.0500 (0.0500) Top1_base: 83.5938 (86.8750) Top1_base_per_class: 81.3522 (87.1476) 
Training Epoch: [201/1000] Step: [20 / 285] Batch Time: 0.1405 (0.2002) Data Time: 0.0110 (0.0680) Average Loss: 0.4817 (0.4720) Average CE Loss (Source):  0.4817 ( 0.4720) Learning Rate: 0.0500 (0.0500) Top1_base: 85.9375 (86.8750) Top1_base_per_class: 85.2381 (86.9769) 
Training Epoch: [201/1000] Step: [30 / 285] Batch Time: 0.1451 (0.1866) Data Time: 0.0117 (0.0541) Average Loss: 0.5728 (0.4555) Average CE Loss (Source):  0.5728 ( 0.4555) Learning Rate: 0.0500 (0.0500) Top1_base: 85.9375 (87.4219) Top1_base_per_class: 87.9762 (87.8433) 
Training Epoch: [201/1000] Step: [40 / 285] Batch Time: 0.1481 (0.1777) Data Time: 0.0137 (0.0449) Average Loss: 0.6756 (0.4655) Average CE Loss (Source):  0.6756 ( 0.4655) Learning Rate: 0.0500 (0.0500) Top1_base: 82.8125 (87.1289) Top1_base_per_class: 82.9783 (87.4739) 
Training Epoch: [201/1000] Step: [50 / 285] Batch Time: 0.1456 (0.1757) Data Time: 0.0119 (0.0430) Average Loss: 0.4857 (0.4704) Average CE Loss (Source):  0.4857 ( 0.4704) Learning Rate: 0.0500 (0.0500) Top1_base: 85.1562 (86.7656) Top1_base_per_class: 88.8793 (87.2167) 
Training Epoch: [201/1000] Step: [60 / 285] Batch Time: 0.1470 (0.1717) Data Time: 0.0107 (0.0391) Average Loss: 0.4232 (0.4778) Average CE Loss (Source):  0.4232 ( 0.4778) Learning Rate: 0.0500 (0.0500) Top1_base: 85.1562 (86.4974) Top1_base_per_class: 83.4211 (86.9189) 
Training Epoch: [201/1000] Step: [70 / 285] Batch Time: 0.1442 (0.1699) Data Time: 0.0107 (0.0373) Average Loss: 0.4869 (0.4831) Average CE Loss (Source):  0.4869 ( 0.4831) Learning Rate: 0.0500 (0.0500) Top1_base: 86.7188 (86.2946) Top1_base_per_class: 85.2299 (86.6221) 
Training Epoch: [201/1000] Step: [80 / 285] Batch Time: 0.1459 (0.1681) Data Time: 0.0125 (0.0353) Average Loss: 0.5707 (0.4860) Average CE Loss (Source):  0.5707 ( 0.4860) Learning Rate: 0.0500 (0.0500) Top1_base: 80.4688 (86.1328) Top1_base_per_class: 82.2515 (86.4527) 
Training Epoch: [201/1000] Step: [90 / 285] Batch Time: 0.1458 (0.1668) Data Time: 0.0129 (0.0340) Average Loss: 0.5368 (0.4888) Average CE Loss (Source):  0.5368 ( 0.4888) Learning Rate: 0.0500 (0.0500) Top1_base: 85.1562 (86.1024) Top1_base_per_class: 85.0000 (86.3591) 
Training Epoch: [201/1000] Step: [100 / 285] Batch Time: 0.1480 (0.1658) Data Time: 0.0133 (0.0331) Average Loss: 0.5353 (0.4879) Average CE Loss (Source):  0.5353 ( 0.4879) Learning Rate: 0.0500 (0.0500) Top1_base: 88.2812 (86.2500) Top1_base_per_class: 88.4849 (86.5154) 
Training Epoch: [201/1000] Step: [110 / 285] Batch Time: 0.1426 (0.1651) Data Time: 0.0114 (0.0324) Average Loss: 0.3806 (0.4898) Average CE Loss (Source):  0.3806 ( 0.4898) Learning Rate: 0.0500 (0.0500) Top1_base: 87.5000 (86.1648) Top1_base_per_class: 90.5952 (86.5670) 
Training Epoch: [201/1000] Step: [120 / 285] Batch Time: 0.1470 (0.1639) Data Time: 0.0133 (0.0311) Average Loss: 0.4316 (0.4915) Average CE Loss (Source):  0.4316 ( 0.4915) Learning Rate: 0.0500 (0.0500) Top1_base: 85.9375 (86.1133) Top1_base_per_class: 86.7488 (86.5222) 
Training Epoch: [201/1000] Step: [130 / 285] Batch Time: 0.1425 (0.1629) Data Time: 0.0114 (0.0302) Average Loss: 0.4692 (0.4947) Average CE Loss (Source):  0.4692 ( 0.4947) Learning Rate: 0.0500 (0.0500) Top1_base: 87.5000 (86.0337) Top1_base_per_class: 87.2727 (86.4727) 
Training Epoch: [201/1000] Step: [140 / 285] Batch Time: 0.1477 (0.1619) Data Time: 0.0130 (0.0291) Average Loss: 0.4852 (0.4925) Average CE Loss (Source):  0.4852 ( 0.4925) Learning Rate: 0.0500 (0.0500) Top1_base: 86.7188 (86.1496) Top1_base_per_class: 87.4011 (86.5904) 
Training Epoch: [201/1000] Step: [150 / 285] Batch Time: 0.1477 (0.1619) Data Time: 0.0121 (0.0290) Average Loss: 0.6964 (0.4968) Average CE Loss (Source):  0.6964 ( 0.4968) Learning Rate: 0.0500 (0.0500) Top1_base: 82.0312 (86.0052) Top1_base_per_class: 84.8485 (86.4594) 
Training Epoch: [201/1000] Step: [160 / 285] Batch Time: 0.1475 (0.1610) Data Time: 0.0130 (0.0281) Average Loss: 0.3166 (0.4938) Average CE Loss (Source):  0.3166 ( 0.4938) Learning Rate: 0.0500 (0.0500) Top1_base: 91.4062 (86.1572) Top1_base_per_class: 90.4321 (86.5358) 
Training Epoch: [201/1000] Step: [170 / 285] Batch Time: 0.1428 (0.1603) Data Time: 0.0104 (0.0275) Average Loss: 0.5477 (0.4950) Average CE Loss (Source):  0.5477 ( 0.4950) Learning Rate: 0.0500 (0.0500) Top1_base: 85.1562 (86.1167) Top1_base_per_class: 87.3563 (86.5209) 
Training Epoch: [201/1000] Step: [180 / 285] Batch Time: 0.1446 (0.1597) Data Time: 0.0123 (0.0269) Average Loss: 0.5210 (0.4958) Average CE Loss (Source):  0.5210 ( 0.4958) Learning Rate: 0.0500 (0.0500) Top1_base: 86.7188 (86.0851) Top1_base_per_class: 87.1069 (86.5016) 
Training Epoch: [201/1000] Step: [190 / 285] Batch Time: 0.1435 (0.1604) Data Time: 0.0114 (0.0276) Average Loss: 0.7334 (0.4975) Average CE Loss (Source):  0.7334 ( 0.4975) Learning Rate: 0.0500 (0.0500) Top1_base: 82.8125 (86.0773) Top1_base_per_class: 83.2078 (86.4816) 
Training Epoch: [201/1000] Step: [200 / 285] Batch Time: 0.1412 (0.1602) Data Time: 0.0110 (0.0274) Average Loss: 0.4265 (0.4999) Average CE Loss (Source):  0.4265 ( 0.4999) Learning Rate: 0.0500 (0.0500) Top1_base: 91.4062 (86.0430) Top1_base_per_class: 90.9649 (86.4135) 
Training Epoch: [201/1000] Step: [210 / 285] Batch Time: 0.1431 (0.1603) Data Time: 0.0114 (0.0275) Average Loss: 0.4891 (0.4995) Average CE Loss (Source):  0.4891 ( 0.4995) Learning Rate: 0.0500 (0.0500) Top1_base: 89.0625 (86.1161) Top1_base_per_class: 90.2576 (86.4736) 
Training Epoch: [201/1000] Step: [220 / 285] Batch Time: 0.1475 (0.1601) Data Time: 0.0132 (0.0272) Average Loss: 0.5900 (0.4996) Average CE Loss (Source):  0.5900 ( 0.4996) Learning Rate: 0.0500 (0.0500) Top1_base: 81.2500 (86.1470) Top1_base_per_class: 84.1515 (86.4404) 
Training Epoch: [201/1000] Step: [230 / 285] Batch Time: 0.1435 (0.1599) Data Time: 0.0115 (0.0271) Average Loss: 0.4805 (0.4990) Average CE Loss (Source):  0.4805 ( 0.4990) Learning Rate: 0.0500 (0.0500) Top1_base: 82.0312 (86.1005) Top1_base_per_class: 80.3030 (86.3864) 
Training Epoch: [201/1000] Step: [240 / 285] Batch Time: 0.1467 (0.1597) Data Time: 0.0136 (0.0268) Average Loss: 0.6086 (0.5004) Average CE Loss (Source):  0.6086 ( 0.5004) Learning Rate: 0.0500 (0.0500) Top1_base: 83.5938 (86.0221) Top1_base_per_class: 82.6786 (86.3128) 
Training Epoch: [201/1000] Step: [250 / 285] Batch Time: 0.1425 (0.1599) Data Time: 0.0113 (0.0271) Average Loss: 0.4588 (0.5013) Average CE Loss (Source):  0.4588 ( 0.5013) Learning Rate: 0.0500 (0.0500) Top1_base: 85.9375 (85.9656) Top1_base_per_class: 86.0057 (86.2482) 
Training Epoch: [201/1000] Step: [260 / 285] Batch Time: 0.1459 (0.1598) Data Time: 0.0117 (0.0269) Average Loss: 0.8433 (0.5050) Average CE Loss (Source):  0.8433 ( 0.5050) Learning Rate: 0.0500 (0.0500) Top1_base: 80.4688 (85.8504) Top1_base_per_class: 81.2022 (86.1191) 
Training Epoch: [201/1000] Step: [270 / 285] Batch Time: 0.1464 (0.1593) Data Time: 0.0137 (0.0265) Average Loss: 0.4127 (0.5034) Average CE Loss (Source):  0.4127 ( 0.5034) Learning Rate: 0.0500 (0.0500) Top1_base: 86.7188 (85.9230) Top1_base_per_class: 90.2825 (86.1879) 
Training Epoch: [201/1000] Step: [280 / 285] Batch Time: 0.1499 (0.1589) Data Time: 0.0142 (0.0261) Average Loss: 0.6190 (0.5044) Average CE Loss (Source):  0.6190 ( 0.5044) Learning Rate: 0.0500 (0.0500) Top1_base: 85.9375 (85.9068) Top1_base_per_class: 86.3782 (86.1794) 
Training Epoch: [202/1000] Step: [0] Batch Time: 0.1446 (0.1587) Data Time: 0.0126 (0.0258) Average Loss: 0.5105 (0.5057) Average CE Loss (Source):  0.5105 ( 0.5057) Learning Rate: 0.0500 (0.0500) Top1_base: 85.9375 (85.8909) Top1_base_per_class: 86.5254 (86.1841) 
 20%|██        | 202/1000 [2:36:50<10:22:43, 46.82s/it] 20%|██        | 203/1000 [2:37:34<10:14:21, 46.25s/it]Training Epoch: [202/1000] Step: [10 / 285] Batch Time: 0.1475 (0.2321) Data Time: 0.0144 (0.0989) Average Loss: 0.5887 (0.5082) Average CE Loss (Source):  0.5887 ( 0.5082) Learning Rate: 0.0500 (0.0500) Top1_base: 83.5938 (85.8594) Top1_base_per_class: 87.1178 (86.6829) 
Training Epoch: [202/1000] Step: [20 / 285] Batch Time: 0.1464 (0.1958) Data Time: 0.0126 (0.0626) Average Loss: 0.5610 (0.4749) Average CE Loss (Source):  0.5610 ( 0.4749) Learning Rate: 0.0500 (0.0500) Top1_base: 86.7188 (87.2266) Top1_base_per_class: 87.5862 (87.8993) 
Training Epoch: [202/1000] Step: [30 / 285] Batch Time: 0.1454 (0.1857) Data Time: 0.0140 (0.0522) Average Loss: 0.5080 (0.4790) Average CE Loss (Source):  0.5080 ( 0.4790) Learning Rate: 0.0500 (0.0500) Top1_base: 85.1562 (86.8750) Top1_base_per_class: 84.8485 (87.0268) 
Training Epoch: [202/1000] Step: [40 / 285] Batch Time: 0.1475 (0.1812) Data Time: 0.0126 (0.0478) Average Loss: 0.4263 (0.4798) Average CE Loss (Source):  0.4263 ( 0.4798) Learning Rate: 0.0500 (0.0500) Top1_base: 89.8438 (86.6992) Top1_base_per_class: 91.4423 (86.8657) 
Training Epoch: [202/1000] Step: [50 / 285] Batch Time: 0.1493 (0.1767) Data Time: 0.0168 (0.0433) Average Loss: 0.3939 (0.4812) Average CE Loss (Source):  0.3939 ( 0.4812) Learning Rate: 0.0500 (0.0500) Top1_base: 88.2812 (86.5781) Top1_base_per_class: 89.8214 (86.7668) 
Training Epoch: [202/1000] Step: [60 / 285] Batch Time: 0.1427 (0.1738) Data Time: 0.0111 (0.0403) Average Loss: 0.5860 (0.4847) Average CE Loss (Source):  0.5860 ( 0.4847) Learning Rate: 0.0500 (0.0500) Top1_base: 88.2812 (86.5495) Top1_base_per_class: 89.6914 (86.9471) 
Training Epoch: [202/1000] Step: [70 / 285] Batch Time: 0.1488 (0.1713) Data Time: 0.0133 (0.0378) Average Loss: 0.5171 (0.4863) Average CE Loss (Source):  0.5171 ( 0.4863) Learning Rate: 0.0500 (0.0500) Top1_base: 86.7188 (86.6183) Top1_base_per_class: 89.5635 (87.0320) 
Training Epoch: [202/1000] Step: [80 / 285] Batch Time: 0.1412 (0.1690) Data Time: 0.0108 (0.0356) Average Loss: 0.3374 (0.4846) Average CE Loss (Source):  0.3374 ( 0.4846) Learning Rate: 0.0500 (0.0500) Top1_base: 90.6250 (86.6602) Top1_base_per_class: 90.8333 (87.1105) 
Training Epoch: [202/1000] Step: [90 / 285] Batch Time: 0.1471 (0.1666) Data Time: 0.0137 (0.0332) Average Loss: 0.4962 (0.4844) Average CE Loss (Source):  0.4962 ( 0.4844) Learning Rate: 0.0500 (0.0500) Top1_base: 87.5000 (86.7188) Top1_base_per_class: 89.6726 (87.1780) 
Training Epoch: [202/1000] Step: [100 / 285] Batch Time: 0.1421 (0.1658) Data Time: 0.0119 (0.0325) Average Loss: 0.5060 (0.4841) Average CE Loss (Source):  0.5060 ( 0.4841) Learning Rate: 0.0500 (0.0500) Top1_base: 82.0312 (86.7578) Top1_base_per_class: 81.1515 (87.2336) 
Training Epoch: [202/1000] Step: [110 / 285] Batch Time: 0.1499 (0.1652) Data Time: 0.0156 (0.0320) Average Loss: 0.3959 (0.4796) Average CE Loss (Source):  0.3959 ( 0.4796) Learning Rate: 0.0500 (0.0500) Top1_base: 88.2812 (86.7827) Top1_base_per_class: 88.0117 (87.2264) 
Training Epoch: [202/1000] Step: [120 / 285] Batch Time: 0.1481 (0.1640) Data Time: 0.0121 (0.0307) Average Loss: 0.4902 (0.4791) Average CE Loss (Source):  0.4902 ( 0.4791) Learning Rate: 0.0500 (0.0500) Top1_base: 85.1562 (86.7383) Top1_base_per_class: 86.8678 (87.2122) 
Training Epoch: [202/1000] Step: [130 / 285] Batch Time: 0.1421 (0.1631) Data Time: 0.0112 (0.0299) Average Loss: 0.6555 (0.4808) Average CE Loss (Source):  0.6555 ( 0.4808) Learning Rate: 0.0500 (0.0500) Top1_base: 75.7812 (86.7308) Top1_base_per_class: 75.3509 (87.1797) 
Training Epoch: [202/1000] Step: [140 / 285] Batch Time: 0.1453 (0.1622) Data Time: 0.0129 (0.0291) Average Loss: 0.5016 (0.4839) Average CE Loss (Source):  0.5016 ( 0.4839) Learning Rate: 0.0500 (0.0500) Top1_base: 87.5000 (86.6741) Top1_base_per_class: 85.4598 (87.1296) 
Training Epoch: [202/1000] Step: [150 / 285] Batch Time: 0.1456 (0.1617) Data Time: 0.0121 (0.0286) Average Loss: 0.4727 (0.4847) Average CE Loss (Source):  0.4727 ( 0.4847) Learning Rate: 0.0500 (0.0500) Top1_base: 83.5938 (86.6615) Top1_base_per_class: 84.3333 (87.1248) 
Training Epoch: [202/1000] Step: [160 / 285] Batch Time: 0.1408 (0.1618) Data Time: 0.0108 (0.0287) Average Loss: 0.4532 (0.4866) Average CE Loss (Source):  0.4532 ( 0.4866) Learning Rate: 0.0500 (0.0500) Top1_base: 88.2812 (86.6455) Top1_base_per_class: 89.5833 (87.1039) 
Training Epoch: [202/1000] Step: [170 / 285] Batch Time: 0.1471 (0.1616) Data Time: 0.0131 (0.0285) Average Loss: 0.5274 (0.4888) Average CE Loss (Source):  0.5274 ( 0.4888) Learning Rate: 0.0500 (0.0500) Top1_base: 84.3750 (86.5809) Top1_base_per_class: 86.4978 (86.9948) 
Training Epoch: [202/1000] Step: [180 / 285] Batch Time: 0.1466 (0.1613) Data Time: 0.0135 (0.0283) Average Loss: 0.5579 (0.4899) Average CE Loss (Source):  0.5579 ( 0.4899) Learning Rate: 0.0500 (0.0500) Top1_base: 82.8125 (86.4931) Top1_base_per_class: 82.8531 (86.9011) 
Training Epoch: [202/1000] Step: [190 / 285] Batch Time: 0.1476 (0.1611) Data Time: 0.0127 (0.0280) Average Loss: 0.5067 (0.4895) Average CE Loss (Source):  0.5067 ( 0.4895) Learning Rate: 0.0500 (0.0500) Top1_base: 84.3750 (86.4762) Top1_base_per_class: 85.9821 (86.9071) 
Training Epoch: [202/1000] Step: [200 / 285] Batch Time: 0.1456 (0.1608) Data Time: 0.0143 (0.0278) Average Loss: 0.6066 (0.4920) Average CE Loss (Source):  0.6066 ( 0.4920) Learning Rate: 0.0500 (0.0500) Top1_base: 83.5938 (86.4062) Top1_base_per_class: 81.4848 (86.8179) 
Training Epoch: [202/1000] Step: [210 / 285] Batch Time: 0.1519 (0.1602) Data Time: 0.0151 (0.0271) Average Loss: 0.4963 (0.4919) Average CE Loss (Source):  0.4963 ( 0.4919) Learning Rate: 0.0500 (0.0500) Top1_base: 88.2812 (86.4062) Top1_base_per_class: 89.3103 (86.8294) 
Training Epoch: [202/1000] Step: [220 / 285] Batch Time: 0.1443 (0.1596) Data Time: 0.0107 (0.0264) Average Loss: 0.4460 (0.4912) Average CE Loss (Source):  0.4460 ( 0.4912) Learning Rate: 0.0500 (0.0500) Top1_base: 89.8438 (86.4311) Top1_base_per_class: 89.0432 (86.8542) 
Training Epoch: [202/1000] Step: [230 / 285] Batch Time: 0.1427 (0.1590) Data Time: 0.0123 (0.0258) Average Loss: 0.5343 (0.4904) Average CE Loss (Source):  0.5343 ( 0.4904) Learning Rate: 0.0500 (0.0500) Top1_base: 85.1562 (86.4300) Top1_base_per_class: 86.5887 (86.8476) 
Training Epoch: [202/1000] Step: [240 / 285] Batch Time: 0.1449 (0.1586) Data Time: 0.0104 (0.0253) Average Loss: 0.6032 (0.4908) Average CE Loss (Source):  0.6032 ( 0.4908) Learning Rate: 0.0500 (0.0500) Top1_base: 78.1250 (86.4095) Top1_base_per_class: 77.7736 (86.8426) 
Training Epoch: [202/1000] Step: [250 / 285] Batch Time: 0.1457 (0.1581) Data Time: 0.0124 (0.0249) Average Loss: 0.4567 (0.4926) Average CE Loss (Source):  0.4567 ( 0.4926) Learning Rate: 0.0500 (0.0500) Top1_base: 87.5000 (86.3469) Top1_base_per_class: 88.3631 (86.7671) 
Training Epoch: [202/1000] Step: [260 / 285] Batch Time: 0.1436 (0.1577) Data Time: 0.0112 (0.0244) Average Loss: 0.4845 (0.4921) Average CE Loss (Source):  0.4845 ( 0.4921) Learning Rate: 0.0500 (0.0500) Top1_base: 85.1562 (86.3401) Top1_base_per_class: 84.6970 (86.7420) 
Training Epoch: [202/1000] Step: [270 / 285] Batch Time: 0.1437 (0.1575) Data Time: 0.0109 (0.0243) Average Loss: 0.4671 (0.4907) Average CE Loss (Source):  0.4671 ( 0.4907) Learning Rate: 0.0500 (0.0500) Top1_base: 85.9375 (86.3686) Top1_base_per_class: 85.6173 (86.7680) 
Training Epoch: [202/1000] Step: [280 / 285] Batch Time: 0.1442 (0.1571) Data Time: 0.0100 (0.0239) Average Loss: 0.6271 (0.4932) Average CE Loss (Source):  0.6271 ( 0.4932) Learning Rate: 0.0500 (0.0500) Top1_base: 82.8125 (86.2779) Top1_base_per_class: 79.5758 (86.6666) 
Training Epoch: [203/1000] Step: [0] Batch Time: 0.2680 (0.1573) Data Time: 0.1334 (0.0241) Average Loss: 0.5683 (0.4941) Average CE Loss (Source):  0.5683 ( 0.4941) Learning Rate: 0.0500 (0.0500) Top1_base: 85.9375 (86.2610) Top1_base_per_class: 84.5912 (86.6483) 
Training Epoch: [203/1000] Step: [10 / 285] Batch Time: 0.1434 (0.2398) Data Time: 0.0124 (0.1062) Average Loss: 0.5190 (0.4887) Average CE Loss (Source):  0.5190 ( 0.4887) Learning Rate: 0.0500 (0.0500) Top1_base: 89.0625 (87.0312) Top1_base_per_class: 86.0000 (86.7302) 
Training Epoch: [203/1000] Step: [20 / 285] Batch Time: 0.1439 (0.1937) Data Time: 0.0102 (0.0606) Average Loss: 0.4480 (0.4761) Average CE Loss (Source):  0.4480 ( 0.4761) Learning Rate: 0.0500 (0.0500) Top1_base: 87.5000 (87.2656) Top1_base_per_class: 87.8947 (87.4597) 
Training Epoch: [203/1000] Step: [30 / 285] Batch Time: 0.1455 (0.1801) Data Time: 0.0135 (0.0470) Average Loss: 0.3712 (0.4807) Average CE Loss (Source):  0.3712 ( 0.4807) Learning Rate: 0.0500 (0.0500) Top1_base: 89.8438 (86.7708) Top1_base_per_class: 90.9524 (86.8934) 
Training Epoch: [203/1000] Step: [40 / 285] Batch Time: 0.1448 (0.1730) Data Time: 0.0108 (0.0397) Average Loss: 0.4688 (0.4790) Average CE Loss (Source):  0.4688 ( 0.4790) Learning Rate: 0.0500 (0.0500) Top1_base: 86.7188 (86.8750) Top1_base_per_class: 90.6061 (87.1653) 
Training Epoch: [203/1000] Step: [50 / 285] Batch Time: 0.1480 (0.1700) Data Time: 0.0135 (0.0367) Average Loss: 0.5791 (0.4851) Average CE Loss (Source):  0.5791 ( 0.4851) Learning Rate: 0.0500 (0.0500) Top1_base: 82.0312 (86.6719) Top1_base_per_class: 79.6893 (86.8610) 
Training Epoch: [203/1000] Step: [60 / 285] Batch Time: 0.1445 (0.1679) Data Time: 0.0110 (0.0347) Average Loss: 0.4437 (0.4832) Average CE Loss (Source):  0.4437 ( 0.4832) Learning Rate: 0.0500 (0.0500) Top1_base: 88.2812 (86.6927) Top1_base_per_class: 88.8691 (86.7735) 
Training Epoch: [203/1000] Step: [70 / 285] Batch Time: 0.1447 (0.1653) Data Time: 0.0141 (0.0321) Average Loss: 0.4865 (0.4790) Average CE Loss (Source):  0.4865 ( 0.4790) Learning Rate: 0.0500 (0.0500) Top1_base: 82.8125 (86.6853) Top1_base_per_class: 81.9136 (86.8526) 
Training Epoch: [203/1000] Step: [80 / 285] Batch Time: 0.1455 (0.1629) Data Time: 0.0115 (0.0298) Average Loss: 0.4092 (0.4754) Average CE Loss (Source):  0.4092 ( 0.4754) Learning Rate: 0.0500 (0.0500) Top1_base: 89.0625 (86.7480) Top1_base_per_class: 89.5614 (87.0666) 
Training Epoch: [203/1000] Step: [90 / 285] Batch Time: 0.1706 (0.1626) Data Time: 0.0402 (0.0297) Average Loss: 0.5173 (0.4700) Average CE Loss (Source):  0.5173 ( 0.4700) Learning Rate: 0.0500 (0.0500) Top1_base: 85.1562 (86.8663) Top1_base_per_class: 84.6474 (87.1879) 
Training Epoch: [203/1000] Step: [100 / 285] Batch Time: 0.1457 (0.1609) Data Time: 0.0113 (0.0280) Average Loss: 0.4376 (0.4717) Average CE Loss (Source):  0.4376 ( 0.4717) Learning Rate: 0.0500 (0.0500) Top1_base: 86.7188 (86.7578) Top1_base_per_class: 87.5000 (87.1089) 
Training Epoch: [203/1000] Step: [110 / 285] Batch Time: 0.1604 (0.1597) Data Time: 0.0286 (0.0268) Average Loss: 0.5125 (0.4759) Average CE Loss (Source):  0.5125 ( 0.4759) Learning Rate: 0.0500 (0.0500) Top1_base: 83.5938 (86.6690) Top1_base_per_class: 85.8908 (87.1245) 
Training Epoch: [203/1000] Step: [120 / 285] Batch Time: 0.1491 (0.1589) Data Time: 0.0123 (0.0261) Average Loss: 0.5714 (0.4763) Average CE Loss (Source):  0.5714 ( 0.4763) Learning Rate: 0.0500 (0.0500) Top1_base: 81.2500 (86.6406) Top1_base_per_class: 80.8333 (87.1592) 
Training Epoch: [203/1000] Step: [130 / 285] Batch Time: 0.1444 (0.1579) Data Time: 0.0117 (0.0251) Average Loss: 0.5811 (0.4788) Average CE Loss (Source):  0.5811 ( 0.4788) Learning Rate: 0.0500 (0.0500) Top1_base: 85.9375 (86.6106) Top1_base_per_class: 88.8949 (87.1506) 
Training Epoch: [203/1000] Step: [140 / 285] Batch Time: 0.1467 (0.1572) Data Time: 0.0105 (0.0242) Average Loss: 0.4049 (0.4792) Average CE Loss (Source):  0.4049 ( 0.4792) Learning Rate: 0.0500 (0.0500) Top1_base: 88.2812 (86.5848) Top1_base_per_class: 86.6369 (87.1090) 
Training Epoch: [203/1000] Step: [150 / 285] Batch Time: 0.1447 (0.1565) Data Time: 0.0120 (0.0235) Average Loss: 0.6482 (0.4785) Average CE Loss (Source):  0.6482 ( 0.4785) Learning Rate: 0.0500 (0.0500) Top1_base: 82.0312 (86.6615) Top1_base_per_class: 81.8129 (87.1874) 
Training Epoch: [203/1000] Step: [160 / 285] Batch Time: 0.1436 (0.1563) Data Time: 0.0118 (0.0234) Average Loss: 0.4993 (0.4819) Average CE Loss (Source):  0.4993 ( 0.4819) Learning Rate: 0.0500 (0.0500) Top1_base: 84.3750 (86.5625) Top1_base_per_class: 86.1111 (87.0848) 
Training Epoch: [203/1000] Step: [170 / 285] Batch Time: 0.1479 (0.1558) Data Time: 0.0154 (0.0229) Average Loss: 0.4242 (0.4833) Average CE Loss (Source):  0.4242 ( 0.4833) Learning Rate: 0.0500 (0.0500) Top1_base: 87.5000 (86.5211) Top1_base_per_class: 84.7934 (87.0255) 
Training Epoch: [203/1000] Step: [180 / 285] Batch Time: 0.1463 (0.1560) Data Time: 0.0103 (0.0231) Average Loss: 0.3101 (0.4825) Average CE Loss (Source):  0.3101 ( 0.4825) Learning Rate: 0.0500 (0.0500) Top1_base: 94.5312 (86.5625) Top1_base_per_class: 95.4094 (87.0628) 
Training Epoch: [203/1000] Step: [190 / 285] Batch Time: 0.1497 (0.1558) Data Time: 0.0161 (0.0227) Average Loss: 0.4332 (0.4842) Average CE Loss (Source):  0.4332 ( 0.4842) Learning Rate: 0.0500 (0.0500) Top1_base: 90.6250 (86.4885) Top1_base_per_class: 90.9747 (87.0141) 
Training Epoch: [203/1000] Step: [200 / 285] Batch Time: 0.1487 (0.1554) Data Time: 0.0131 (0.0222) Average Loss: 0.6125 (0.4859) Average CE Loss (Source):  0.6125 ( 0.4859) Learning Rate: 0.0500 (0.0500) Top1_base: 82.8125 (86.4531) Top1_base_per_class: 83.4965 (86.9566) 
Training Epoch: [203/1000] Step: [210 / 285] Batch Time: 0.1467 (0.1556) Data Time: 0.0140 (0.0225) Average Loss: 0.5356 (0.4902) Average CE Loss (Source):  0.5356 ( 0.4902) Learning Rate: 0.0500 (0.0500) Top1_base: 86.7188 (86.3281) Top1_base_per_class: 85.2632 (86.7730) 
Training Epoch: [203/1000] Step: [220 / 285] Batch Time: 0.1439 (0.1555) Data Time: 0.0106 (0.0224) Average Loss: 0.3480 (0.4917) Average CE Loss (Source):  0.3480 ( 0.4917) Learning Rate: 0.0500 (0.0500) Top1_base: 89.8438 (86.2926) Top1_base_per_class: 90.3274 (86.7424) 
Training Epoch: [203/1000] Step: [230 / 285] Batch Time: 0.1469 (0.1551) Data Time: 0.0130 (0.0220) Average Loss: 0.4027 (0.4906) Average CE Loss (Source):  0.4027 ( 0.4906) Learning Rate: 0.0500 (0.0500) Top1_base: 89.0625 (86.3383) Top1_base_per_class: 86.9753 (86.7709) 
Training Epoch: [203/1000] Step: [240 / 285] Batch Time: 0.1436 (0.1548) Data Time: 0.0131 (0.0218) Average Loss: 0.7337 (0.4922) Average CE Loss (Source):  0.7337 ( 0.4922) Learning Rate: 0.0500 (0.0500) Top1_base: 79.6875 (86.3184) Top1_base_per_class: 78.7719 (86.7526) 
Training Epoch: [203/1000] Step: [250 / 285] Batch Time: 0.1468 (0.1544) Data Time: 0.0140 (0.0215) Average Loss: 0.4548 (0.4927) Average CE Loss (Source):  0.4548 ( 0.4927) Learning Rate: 0.0500 (0.0500) Top1_base: 89.0625 (86.3125) Top1_base_per_class: 90.6277 (86.7974) 
Training Epoch: [203/1000] Step: [260 / 285] Batch Time: 0.1457 (0.1543) Data Time: 0.0114 (0.0214) Average Loss: 0.5928 (0.4941) Average CE Loss (Source):  0.5928 ( 0.4941) Learning Rate: 0.0500 (0.0500) Top1_base: 85.9375 (86.2590) Top1_base_per_class: 87.8182 (86.7504) 
Training Epoch: [203/1000] Step: [270 / 285] Batch Time: 0.1588 (0.1541) Data Time: 0.0264 (0.0212) Average Loss: 0.5298 (0.4962) Average CE Loss (Source):  0.5298 ( 0.4962) Learning Rate: 0.0500 (0.0500) Top1_base: 85.1562 (86.1632) Top1_base_per_class: 85.6536 (86.6289) 
Training Epoch: [203/1000] Step: [280 / 285] Batch Time: 0.1429 (0.1539) Data Time: 0.0123 (0.0211) Average Loss: 0.4178 (0.4967) Average CE Loss (Source):  0.4178 ( 0.4967) Learning Rate: 0.0500 (0.0500) Top1_base: 89.0625 (86.1523) Top1_base_per_class: 92.0909 (86.5927) 
Training Epoch: [204/1000] Step: [0] Batch Time: 0.1476 (0.1541) Data Time: 0.0126 (0.0213) Average Loss: 0.5050 (0.4971) Average CE Loss (Source):  0.5050 ( 0.4971) Learning Rate: 0.0500 (0.0500) Top1_base: 85.1562 (86.1075) Top1_base_per_class: 81.6667 (86.5461) 
 20%|██        | 204/1000 [2:38:21<10:15:27, 46.39s/it] 20%|██        | 205/1000 [2:39:07<10:10:47, 46.10s/it]Training Epoch: [204/1000] Step: [10 / 285] Batch Time: 0.1441 (0.2335) Data Time: 0.0145 (0.1005) Average Loss: 0.4140 (0.4439) Average CE Loss (Source):  0.4140 ( 0.4439) Learning Rate: 0.0250 (0.0250) Top1_base: 92.1875 (87.8906) Top1_base_per_class: 92.1088 (87.6878) 
Training Epoch: [204/1000] Step: [20 / 285] Batch Time: 0.1510 (0.1938) Data Time: 0.0165 (0.0608) Average Loss: 0.3052 (0.4335) Average CE Loss (Source):  0.3052 ( 0.4335) Learning Rate: 0.0250 (0.0250) Top1_base: 90.6250 (88.2031) Top1_base_per_class: 91.3277 (88.1209) 
Training Epoch: [204/1000] Step: [30 / 285] Batch Time: 0.1473 (0.1829) Data Time: 0.0141 (0.0498) Average Loss: 0.4315 (0.4274) Average CE Loss (Source):  0.4315 ( 0.4274) Learning Rate: 0.0250 (0.0250) Top1_base: 89.0625 (88.5417) Top1_base_per_class: 90.3801 (89.0389) 
Training Epoch: [204/1000] Step: [40 / 285] Batch Time: 0.1457 (0.1799) Data Time: 0.0116 (0.0469) Average Loss: 0.3796 (0.4393) Average CE Loss (Source):  0.3796 ( 0.4393) Learning Rate: 0.0250 (0.0250) Top1_base: 91.4062 (88.1641) Top1_base_per_class: 92.8105 (88.6450) 
Training Epoch: [204/1000] Step: [50 / 285] Batch Time: 0.1760 (0.1742) Data Time: 0.0438 (0.0411) Average Loss: 0.4370 (0.4345) Average CE Loss (Source):  0.4370 ( 0.4345) Learning Rate: 0.0250 (0.0250) Top1_base: 88.2812 (88.3906) Top1_base_per_class: 88.0952 (88.9796) 
Training Epoch: [204/1000] Step: [60 / 285] Batch Time: 0.1443 (0.1713) Data Time: 0.0101 (0.0380) Average Loss: 0.3378 (0.4303) Average CE Loss (Source):  0.3378 ( 0.4303) Learning Rate: 0.0250 (0.0250) Top1_base: 89.8438 (88.4766) Top1_base_per_class: 92.8485 (89.1784) 
Training Epoch: [204/1000] Step: [70 / 285] Batch Time: 0.1540 (0.1696) Data Time: 0.0232 (0.0365) Average Loss: 0.4182 (0.4197) Average CE Loss (Source):  0.4182 ( 0.4197) Learning Rate: 0.0250 (0.0250) Top1_base: 86.7188 (88.7388) Top1_base_per_class: 89.3030 (89.4915) 
Training Epoch: [204/1000] Step: [80 / 285] Batch Time: 0.1425 (0.1676) Data Time: 0.0106 (0.0345) Average Loss: 0.3355 (0.4174) Average CE Loss (Source):  0.3355 ( 0.4174) Learning Rate: 0.0250 (0.0250) Top1_base: 91.4062 (88.8281) Top1_base_per_class: 94.0936 (89.5895) 
Training Epoch: [204/1000] Step: [90 / 285] Batch Time: 0.2092 (0.1663) Data Time: 0.0767 (0.0331) Average Loss: 0.2939 (0.4186) Average CE Loss (Source):  0.2939 ( 0.4186) Learning Rate: 0.0250 (0.0250) Top1_base: 91.4062 (88.6545) Top1_base_per_class: 92.0000 (89.3065) 
Training Epoch: [204/1000] Step: [100 / 285] Batch Time: 0.1468 (0.1657) Data Time: 0.0110 (0.0325) Average Loss: 0.3283 (0.4184) Average CE Loss (Source):  0.3283 ( 0.4184) Learning Rate: 0.0250 (0.0250) Top1_base: 92.1875 (88.7422) Top1_base_per_class: 93.6111 (89.3693) 
Training Epoch: [204/1000] Step: [110 / 285] Batch Time: 0.1634 (0.1653) Data Time: 0.0322 (0.0321) Average Loss: 0.3419 (0.4189) Average CE Loss (Source):  0.3419 ( 0.4189) Learning Rate: 0.0250 (0.0250) Top1_base: 89.0625 (88.7216) Top1_base_per_class: 89.9123 (89.3945) 
Training Epoch: [204/1000] Step: [120 / 285] Batch Time: 0.1471 (0.1642) Data Time: 0.0112 (0.0310) Average Loss: 0.4327 (0.4154) Average CE Loss (Source):  0.4327 ( 0.4154) Learning Rate: 0.0250 (0.0250) Top1_base: 89.0625 (88.7956) Top1_base_per_class: 90.7879 (89.3886) 
Training Epoch: [204/1000] Step: [130 / 285] Batch Time: 0.1477 (0.1633) Data Time: 0.0154 (0.0302) Average Loss: 0.4392 (0.4121) Average CE Loss (Source):  0.4392 ( 0.4121) Learning Rate: 0.0250 (0.0250) Top1_base: 89.8438 (88.8341) Top1_base_per_class: 91.2787 (89.3998) 
Training Epoch: [204/1000] Step: [140 / 285] Batch Time: 0.1468 (0.1622) Data Time: 0.0111 (0.0291) Average Loss: 0.3436 (0.4109) Average CE Loss (Source):  0.3436 ( 0.4109) Learning Rate: 0.0250 (0.0250) Top1_base: 92.1875 (88.8951) Top1_base_per_class: 92.4269 (89.4349) 
Training Epoch: [204/1000] Step: [150 / 285] Batch Time: 0.1794 (0.1619) Data Time: 0.0484 (0.0288) Average Loss: 0.3931 (0.4112) Average CE Loss (Source):  0.3931 ( 0.4112) Learning Rate: 0.0250 (0.0250) Top1_base: 90.6250 (88.8854) Top1_base_per_class: 92.4545 (89.4205) 
Training Epoch: [204/1000] Step: [160 / 285] Batch Time: 0.1448 (0.1621) Data Time: 0.0108 (0.0290) Average Loss: 0.3190 (0.4112) Average CE Loss (Source):  0.3190 ( 0.4112) Learning Rate: 0.0250 (0.0250) Top1_base: 91.4062 (88.8770) Top1_base_per_class: 92.3522 (89.3657) 
Training Epoch: [204/1000] Step: [170 / 285] Batch Time: 0.1468 (0.1611) Data Time: 0.0152 (0.0281) Average Loss: 0.4278 (0.4092) Average CE Loss (Source):  0.4278 ( 0.4092) Learning Rate: 0.0250 (0.0250) Top1_base: 86.7188 (88.9430) Top1_base_per_class: 87.5893 (89.4187) 
Training Epoch: [204/1000] Step: [180 / 285] Batch Time: 0.1442 (0.1606) Data Time: 0.0103 (0.0276) Average Loss: 0.3012 (0.4083) Average CE Loss (Source):  0.3012 ( 0.4083) Learning Rate: 0.0250 (0.0250) Top1_base: 91.4062 (88.9583) Top1_base_per_class: 92.5309 (89.4395) 
Training Epoch: [204/1000] Step: [190 / 285] Batch Time: 0.2057 (0.1611) Data Time: 0.0712 (0.0281) Average Loss: 0.4561 (0.4077) Average CE Loss (Source):  0.4561 ( 0.4077) Learning Rate: 0.0250 (0.0250) Top1_base: 88.2812 (88.9762) Top1_base_per_class: 87.7976 (89.4607) 
Training Epoch: [204/1000] Step: [200 / 285] Batch Time: 0.1455 (0.1604) Data Time: 0.0100 (0.0274) Average Loss: 0.2468 (0.4071) Average CE Loss (Source):  0.2468 ( 0.4071) Learning Rate: 0.0250 (0.0250) Top1_base: 94.5312 (88.9844) Top1_base_per_class: 95.1543 (89.4620) 
Training Epoch: [204/1000] Step: [210 / 285] Batch Time: 0.1493 (0.1605) Data Time: 0.0192 (0.0275) Average Loss: 0.5167 (0.4083) Average CE Loss (Source):  0.5167 ( 0.4083) Learning Rate: 0.0250 (0.0250) Top1_base: 85.1562 (88.9360) Top1_base_per_class: 85.0000 (89.4062) 
Training Epoch: [204/1000] Step: [220 / 285] Batch Time: 0.1428 (0.1601) Data Time: 0.0105 (0.0272) Average Loss: 0.2443 (0.4057) Average CE Loss (Source):  0.2443 ( 0.4057) Learning Rate: 0.0250 (0.0250) Top1_base: 93.7500 (89.0376) Top1_base_per_class: 96.0119 (89.4971) 
Training Epoch: [204/1000] Step: [230 / 285] Batch Time: 0.1785 (0.1599) Data Time: 0.0475 (0.0270) Average Loss: 0.4001 (0.4063) Average CE Loss (Source):  0.4001 ( 0.4063) Learning Rate: 0.0250 (0.0250) Top1_base: 89.0625 (89.0557) Top1_base_per_class: 89.3711 (89.5125) 
Training Epoch: [204/1000] Step: [240 / 285] Batch Time: 0.1437 (0.1598) Data Time: 0.0108 (0.0269) Average Loss: 0.4060 (0.4046) Average CE Loss (Source):  0.4060 ( 0.4046) Learning Rate: 0.0250 (0.0250) Top1_base: 91.4062 (89.1113) Top1_base_per_class: 92.8395 (89.5423) 
Training Epoch: [204/1000] Step: [250 / 285] Batch Time: 0.1734 (0.1599) Data Time: 0.0392 (0.0269) Average Loss: 0.4506 (0.4048) Average CE Loss (Source):  0.4506 ( 0.4048) Learning Rate: 0.0250 (0.0250) Top1_base: 90.6250 (89.0781) Top1_base_per_class: 89.8055 (89.5343) 
Training Epoch: [204/1000] Step: [260 / 285] Batch Time: 0.1455 (0.1597) Data Time: 0.0108 (0.0268) Average Loss: 0.4018 (0.4049) Average CE Loss (Source):  0.4018 ( 0.4049) Learning Rate: 0.0250 (0.0250) Top1_base: 87.5000 (89.0625) Top1_base_per_class: 87.1384 (89.4770) 
Training Epoch: [204/1000] Step: [270 / 285] Batch Time: 0.1824 (0.1596) Data Time: 0.0514 (0.0267) Average Loss: 0.4415 (0.4061) Average CE Loss (Source):  0.4415 ( 0.4061) Learning Rate: 0.0250 (0.0250) Top1_base: 87.5000 (89.0451) Top1_base_per_class: 88.0117 (89.4552) 
Training Epoch: [204/1000] Step: [280 / 285] Batch Time: 0.1452 (0.1592) Data Time: 0.0105 (0.0263) Average Loss: 0.3036 (0.4049) Average CE Loss (Source):  0.3036 ( 0.4049) Learning Rate: 0.0250 (0.0250) Top1_base: 90.6250 (89.0681) Top1_base_per_class: 91.1607 (89.4612) 
Training Epoch: [205/1000] Step: [0] Batch Time: 0.1426 (0.1591) Data Time: 0.0100 (0.0262) Average Loss: 0.3988 (0.4054) Average CE Loss (Source):  0.3988 ( 0.4054) Learning Rate: 0.0250 (0.0250) Top1_base: 89.0625 (89.0323) Top1_base_per_class: 91.0377 (89.4122) 
Training Epoch: [205/1000] Step: [10 / 285] Batch Time: 0.1460 (0.2243) Data Time: 0.0121 (0.0919) Average Loss: 0.4454 (0.3869) Average CE Loss (Source):  0.4454 ( 0.3869) Learning Rate: 0.0250 (0.0250) Top1_base: 88.2812 (90.0000) Top1_base_per_class: 89.1204 (90.5107) 
Training Epoch: [205/1000] Step: [20 / 285] Batch Time: 0.1445 (0.1884) Data Time: 0.0103 (0.0556) Average Loss: 0.5292 (0.3858) Average CE Loss (Source):  0.5292 ( 0.3858) Learning Rate: 0.0250 (0.0250) Top1_base: 83.5938 (89.4141) Top1_base_per_class: 87.1637 (89.8364) 
Training Epoch: [205/1000] Step: [30 / 285] Batch Time: 0.1463 (0.1766) Data Time: 0.0146 (0.0439) Average Loss: 0.4015 (0.3994) Average CE Loss (Source):  0.4015 ( 0.3994) Learning Rate: 0.0250 (0.0250) Top1_base: 88.2812 (89.0104) Top1_base_per_class: 88.3636 (89.5086) 
Training Epoch: [205/1000] Step: [40 / 285] Batch Time: 0.1449 (0.1689) Data Time: 0.0103 (0.0362) Average Loss: 0.2859 (0.3951) Average CE Loss (Source):  0.2859 ( 0.3951) Learning Rate: 0.0250 (0.0250) Top1_base: 93.7500 (89.3359) Top1_base_per_class: 93.7738 (89.7460) 
Training Epoch: [205/1000] Step: [50 / 285] Batch Time: 0.1500 (0.1658) Data Time: 0.0143 (0.0330) Average Loss: 0.3653 (0.3955) Average CE Loss (Source):  0.3653 ( 0.3955) Learning Rate: 0.0250 (0.0250) Top1_base: 90.6250 (89.5000) Top1_base_per_class: 92.0536 (89.9094) 
Training Epoch: [205/1000] Step: [60 / 285] Batch Time: 0.1448 (0.1643) Data Time: 0.0110 (0.0315) Average Loss: 0.4348 (0.3987) Average CE Loss (Source):  0.4348 ( 0.3987) Learning Rate: 0.0250 (0.0250) Top1_base: 86.7188 (89.5703) Top1_base_per_class: 86.9940 (89.9336) 
Training Epoch: [205/1000] Step: [70 / 285] Batch Time: 0.1462 (0.1620) Data Time: 0.0145 (0.0292) Average Loss: 0.4646 (0.3942) Average CE Loss (Source):  0.4646 ( 0.3942) Learning Rate: 0.0250 (0.0250) Top1_base: 88.2812 (89.6429) Top1_base_per_class: 89.0774 (90.0249) 
Training Epoch: [205/1000] Step: [80 / 285] Batch Time: 0.1439 (0.1607) Data Time: 0.0110 (0.0279) Average Loss: 0.2945 (0.3889) Average CE Loss (Source):  0.2945 ( 0.3889) Learning Rate: 0.0250 (0.0250) Top1_base: 90.6250 (89.7461) Top1_base_per_class: 88.8365 (90.2494) 
Training Epoch: [205/1000] Step: [90 / 285] Batch Time: 0.1477 (0.1614) Data Time: 0.0155 (0.0286) Average Loss: 0.2633 (0.3843) Average CE Loss (Source):  0.2633 ( 0.3843) Learning Rate: 0.0250 (0.0250) Top1_base: 91.4062 (89.8524) Top1_base_per_class: 93.4615 (90.4370) 
Training Epoch: [205/1000] Step: [100 / 285] Batch Time: 0.1445 (0.1619) Data Time: 0.0112 (0.0291) Average Loss: 0.2539 (0.3779) Average CE Loss (Source):  0.2539 ( 0.3779) Learning Rate: 0.0250 (0.0250) Top1_base: 93.7500 (89.9453) Top1_base_per_class: 95.4630 (90.5479) 
Training Epoch: [205/1000] Step: [110 / 285] Batch Time: 0.1461 (0.1608) Data Time: 0.0146 (0.0279) Average Loss: 0.3655 (0.3764) Average CE Loss (Source):  0.3655 ( 0.3764) Learning Rate: 0.0250 (0.0250) Top1_base: 89.0625 (89.9858) Top1_base_per_class: 90.2201 (90.5281) 
Training Epoch: [205/1000] Step: [120 / 285] Batch Time: 0.1455 (0.1601) Data Time: 0.0113 (0.0272) Average Loss: 0.3422 (0.3768) Average CE Loss (Source):  0.3422 ( 0.3768) Learning Rate: 0.0250 (0.0250) Top1_base: 89.0625 (89.9609) Top1_base_per_class: 89.1520 (90.4737) 
Training Epoch: [205/1000] Step: [130 / 285] Batch Time: 0.1453 (0.1599) Data Time: 0.0107 (0.0270) Average Loss: 0.4352 (0.3756) Average CE Loss (Source):  0.4352 ( 0.3756) Learning Rate: 0.0250 (0.0250) Top1_base: 89.0625 (89.9339) Top1_base_per_class: 87.7359 (90.4260) 
Training Epoch: [205/1000] Step: [140 / 285] Batch Time: 0.1443 (0.1591) Data Time: 0.0133 (0.0262) Average Loss: 0.3635 (0.3763) Average CE Loss (Source):  0.3635 ( 0.3763) Learning Rate: 0.0250 (0.0250) Top1_base: 87.5000 (89.9330) Top1_base_per_class: 89.3678 (90.4196) 
Training Epoch: [205/1000] Step: [150 / 285] Batch Time: 0.1515 (0.1584) Data Time: 0.0144 (0.0255) Average Loss: 0.3145 (0.3729) Average CE Loss (Source):  0.3145 ( 0.3729) Learning Rate: 0.0250 (0.0250) Top1_base: 93.7500 (90.0208) Top1_base_per_class: 93.4848 (90.4289) 
Training Epoch: [205/1000] Step: [160 / 285] Batch Time: 0.1472 (0.1578) Data Time: 0.0117 (0.0248) Average Loss: 0.6457 (0.3740) Average CE Loss (Source):  0.6457 ( 0.3740) Learning Rate: 0.0250 (0.0250) Top1_base: 82.8125 (89.9707) Top1_base_per_class: 85.1258 (90.3878) 
Training Epoch: [205/1000] Step: [170 / 285] Batch Time: 0.1466 (0.1572) Data Time: 0.0127 (0.0241) Average Loss: 0.2840 (0.3746) Average CE Loss (Source):  0.2840 ( 0.3746) Learning Rate: 0.0250 (0.0250) Top1_base: 93.7500 (89.9678) Top1_base_per_class: 93.6012 (90.3738) 
Training Epoch: [205/1000] Step: [180 / 285] Batch Time: 0.1447 (0.1567) Data Time: 0.0128 (0.0235) Average Loss: 0.3357 (0.3780) Average CE Loss (Source):  0.3357 ( 0.3780) Learning Rate: 0.0250 (0.0250) Top1_base: 92.9688 (89.9479) Top1_base_per_class: 94.1599 (90.3348) 
Training Epoch: [205/1000] Step: [190 / 285] Batch Time: 0.1453 (0.1565) Data Time: 0.0114 (0.0233) Average Loss: 0.3881 (0.3771) Average CE Loss (Source):  0.3881 ( 0.3771) Learning Rate: 0.0250 (0.0250) Top1_base: 90.6250 (89.9630) Top1_base_per_class: 91.1818 (90.3260) 
Training Epoch: [205/1000] Step: [200 / 285] Batch Time: 0.1448 (0.1559) Data Time: 0.0114 (0.0228) Average Loss: 0.4626 (0.3789) Average CE Loss (Source):  0.4626 ( 0.3789) Learning Rate: 0.0250 (0.0250) Top1_base: 85.9375 (89.9219) Top1_base_per_class: 86.8868 (90.2988) 
Training Epoch: [205/1000] Step: [210 / 285] Batch Time: 0.1474 (0.1555) Data Time: 0.0156 (0.0223) Average Loss: 0.4585 (0.3792) Average CE Loss (Source):  0.4585 ( 0.3792) Learning Rate: 0.0250 (0.0250) Top1_base: 85.1562 (89.8996) Top1_base_per_class: 85.4678 (90.2652) 
Training Epoch: [205/1000] Step: [220 / 285] Batch Time: 0.1439 (0.1551) Data Time: 0.0127 (0.0219) Average Loss: 0.2692 (0.3782) Average CE Loss (Source):  0.2692 ( 0.3782) Learning Rate: 0.0250 (0.0250) Top1_base: 92.9688 (89.9219) Top1_base_per_class: 94.2857 (90.2821) 
Training Epoch: [205/1000] Step: [230 / 285] Batch Time: 0.1484 (0.1548) Data Time: 0.0140 (0.0216) Average Loss: 0.3390 (0.3776) Average CE Loss (Source):  0.3390 ( 0.3776) Learning Rate: 0.0250 (0.0250) Top1_base: 93.7500 (89.9117) Top1_base_per_class: 92.7706 (90.2388) 
Training Epoch: [205/1000] Step: [240 / 285] Batch Time: 0.1457 (0.1545) Data Time: 0.0107 (0.0212) Average Loss: 0.2212 (0.3747) Average CE Loss (Source):  0.2212 ( 0.3747) Learning Rate: 0.0250 (0.0250) Top1_base: 94.5312 (89.9512) Top1_base_per_class: 93.8462 (90.2921) 
Training Epoch: [205/1000] Step: [250 / 285] Batch Time: 0.1480 (0.1543) Data Time: 0.0133 (0.0209) Average Loss: 0.4412 (0.3740) Average CE Loss (Source):  0.4412 ( 0.3740) Learning Rate: 0.0250 (0.0250) Top1_base: 89.8438 (89.9844) Top1_base_per_class: 88.3929 (90.3045) 
Training Epoch: [205/1000] Step: [260 / 285] Batch Time: 0.1442 (0.1540) Data Time: 0.0109 (0.0206) Average Loss: 0.4313 (0.3724) Average CE Loss (Source):  0.4313 ( 0.3724) Learning Rate: 0.0250 (0.0250) Top1_base: 86.7188 (90.0210) Top1_base_per_class: 89.0643 (90.3471) 
Training Epoch: [205/1000] Step: [270 / 285] Batch Time: 0.1488 (0.1538) Data Time: 0.0137 (0.0204) Average Loss: 0.2910 (0.3713) Average CE Loss (Source):  0.2910 ( 0.3713) Learning Rate: 0.0250 (0.0250) Top1_base: 92.1875 (90.0550) Top1_base_per_class: 94.4445 (90.4159) 
Training Epoch: [205/1000] Step: [280 / 285] Batch Time: 0.1467 (0.1536) Data Time: 0.0102 (0.0201) Average Loss: 0.4112 (0.3705) Average CE Loss (Source):  0.4112 ( 0.3705) Learning Rate: 0.0250 (0.0250) Top1_base: 88.2812 (90.0725) Top1_base_per_class: 90.9654 (90.4347) 
Training Epoch: [206/1000] Step: [0] Batch Time: 0.1481 (0.1535) Data Time: 0.0124 (0.0200) Average Loss: 0.4446 (0.3708) Average CE Loss (Source):  0.4446 ( 0.3708) Learning Rate: 0.0250 (0.0250) Top1_base: 85.9375 (90.0630) Top1_base_per_class: 86.9136 (90.4239) 
 21%|██        | 206/1000 [2:39:53<10:12:09, 46.26s/it] 21%|██        | 207/1000 [2:40:38<10:07:11, 45.94s/it]Training Epoch: [206/1000] Step: [10 / 285] Batch Time: 0.1472 (0.2310) Data Time: 0.0125 (0.0974) Average Loss: 0.2671 (0.3348) Average CE Loss (Source):  0.2671 ( 0.3348) Learning Rate: 0.0250 (0.0250) Top1_base: 92.9688 (92.1875) Top1_base_per_class: 90.8772 (91.1883) 
Training Epoch: [206/1000] Step: [20 / 285] Batch Time: 0.1458 (0.1932) Data Time: 0.0129 (0.0598) Average Loss: 0.3482 (0.3654) Average CE Loss (Source):  0.3482 ( 0.3654) Learning Rate: 0.0250 (0.0250) Top1_base: 88.2812 (90.6250) Top1_base_per_class: 89.0606 (89.8567) 
Training Epoch: [206/1000] Step: [30 / 285] Batch Time: 0.1485 (0.1791) Data Time: 0.0146 (0.0457) Average Loss: 0.5789 (0.3716) Average CE Loss (Source):  0.5789 ( 0.3716) Learning Rate: 0.0250 (0.0250) Top1_base: 83.5938 (90.3906) Top1_base_per_class: 78.2738 (89.8892) 
Training Epoch: [206/1000] Step: [40 / 285] Batch Time: 0.1442 (0.1757) Data Time: 0.0124 (0.0426) Average Loss: 0.4110 (0.3817) Average CE Loss (Source):  0.4110 ( 0.3817) Learning Rate: 0.0250 (0.0250) Top1_base: 87.5000 (90.0195) Top1_base_per_class: 89.9708 (89.7496) 
Training Epoch: [206/1000] Step: [50 / 285] Batch Time: 0.1509 (0.1724) Data Time: 0.0163 (0.0391) Average Loss: 0.4437 (0.3782) Average CE Loss (Source):  0.4437 ( 0.3782) Learning Rate: 0.0250 (0.0250) Top1_base: 89.8438 (90.1094) Top1_base_per_class: 87.9310 (89.8175) 
Training Epoch: [206/1000] Step: [60 / 285] Batch Time: 0.1451 (0.1690) Data Time: 0.0131 (0.0356) Average Loss: 0.3315 (0.3799) Average CE Loss (Source):  0.3315 ( 0.3799) Learning Rate: 0.0250 (0.0250) Top1_base: 87.5000 (90.0260) Top1_base_per_class: 88.8634 (89.9491) 
Training Epoch: [206/1000] Step: [70 / 285] Batch Time: 0.1490 (0.1664) Data Time: 0.0155 (0.0329) Average Loss: 0.3219 (0.3733) Average CE Loss (Source):  0.3219 ( 0.3733) Learning Rate: 0.0250 (0.0250) Top1_base: 90.6250 (90.2344) Top1_base_per_class: 90.3390 (90.2274) 
Training Epoch: [206/1000] Step: [80 / 285] Batch Time: 0.1464 (0.1641) Data Time: 0.0151 (0.0308) Average Loss: 0.2977 (0.3748) Average CE Loss (Source):  0.2977 ( 0.3748) Learning Rate: 0.0250 (0.0250) Top1_base: 92.1875 (90.2344) Top1_base_per_class: 90.5031 (90.3181) 
Training Epoch: [206/1000] Step: [90 / 285] Batch Time: 0.1502 (0.1628) Data Time: 0.0161 (0.0294) Average Loss: 0.6611 (0.3777) Average CE Loss (Source):  0.6611 ( 0.3777) Learning Rate: 0.0250 (0.0250) Top1_base: 87.5000 (90.1736) Top1_base_per_class: 88.5555 (90.3142) 
Training Epoch: [206/1000] Step: [100 / 285] Batch Time: 0.1443 (0.1621) Data Time: 0.0128 (0.0288) Average Loss: 0.3858 (0.3749) Average CE Loss (Source):  0.3858 ( 0.3749) Learning Rate: 0.0250 (0.0250) Top1_base: 88.2812 (90.1953) Top1_base_per_class: 89.2727 (90.3667) 
Training Epoch: [206/1000] Step: [110 / 285] Batch Time: 0.1468 (0.1608) Data Time: 0.0122 (0.0276) Average Loss: 0.2532 (0.3754) Average CE Loss (Source):  0.2532 ( 0.3754) Learning Rate: 0.0250 (0.0250) Top1_base: 92.9688 (90.1207) Top1_base_per_class: 95.7094 (90.2614) 
Training Epoch: [206/1000] Step: [120 / 285] Batch Time: 0.1886 (0.1606) Data Time: 0.0572 (0.0274) Average Loss: 0.3976 (0.3755) Average CE Loss (Source):  0.3976 ( 0.3755) Learning Rate: 0.0250 (0.0250) Top1_base: 90.6250 (90.1107) Top1_base_per_class: 91.1064 (90.2728) 
Training Epoch: [206/1000] Step: [130 / 285] Batch Time: 0.1454 (0.1601) Data Time: 0.0143 (0.0270) Average Loss: 0.4354 (0.3777) Average CE Loss (Source):  0.4354 ( 0.3777) Learning Rate: 0.0250 (0.0250) Top1_base: 85.9375 (90.0240) Top1_base_per_class: 83.9943 (90.1545) 
Training Epoch: [206/1000] Step: [140 / 285] Batch Time: 0.1837 (0.1597) Data Time: 0.0519 (0.0266) Average Loss: 0.5675 (0.3756) Average CE Loss (Source):  0.5675 ( 0.3756) Learning Rate: 0.0250 (0.0250) Top1_base: 88.2812 (90.1228) Top1_base_per_class: 87.9950 (90.2524) 
Training Epoch: [206/1000] Step: [150 / 285] Batch Time: 0.1465 (0.1590) Data Time: 0.0119 (0.0259) Average Loss: 0.4295 (0.3725) Average CE Loss (Source):  0.4295 ( 0.3725) Learning Rate: 0.0250 (0.0250) Top1_base: 86.7188 (90.1927) Top1_base_per_class: 85.2288 (90.3545) 
Training Epoch: [206/1000] Step: [160 / 285] Batch Time: 0.2630 (0.1593) Data Time: 0.1313 (0.0263) Average Loss: 0.4743 (0.3745) Average CE Loss (Source):  0.4743 ( 0.3745) Learning Rate: 0.0250 (0.0250) Top1_base: 88.2812 (90.1660) Top1_base_per_class: 89.6078 (90.3861) 
Training Epoch: [206/1000] Step: [170 / 285] Batch Time: 0.1477 (0.1594) Data Time: 0.0139 (0.0264) Average Loss: 0.3711 (0.3736) Average CE Loss (Source):  0.3711 ( 0.3736) Learning Rate: 0.0250 (0.0250) Top1_base: 89.8438 (90.2068) Top1_base_per_class: 91.3030 (90.4587) 
Training Epoch: [206/1000] Step: [180 / 285] Batch Time: 0.1820 (0.1593) Data Time: 0.0492 (0.0263) Average Loss: 0.2690 (0.3748) Average CE Loss (Source):  0.2690 ( 0.3748) Learning Rate: 0.0250 (0.0250) Top1_base: 92.9688 (90.1736) Top1_base_per_class: 91.2121 (90.4181) 
Training Epoch: [206/1000] Step: [190 / 285] Batch Time: 0.1471 (0.1590) Data Time: 0.0136 (0.0260) Average Loss: 0.4909 (0.3778) Average CE Loss (Source):  0.4909 ( 0.3778) Learning Rate: 0.0250 (0.0250) Top1_base: 88.2812 (90.1398) Top1_base_per_class: 88.6550 (90.3974) 
Training Epoch: [206/1000] Step: [200 / 285] Batch Time: 0.1625 (0.1588) Data Time: 0.0301 (0.0258) Average Loss: 0.2797 (0.3750) Average CE Loss (Source):  0.2797 ( 0.3750) Learning Rate: 0.0250 (0.0250) Top1_base: 95.3125 (90.2422) Top1_base_per_class: 96.2798 (90.4926) 
Training Epoch: [206/1000] Step: [210 / 285] Batch Time: 0.1467 (0.1586) Data Time: 0.0120 (0.0255) Average Loss: 0.2431 (0.3741) Average CE Loss (Source):  0.2431 ( 0.3741) Learning Rate: 0.0250 (0.0250) Top1_base: 93.7500 (90.2269) Top1_base_per_class: 93.8012 (90.4214) 
Training Epoch: [206/1000] Step: [220 / 285] Batch Time: 0.1757 (0.1583) Data Time: 0.0440 (0.0253) Average Loss: 0.4500 (0.3738) Average CE Loss (Source):  0.4500 ( 0.3738) Learning Rate: 0.0250 (0.0250) Top1_base: 88.2812 (90.2060) Top1_base_per_class: 89.3391 (90.4123) 
Training Epoch: [206/1000] Step: [230 / 285] Batch Time: 0.1491 (0.1579) Data Time: 0.0135 (0.0250) Average Loss: 0.2803 (0.3731) Average CE Loss (Source):  0.2803 ( 0.3731) Learning Rate: 0.0250 (0.0250) Top1_base: 91.4062 (90.2208) Top1_base_per_class: 93.0996 (90.4518) 
Training Epoch: [206/1000] Step: [240 / 285] Batch Time: 0.1643 (0.1578) Data Time: 0.0314 (0.0249) Average Loss: 0.3262 (0.3727) Average CE Loss (Source):  0.3262 ( 0.3727) Learning Rate: 0.0250 (0.0250) Top1_base: 92.9688 (90.2572) Top1_base_per_class: 93.5119 (90.5194) 
Training Epoch: [206/1000] Step: [250 / 285] Batch Time: 0.1451 (0.1577) Data Time: 0.0124 (0.0247) Average Loss: 0.5233 (0.3737) Average CE Loss (Source):  0.5233 ( 0.3737) Learning Rate: 0.0250 (0.0250) Top1_base: 87.5000 (90.2250) Top1_base_per_class: 86.3450 (90.5182) 
Training Epoch: [206/1000] Step: [260 / 285] Batch Time: 0.1668 (0.1578) Data Time: 0.0361 (0.0248) Average Loss: 0.4670 (0.3731) Average CE Loss (Source):  0.4670 ( 0.3731) Learning Rate: 0.0250 (0.0250) Top1_base: 85.9375 (90.2194) Top1_base_per_class: 86.0909 (90.5359) 
Training Epoch: [206/1000] Step: [270 / 285] Batch Time: 0.1482 (0.1580) Data Time: 0.0135 (0.0250) Average Loss: 0.3846 (0.3725) Average CE Loss (Source):  0.3846 ( 0.3725) Learning Rate: 0.0250 (0.0250) Top1_base: 88.2812 (90.2199) Top1_base_per_class: 85.2542 (90.5222) 
Training Epoch: [206/1000] Step: [280 / 285] Batch Time: 0.2131 (0.1582) Data Time: 0.0829 (0.0253) Average Loss: 0.3617 (0.3713) Average CE Loss (Source):  0.3617 ( 0.3713) Learning Rate: 0.0250 (0.0250) Top1_base: 90.6250 (90.2455) Top1_base_per_class: 90.4386 (90.5779) 
Training Epoch: [207/1000] Step: [0] Batch Time: 0.1419 (0.1583) Data Time: 0.0116 (0.0254) Average Loss: 0.4511 (0.3724) Average CE Loss (Source):  0.4511 ( 0.3724) Learning Rate: 0.0250 (0.0250) Top1_base: 89.0625 (90.2083) Top1_base_per_class: 91.8889 (90.5495) 
Training Epoch: [207/1000] Step: [10 / 285] Batch Time: 0.1601 (0.2314) Data Time: 0.0236 (0.0963) Average Loss: 0.3161 (0.3784) Average CE Loss (Source):  0.3161 ( 0.3784) Learning Rate: 0.0250 (0.0250) Top1_base: 91.4062 (89.6094) Top1_base_per_class: 92.9096 (89.6416) 
Training Epoch: [207/1000] Step: [20 / 285] Batch Time: 0.1475 (0.1991) Data Time: 0.0132 (0.0649) Average Loss: 0.3542 (0.3664) Average CE Loss (Source):  0.3542 ( 0.3664) Learning Rate: 0.0250 (0.0250) Top1_base: 89.0625 (89.9609) Top1_base_per_class: 88.5494 (90.0248) 
Training Epoch: [207/1000] Step: [30 / 285] Batch Time: 0.2864 (0.1889) Data Time: 0.1566 (0.0555) Average Loss: 0.3622 (0.3592) Average CE Loss (Source):  0.3622 ( 0.3592) Learning Rate: 0.0250 (0.0250) Top1_base: 89.8438 (90.2083) Top1_base_per_class: 89.2857 (90.3841) 
Training Epoch: [207/1000] Step: [40 / 285] Batch Time: 0.1476 (0.1823) Data Time: 0.0120 (0.0491) Average Loss: 0.3519 (0.3466) Average CE Loss (Source):  0.3519 ( 0.3466) Learning Rate: 0.0250 (0.0250) Top1_base: 89.8438 (90.6836) Top1_base_per_class: 90.8333 (90.9182) 
Training Epoch: [207/1000] Step: [50 / 285] Batch Time: 0.1987 (0.1779) Data Time: 0.0671 (0.0448) Average Loss: 0.3431 (0.3530) Average CE Loss (Source):  0.3431 ( 0.3530) Learning Rate: 0.0250 (0.0250) Top1_base: 89.0625 (90.3438) Top1_base_per_class: 89.9123 (90.6427) 
Training Epoch: [207/1000] Step: [60 / 285] Batch Time: 0.1432 (0.1746) Data Time: 0.0115 (0.0415) Average Loss: 0.4556 (0.3514) Average CE Loss (Source):  0.4556 ( 0.3514) Learning Rate: 0.0250 (0.0250) Top1_base: 84.3750 (90.4036) Top1_base_per_class: 83.4295 (90.7100) 
Training Epoch: [207/1000] Step: [70 / 285] Batch Time: 0.1904 (0.1719) Data Time: 0.0570 (0.0390) Average Loss: 0.2839 (0.3558) Average CE Loss (Source):  0.2839 ( 0.3558) Learning Rate: 0.0250 (0.0250) Top1_base: 93.7500 (90.3348) Top1_base_per_class: 93.7500 (90.6423) 
Training Epoch: [207/1000] Step: [80 / 285] Batch Time: 0.1427 (0.1691) Data Time: 0.0106 (0.0362) Average Loss: 0.2601 (0.3487) Average CE Loss (Source):  0.2601 ( 0.3487) Learning Rate: 0.0250 (0.0250) Top1_base: 94.5312 (90.5664) Top1_base_per_class: 94.5758 (90.7973) 
Training Epoch: [207/1000] Step: [90 / 285] Batch Time: 0.2607 (0.1686) Data Time: 0.1283 (0.0357) Average Loss: 0.3292 (0.3492) Average CE Loss (Source):  0.3292 ( 0.3492) Learning Rate: 0.0250 (0.0250) Top1_base: 91.4062 (90.5035) Top1_base_per_class: 89.7361 (90.6723) 
Training Epoch: [207/1000] Step: [100 / 285] Batch Time: 0.1422 (0.1668) Data Time: 0.0106 (0.0341) Average Loss: 0.5226 (0.3513) Average CE Loss (Source):  0.5226 ( 0.3513) Learning Rate: 0.0250 (0.0250) Top1_base: 87.5000 (90.4609) Top1_base_per_class: 86.0544 (90.6052) 
Training Epoch: [207/1000] Step: [110 / 285] Batch Time: 0.1931 (0.1663) Data Time: 0.0625 (0.0336) Average Loss: 0.3522 (0.3546) Average CE Loss (Source):  0.3522 ( 0.3546) Learning Rate: 0.0250 (0.0250) Top1_base: 89.8438 (90.4332) Top1_base_per_class: 92.6667 (90.5992) 
Training Epoch: [207/1000] Step: [120 / 285] Batch Time: 0.1451 (0.1656) Data Time: 0.0116 (0.0329) Average Loss: 0.2206 (0.3532) Average CE Loss (Source):  0.2206 ( 0.3532) Learning Rate: 0.0250 (0.0250) Top1_base: 96.0938 (90.4232) Top1_base_per_class: 95.2679 (90.5999) 
Training Epoch: [207/1000] Step: [130 / 285] Batch Time: 0.1850 (0.1653) Data Time: 0.0536 (0.0326) Average Loss: 0.2349 (0.3546) Average CE Loss (Source):  0.2349 ( 0.3546) Learning Rate: 0.0250 (0.0250) Top1_base: 93.7500 (90.3245) Top1_base_per_class: 94.1521 (90.4937) 
Training Epoch: [207/1000] Step: [140 / 285] Batch Time: 0.1446 (0.1647) Data Time: 0.0118 (0.0321) Average Loss: 0.3790 (0.3548) Average CE Loss (Source):  0.3790 ( 0.3548) Learning Rate: 0.0250 (0.0250) Top1_base: 89.0625 (90.3404) Top1_base_per_class: 89.3910 (90.5437) 
Training Epoch: [207/1000] Step: [150 / 285] Batch Time: 0.1705 (0.1638) Data Time: 0.0402 (0.0313) Average Loss: 0.3255 (0.3530) Average CE Loss (Source):  0.3255 ( 0.3530) Learning Rate: 0.0250 (0.0250) Top1_base: 90.6250 (90.3958) Top1_base_per_class: 89.8742 (90.5867) 
Training Epoch: [207/1000] Step: [160 / 285] Batch Time: 0.1470 (0.1633) Data Time: 0.0135 (0.0307) Average Loss: 0.3552 (0.3524) Average CE Loss (Source):  0.3552 ( 0.3524) Learning Rate: 0.0250 (0.0250) Top1_base: 91.4062 (90.4297) Top1_base_per_class: 93.2582 (90.6469) 
Training Epoch: [207/1000] Step: [170 / 285] Batch Time: 0.1494 (0.1630) Data Time: 0.0164 (0.0304) Average Loss: 0.3981 (0.3527) Average CE Loss (Source):  0.3981 ( 0.3527) Learning Rate: 0.0250 (0.0250) Top1_base: 91.4062 (90.4366) Top1_base_per_class: 90.8631 (90.6518) 
Training Epoch: [207/1000] Step: [180 / 285] Batch Time: 0.1471 (0.1632) Data Time: 0.0130 (0.0305) Average Loss: 0.3141 (0.3556) Average CE Loss (Source):  0.3141 ( 0.3556) Learning Rate: 0.0250 (0.0250) Top1_base: 92.1875 (90.3776) Top1_base_per_class: 92.8395 (90.6144) 
Training Epoch: [207/1000] Step: [190 / 285] Batch Time: 0.1587 (0.1627) Data Time: 0.0238 (0.0300) Average Loss: 0.2740 (0.3553) Average CE Loss (Source):  0.2740 ( 0.3553) Learning Rate: 0.0250 (0.0250) Top1_base: 92.9688 (90.3495) Top1_base_per_class: 92.1429 (90.5780) 
Training Epoch: [207/1000] Step: [200 / 285] Batch Time: 0.1415 (0.1619) Data Time: 0.0109 (0.0292) Average Loss: 0.3407 (0.3569) Average CE Loss (Source):  0.3407 ( 0.3569) Learning Rate: 0.0250 (0.0250) Top1_base: 89.0625 (90.3477) Top1_base_per_class: 90.7568 (90.5557) 
Training Epoch: [207/1000] Step: [210 / 285] Batch Time: 0.1509 (0.1612) Data Time: 0.0183 (0.0285) Average Loss: 0.3849 (0.3597) Average CE Loss (Source):  0.3849 ( 0.3597) Learning Rate: 0.0250 (0.0250) Top1_base: 89.0625 (90.2753) Top1_base_per_class: 89.6795 (90.4657) 
Training Epoch: [207/1000] Step: [220 / 285] Batch Time: 0.1438 (0.1606) Data Time: 0.0124 (0.0279) Average Loss: 0.4687 (0.3596) Average CE Loss (Source):  0.4687 ( 0.3596) Learning Rate: 0.0250 (0.0250) Top1_base: 86.7188 (90.3018) Top1_base_per_class: 87.7381 (90.5055) 
Training Epoch: [207/1000] Step: [230 / 285] Batch Time: 0.2075 (0.1608) Data Time: 0.0766 (0.0281) Average Loss: 0.3249 (0.3602) Average CE Loss (Source):  0.3249 ( 0.3602) Learning Rate: 0.0250 (0.0250) Top1_base: 91.4062 (90.2955) Top1_base_per_class: 87.9464 (90.4882) 
Training Epoch: [207/1000] Step: [240 / 285] Batch Time: 0.1505 (0.1608) Data Time: 0.0135 (0.0281) Average Loss: 0.3675 (0.3605) Average CE Loss (Source):  0.3675 ( 0.3605) Learning Rate: 0.0250 (0.0250) Top1_base: 89.0625 (90.2930) Top1_base_per_class: 90.2924 (90.5114) 
Training Epoch: [207/1000] Step: [250 / 285] Batch Time: 0.2062 (0.1606) Data Time: 0.0749 (0.0279) Average Loss: 0.3095 (0.3611) Average CE Loss (Source):  0.3095 ( 0.3611) Learning Rate: 0.0250 (0.0250) Top1_base: 90.6250 (90.2844) Top1_base_per_class: 88.2372 (90.4898) 
Training Epoch: [207/1000] Step: [260 / 285] Batch Time: 0.1413 (0.1601) Data Time: 0.0106 (0.0275) Average Loss: 0.2776 (0.3613) Average CE Loss (Source):  0.2776 ( 0.3613) Learning Rate: 0.0250 (0.0250) Top1_base: 93.7500 (90.2855) Top1_base_per_class: 95.3274 (90.5080) 
Training Epoch: [207/1000] Step: [270 / 285] Batch Time: 0.1485 (0.1599) Data Time: 0.0176 (0.0273) Average Loss: 0.3638 (0.3618) Average CE Loss (Source):  0.3638 ( 0.3618) Learning Rate: 0.0250 (0.0250) Top1_base: 93.7500 (90.2951) Top1_base_per_class: 93.2390 (90.5194) 
Training Epoch: [207/1000] Step: [280 / 285] Batch Time: 0.1456 (0.1594) Data Time: 0.0128 (0.0268) Average Loss: 0.3001 (0.3619) Average CE Loss (Source):  0.3001 ( 0.3619) Learning Rate: 0.0250 (0.0250) Top1_base: 92.9688 (90.3097) Top1_base_per_class: 94.3210 (90.5670) 
Training Epoch: [208/1000] Step: [0] Batch Time: 0.1418 (0.1593) Data Time: 0.0105 (0.0268) Average Loss: 0.3536 (0.3616) Average CE Loss (Source):  0.3536 ( 0.3616) Learning Rate: 0.0250 (0.0250) Top1_base: 92.1875 (90.3289) Top1_base_per_class: 90.8176 (90.5855) 
 21%|██        | 208/1000 [2:41:27<10:15:33, 46.63s/it] 21%|██        | 209/1000 [2:42:11<10:06:17, 45.99s/it]Training Epoch: [208/1000] Step: [10 / 285] Batch Time: 0.1489 (0.2285) Data Time: 0.0135 (0.0940) Average Loss: 0.2355 (0.3572) Average CE Loss (Source):  0.2355 ( 0.3572) Learning Rate: 0.0250 (0.0250) Top1_base: 92.9688 (90.3906) Top1_base_per_class: 93.0247 (90.7620) 
Training Epoch: [208/1000] Step: [20 / 285] Batch Time: 0.1473 (0.1924) Data Time: 0.0129 (0.0589) Average Loss: 0.2708 (0.3611) Average CE Loss (Source):  0.2708 ( 0.3611) Learning Rate: 0.0250 (0.0250) Top1_base: 94.5312 (90.0000) Top1_base_per_class: 95.6604 (90.4836) 
Training Epoch: [208/1000] Step: [30 / 285] Batch Time: 0.1437 (0.1821) Data Time: 0.0109 (0.0488) Average Loss: 0.3382 (0.3547) Average CE Loss (Source):  0.3382 ( 0.3547) Learning Rate: 0.0250 (0.0250) Top1_base: 89.8438 (90.3125) Top1_base_per_class: 91.0234 (90.5963) 
Training Epoch: [208/1000] Step: [40 / 285] Batch Time: 0.1438 (0.1730) Data Time: 0.0115 (0.0400) Average Loss: 0.3416 (0.3544) Average CE Loss (Source):  0.3416 ( 0.3544) Learning Rate: 0.0250 (0.0250) Top1_base: 89.8438 (90.2539) Top1_base_per_class: 92.0606 (90.6569) 
Training Epoch: [208/1000] Step: [50 / 285] Batch Time: 0.1549 (0.1695) Data Time: 0.0178 (0.0362) Average Loss: 0.3824 (0.3511) Average CE Loss (Source):  0.3824 ( 0.3511) Learning Rate: 0.0250 (0.0250) Top1_base: 92.1875 (90.3906) Top1_base_per_class: 93.5494 (90.8111) 
Training Epoch: [208/1000] Step: [60 / 285] Batch Time: 0.1411 (0.1676) Data Time: 0.0106 (0.0344) Average Loss: 0.2827 (0.3475) Average CE Loss (Source):  0.2827 ( 0.3475) Learning Rate: 0.0250 (0.0250) Top1_base: 91.4062 (90.5599) Top1_base_per_class: 91.4286 (90.9516) 
Training Epoch: [208/1000] Step: [70 / 285] Batch Time: 0.1508 (0.1658) Data Time: 0.0159 (0.0324) Average Loss: 0.3735 (0.3502) Average CE Loss (Source):  0.3735 ( 0.3502) Learning Rate: 0.0250 (0.0250) Top1_base: 89.0625 (90.4911) Top1_base_per_class: 90.9226 (90.9184) 
Training Epoch: [208/1000] Step: [80 / 285] Batch Time: 0.1478 (0.1634) Data Time: 0.0145 (0.0301) Average Loss: 0.3318 (0.3515) Average CE Loss (Source):  0.3318 ( 0.3515) Learning Rate: 0.0250 (0.0250) Top1_base: 92.1875 (90.4297) Top1_base_per_class: 90.6215 (90.8097) 
Training Epoch: [208/1000] Step: [90 / 285] Batch Time: 0.1487 (0.1618) Data Time: 0.0133 (0.0283) Average Loss: 0.3601 (0.3592) Average CE Loss (Source):  0.3601 ( 0.3592) Learning Rate: 0.0250 (0.0250) Top1_base: 90.6250 (90.2344) Top1_base_per_class: 86.7816 (90.6312) 
Training Epoch: [208/1000] Step: [100 / 285] Batch Time: 0.1433 (0.1603) Data Time: 0.0112 (0.0269) Average Loss: 0.3294 (0.3597) Average CE Loss (Source):  0.3294 ( 0.3597) Learning Rate: 0.0250 (0.0250) Top1_base: 92.9688 (90.2891) Top1_base_per_class: 93.7273 (90.6989) 
Training Epoch: [208/1000] Step: [110 / 285] Batch Time: 0.1456 (0.1591) Data Time: 0.0145 (0.0257) Average Loss: 0.3980 (0.3612) Average CE Loss (Source):  0.3980 ( 0.3612) Learning Rate: 0.0250 (0.0250) Top1_base: 92.1875 (90.2628) Top1_base_per_class: 93.3185 (90.5898) 
Training Epoch: [208/1000] Step: [120 / 285] Batch Time: 0.1451 (0.1591) Data Time: 0.0108 (0.0254) Average Loss: 0.3574 (0.3620) Average CE Loss (Source):  0.3574 ( 0.3620) Learning Rate: 0.0250 (0.0250) Top1_base: 89.8438 (90.1823) Top1_base_per_class: 91.4780 (90.5453) 
Training Epoch: [208/1000] Step: [130 / 285] Batch Time: 0.1434 (0.1588) Data Time: 0.0116 (0.0252) Average Loss: 0.3311 (0.3651) Average CE Loss (Source):  0.3311 ( 0.3651) Learning Rate: 0.0250 (0.0250) Top1_base: 92.9688 (90.0901) Top1_base_per_class: 92.1280 (90.4646) 
Training Epoch: [208/1000] Step: [140 / 285] Batch Time: 0.1461 (0.1580) Data Time: 0.0141 (0.0244) Average Loss: 0.3789 (0.3632) Average CE Loss (Source):  0.3789 ( 0.3632) Learning Rate: 0.0250 (0.0250) Top1_base: 87.5000 (90.1451) Top1_base_per_class: 87.4528 (90.5175) 
Training Epoch: [208/1000] Step: [150 / 285] Batch Time: 0.1427 (0.1575) Data Time: 0.0108 (0.0240) Average Loss: 0.4493 (0.3635) Average CE Loss (Source):  0.4493 ( 0.3635) Learning Rate: 0.0250 (0.0250) Top1_base: 89.0625 (90.0990) Top1_base_per_class: 88.0357 (90.4732) 
Training Epoch: [208/1000] Step: [160 / 285] Batch Time: 0.1460 (0.1574) Data Time: 0.0115 (0.0239) Average Loss: 0.2564 (0.3611) Average CE Loss (Source):  0.2564 ( 0.3611) Learning Rate: 0.0250 (0.0250) Top1_base: 92.9688 (90.1416) Top1_base_per_class: 93.1897 (90.5002) 
Training Epoch: [208/1000] Step: [170 / 285] Batch Time: 0.1508 (0.1572) Data Time: 0.0140 (0.0238) Average Loss: 0.4107 (0.3591) Average CE Loss (Source):  0.4107 ( 0.3591) Learning Rate: 0.0250 (0.0250) Top1_base: 90.6250 (90.2114) Top1_base_per_class: 91.6667 (90.5866) 
Training Epoch: [208/1000] Step: [180 / 285] Batch Time: 0.1464 (0.1572) Data Time: 0.0130 (0.0239) Average Loss: 0.2924 (0.3593) Average CE Loss (Source):  0.2924 ( 0.3593) Learning Rate: 0.0250 (0.0250) Top1_base: 94.5312 (90.2691) Top1_base_per_class: 93.8889 (90.6281) 
Training Epoch: [208/1000] Step: [190 / 285] Batch Time: 0.1429 (0.1568) Data Time: 0.0114 (0.0234) Average Loss: 0.4491 (0.3608) Average CE Loss (Source):  0.4491 ( 0.3608) Learning Rate: 0.0250 (0.0250) Top1_base: 86.7188 (90.2590) Top1_base_per_class: 85.4464 (90.6077) 
Training Epoch: [208/1000] Step: [200 / 285] Batch Time: 0.1456 (0.1566) Data Time: 0.0116 (0.0233) Average Loss: 0.3085 (0.3612) Average CE Loss (Source):  0.3085 ( 0.3612) Learning Rate: 0.0250 (0.0250) Top1_base: 90.6250 (90.2344) Top1_base_per_class: 90.2160 (90.5535) 
Training Epoch: [208/1000] Step: [210 / 285] Batch Time: 0.1478 (0.1569) Data Time: 0.0116 (0.0236) Average Loss: 0.4930 (0.3632) Average CE Loss (Source):  0.4930 ( 0.3632) Learning Rate: 0.0250 (0.0250) Top1_base: 88.2812 (90.2046) Top1_base_per_class: 88.6782 (90.5010) 
Training Epoch: [208/1000] Step: [220 / 285] Batch Time: 0.1504 (0.1569) Data Time: 0.0183 (0.0236) Average Loss: 0.2354 (0.3623) Average CE Loss (Source):  0.2354 ( 0.3623) Learning Rate: 0.0250 (0.0250) Top1_base: 94.5312 (90.2237) Top1_base_per_class: 96.7403 (90.5241) 
Training Epoch: [208/1000] Step: [230 / 285] Batch Time: 0.1450 (0.1568) Data Time: 0.0121 (0.0235) Average Loss: 0.3905 (0.3645) Average CE Loss (Source):  0.3905 ( 0.3645) Learning Rate: 0.0250 (0.0250) Top1_base: 88.2812 (90.1562) Top1_base_per_class: 88.1871 (90.4534) 
Training Epoch: [208/1000] Step: [240 / 285] Batch Time: 0.1425 (0.1568) Data Time: 0.0104 (0.0237) Average Loss: 0.3552 (0.3644) Average CE Loss (Source):  0.3552 ( 0.3644) Learning Rate: 0.0250 (0.0250) Top1_base: 88.2812 (90.1335) Top1_base_per_class: 89.0385 (90.4305) 
Training Epoch: [208/1000] Step: [250 / 285] Batch Time: 0.1451 (0.1566) Data Time: 0.0133 (0.0234) Average Loss: 0.3628 (0.3644) Average CE Loss (Source):  0.3628 ( 0.3644) Learning Rate: 0.0250 (0.0250) Top1_base: 91.4062 (90.1562) Top1_base_per_class: 92.6554 (90.4433) 
Training Epoch: [208/1000] Step: [260 / 285] Batch Time: 0.1419 (0.1562) Data Time: 0.0102 (0.0231) Average Loss: 0.4037 (0.3654) Average CE Loss (Source):  0.4037 ( 0.3654) Learning Rate: 0.0250 (0.0250) Top1_base: 87.5000 (90.1112) Top1_base_per_class: 89.9107 (90.3978) 
Training Epoch: [208/1000] Step: [270 / 285] Batch Time: 0.1438 (0.1559) Data Time: 0.0116 (0.0228) Average Loss: 0.2956 (0.3642) Average CE Loss (Source):  0.2956 ( 0.3642) Learning Rate: 0.0250 (0.0250) Top1_base: 91.4062 (90.1534) Top1_base_per_class: 92.3452 (90.4210) 
Training Epoch: [208/1000] Step: [280 / 285] Batch Time: 0.1415 (0.1558) Data Time: 0.0100 (0.0227) Average Loss: 0.5177 (0.3655) Average CE Loss (Source):  0.5177 ( 0.3655) Learning Rate: 0.0250 (0.0250) Top1_base: 82.0312 (90.1060) Top1_base_per_class: 82.9321 (90.3868) 
Training Epoch: [209/1000] Step: [0] Batch Time: 0.1419 (0.1559) Data Time: 0.0099 (0.0228) Average Loss: 0.3509 (0.3668) Average CE Loss (Source):  0.3509 ( 0.3668) Learning Rate: 0.0250 (0.0250) Top1_base: 92.9688 (90.0630) Top1_base_per_class: 94.3396 (90.3516) 
Training Epoch: [209/1000] Step: [10 / 285] Batch Time: 0.1472 (0.2378) Data Time: 0.0100 (0.1041) Average Loss: 0.4444 (0.3627) Average CE Loss (Source):  0.4444 ( 0.3627) Learning Rate: 0.0250 (0.0250) Top1_base: 89.8438 (90.2344) Top1_base_per_class: 87.9167 (90.1039) 
Training Epoch: [209/1000] Step: [20 / 285] Batch Time: 0.1467 (0.1979) Data Time: 0.0129 (0.0645) Average Loss: 0.3746 (0.3514) Average CE Loss (Source):  0.3746 ( 0.3514) Learning Rate: 0.0250 (0.0250) Top1_base: 90.6250 (90.7812) Top1_base_per_class: 90.1977 (90.8924) 
Training Epoch: [209/1000] Step: [30 / 285] Batch Time: 0.1445 (0.1863) Data Time: 0.0118 (0.0530) Average Loss: 0.4683 (0.3732) Average CE Loss (Source):  0.4683 ( 0.3732) Learning Rate: 0.0250 (0.0250) Top1_base: 87.5000 (90.1302) Top1_base_per_class: 89.2982 (90.2673) 
Training Epoch: [209/1000] Step: [40 / 285] Batch Time: 0.1449 (0.1806) Data Time: 0.0106 (0.0473) Average Loss: 0.3579 (0.3644) Average CE Loss (Source):  0.3579 ( 0.3644) Learning Rate: 0.0250 (0.0250) Top1_base: 89.8438 (90.2539) Top1_base_per_class: 92.6023 (90.3841) 
Training Epoch: [209/1000] Step: [50 / 285] Batch Time: 0.1475 (0.1748) Data Time: 0.0121 (0.0414) Average Loss: 0.3049 (0.3662) Average CE Loss (Source):  0.3049 ( 0.3662) Learning Rate: 0.0250 (0.0250) Top1_base: 91.4062 (90.1094) Top1_base_per_class: 93.3631 (90.3152) 
Training Epoch: [209/1000] Step: [60 / 285] Batch Time: 0.1460 (0.1725) Data Time: 0.0118 (0.0391) Average Loss: 0.2224 (0.3596) Average CE Loss (Source):  0.2224 ( 0.3596) Learning Rate: 0.0250 (0.0250) Top1_base: 93.7500 (90.2604) Top1_base_per_class: 92.0606 (90.5426) 
Training Epoch: [209/1000] Step: [70 / 285] Batch Time: 0.1465 (0.1702) Data Time: 0.0113 (0.0369) Average Loss: 0.5742 (0.3573) Average CE Loss (Source):  0.5742 ( 0.3573) Learning Rate: 0.0250 (0.0250) Top1_base: 87.5000 (90.3795) Top1_base_per_class: 85.3939 (90.6272) 
Training Epoch: [209/1000] Step: [80 / 285] Batch Time: 0.1453 (0.1693) Data Time: 0.0104 (0.0360) Average Loss: 0.4102 (0.3566) Average CE Loss (Source):  0.4102 ( 0.3566) Learning Rate: 0.0250 (0.0250) Top1_base: 87.5000 (90.3516) Top1_base_per_class: 87.3851 (90.6445) 
Training Epoch: [209/1000] Step: [90 / 285] Batch Time: 0.1462 (0.1672) Data Time: 0.0146 (0.0339) Average Loss: 0.4610 (0.3559) Average CE Loss (Source):  0.4610 ( 0.3559) Learning Rate: 0.0250 (0.0250) Top1_base: 89.8438 (90.4253) Top1_base_per_class: 88.7576 (90.7166) 
Training Epoch: [209/1000] Step: [100 / 285] Batch Time: 0.1425 (0.1669) Data Time: 0.0115 (0.0337) Average Loss: 0.3452 (0.3573) Average CE Loss (Source):  0.3452 ( 0.3573) Learning Rate: 0.0250 (0.0250) Top1_base: 92.9688 (90.3125) Top1_base_per_class: 92.5265 (90.5299) 
Training Epoch: [209/1000] Step: [110 / 285] Batch Time: 0.1429 (0.1664) Data Time: 0.0116 (0.0332) Average Loss: 0.3626 (0.3564) Average CE Loss (Source):  0.3626 ( 0.3564) Learning Rate: 0.0250 (0.0250) Top1_base: 90.6250 (90.3409) Top1_base_per_class: 92.0760 (90.5931) 
Training Epoch: [209/1000] Step: [120 / 285] Batch Time: 0.1448 (0.1653) Data Time: 0.0120 (0.0321) Average Loss: 0.2220 (0.3568) Average CE Loss (Source):  0.2220 ( 0.3568) Learning Rate: 0.0250 (0.0250) Top1_base: 92.1875 (90.3776) Top1_base_per_class: 91.6082 (90.6230) 
Training Epoch: [209/1000] Step: [130 / 285] Batch Time: 0.1536 (0.1643) Data Time: 0.0188 (0.0310) Average Loss: 0.3849 (0.3567) Average CE Loss (Source):  0.3849 ( 0.3567) Learning Rate: 0.0250 (0.0250) Top1_base: 89.8438 (90.3726) Top1_base_per_class: 90.0943 (90.6053) 
Training Epoch: [209/1000] Step: [140 / 285] Batch Time: 0.1466 (0.1631) Data Time: 0.0144 (0.0299) Average Loss: 0.4965 (0.3564) Average CE Loss (Source):  0.4965 ( 0.3564) Learning Rate: 0.0250 (0.0250) Top1_base: 88.2812 (90.3850) Top1_base_per_class: 88.1447 (90.6400) 
Training Epoch: [209/1000] Step: [150 / 285] Batch Time: 0.1491 (0.1624) Data Time: 0.0128 (0.0290) Average Loss: 0.2575 (0.3554) Average CE Loss (Source):  0.2575 ( 0.3554) Learning Rate: 0.0250 (0.0250) Top1_base: 92.1875 (90.4219) Top1_base_per_class: 90.4119 (90.6091) 
Training Epoch: [209/1000] Step: [160 / 285] Batch Time: 0.1464 (0.1619) Data Time: 0.0107 (0.0284) Average Loss: 0.2875 (0.3571) Average CE Loss (Source):  0.2875 ( 0.3571) Learning Rate: 0.0250 (0.0250) Top1_base: 91.4062 (90.3467) Top1_base_per_class: 93.9198 (90.5654) 
Training Epoch: [209/1000] Step: [170 / 285] Batch Time: 0.1499 (0.1614) Data Time: 0.0125 (0.0278) Average Loss: 0.2520 (0.3573) Average CE Loss (Source):  0.2520 ( 0.3573) Learning Rate: 0.0250 (0.0250) Top1_base: 92.9688 (90.3493) Top1_base_per_class: 95.1977 (90.5970) 
Training Epoch: [209/1000] Step: [180 / 285] Batch Time: 0.1501 (0.1614) Data Time: 0.0122 (0.0276) Average Loss: 0.5391 (0.3592) Average CE Loss (Source):  0.5391 ( 0.3592) Learning Rate: 0.0250 (0.0250) Top1_base: 85.1562 (90.2951) Top1_base_per_class: 88.2974 (90.5678) 
Training Epoch: [209/1000] Step: [190 / 285] Batch Time: 0.1447 (0.1606) Data Time: 0.0124 (0.0269) Average Loss: 0.4580 (0.3593) Average CE Loss (Source):  0.4580 ( 0.3593) Learning Rate: 0.0250 (0.0250) Top1_base: 88.2812 (90.3084) Top1_base_per_class: 89.2241 (90.5817) 
Training Epoch: [209/1000] Step: [200 / 285] Batch Time: 0.1469 (0.1604) Data Time: 0.0106 (0.0266) Average Loss: 0.3098 (0.3601) Average CE Loss (Source):  0.3098 ( 0.3601) Learning Rate: 0.0250 (0.0250) Top1_base: 90.6250 (90.2852) Top1_base_per_class: 87.5298 (90.5593) 
Training Epoch: [209/1000] Step: [210 / 285] Batch Time: 0.1461 (0.1598) Data Time: 0.0147 (0.0260) Average Loss: 0.4227 (0.3610) Average CE Loss (Source):  0.4227 ( 0.3610) Learning Rate: 0.0250 (0.0250) Top1_base: 87.5000 (90.2418) Top1_base_per_class: 88.6310 (90.5355) 
Training Epoch: [209/1000] Step: [220 / 285] Batch Time: 0.1499 (0.1595) Data Time: 0.0137 (0.0257) Average Loss: 0.3148 (0.3601) Average CE Loss (Source):  0.3148 ( 0.3601) Learning Rate: 0.0250 (0.0250) Top1_base: 91.4062 (90.2486) Top1_base_per_class: 90.4545 (90.5506) 
Training Epoch: [209/1000] Step: [230 / 285] Batch Time: 0.1479 (0.1592) Data Time: 0.0110 (0.0253) Average Loss: 0.5145 (0.3600) Average CE Loss (Source):  0.5145 ( 0.3600) Learning Rate: 0.0250 (0.0250) Top1_base: 85.1562 (90.2242) Top1_base_per_class: 87.3810 (90.5669) 
Training Epoch: [209/1000] Step: [240 / 285] Batch Time: 0.1492 (0.1588) Data Time: 0.0109 (0.0249) Average Loss: 0.2812 (0.3589) Average CE Loss (Source):  0.2812 ( 0.3589) Learning Rate: 0.0250 (0.0250) Top1_base: 89.0625 (90.2246) Top1_base_per_class: 89.0643 (90.5203) 
Training Epoch: [209/1000] Step: [250 / 285] Batch Time: 0.1484 (0.1585) Data Time: 0.0136 (0.0245) Average Loss: 0.3418 (0.3582) Average CE Loss (Source):  0.3418 ( 0.3582) Learning Rate: 0.0250 (0.0250) Top1_base: 89.8438 (90.2594) Top1_base_per_class: 88.5758 (90.5584) 
Training Epoch: [209/1000] Step: [260 / 285] Batch Time: 0.1465 (0.1588) Data Time: 0.0115 (0.0248) Average Loss: 0.2621 (0.3568) Average CE Loss (Source):  0.2621 ( 0.3568) Learning Rate: 0.0250 (0.0250) Top1_base: 92.1875 (90.3005) Top1_base_per_class: 94.0741 (90.6186) 
Training Epoch: [209/1000] Step: [270 / 285] Batch Time: 0.1468 (0.1585) Data Time: 0.0111 (0.0246) Average Loss: 0.4750 (0.3580) Average CE Loss (Source):  0.4750 ( 0.3580) Learning Rate: 0.0250 (0.0250) Top1_base: 88.2812 (90.2778) Top1_base_per_class: 88.9697 (90.6021) 
Training Epoch: [209/1000] Step: [280 / 285] Batch Time: 0.1461 (0.1585) Data Time: 0.0107 (0.0245) Average Loss: 0.2796 (0.3581) Average CE Loss (Source):  0.2796 ( 0.3581) Learning Rate: 0.0250 (0.0250) Top1_base: 92.9688 (90.2902) Top1_base_per_class: 93.0357 (90.6101) 
Training Epoch: [210/1000] Step: [0] Batch Time: 0.1445 (0.1583) Data Time: 0.0121 (0.0243) Average Loss: 0.4293 (0.3588) Average CE Loss (Source):  0.4293 ( 0.3588) Learning Rate: 0.0250 (0.0250) Top1_base: 89.8438 (90.2769) Top1_base_per_class: 88.4483 (90.6000) 
 21%|██        | 210/1000 [2:42:59<10:13:03, 46.56s/it] 21%|██        | 211/1000 [2:43:44<10:07:40, 46.21s/it]Training Epoch: [210/1000] Step: [10 / 285] Batch Time: 0.1430 (0.2340) Data Time: 0.0121 (0.1024) Average Loss: 0.4516 (0.3706) Average CE Loss (Source):  0.4516 ( 0.3706) Learning Rate: 0.0250 (0.0250) Top1_base: 85.9375 (88.9844) Top1_base_per_class: 87.8655 (89.1339) 
Training Epoch: [210/1000] Step: [20 / 285] Batch Time: 0.1491 (0.1981) Data Time: 0.0111 (0.0660) Average Loss: 0.4735 (0.3741) Average CE Loss (Source):  0.4735 ( 0.3741) Learning Rate: 0.0250 (0.0250) Top1_base: 87.5000 (89.2578) Top1_base_per_class: 87.8086 (89.6371) 
Training Epoch: [210/1000] Step: [30 / 285] Batch Time: 0.1430 (0.1841) Data Time: 0.0107 (0.0520) Average Loss: 0.4298 (0.3717) Average CE Loss (Source):  0.4298 ( 0.3717) Learning Rate: 0.0250 (0.0250) Top1_base: 88.2812 (89.5312) Top1_base_per_class: 88.2390 (89.8279) 
Training Epoch: [210/1000] Step: [40 / 285] Batch Time: 0.1426 (0.1785) Data Time: 0.0112 (0.0464) Average Loss: 0.4138 (0.3671) Average CE Loss (Source):  0.4138 ( 0.3671) Learning Rate: 0.0250 (0.0250) Top1_base: 89.8438 (89.6875) Top1_base_per_class: 92.2487 (90.0253) 
Training Epoch: [210/1000] Step: [50 / 285] Batch Time: 0.1439 (0.1720) Data Time: 0.0121 (0.0400) Average Loss: 0.6945 (0.3756) Average CE Loss (Source):  0.6945 ( 0.3756) Learning Rate: 0.0250 (0.0250) Top1_base: 81.2500 (89.6094) Top1_base_per_class: 83.0655 (90.0024) 
Training Epoch: [210/1000] Step: [60 / 285] Batch Time: 0.1461 (0.1688) Data Time: 0.0143 (0.0369) Average Loss: 0.2593 (0.3670) Average CE Loss (Source):  0.2593 ( 0.3670) Learning Rate: 0.0250 (0.0250) Top1_base: 93.7500 (90.0000) Top1_base_per_class: 95.2161 (90.3477) 
Training Epoch: [210/1000] Step: [70 / 285] Batch Time: 0.1463 (0.1669) Data Time: 0.0126 (0.0351) Average Loss: 0.3608 (0.3666) Average CE Loss (Source):  0.3608 ( 0.3666) Learning Rate: 0.0250 (0.0250) Top1_base: 88.2812 (89.9777) Top1_base_per_class: 85.7602 (90.2577) 
Training Epoch: [210/1000] Step: [80 / 285] Batch Time: 0.1460 (0.1646) Data Time: 0.0138 (0.0326) Average Loss: 0.4538 (0.3654) Average CE Loss (Source):  0.4538 ( 0.3654) Learning Rate: 0.0250 (0.0250) Top1_base: 86.7188 (89.9805) Top1_base_per_class: 86.2424 (90.2549) 
Training Epoch: [210/1000] Step: [90 / 285] Batch Time: 0.1445 (0.1629) Data Time: 0.0119 (0.0309) Average Loss: 0.5255 (0.3618) Average CE Loss (Source):  0.5255 ( 0.3618) Learning Rate: 0.0250 (0.0250) Top1_base: 85.9375 (90.1910) Top1_base_per_class: 83.6550 (90.4657) 
Training Epoch: [210/1000] Step: [100 / 285] Batch Time: 0.1464 (0.1613) Data Time: 0.0125 (0.0293) Average Loss: 0.4943 (0.3593) Average CE Loss (Source):  0.4943 ( 0.3593) Learning Rate: 0.0250 (0.0250) Top1_base: 84.3750 (90.1953) Top1_base_per_class: 85.0736 (90.4887) 
Training Epoch: [210/1000] Step: [110 / 285] Batch Time: 0.1455 (0.1615) Data Time: 0.0121 (0.0295) Average Loss: 0.1892 (0.3592) Average CE Loss (Source):  0.1892 ( 0.3592) Learning Rate: 0.0250 (0.0250) Top1_base: 96.0938 (90.1989) Top1_base_per_class: 97.7258 (90.5531) 
Training Epoch: [210/1000] Step: [120 / 285] Batch Time: 0.1439 (0.1628) Data Time: 0.0119 (0.0309) Average Loss: 0.3980 (0.3597) Average CE Loss (Source):  0.3980 ( 0.3597) Learning Rate: 0.0250 (0.0250) Top1_base: 89.0625 (90.2214) Top1_base_per_class: 91.0802 (90.5488) 
Training Epoch: [210/1000] Step: [130 / 285] Batch Time: 0.1479 (0.1619) Data Time: 0.0138 (0.0299) Average Loss: 0.3840 (0.3608) Average CE Loss (Source):  0.3840 ( 0.3608) Learning Rate: 0.0250 (0.0250) Top1_base: 89.8438 (90.2163) Top1_base_per_class: 90.2924 (90.5000) 
Training Epoch: [210/1000] Step: [140 / 285] Batch Time: 0.1460 (0.1611) Data Time: 0.0124 (0.0291) Average Loss: 0.2275 (0.3593) Average CE Loss (Source):  0.2275 ( 0.3593) Learning Rate: 0.0250 (0.0250) Top1_base: 94.5312 (90.3237) Top1_base_per_class: 92.5309 (90.6012) 
Training Epoch: [210/1000] Step: [150 / 285] Batch Time: 0.1567 (0.1608) Data Time: 0.0263 (0.0288) Average Loss: 0.4002 (0.3592) Average CE Loss (Source):  0.4002 ( 0.3592) Learning Rate: 0.0250 (0.0250) Top1_base: 91.4062 (90.3385) Top1_base_per_class: 90.4612 (90.5970) 
Training Epoch: [210/1000] Step: [160 / 285] Batch Time: 0.1446 (0.1599) Data Time: 0.0108 (0.0278) Average Loss: 0.2908 (0.3570) Average CE Loss (Source):  0.2908 ( 0.3570) Learning Rate: 0.0250 (0.0250) Top1_base: 94.5312 (90.4395) Top1_base_per_class: 95.4848 (90.7280) 
Training Epoch: [210/1000] Step: [170 / 285] Batch Time: 0.2116 (0.1596) Data Time: 0.0783 (0.0275) Average Loss: 0.3025 (0.3581) Average CE Loss (Source):  0.3025 ( 0.3581) Learning Rate: 0.0250 (0.0250) Top1_base: 92.9688 (90.3860) Top1_base_per_class: 94.3590 (90.6983) 
Training Epoch: [210/1000] Step: [180 / 285] Batch Time: 0.1449 (0.1590) Data Time: 0.0126 (0.0269) Average Loss: 0.4441 (0.3582) Average CE Loss (Source):  0.4441 ( 0.3582) Learning Rate: 0.0250 (0.0250) Top1_base: 85.9375 (90.3733) Top1_base_per_class: 83.1250 (90.6516) 
Training Epoch: [210/1000] Step: [190 / 285] Batch Time: 0.2070 (0.1590) Data Time: 0.0737 (0.0268) Average Loss: 0.2776 (0.3573) Average CE Loss (Source):  0.2776 ( 0.3573) Learning Rate: 0.0250 (0.0250) Top1_base: 93.7500 (90.3783) Top1_base_per_class: 94.4915 (90.6591) 
Training Epoch: [210/1000] Step: [200 / 285] Batch Time: 0.1452 (0.1592) Data Time: 0.0124 (0.0270) Average Loss: 0.2899 (0.3561) Average CE Loss (Source):  0.2899 ( 0.3561) Learning Rate: 0.0250 (0.0250) Top1_base: 92.1875 (90.3672) Top1_base_per_class: 90.6918 (90.6457) 
Training Epoch: [210/1000] Step: [210 / 285] Batch Time: 0.1748 (0.1595) Data Time: 0.0416 (0.0272) Average Loss: 0.3086 (0.3552) Average CE Loss (Source):  0.3086 ( 0.3552) Learning Rate: 0.0250 (0.0250) Top1_base: 92.9688 (90.3720) Top1_base_per_class: 91.9444 (90.6383) 
Training Epoch: [210/1000] Step: [220 / 285] Batch Time: 0.1433 (0.1597) Data Time: 0.0120 (0.0275) Average Loss: 0.3605 (0.3550) Average CE Loss (Source):  0.3605 ( 0.3550) Learning Rate: 0.0250 (0.0250) Top1_base: 88.2812 (90.3800) Top1_base_per_class: 87.6667 (90.6449) 
Training Epoch: [210/1000] Step: [230 / 285] Batch Time: 0.1706 (0.1594) Data Time: 0.0378 (0.0271) Average Loss: 0.3325 (0.3556) Average CE Loss (Source):  0.3325 ( 0.3556) Learning Rate: 0.0250 (0.0250) Top1_base: 89.8438 (90.3329) Top1_base_per_class: 87.6901 (90.5832) 
Training Epoch: [210/1000] Step: [240 / 285] Batch Time: 0.1450 (0.1592) Data Time: 0.0125 (0.0269) Average Loss: 0.3705 (0.3571) Average CE Loss (Source):  0.3705 ( 0.3571) Learning Rate: 0.0250 (0.0250) Top1_base: 90.6250 (90.3027) Top1_base_per_class: 88.9266 (90.5545) 
Training Epoch: [210/1000] Step: [250 / 285] Batch Time: 0.2000 (0.1593) Data Time: 0.0679 (0.0270) Average Loss: 0.3033 (0.3570) Average CE Loss (Source):  0.3033 ( 0.3570) Learning Rate: 0.0250 (0.0250) Top1_base: 89.8438 (90.3187) Top1_base_per_class: 89.9371 (90.5713) 
Training Epoch: [210/1000] Step: [260 / 285] Batch Time: 0.1462 (0.1593) Data Time: 0.0138 (0.0270) Average Loss: 0.4792 (0.3587) Average CE Loss (Source):  0.4792 ( 0.3587) Learning Rate: 0.0250 (0.0250) Top1_base: 92.9688 (90.3245) Top1_base_per_class: 93.8788 (90.5947) 
Training Epoch: [210/1000] Step: [270 / 285] Batch Time: 0.1883 (0.1595) Data Time: 0.0544 (0.0271) Average Loss: 0.3778 (0.3587) Average CE Loss (Source):  0.3778 ( 0.3587) Learning Rate: 0.0250 (0.0250) Top1_base: 90.6250 (90.3212) Top1_base_per_class: 86.8954 (90.5916) 
Training Epoch: [210/1000] Step: [280 / 285] Batch Time: 0.1441 (0.1593) Data Time: 0.0114 (0.0269) Average Loss: 0.3416 (0.3589) Average CE Loss (Source):  0.3416 ( 0.3589) Learning Rate: 0.0250 (0.0250) Top1_base: 89.0625 (90.2818) Top1_base_per_class: 88.9181 (90.5353) 
Training Epoch: [211/1000] Step: [0] Batch Time: 0.1403 (0.1590) Data Time: 0.0113 (0.0267) Average Loss: 0.3453 (0.3587) Average CE Loss (Source):  0.3453 ( 0.3587) Learning Rate: 0.0250 (0.0250) Top1_base: 89.0625 (90.2961) Top1_base_per_class: 88.5417 (90.5587) 
Training Epoch: [211/1000] Step: [10 / 285] Batch Time: 0.1447 (0.2383) Data Time: 0.0110 (0.1054) Average Loss: 0.3280 (0.3408) Average CE Loss (Source):  0.3280 ( 0.3408) Learning Rate: 0.0250 (0.0250) Top1_base: 90.6250 (90.8594) Top1_base_per_class: 90.3736 (90.9709) 
Training Epoch: [211/1000] Step: [20 / 285] Batch Time: 0.1477 (0.2007) Data Time: 0.0142 (0.0676) Average Loss: 0.3897 (0.3478) Average CE Loss (Source):  0.3897 ( 0.3478) Learning Rate: 0.0250 (0.0250) Top1_base: 85.9375 (90.2734) Top1_base_per_class: 88.4354 (90.4773) 
Training Epoch: [211/1000] Step: [30 / 285] Batch Time: 0.1440 (0.1883) Data Time: 0.0125 (0.0550) Average Loss: 0.2654 (0.3388) Average CE Loss (Source):  0.2654 ( 0.3388) Learning Rate: 0.0250 (0.0250) Top1_base: 94.5312 (90.7031) Top1_base_per_class: 95.2381 (90.9565) 
Training Epoch: [211/1000] Step: [40 / 285] Batch Time: 0.1431 (0.1786) Data Time: 0.0112 (0.0452) Average Loss: 0.2386 (0.3297) Average CE Loss (Source):  0.2386 ( 0.3297) Learning Rate: 0.0250 (0.0250) Top1_base: 92.1875 (90.9961) Top1_base_per_class: 91.5152 (91.1888) 
Training Epoch: [211/1000] Step: [50 / 285] Batch Time: 0.1699 (0.1727) Data Time: 0.0365 (0.0393) Average Loss: 0.3336 (0.3395) Average CE Loss (Source):  0.3336 ( 0.3395) Learning Rate: 0.0250 (0.0250) Top1_base: 94.5312 (90.9531) Top1_base_per_class: 95.5975 (91.2545) 
Training Epoch: [211/1000] Step: [60 / 285] Batch Time: 0.1431 (0.1691) Data Time: 0.0109 (0.0357) Average Loss: 0.3912 (0.3412) Average CE Loss (Source):  0.3912 ( 0.3412) Learning Rate: 0.0250 (0.0250) Top1_base: 92.1875 (91.0156) Top1_base_per_class: 93.5088 (91.3039) 
Training Epoch: [211/1000] Step: [70 / 285] Batch Time: 0.1507 (0.1666) Data Time: 0.0170 (0.0332) Average Loss: 0.3733 (0.3421) Average CE Loss (Source):  0.3733 ( 0.3421) Learning Rate: 0.0250 (0.0250) Top1_base: 89.0625 (90.9040) Top1_base_per_class: 87.0370 (91.1509) 
Training Epoch: [211/1000] Step: [80 / 285] Batch Time: 0.1455 (0.1640) Data Time: 0.0125 (0.0307) Average Loss: 0.3674 (0.3454) Average CE Loss (Source):  0.3674 ( 0.3454) Learning Rate: 0.0250 (0.0250) Top1_base: 88.2812 (90.6836) Top1_base_per_class: 89.4722 (91.0203) 
Training Epoch: [211/1000] Step: [90 / 285] Batch Time: 0.1491 (0.1637) Data Time: 0.0159 (0.0304) Average Loss: 0.2714 (0.3479) Average CE Loss (Source):  0.2714 ( 0.3479) Learning Rate: 0.0250 (0.0250) Top1_base: 94.5312 (90.6684) Top1_base_per_class: 92.1212 (91.0260) 
Training Epoch: [211/1000] Step: [100 / 285] Batch Time: 0.1438 (0.1620) Data Time: 0.0111 (0.0288) Average Loss: 0.4100 (0.3481) Average CE Loss (Source):  0.4100 ( 0.3481) Learning Rate: 0.0250 (0.0250) Top1_base: 87.5000 (90.6094) Top1_base_per_class: 91.3690 (91.0312) 
Training Epoch: [211/1000] Step: [110 / 285] Batch Time: 0.1434 (0.1612) Data Time: 0.0128 (0.0279) Average Loss: 0.4401 (0.3533) Average CE Loss (Source):  0.4401 ( 0.3533) Learning Rate: 0.0250 (0.0250) Top1_base: 86.7188 (90.4119) Top1_base_per_class: 83.9655 (90.8083) 
Training Epoch: [211/1000] Step: [120 / 285] Batch Time: 0.1457 (0.1604) Data Time: 0.0122 (0.0271) Average Loss: 0.4982 (0.3538) Average CE Loss (Source):  0.4982 ( 0.3538) Learning Rate: 0.0250 (0.0250) Top1_base: 83.5938 (90.3646) Top1_base_per_class: 84.3711 (90.7696) 
Training Epoch: [211/1000] Step: [130 / 285] Batch Time: 0.1510 (0.1603) Data Time: 0.0158 (0.0268) Average Loss: 0.3728 (0.3539) Average CE Loss (Source):  0.3728 ( 0.3539) Learning Rate: 0.0250 (0.0250) Top1_base: 90.6250 (90.3185) Top1_base_per_class: 87.5000 (90.7432) 
Training Epoch: [211/1000] Step: [140 / 285] Batch Time: 0.1457 (0.1605) Data Time: 0.0117 (0.0269) Average Loss: 0.3227 (0.3552) Average CE Loss (Source):  0.3227 ( 0.3552) Learning Rate: 0.0250 (0.0250) Top1_base: 88.2812 (90.2958) Top1_base_per_class: 85.9649 (90.6360) 
Training Epoch: [211/1000] Step: [150 / 285] Batch Time: 0.1533 (0.1598) Data Time: 0.0165 (0.0260) Average Loss: 0.3607 (0.3536) Average CE Loss (Source):  0.3607 ( 0.3536) Learning Rate: 0.0250 (0.0250) Top1_base: 88.2812 (90.3021) Top1_base_per_class: 90.5864 (90.6684) 
Training Epoch: [211/1000] Step: [160 / 285] Batch Time: 0.1473 (0.1593) Data Time: 0.0153 (0.0255) Average Loss: 0.4010 (0.3528) Average CE Loss (Source):  0.4010 ( 0.3528) Learning Rate: 0.0250 (0.0250) Top1_base: 90.6250 (90.3516) Top1_base_per_class: 91.1111 (90.7399) 
Training Epoch: [211/1000] Step: [170 / 285] Batch Time: 0.1450 (0.1586) Data Time: 0.0136 (0.0248) Average Loss: 0.3167 (0.3543) Average CE Loss (Source):  0.3167 ( 0.3543) Learning Rate: 0.0250 (0.0250) Top1_base: 92.9688 (90.3309) Top1_base_per_class: 94.1799 (90.6957) 
Training Epoch: [211/1000] Step: [180 / 285] Batch Time: 0.1465 (0.1579) Data Time: 0.0122 (0.0242) Average Loss: 0.3806 (0.3551) Average CE Loss (Source):  0.3806 ( 0.3551) Learning Rate: 0.0250 (0.0250) Top1_base: 85.9375 (90.2821) Top1_base_per_class: 86.6970 (90.6521) 
Training Epoch: [211/1000] Step: [190 / 285] Batch Time: 0.1462 (0.1574) Data Time: 0.0147 (0.0237) Average Loss: 0.2887 (0.3566) Average CE Loss (Source):  0.2887 ( 0.3566) Learning Rate: 0.0250 (0.0250) Top1_base: 90.6250 (90.2179) Top1_base_per_class: 90.5655 (90.5572) 
Training Epoch: [211/1000] Step: [200 / 285] Batch Time: 0.1471 (0.1571) Data Time: 0.0141 (0.0235) Average Loss: 0.4155 (0.3590) Average CE Loss (Source):  0.4155 ( 0.3590) Learning Rate: 0.0250 (0.0250) Top1_base: 87.5000 (90.1445) Top1_base_per_class: 88.3046 (90.4944) 
Training Epoch: [211/1000] Step: [210 / 285] Batch Time: 0.1451 (0.1573) Data Time: 0.0136 (0.0237) Average Loss: 0.2965 (0.3579) Average CE Loss (Source):  0.2965 ( 0.3579) Learning Rate: 0.0250 (0.0250) Top1_base: 92.1875 (90.1823) Top1_base_per_class: 94.2284 (90.5469) 
Training Epoch: [211/1000] Step: [220 / 285] Batch Time: 0.1468 (0.1571) Data Time: 0.0148 (0.0235) Average Loss: 0.3837 (0.3599) Average CE Loss (Source):  0.3837 ( 0.3599) Learning Rate: 0.0250 (0.0250) Top1_base: 89.8438 (90.1562) Top1_base_per_class: 86.7377 (90.5044) 
Training Epoch: [211/1000] Step: [230 / 285] Batch Time: 0.1430 (0.1567) Data Time: 0.0128 (0.0232) Average Loss: 0.6009 (0.3610) Average CE Loss (Source):  0.6009 ( 0.3610) Learning Rate: 0.0250 (0.0250) Top1_base: 82.0312 (90.1359) Top1_base_per_class: 82.7874 (90.5180) 
Training Epoch: [211/1000] Step: [240 / 285] Batch Time: 0.1470 (0.1565) Data Time: 0.0124 (0.0229) Average Loss: 0.4686 (0.3599) Average CE Loss (Source):  0.4686 ( 0.3599) Learning Rate: 0.0250 (0.0250) Top1_base: 85.9375 (90.1823) Top1_base_per_class: 83.3631 (90.5474) 
Training Epoch: [211/1000] Step: [250 / 285] Batch Time: 0.1957 (0.1564) Data Time: 0.0615 (0.0228) Average Loss: 0.3942 (0.3592) Average CE Loss (Source):  0.3942 ( 0.3592) Learning Rate: 0.0250 (0.0250) Top1_base: 89.0625 (90.2156) Top1_base_per_class: 88.5965 (90.5622) 
Training Epoch: [211/1000] Step: [260 / 285] Batch Time: 0.1446 (0.1562) Data Time: 0.0135 (0.0226) Average Loss: 0.3037 (0.3590) Average CE Loss (Source):  0.3037 ( 0.3590) Learning Rate: 0.0250 (0.0250) Top1_base: 91.4062 (90.2494) Top1_base_per_class: 92.4039 (90.6040) 
Training Epoch: [211/1000] Step: [270 / 285] Batch Time: 0.1506 (0.1560) Data Time: 0.0169 (0.0224) Average Loss: 0.3276 (0.3589) Average CE Loss (Source):  0.3276 ( 0.3589) Learning Rate: 0.0250 (0.0250) Top1_base: 92.1875 (90.2546) Top1_base_per_class: 92.5595 (90.6267) 
Training Epoch: [211/1000] Step: [280 / 285] Batch Time: 0.1418 (0.1557) Data Time: 0.0101 (0.0222) Average Loss: 0.3900 (0.3583) Average CE Loss (Source):  0.3900 ( 0.3583) Learning Rate: 0.0250 (0.0250) Top1_base: 89.0625 (90.2455) Top1_base_per_class: 89.1667 (90.6373) 
Training Epoch: [212/1000] Step: [0] Batch Time: 0.1458 (0.1555) Data Time: 0.0116 (0.0220) Average Loss: 0.4737 (0.3592) Average CE Loss (Source):  0.4737 ( 0.3592) Learning Rate: 0.0250 (0.0250) Top1_base: 84.3750 (90.2220) Top1_base_per_class: 83.2051 (90.6061) 
 21%|██        | 212/1000 [2:44:32<10:10:34, 46.49s/it] 21%|██▏       | 213/1000 [2:45:16<10:02:59, 45.97s/it]Training Epoch: [212/1000] Step: [10 / 285] Batch Time: 0.1450 (0.2352) Data Time: 0.0123 (0.1027) Average Loss: 0.3426 (0.3227) Average CE Loss (Source):  0.3426 ( 0.3227) Learning Rate: 0.0250 (0.0250) Top1_base: 90.6250 (91.9531) Top1_base_per_class: 90.1235 (91.4102) 
Training Epoch: [212/1000] Step: [20 / 285] Batch Time: 0.1428 (0.1999) Data Time: 0.0116 (0.0674) Average Loss: 0.3875 (0.3379) Average CE Loss (Source):  0.3875 ( 0.3379) Learning Rate: 0.0250 (0.0250) Top1_base: 87.5000 (91.1328) Top1_base_per_class: 87.6543 (91.2640) 
Training Epoch: [212/1000] Step: [30 / 285] Batch Time: 0.1606 (0.1882) Data Time: 0.0265 (0.0555) Average Loss: 0.4100 (0.3503) Average CE Loss (Source):  0.4100 ( 0.3503) Learning Rate: 0.0250 (0.0250) Top1_base: 87.5000 (90.5469) Top1_base_per_class: 86.7576 (90.6848) 
Training Epoch: [212/1000] Step: [40 / 285] Batch Time: 0.1463 (0.1782) Data Time: 0.0119 (0.0452) Average Loss: 0.2087 (0.3500) Average CE Loss (Source):  0.2087 ( 0.3500) Learning Rate: 0.0250 (0.0250) Top1_base: 95.3125 (90.6055) Top1_base_per_class: 97.3030 (90.7518) 
Training Epoch: [212/1000] Step: [50 / 285] Batch Time: 0.1471 (0.1722) Data Time: 0.0133 (0.0391) Average Loss: 0.3960 (0.3393) Average CE Loss (Source):  0.3960 ( 0.3393) Learning Rate: 0.0250 (0.0250) Top1_base: 89.0625 (90.7812) Top1_base_per_class: 89.4848 (90.7910) 
Training Epoch: [212/1000] Step: [60 / 285] Batch Time: 0.1486 (0.1688) Data Time: 0.0116 (0.0353) Average Loss: 0.2426 (0.3396) Average CE Loss (Source):  0.2426 ( 0.3396) Learning Rate: 0.0250 (0.0250) Top1_base: 94.5312 (90.8073) Top1_base_per_class: 93.9286 (90.7604) 
Training Epoch: [212/1000] Step: [70 / 285] Batch Time: 0.1507 (0.1665) Data Time: 0.0145 (0.0326) Average Loss: 0.3819 (0.3436) Average CE Loss (Source):  0.3819 ( 0.3436) Learning Rate: 0.0250 (0.0250) Top1_base: 88.2812 (90.5580) Top1_base_per_class: 89.3519 (90.5240) 
Training Epoch: [212/1000] Step: [80 / 285] Batch Time: 0.1471 (0.1657) Data Time: 0.0103 (0.0317) Average Loss: 0.2462 (0.3446) Average CE Loss (Source):  0.2462 ( 0.3446) Learning Rate: 0.0250 (0.0250) Top1_base: 92.1875 (90.6055) Top1_base_per_class: 93.7069 (90.6063) 
Training Epoch: [212/1000] Step: [90 / 285] Batch Time: 0.1467 (0.1667) Data Time: 0.0103 (0.0327) Average Loss: 0.3996 (0.3444) Average CE Loss (Source):  0.3996 ( 0.3444) Learning Rate: 0.0250 (0.0250) Top1_base: 90.6250 (90.6250) Top1_base_per_class: 90.1462 (90.6199) 
Training Epoch: [212/1000] Step: [100 / 285] Batch Time: 0.1446 (0.1663) Data Time: 0.0118 (0.0324) Average Loss: 0.2802 (0.3483) Average CE Loss (Source):  0.2802 ( 0.3483) Learning Rate: 0.0250 (0.0250) Top1_base: 92.1875 (90.5469) Top1_base_per_class: 93.1035 (90.6079) 
Training Epoch: [212/1000] Step: [110 / 285] Batch Time: 0.1428 (0.1648) Data Time: 0.0114 (0.0310) Average Loss: 0.4356 (0.3495) Average CE Loss (Source):  0.4356 ( 0.3495) Learning Rate: 0.0250 (0.0250) Top1_base: 87.5000 (90.5753) Top1_base_per_class: 87.9444 (90.6727) 
Training Epoch: [212/1000] Step: [120 / 285] Batch Time: 0.1501 (0.1636) Data Time: 0.0131 (0.0297) Average Loss: 0.3078 (0.3454) Average CE Loss (Source):  0.3078 ( 0.3454) Learning Rate: 0.0250 (0.0250) Top1_base: 89.8438 (90.6380) Top1_base_per_class: 89.1228 (90.6944) 
Training Epoch: [212/1000] Step: [130 / 285] Batch Time: 0.1456 (0.1628) Data Time: 0.0113 (0.0288) Average Loss: 0.2911 (0.3454) Average CE Loss (Source):  0.2911 ( 0.3454) Learning Rate: 0.0250 (0.0250) Top1_base: 89.8438 (90.6070) Top1_base_per_class: 89.4372 (90.7201) 
Training Epoch: [212/1000] Step: [140 / 285] Batch Time: 0.1506 (0.1620) Data Time: 0.0128 (0.0280) Average Loss: 0.2851 (0.3424) Average CE Loss (Source):  0.2851 ( 0.3424) Learning Rate: 0.0250 (0.0250) Top1_base: 92.9688 (90.7310) Top1_base_per_class: 93.7798 (90.9173) 
Training Epoch: [212/1000] Step: [150 / 285] Batch Time: 0.1442 (0.1611) Data Time: 0.0113 (0.0270) Average Loss: 0.4557 (0.3438) Average CE Loss (Source):  0.4557 ( 0.3438) Learning Rate: 0.0250 (0.0250) Top1_base: 87.5000 (90.6823) Top1_base_per_class: 88.4849 (90.9377) 
Training Epoch: [212/1000] Step: [160 / 285] Batch Time: 0.1449 (0.1611) Data Time: 0.0133 (0.0272) Average Loss: 0.4767 (0.3462) Average CE Loss (Source):  0.4767 ( 0.3462) Learning Rate: 0.0250 (0.0250) Top1_base: 86.7188 (90.6543) Top1_base_per_class: 89.1824 (90.9236) 
Training Epoch: [212/1000] Step: [170 / 285] Batch Time: 0.1481 (0.1609) Data Time: 0.0113 (0.0270) Average Loss: 0.3364 (0.3468) Average CE Loss (Source):  0.3364 ( 0.3468) Learning Rate: 0.0250 (0.0250) Top1_base: 90.6250 (90.6250) Top1_base_per_class: 91.3030 (90.8971) 
Training Epoch: [212/1000] Step: [180 / 285] Batch Time: 0.1475 (0.1605) Data Time: 0.0111 (0.0265) Average Loss: 0.2974 (0.3472) Average CE Loss (Source):  0.2974 ( 0.3472) Learning Rate: 0.0250 (0.0250) Top1_base: 90.6250 (90.5816) Top1_base_per_class: 89.6605 (90.8726) 
Training Epoch: [212/1000] Step: [190 / 285] Batch Time: 0.1462 (0.1599) Data Time: 0.0124 (0.0260) Average Loss: 0.5178 (0.3485) Average CE Loss (Source):  0.5178 ( 0.3485) Learning Rate: 0.0250 (0.0250) Top1_base: 86.7188 (90.5551) Top1_base_per_class: 85.2924 (90.8880) 
Training Epoch: [212/1000] Step: [200 / 285] Batch Time: 0.1481 (0.1595) Data Time: 0.0114 (0.0255) Average Loss: 0.3044 (0.3494) Average CE Loss (Source):  0.3044 ( 0.3494) Learning Rate: 0.0250 (0.0250) Top1_base: 91.4062 (90.5195) Top1_base_per_class: 91.5497 (90.8835) 
Training Epoch: [212/1000] Step: [210 / 285] Batch Time: 0.1477 (0.1590) Data Time: 0.0118 (0.0250) Average Loss: 0.3669 (0.3501) Average CE Loss (Source):  0.3669 ( 0.3501) Learning Rate: 0.0250 (0.0250) Top1_base: 89.8438 (90.5022) Top1_base_per_class: 92.5706 (90.8585) 
Training Epoch: [212/1000] Step: [220 / 285] Batch Time: 0.1484 (0.1588) Data Time: 0.0107 (0.0247) Average Loss: 0.3313 (0.3495) Average CE Loss (Source):  0.3313 ( 0.3495) Learning Rate: 0.0250 (0.0250) Top1_base: 92.9688 (90.5327) Top1_base_per_class: 94.2857 (90.8995) 
Training Epoch: [212/1000] Step: [230 / 285] Batch Time: 0.1430 (0.1584) Data Time: 0.0127 (0.0243) Average Loss: 0.3959 (0.3500) Average CE Loss (Source):  0.3959 ( 0.3500) Learning Rate: 0.0250 (0.0250) Top1_base: 92.9688 (90.5231) Top1_base_per_class: 94.4340 (90.8582) 
Training Epoch: [212/1000] Step: [240 / 285] Batch Time: 0.1483 (0.1583) Data Time: 0.0116 (0.0242) Average Loss: 0.4350 (0.3500) Average CE Loss (Source):  0.4350 ( 0.3500) Learning Rate: 0.0250 (0.0250) Top1_base: 87.5000 (90.5404) Top1_base_per_class: 89.9717 (90.8922) 
Training Epoch: [212/1000] Step: [250 / 285] Batch Time: 0.1494 (0.1579) Data Time: 0.0122 (0.0238) Average Loss: 0.3746 (0.3505) Average CE Loss (Source):  0.3746 ( 0.3505) Learning Rate: 0.0250 (0.0250) Top1_base: 89.8438 (90.5156) Top1_base_per_class: 87.3636 (90.8433) 
Training Epoch: [212/1000] Step: [260 / 285] Batch Time: 0.1433 (0.1575) Data Time: 0.0138 (0.0234) Average Loss: 0.4548 (0.3510) Average CE Loss (Source):  0.4548 ( 0.3510) Learning Rate: 0.0250 (0.0250) Top1_base: 87.5000 (90.5048) Top1_base_per_class: 87.5731 (90.8407) 
Training Epoch: [212/1000] Step: [270 / 285] Batch Time: 0.1477 (0.1573) Data Time: 0.0110 (0.0232) Average Loss: 0.2977 (0.3519) Average CE Loss (Source):  0.2977 ( 0.3519) Learning Rate: 0.0250 (0.0250) Top1_base: 91.4062 (90.4543) Top1_base_per_class: 91.3629 (90.7850) 
Training Epoch: [212/1000] Step: [280 / 285] Batch Time: 0.1473 (0.1570) Data Time: 0.0109 (0.0229) Average Loss: 0.2700 (0.3516) Average CE Loss (Source):  0.2700 ( 0.3516) Learning Rate: 0.0250 (0.0250) Top1_base: 93.7500 (90.4799) Top1_base_per_class: 92.6282 (90.7976) 
Training Epoch: [213/1000] Step: [0] Batch Time: 0.1475 (0.1568) Data Time: 0.0130 (0.0227) Average Loss: 0.3015 (0.3513) Average CE Loss (Source):  0.3015 ( 0.3513) Learning Rate: 0.0250 (0.0250) Top1_base: 92.1875 (90.4852) Top1_base_per_class: 92.7576 (90.7968) 
Training Epoch: [213/1000] Step: [10 / 285] Batch Time: 0.1437 (0.2284) Data Time: 0.0120 (0.0966) Average Loss: 0.4322 (0.3197) Average CE Loss (Source):  0.4322 ( 0.3197) Learning Rate: 0.0250 (0.0250) Top1_base: 84.3750 (90.8594) Top1_base_per_class: 85.4310 (91.0312) 
Training Epoch: [213/1000] Step: [20 / 285] Batch Time: 0.1439 (0.1931) Data Time: 0.0105 (0.0612) Average Loss: 0.4215 (0.3397) Average CE Loss (Source):  0.4215 ( 0.3397) Learning Rate: 0.0250 (0.0250) Top1_base: 88.2812 (90.6250) Top1_base_per_class: 87.8205 (90.2116) 
Training Epoch: [213/1000] Step: [30 / 285] Batch Time: 0.1443 (0.1825) Data Time: 0.0104 (0.0504) Average Loss: 0.3078 (0.3388) Average CE Loss (Source):  0.3078 ( 0.3388) Learning Rate: 0.0250 (0.0250) Top1_base: 92.9688 (90.6250) Top1_base_per_class: 94.8485 (90.4484) 
Training Epoch: [213/1000] Step: [40 / 285] Batch Time: 0.1485 (0.1744) Data Time: 0.0133 (0.0414) Average Loss: 0.4745 (0.3460) Average CE Loss (Source):  0.4745 ( 0.3460) Learning Rate: 0.0250 (0.0250) Top1_base: 89.0625 (90.4492) Top1_base_per_class: 86.9940 (90.3240) 
Training Epoch: [213/1000] Step: [50 / 285] Batch Time: 0.1443 (0.1706) Data Time: 0.0123 (0.0377) Average Loss: 0.2737 (0.3502) Average CE Loss (Source):  0.2737 ( 0.3502) Learning Rate: 0.0250 (0.0250) Top1_base: 92.9688 (90.4844) Top1_base_per_class: 94.8485 (90.4229) 
Training Epoch: [213/1000] Step: [60 / 285] Batch Time: 0.1452 (0.1682) Data Time: 0.0123 (0.0354) Average Loss: 0.4243 (0.3521) Average CE Loss (Source):  0.4243 ( 0.3521) Learning Rate: 0.0250 (0.0250) Top1_base: 89.0625 (90.3516) Top1_base_per_class: 89.7487 (90.5045) 
Training Epoch: [213/1000] Step: [70 / 285] Batch Time: 0.1463 (0.1655) Data Time: 0.0115 (0.0326) Average Loss: 0.3667 (0.3565) Average CE Loss (Source):  0.3667 ( 0.3565) Learning Rate: 0.0250 (0.0250) Top1_base: 90.6250 (90.2344) Top1_base_per_class: 90.2516 (90.3669) 
Training Epoch: [213/1000] Step: [80 / 285] Batch Time: 0.1475 (0.1636) Data Time: 0.0143 (0.0306) Average Loss: 0.4432 (0.3577) Average CE Loss (Source):  0.4432 ( 0.3577) Learning Rate: 0.0250 (0.0250) Top1_base: 87.5000 (90.2051) Top1_base_per_class: 88.1818 (90.3767) 
Training Epoch: [213/1000] Step: [90 / 285] Batch Time: 0.1431 (0.1622) Data Time: 0.0121 (0.0293) Average Loss: 0.2380 (0.3536) Average CE Loss (Source):  0.2380 ( 0.3536) Learning Rate: 0.0250 (0.0250) Top1_base: 92.9688 (90.2865) Top1_base_per_class: 93.2440 (90.4583) 
Training Epoch: [213/1000] Step: [100 / 285] Batch Time: 0.1465 (0.1619) Data Time: 0.0124 (0.0290) Average Loss: 0.3713 (0.3550) Average CE Loss (Source):  0.3713 ( 0.3550) Learning Rate: 0.0250 (0.0250) Top1_base: 89.8438 (90.3516) Top1_base_per_class: 88.3291 (90.4643) 
Training Epoch: [213/1000] Step: [110 / 285] Batch Time: 0.1454 (0.1605) Data Time: 0.0107 (0.0276) Average Loss: 0.3615 (0.3540) Average CE Loss (Source):  0.3615 ( 0.3540) Learning Rate: 0.0250 (0.0250) Top1_base: 89.8438 (90.3338) Top1_base_per_class: 90.9357 (90.5222) 
Training Epoch: [213/1000] Step: [120 / 285] Batch Time: 0.1461 (0.1592) Data Time: 0.0122 (0.0264) Average Loss: 0.4176 (0.3519) Average CE Loss (Source):  0.4176 ( 0.3519) Learning Rate: 0.0250 (0.0250) Top1_base: 89.0625 (90.3971) Top1_base_per_class: 89.5763 (90.5566) 
Training Epoch: [213/1000] Step: [130 / 285] Batch Time: 0.1462 (0.1594) Data Time: 0.0117 (0.0266) Average Loss: 0.4694 (0.3528) Average CE Loss (Source):  0.4694 ( 0.3528) Learning Rate: 0.0250 (0.0250) Top1_base: 89.0625 (90.3846) Top1_base_per_class: 89.6970 (90.5051) 
Training Epoch: [213/1000] Step: [140 / 285] Batch Time: 0.1926 (0.1594) Data Time: 0.0564 (0.0265) Average Loss: 0.3136 (0.3514) Average CE Loss (Source):  0.3136 ( 0.3514) Learning Rate: 0.0250 (0.0250) Top1_base: 92.9688 (90.4408) Top1_base_per_class: 94.0936 (90.6061) 
Training Epoch: [213/1000] Step: [150 / 285] Batch Time: 0.1462 (0.1594) Data Time: 0.0111 (0.0264) Average Loss: 0.3055 (0.3533) Average CE Loss (Source):  0.3055 ( 0.3533) Learning Rate: 0.0250 (0.0250) Top1_base: 90.6250 (90.3802) Top1_base_per_class: 90.9524 (90.5511) 
Training Epoch: [213/1000] Step: [160 / 285] Batch Time: 0.1720 (0.1596) Data Time: 0.0399 (0.0266) Average Loss: 0.4568 (0.3519) Average CE Loss (Source):  0.4568 ( 0.3519) Learning Rate: 0.0250 (0.0250) Top1_base: 89.0625 (90.4492) Top1_base_per_class: 87.5000 (90.6257) 
Training Epoch: [213/1000] Step: [170 / 285] Batch Time: 0.1497 (0.1594) Data Time: 0.0155 (0.0265) Average Loss: 0.3883 (0.3516) Average CE Loss (Source):  0.3883 ( 0.3516) Learning Rate: 0.0250 (0.0250) Top1_base: 90.6250 (90.4917) Top1_base_per_class: 92.4235 (90.6565) 
Training Epoch: [213/1000] Step: [180 / 285] Batch Time: 0.1965 (0.1590) Data Time: 0.0633 (0.0261) Average Loss: 0.4572 (0.3528) Average CE Loss (Source):  0.4572 ( 0.3528) Learning Rate: 0.0250 (0.0250) Top1_base: 87.5000 (90.4818) Top1_base_per_class: 88.9815 (90.7033) 
Training Epoch: [213/1000] Step: [190 / 285] Batch Time: 0.1470 (0.1593) Data Time: 0.0117 (0.0264) Average Loss: 0.2225 (0.3531) Average CE Loss (Source):  0.2225 ( 0.3531) Learning Rate: 0.0250 (0.0250) Top1_base: 92.1875 (90.4770) Top1_base_per_class: 93.2471 (90.7277) 
Training Epoch: [213/1000] Step: [200 / 285] Batch Time: 0.1591 (0.1588) Data Time: 0.0274 (0.0259) Average Loss: 0.2320 (0.3519) Average CE Loss (Source):  0.2320 ( 0.3519) Learning Rate: 0.0250 (0.0250) Top1_base: 94.5312 (90.5312) Top1_base_per_class: 96.9048 (90.8196) 
Training Epoch: [213/1000] Step: [210 / 285] Batch Time: 0.1466 (0.1586) Data Time: 0.0120 (0.0258) Average Loss: 0.3191 (0.3523) Average CE Loss (Source):  0.3191 ( 0.3523) Learning Rate: 0.0250 (0.0250) Top1_base: 89.8438 (90.5283) Top1_base_per_class: 88.5417 (90.8245) 
Training Epoch: [213/1000] Step: [220 / 285] Batch Time: 0.1983 (0.1585) Data Time: 0.0664 (0.0256) Average Loss: 0.4931 (0.3529) Average CE Loss (Source):  0.4931 ( 0.3529) Learning Rate: 0.0250 (0.0250) Top1_base: 87.5000 (90.4972) Top1_base_per_class: 86.9811 (90.7861) 
Training Epoch: [213/1000] Step: [230 / 285] Batch Time: 0.1452 (0.1580) Data Time: 0.0114 (0.0251) Average Loss: 0.3642 (0.3530) Average CE Loss (Source):  0.3642 ( 0.3530) Learning Rate: 0.0250 (0.0250) Top1_base: 89.8438 (90.4891) Top1_base_per_class: 88.2440 (90.7492) 
Training Epoch: [213/1000] Step: [240 / 285] Batch Time: 0.2548 (0.1582) Data Time: 0.1235 (0.0253) Average Loss: 0.3566 (0.3532) Average CE Loss (Source):  0.3566 ( 0.3532) Learning Rate: 0.0250 (0.0250) Top1_base: 89.0625 (90.4720) Top1_base_per_class: 87.8122 (90.7188) 
Training Epoch: [213/1000] Step: [250 / 285] Batch Time: 0.1482 (0.1578) Data Time: 0.0144 (0.0250) Average Loss: 0.3090 (0.3521) Average CE Loss (Source):  0.3090 ( 0.3521) Learning Rate: 0.0250 (0.0250) Top1_base: 92.1875 (90.5000) Top1_base_per_class: 94.1369 (90.7672) 
Training Epoch: [213/1000] Step: [260 / 285] Batch Time: 0.1575 (0.1577) Data Time: 0.0250 (0.0249) Average Loss: 0.2525 (0.3527) Average CE Loss (Source):  0.2525 ( 0.3527) Learning Rate: 0.0250 (0.0250) Top1_base: 93.7500 (90.4898) Top1_base_per_class: 91.3690 (90.7456) 
Training Epoch: [213/1000] Step: [270 / 285] Batch Time: 0.1424 (0.1577) Data Time: 0.0117 (0.0249) Average Loss: 0.2358 (0.3541) Average CE Loss (Source):  0.2358 ( 0.3541) Learning Rate: 0.0250 (0.0250) Top1_base: 94.5312 (90.4601) Top1_base_per_class: 94.5763 (90.7188) 
Training Epoch: [213/1000] Step: [280 / 285] Batch Time: 0.1516 (0.1575) Data Time: 0.0197 (0.0247) Average Loss: 0.3635 (0.3547) Average CE Loss (Source):  0.3635 ( 0.3547) Learning Rate: 0.0250 (0.0250) Top1_base: 89.8438 (90.4604) Top1_base_per_class: 91.9006 (90.7483) 
Training Epoch: [214/1000] Step: [0] Batch Time: 0.1457 (0.1575) Data Time: 0.0137 (0.0248) Average Loss: 0.2335 (0.3543) Average CE Loss (Source):  0.2335 ( 0.3543) Learning Rate: 0.0250 (0.0250) Top1_base: 92.1875 (90.4797) Top1_base_per_class: 91.3158 (90.7616) 
 21%|██▏       | 214/1000 [2:46:04<10:09:03, 46.49s/it] 22%|██▏       | 215/1000 [2:46:49<10:02:09, 46.02s/it]Training Epoch: [214/1000] Step: [10 / 285] Batch Time: 0.1470 (0.2492) Data Time: 0.0115 (0.1156) Average Loss: 0.3580 (0.3148) Average CE Loss (Source):  0.3580 ( 0.3148) Learning Rate: 0.0250 (0.0250) Top1_base: 91.4062 (91.4062) Top1_base_per_class: 91.7576 (91.6967) 
Training Epoch: [214/1000] Step: [20 / 285] Batch Time: 0.1475 (0.2044) Data Time: 0.0128 (0.0706) Average Loss: 0.2736 (0.3348) Average CE Loss (Source):  0.2736 ( 0.3348) Learning Rate: 0.0250 (0.0250) Top1_base: 94.5312 (91.0938) Top1_base_per_class: 94.9708 (91.1882) 
Training Epoch: [214/1000] Step: [30 / 285] Batch Time: 0.1444 (0.1890) Data Time: 0.0130 (0.0553) Average Loss: 0.3101 (0.3318) Average CE Loss (Source):  0.3101 ( 0.3318) Learning Rate: 0.0250 (0.0250) Top1_base: 92.9688 (91.3021) Top1_base_per_class: 93.2390 (91.6436) 
Training Epoch: [214/1000] Step: [40 / 285] Batch Time: 0.1489 (0.1801) Data Time: 0.0142 (0.0464) Average Loss: 0.4504 (0.3338) Average CE Loss (Source):  0.4504 ( 0.3338) Learning Rate: 0.0250 (0.0250) Top1_base: 86.7188 (91.1133) Top1_base_per_class: 85.4167 (91.4845) 
Training Epoch: [214/1000] Step: [50 / 285] Batch Time: 0.1448 (0.1751) Data Time: 0.0108 (0.0415) Average Loss: 0.3406 (0.3267) Average CE Loss (Source):  0.3406 ( 0.3267) Learning Rate: 0.0250 (0.0250) Top1_base: 92.1875 (91.4844) Top1_base_per_class: 92.7222 (91.8227) 
Training Epoch: [214/1000] Step: [60 / 285] Batch Time: 0.1437 (0.1711) Data Time: 0.0120 (0.0375) Average Loss: 0.3155 (0.3268) Average CE Loss (Source):  0.3155 ( 0.3268) Learning Rate: 0.0250 (0.0250) Top1_base: 91.4062 (91.4844) Top1_base_per_class: 90.4321 (91.9080) 
Training Epoch: [214/1000] Step: [70 / 285] Batch Time: 0.1448 (0.1683) Data Time: 0.0115 (0.0349) Average Loss: 0.2871 (0.3291) Average CE Loss (Source):  0.2871 ( 0.3291) Learning Rate: 0.0250 (0.0250) Top1_base: 89.8438 (91.3058) Top1_base_per_class: 92.5157 (91.7417) 
Training Epoch: [214/1000] Step: [80 / 285] Batch Time: 0.1428 (0.1669) Data Time: 0.0122 (0.0337) Average Loss: 0.2650 (0.3260) Average CE Loss (Source):  0.2650 ( 0.3260) Learning Rate: 0.0250 (0.0250) Top1_base: 92.9688 (91.3574) Top1_base_per_class: 91.6061 (91.7831) 
Training Epoch: [214/1000] Step: [90 / 285] Batch Time: 0.1446 (0.1655) Data Time: 0.0106 (0.0323) Average Loss: 0.3683 (0.3237) Average CE Loss (Source):  0.3683 ( 0.3237) Learning Rate: 0.0250 (0.0250) Top1_base: 89.0625 (91.4323) Top1_base_per_class: 89.7701 (91.8480) 
Training Epoch: [214/1000] Step: [100 / 285] Batch Time: 0.1484 (0.1643) Data Time: 0.0134 (0.0310) Average Loss: 0.3502 (0.3259) Average CE Loss (Source):  0.3502 ( 0.3259) Learning Rate: 0.0250 (0.0250) Top1_base: 90.6250 (91.3828) Top1_base_per_class: 91.1775 (91.7856) 
Training Epoch: [214/1000] Step: [110 / 285] Batch Time: 0.1467 (0.1637) Data Time: 0.0115 (0.0304) Average Loss: 0.3083 (0.3278) Average CE Loss (Source):  0.3083 ( 0.3278) Learning Rate: 0.0250 (0.0250) Top1_base: 91.4062 (91.3565) Top1_base_per_class: 93.4242 (91.7969) 
Training Epoch: [214/1000] Step: [120 / 285] Batch Time: 0.1469 (0.1623) Data Time: 0.0119 (0.0290) Average Loss: 0.3977 (0.3308) Average CE Loss (Source):  0.3977 ( 0.3308) Learning Rate: 0.0250 (0.0250) Top1_base: 89.8438 (91.2240) Top1_base_per_class: 90.6250 (91.6397) 
Training Epoch: [214/1000] Step: [130 / 285] Batch Time: 0.1464 (0.1618) Data Time: 0.0115 (0.0285) Average Loss: 0.4340 (0.3303) Average CE Loss (Source):  0.4340 ( 0.3303) Learning Rate: 0.0250 (0.0250) Top1_base: 83.5938 (91.2320) Top1_base_per_class: 82.1930 (91.6019) 
Training Epoch: [214/1000] Step: [140 / 285] Batch Time: 0.1519 (0.1614) Data Time: 0.0147 (0.0280) Average Loss: 0.3226 (0.3307) Average CE Loss (Source):  0.3226 ( 0.3307) Learning Rate: 0.0250 (0.0250) Top1_base: 91.4062 (91.1942) Top1_base_per_class: 91.8333 (91.6111) 
Training Epoch: [214/1000] Step: [150 / 285] Batch Time: 0.1465 (0.1608) Data Time: 0.0112 (0.0272) Average Loss: 0.3690 (0.3315) Average CE Loss (Source):  0.3690 ( 0.3315) Learning Rate: 0.0250 (0.0250) Top1_base: 90.6250 (91.2031) Top1_base_per_class: 90.2516 (91.6117) 
Training Epoch: [214/1000] Step: [160 / 285] Batch Time: 0.1507 (0.1602) Data Time: 0.0145 (0.0264) Average Loss: 0.3561 (0.3315) Average CE Loss (Source):  0.3561 ( 0.3315) Learning Rate: 0.0250 (0.0250) Top1_base: 86.7188 (91.1426) Top1_base_per_class: 87.3214 (91.5081) 
Training Epoch: [214/1000] Step: [170 / 285] Batch Time: 0.1597 (0.1599) Data Time: 0.0269 (0.0260) Average Loss: 0.3952 (0.3318) Average CE Loss (Source):  0.3952 ( 0.3318) Learning Rate: 0.0250 (0.0250) Top1_base: 89.8438 (91.1719) Top1_base_per_class: 91.9281 (91.5182) 
Training Epoch: [214/1000] Step: [180 / 285] Batch Time: 0.1481 (0.1593) Data Time: 0.0131 (0.0253) Average Loss: 0.4992 (0.3323) Average CE Loss (Source):  0.4992 ( 0.3323) Learning Rate: 0.0250 (0.0250) Top1_base: 88.2812 (91.1632) Top1_base_per_class: 91.2554 (91.5382) 
Training Epoch: [214/1000] Step: [190 / 285] Batch Time: 0.1451 (0.1590) Data Time: 0.0140 (0.0250) Average Loss: 0.2445 (0.3322) Average CE Loss (Source):  0.2445 ( 0.3322) Learning Rate: 0.0250 (0.0250) Top1_base: 91.4062 (91.1390) Top1_base_per_class: 89.2262 (91.5026) 
Training Epoch: [214/1000] Step: [200 / 285] Batch Time: 0.1428 (0.1586) Data Time: 0.0122 (0.0247) Average Loss: 0.3875 (0.3344) Average CE Loss (Source):  0.3875 ( 0.3344) Learning Rate: 0.0250 (0.0250) Top1_base: 88.2812 (91.0352) Top1_base_per_class: 91.3418 (91.4362) 
Training Epoch: [214/1000] Step: [210 / 285] Batch Time: 0.1452 (0.1583) Data Time: 0.0143 (0.0245) Average Loss: 0.4632 (0.3370) Average CE Loss (Source):  0.4632 ( 0.3370) Learning Rate: 0.0250 (0.0250) Top1_base: 86.7188 (90.9412) Top1_base_per_class: 84.9691 (91.2876) 
Training Epoch: [214/1000] Step: [220 / 285] Batch Time: 0.1510 (0.1583) Data Time: 0.0149 (0.0244) Average Loss: 0.3082 (0.3373) Average CE Loss (Source):  0.3082 ( 0.3373) Learning Rate: 0.0250 (0.0250) Top1_base: 91.4062 (90.9411) Top1_base_per_class: 91.8966 (91.2815) 
Training Epoch: [214/1000] Step: [230 / 285] Batch Time: 0.1451 (0.1580) Data Time: 0.0105 (0.0241) Average Loss: 0.3461 (0.3374) Average CE Loss (Source):  0.3461 ( 0.3374) Learning Rate: 0.0250 (0.0250) Top1_base: 89.8438 (90.9137) Top1_base_per_class: 88.8235 (91.2350) 
Training Epoch: [214/1000] Step: [240 / 285] Batch Time: 0.1430 (0.1577) Data Time: 0.0116 (0.0239) Average Loss: 0.2811 (0.3394) Average CE Loss (Source):  0.2811 ( 0.3394) Learning Rate: 0.0250 (0.0250) Top1_base: 92.1875 (90.8659) Top1_base_per_class: 94.2857 (91.1931) 
Training Epoch: [214/1000] Step: [250 / 285] Batch Time: 0.1439 (0.1574) Data Time: 0.0128 (0.0236) Average Loss: 0.2684 (0.3397) Average CE Loss (Source):  0.2684 ( 0.3397) Learning Rate: 0.0250 (0.0250) Top1_base: 94.5312 (90.8500) Top1_base_per_class: 95.1786 (91.1743) 
Training Epoch: [214/1000] Step: [260 / 285] Batch Time: 0.1491 (0.1575) Data Time: 0.0144 (0.0237) Average Loss: 0.4047 (0.3404) Average CE Loss (Source):  0.4047 ( 0.3404) Learning Rate: 0.0250 (0.0250) Top1_base: 88.2812 (90.8293) Top1_base_per_class: 88.5417 (91.1280) 
Training Epoch: [214/1000] Step: [270 / 285] Batch Time: 0.1429 (0.1579) Data Time: 0.0105 (0.0241) Average Loss: 0.4692 (0.3415) Average CE Loss (Source):  0.4692 ( 0.3415) Learning Rate: 0.0250 (0.0250) Top1_base: 89.0625 (90.8218) Top1_base_per_class: 85.9091 (91.1270) 
Training Epoch: [214/1000] Step: [280 / 285] Batch Time: 0.1473 (0.1576) Data Time: 0.0138 (0.0238) Average Loss: 0.3405 (0.3417) Average CE Loss (Source):  0.3405 ( 0.3417) Learning Rate: 0.0250 (0.0250) Top1_base: 89.8438 (90.8203) Top1_base_per_class: 90.3704 (91.1245) 
Training Epoch: [215/1000] Step: [0] Batch Time: 0.1424 (0.1574) Data Time: 0.0100 (0.0237) Average Loss: 0.3647 (0.3420) Average CE Loss (Source):  0.3647 ( 0.3420) Learning Rate: 0.0250 (0.0250) Top1_base: 89.8438 (90.8004) Top1_base_per_class: 89.5029 (91.0903) 
Training Epoch: [215/1000] Step: [10 / 285] Batch Time: 0.1499 (0.2315) Data Time: 0.0149 (0.0992) Average Loss: 0.3197 (0.3511) Average CE Loss (Source):  0.3197 ( 0.3511) Learning Rate: 0.0250 (0.0250) Top1_base: 90.6250 (89.7656) Top1_base_per_class: 92.3636 (90.4881) 
Training Epoch: [215/1000] Step: [20 / 285] Batch Time: 0.1406 (0.1940) Data Time: 0.0099 (0.0618) Average Loss: 0.3801 (0.3697) Average CE Loss (Source):  0.3801 ( 0.3697) Learning Rate: 0.0250 (0.0250) Top1_base: 86.7188 (89.6094) Top1_base_per_class: 86.1861 (89.7853) 
Training Epoch: [215/1000] Step: [30 / 285] Batch Time: 0.1437 (0.1841) Data Time: 0.0111 (0.0517) Average Loss: 0.3914 (0.3614) Average CE Loss (Source):  0.3914 ( 0.3614) Learning Rate: 0.0250 (0.0250) Top1_base: 89.0625 (90.0000) Top1_base_per_class: 90.5660 (90.0028) 
Training Epoch: [215/1000] Step: [40 / 285] Batch Time: 0.1436 (0.1766) Data Time: 0.0120 (0.0437) Average Loss: 0.2466 (0.3497) Average CE Loss (Source):  0.2466 ( 0.3497) Learning Rate: 0.0250 (0.0250) Top1_base: 96.8750 (90.4102) Top1_base_per_class: 97.2727 (90.2126) 
Training Epoch: [215/1000] Step: [50 / 285] Batch Time: 0.1463 (0.1723) Data Time: 0.0128 (0.0394) Average Loss: 0.3863 (0.3613) Average CE Loss (Source):  0.3863 ( 0.3613) Learning Rate: 0.0250 (0.0250) Top1_base: 90.6250 (90.2969) Top1_base_per_class: 92.1088 (90.1923) 
Training Epoch: [215/1000] Step: [60 / 285] Batch Time: 0.1451 (0.1708) Data Time: 0.0118 (0.0379) Average Loss: 0.3742 (0.3630) Average CE Loss (Source):  0.3742 ( 0.3630) Learning Rate: 0.0250 (0.0250) Top1_base: 87.5000 (90.2474) Top1_base_per_class: 88.7736 (90.2243) 
Training Epoch: [215/1000] Step: [70 / 285] Batch Time: 0.2210 (0.1694) Data Time: 0.0909 (0.0365) Average Loss: 0.4641 (0.3573) Average CE Loss (Source):  0.4641 ( 0.3573) Learning Rate: 0.0250 (0.0250) Top1_base: 90.6250 (90.4911) Top1_base_per_class: 91.8590 (90.5471) 
Training Epoch: [215/1000] Step: [80 / 285] Batch Time: 0.1498 (0.1677) Data Time: 0.0145 (0.0347) Average Loss: 0.2278 (0.3554) Average CE Loss (Source):  0.2278 ( 0.3554) Learning Rate: 0.0250 (0.0250) Top1_base: 93.7500 (90.5566) Top1_base_per_class: 91.6667 (90.6435) 
Training Epoch: [215/1000] Step: [90 / 285] Batch Time: 0.2270 (0.1674) Data Time: 0.0916 (0.0342) Average Loss: 0.3450 (0.3524) Average CE Loss (Source):  0.3450 ( 0.3524) Learning Rate: 0.0250 (0.0250) Top1_base: 89.8438 (90.6424) Top1_base_per_class: 92.0833 (90.7643) 
Training Epoch: [215/1000] Step: [100 / 285] Batch Time: 0.1491 (0.1662) Data Time: 0.0152 (0.0329) Average Loss: 0.3309 (0.3489) Average CE Loss (Source):  0.3309 ( 0.3489) Learning Rate: 0.0250 (0.0250) Top1_base: 89.8438 (90.7344) Top1_base_per_class: 92.9825 (90.9520) 
Training Epoch: [215/1000] Step: [110 / 285] Batch Time: 0.1776 (0.1654) Data Time: 0.0447 (0.0321) Average Loss: 0.3407 (0.3481) Average CE Loss (Source):  0.3407 ( 0.3481) Learning Rate: 0.0250 (0.0250) Top1_base: 91.4062 (90.6960) Top1_base_per_class: 92.1698 (90.9472) 
Training Epoch: [215/1000] Step: [120 / 285] Batch Time: 0.1481 (0.1655) Data Time: 0.0134 (0.0321) Average Loss: 0.3400 (0.3461) Average CE Loss (Source):  0.3400 ( 0.3461) Learning Rate: 0.0250 (0.0250) Top1_base: 89.8438 (90.7422) Top1_base_per_class: 91.4545 (91.0248) 
Training Epoch: [215/1000] Step: [130 / 285] Batch Time: 0.1489 (0.1644) Data Time: 0.0173 (0.0311) Average Loss: 0.4226 (0.3473) Average CE Loss (Source):  0.4226 ( 0.3473) Learning Rate: 0.0250 (0.0250) Top1_base: 89.0625 (90.7873) Top1_base_per_class: 88.8055 (91.0642) 
Training Epoch: [215/1000] Step: [140 / 285] Batch Time: 0.1471 (0.1634) Data Time: 0.0120 (0.0301) Average Loss: 0.3998 (0.3472) Average CE Loss (Source):  0.3998 ( 0.3472) Learning Rate: 0.0250 (0.0250) Top1_base: 89.0625 (90.7645) Top1_base_per_class: 89.5115 (91.0177) 
Training Epoch: [215/1000] Step: [150 / 285] Batch Time: 0.1884 (0.1628) Data Time: 0.0561 (0.0295) Average Loss: 0.3252 (0.3465) Average CE Loss (Source):  0.3252 ( 0.3465) Learning Rate: 0.0250 (0.0250) Top1_base: 91.4062 (90.7708) Top1_base_per_class: 91.7901 (91.0287) 
Training Epoch: [215/1000] Step: [160 / 285] Batch Time: 0.1427 (0.1623) Data Time: 0.0117 (0.0290) Average Loss: 0.2825 (0.3484) Average CE Loss (Source):  0.2825 ( 0.3484) Learning Rate: 0.0250 (0.0250) Top1_base: 92.1875 (90.7080) Top1_base_per_class: 94.5115 (90.9792) 
Training Epoch: [215/1000] Step: [170 / 285] Batch Time: 0.2373 (0.1627) Data Time: 0.1043 (0.0294) Average Loss: 0.2182 (0.3466) Average CE Loss (Source):  0.2182 ( 0.3466) Learning Rate: 0.0250 (0.0250) Top1_base: 97.6562 (90.7812) Top1_base_per_class: 98.0864 (91.0344) 
Training Epoch: [215/1000] Step: [180 / 285] Batch Time: 0.1480 (0.1621) Data Time: 0.0144 (0.0288) Average Loss: 0.3748 (0.3471) Average CE Loss (Source):  0.3748 ( 0.3471) Learning Rate: 0.0250 (0.0250) Top1_base: 89.0625 (90.7161) Top1_base_per_class: 90.3801 (91.0005) 
Training Epoch: [215/1000] Step: [190 / 285] Batch Time: 0.1510 (0.1616) Data Time: 0.0188 (0.0284) Average Loss: 0.4952 (0.3492) Average CE Loss (Source):  0.4952 ( 0.3492) Learning Rate: 0.0250 (0.0250) Top1_base: 91.4062 (90.6826) Top1_base_per_class: 89.7879 (90.9571) 
Training Epoch: [215/1000] Step: [200 / 285] Batch Time: 0.1422 (0.1609) Data Time: 0.0119 (0.0277) Average Loss: 0.2919 (0.3502) Average CE Loss (Source):  0.2919 ( 0.3502) Learning Rate: 0.0250 (0.0250) Top1_base: 92.1875 (90.6680) Top1_base_per_class: 92.6488 (90.9441) 
Training Epoch: [215/1000] Step: [210 / 285] Batch Time: 0.2487 (0.1608) Data Time: 0.1174 (0.0276) Average Loss: 0.2269 (0.3496) Average CE Loss (Source):  0.2269 ( 0.3496) Learning Rate: 0.0250 (0.0250) Top1_base: 94.5312 (90.6957) Top1_base_per_class: 95.0893 (90.9469) 
Training Epoch: [215/1000] Step: [220 / 285] Batch Time: 0.1479 (0.1608) Data Time: 0.0141 (0.0276) Average Loss: 0.3586 (0.3491) Average CE Loss (Source):  0.3586 ( 0.3491) Learning Rate: 0.0250 (0.0250) Top1_base: 91.4062 (90.7280) Top1_base_per_class: 91.9444 (90.9858) 
Training Epoch: [215/1000] Step: [230 / 285] Batch Time: 0.1515 (0.1602) Data Time: 0.0211 (0.0270) Average Loss: 0.3643 (0.3482) Average CE Loss (Source):  0.3643 ( 0.3482) Learning Rate: 0.0250 (0.0250) Top1_base: 92.1875 (90.7745) Top1_base_per_class: 93.7208 (91.0373) 
Training Epoch: [215/1000] Step: [240 / 285] Batch Time: 0.1463 (0.1599) Data Time: 0.0120 (0.0267) Average Loss: 0.3969 (0.3488) Average CE Loss (Source):  0.3969 ( 0.3488) Learning Rate: 0.0250 (0.0250) Top1_base: 88.2812 (90.7650) Top1_base_per_class: 88.2440 (91.0549) 
Training Epoch: [215/1000] Step: [250 / 285] Batch Time: 0.2179 (0.1599) Data Time: 0.0856 (0.0268) Average Loss: 0.4242 (0.3491) Average CE Loss (Source):  0.4242 ( 0.3491) Learning Rate: 0.0250 (0.0250) Top1_base: 89.8438 (90.7594) Top1_base_per_class: 90.4167 (91.0529) 
Training Epoch: [215/1000] Step: [260 / 285] Batch Time: 0.1480 (0.1597) Data Time: 0.0142 (0.0265) Average Loss: 0.3870 (0.3482) Average CE Loss (Source):  0.3870 ( 0.3482) Learning Rate: 0.0250 (0.0250) Top1_base: 88.2812 (90.7542) Top1_base_per_class: 87.5893 (91.0696) 
Training Epoch: [215/1000] Step: [270 / 285] Batch Time: 0.1957 (0.1599) Data Time: 0.0628 (0.0268) Average Loss: 0.2876 (0.3473) Average CE Loss (Source):  0.2876 ( 0.3473) Learning Rate: 0.0250 (0.0250) Top1_base: 91.4062 (90.7726) Top1_base_per_class: 90.1786 (91.0609) 
Training Epoch: [215/1000] Step: [280 / 285] Batch Time: 0.1487 (0.1599) Data Time: 0.0146 (0.0268) Average Loss: 0.3645 (0.3463) Average CE Loss (Source):  0.3645 ( 0.3463) Learning Rate: 0.0250 (0.0250) Top1_base: 91.4062 (90.7757) Top1_base_per_class: 90.2516 (91.0617) 
Training Epoch: [216/1000] Step: [0] Batch Time: 0.1430 (0.1599) Data Time: 0.0123 (0.0268) Average Loss: 0.3622 (0.3460) Average CE Loss (Source):  0.3622 ( 0.3460) Learning Rate: 0.0250 (0.0250) Top1_base: 91.4062 (90.7977) Top1_base_per_class: 91.4780 (91.0862) 
 22%|██▏       | 216/1000 [2:47:37<10:10:40, 46.74s/it] 22%|██▏       | 217/1000 [2:48:22<10:01:58, 46.13s/it]Training Epoch: [216/1000] Step: [10 / 285] Batch Time: 0.1426 (0.2374) Data Time: 0.0109 (0.1053) Average Loss: 0.3538 (0.3014) Average CE Loss (Source):  0.3538 ( 0.3014) Learning Rate: 0.0250 (0.0250) Top1_base: 90.6250 (91.8750) Top1_base_per_class: 91.6667 (92.5230) 
Training Epoch: [216/1000] Step: [20 / 285] Batch Time: 0.1495 (0.2008) Data Time: 0.0152 (0.0681) Average Loss: 0.3731 (0.3246) Average CE Loss (Source):  0.3731 ( 0.3246) Learning Rate: 0.0250 (0.0250) Top1_base: 92.1875 (91.5625) Top1_base_per_class: 93.2471 (91.7617) 
Training Epoch: [216/1000] Step: [30 / 285] Batch Time: 0.1464 (0.1876) Data Time: 0.0107 (0.0544) Average Loss: 0.3948 (0.3534) Average CE Loss (Source):  0.3948 ( 0.3534) Learning Rate: 0.0250 (0.0250) Top1_base: 92.1875 (90.9635) Top1_base_per_class: 92.4854 (90.7707) 
Training Epoch: [216/1000] Step: [40 / 285] Batch Time: 0.1481 (0.1788) Data Time: 0.0143 (0.0456) Average Loss: 0.3555 (0.3554) Average CE Loss (Source):  0.3555 ( 0.3554) Learning Rate: 0.0250 (0.0250) Top1_base: 89.0625 (90.7422) Top1_base_per_class: 87.2807 (90.8019) 
Training Epoch: [216/1000] Step: [50 / 285] Batch Time: 0.1451 (0.1723) Data Time: 0.0104 (0.0392) Average Loss: 0.3636 (0.3620) Average CE Loss (Source):  0.3636 ( 0.3620) Learning Rate: 0.0250 (0.0250) Top1_base: 90.6250 (90.5156) Top1_base_per_class: 89.0130 (90.6126) 
Training Epoch: [216/1000] Step: [60 / 285] Batch Time: 0.1491 (0.1689) Data Time: 0.0159 (0.0356) Average Loss: 0.2075 (0.3502) Average CE Loss (Source):  0.2075 ( 0.3502) Learning Rate: 0.0250 (0.0250) Top1_base: 93.7500 (90.7552) Top1_base_per_class: 95.2201 (90.8506) 
Training Epoch: [216/1000] Step: [70 / 285] Batch Time: 0.1465 (0.1683) Data Time: 0.0124 (0.0350) Average Loss: 0.3009 (0.3523) Average CE Loss (Source):  0.3009 ( 0.3523) Learning Rate: 0.0250 (0.0250) Top1_base: 92.9688 (90.7254) Top1_base_per_class: 94.2767 (90.9435) 
Training Epoch: [216/1000] Step: [80 / 285] Batch Time: 0.1471 (0.1656) Data Time: 0.0145 (0.0323) Average Loss: 0.3989 (0.3535) Average CE Loss (Source):  0.3989 ( 0.3535) Learning Rate: 0.0250 (0.0250) Top1_base: 91.4062 (90.7227) Top1_base_per_class: 93.2075 (90.9504) 
Training Epoch: [216/1000] Step: [90 / 285] Batch Time: 0.1452 (0.1648) Data Time: 0.0122 (0.0315) Average Loss: 0.2727 (0.3529) Average CE Loss (Source):  0.2727 ( 0.3529) Learning Rate: 0.0250 (0.0250) Top1_base: 92.1875 (90.7031) Top1_base_per_class: 91.9753 (90.8661) 
Training Epoch: [216/1000] Step: [100 / 285] Batch Time: 0.2096 (0.1649) Data Time: 0.0771 (0.0316) Average Loss: 0.2750 (0.3541) Average CE Loss (Source):  0.2750 ( 0.3541) Learning Rate: 0.0250 (0.0250) Top1_base: 95.3125 (90.6406) Top1_base_per_class: 93.4848 (90.8808) 
Training Epoch: [216/1000] Step: [110 / 285] Batch Time: 0.1471 (0.1636) Data Time: 0.0120 (0.0304) Average Loss: 0.3563 (0.3520) Average CE Loss (Source):  0.3563 ( 0.3520) Learning Rate: 0.0250 (0.0250) Top1_base: 87.5000 (90.7102) Top1_base_per_class: 87.5000 (90.9228) 
Training Epoch: [216/1000] Step: [120 / 285] Batch Time: 0.1693 (0.1625) Data Time: 0.0375 (0.0293) Average Loss: 0.2918 (0.3512) Average CE Loss (Source):  0.2918 ( 0.3512) Learning Rate: 0.0250 (0.0250) Top1_base: 93.7500 (90.7617) Top1_base_per_class: 94.2262 (90.9952) 
Training Epoch: [216/1000] Step: [130 / 285] Batch Time: 0.1464 (0.1620) Data Time: 0.0120 (0.0288) Average Loss: 0.2613 (0.3470) Average CE Loss (Source):  0.2613 ( 0.3470) Learning Rate: 0.0250 (0.0250) Top1_base: 94.5312 (90.8894) Top1_base_per_class: 95.7706 (91.1669) 
Training Epoch: [216/1000] Step: [140 / 285] Batch Time: 0.1680 (0.1615) Data Time: 0.0356 (0.0284) Average Loss: 0.5772 (0.3477) Average CE Loss (Source):  0.5772 ( 0.3477) Learning Rate: 0.0250 (0.0250) Top1_base: 84.3750 (90.8203) Top1_base_per_class: 83.8615 (91.1182) 
Training Epoch: [216/1000] Step: [150 / 285] Batch Time: 0.1428 (0.1606) Data Time: 0.0123 (0.0274) Average Loss: 0.3687 (0.3473) Average CE Loss (Source):  0.3687 ( 0.3473) Learning Rate: 0.0250 (0.0250) Top1_base: 88.2812 (90.7760) Top1_base_per_class: 86.3290 (91.0150) 
Training Epoch: [216/1000] Step: [160 / 285] Batch Time: 0.2114 (0.1606) Data Time: 0.0771 (0.0274) Average Loss: 0.2924 (0.3489) Average CE Loss (Source):  0.2924 ( 0.3489) Learning Rate: 0.0250 (0.0250) Top1_base: 90.6250 (90.7031) Top1_base_per_class: 88.2456 (90.9993) 
Training Epoch: [216/1000] Step: [170 / 285] Batch Time: 0.1430 (0.1600) Data Time: 0.0118 (0.0268) Average Loss: 0.3651 (0.3486) Average CE Loss (Source):  0.3651 ( 0.3486) Learning Rate: 0.0250 (0.0250) Top1_base: 89.0625 (90.6756) Top1_base_per_class: 91.5860 (90.8987) 
Training Epoch: [216/1000] Step: [180 / 285] Batch Time: 0.1781 (0.1598) Data Time: 0.0426 (0.0267) Average Loss: 0.2800 (0.3484) Average CE Loss (Source):  0.2800 ( 0.3484) Learning Rate: 0.0250 (0.0250) Top1_base: 89.8438 (90.6684) Top1_base_per_class: 89.5238 (90.8470) 
Training Epoch: [216/1000] Step: [190 / 285] Batch Time: 0.1433 (0.1593) Data Time: 0.0125 (0.0260) Average Loss: 0.4487 (0.3494) Average CE Loss (Source):  0.4487 ( 0.3494) Learning Rate: 0.0250 (0.0250) Top1_base: 89.0625 (90.6661) Top1_base_per_class: 89.4295 (90.8613) 
Training Epoch: [216/1000] Step: [200 / 285] Batch Time: 0.1521 (0.1591) Data Time: 0.0178 (0.0258) Average Loss: 0.3715 (0.3512) Average CE Loss (Source):  0.3715 ( 0.3512) Learning Rate: 0.0250 (0.0250) Top1_base: 89.8438 (90.6289) Top1_base_per_class: 88.6364 (90.8486) 
Training Epoch: [216/1000] Step: [210 / 285] Batch Time: 0.1490 (0.1586) Data Time: 0.0115 (0.0252) Average Loss: 0.3921 (0.3493) Average CE Loss (Source):  0.3921 ( 0.3493) Learning Rate: 0.0250 (0.0250) Top1_base: 92.1875 (90.6845) Top1_base_per_class: 90.3704 (90.9251) 
Training Epoch: [216/1000] Step: [220 / 285] Batch Time: 0.1532 (0.1582) Data Time: 0.0170 (0.0248) Average Loss: 0.3877 (0.3489) Average CE Loss (Source):  0.3877 ( 0.3489) Learning Rate: 0.0250 (0.0250) Top1_base: 89.8438 (90.6889) Top1_base_per_class: 92.2236 (90.9109) 
Training Epoch: [216/1000] Step: [230 / 285] Batch Time: 0.1494 (0.1578) Data Time: 0.0109 (0.0243) Average Loss: 0.3412 (0.3490) Average CE Loss (Source):  0.3412 ( 0.3490) Learning Rate: 0.0250 (0.0250) Top1_base: 89.0625 (90.6590) Top1_base_per_class: 93.0172 (90.9392) 
Training Epoch: [216/1000] Step: [240 / 285] Batch Time: 0.1507 (0.1575) Data Time: 0.0174 (0.0239) Average Loss: 0.3494 (0.3494) Average CE Loss (Source):  0.3494 ( 0.3494) Learning Rate: 0.0250 (0.0250) Top1_base: 90.6250 (90.6250) Top1_base_per_class: 88.9937 (90.9112) 
Training Epoch: [216/1000] Step: [250 / 285] Batch Time: 0.1506 (0.1572) Data Time: 0.0143 (0.0235) Average Loss: 0.4250 (0.3496) Average CE Loss (Source):  0.4250 ( 0.3496) Learning Rate: 0.0250 (0.0250) Top1_base: 89.0625 (90.6312) Top1_base_per_class: 91.0000 (90.9381) 
Training Epoch: [216/1000] Step: [260 / 285] Batch Time: 0.1574 (0.1569) Data Time: 0.0248 (0.0231) Average Loss: 0.3454 (0.3504) Average CE Loss (Source):  0.3454 ( 0.3504) Learning Rate: 0.0250 (0.0250) Top1_base: 91.4062 (90.5950) Top1_base_per_class: 90.2516 (90.9057) 
Training Epoch: [216/1000] Step: [270 / 285] Batch Time: 0.1471 (0.1566) Data Time: 0.0120 (0.0229) Average Loss: 0.3910 (0.3518) Average CE Loss (Source):  0.3910 ( 0.3518) Learning Rate: 0.0250 (0.0250) Top1_base: 89.8438 (90.5556) Top1_base_per_class: 89.4317 (90.8760) 
Training Epoch: [216/1000] Step: [280 / 285] Batch Time: 0.1687 (0.1567) Data Time: 0.0388 (0.0229) Average Loss: 0.2113 (0.3501) Average CE Loss (Source):  0.2113 ( 0.3501) Learning Rate: 0.0250 (0.0250) Top1_base: 94.5312 (90.5887) Top1_base_per_class: 94.2816 (90.8996) 
Training Epoch: [217/1000] Step: [0] Batch Time: 0.1462 (0.1566) Data Time: 0.0116 (0.0229) Average Loss: 0.1438 (0.3497) Average CE Loss (Source):  0.1438 ( 0.3497) Learning Rate: 0.0250 (0.0250) Top1_base: 95.3125 (90.5921) Top1_base_per_class: 94.9138 (90.9024) 
Training Epoch: [217/1000] Step: [10 / 285] Batch Time: 0.1441 (0.2436) Data Time: 0.0114 (0.1106) Average Loss: 0.4156 (0.3198) Average CE Loss (Source):  0.4156 ( 0.3198) Learning Rate: 0.0250 (0.0250) Top1_base: 86.7188 (90.8594) Top1_base_per_class: 89.4643 (91.6951) 
Training Epoch: [217/1000] Step: [20 / 285] Batch Time: 0.1482 (0.1996) Data Time: 0.0163 (0.0668) Average Loss: 0.4339 (0.3618) Average CE Loss (Source):  0.4339 ( 0.3618) Learning Rate: 0.0250 (0.0250) Top1_base: 88.2812 (90.5078) Top1_base_per_class: 88.2076 (91.0746) 
Training Epoch: [217/1000] Step: [30 / 285] Batch Time: 0.1484 (0.1857) Data Time: 0.0125 (0.0528) Average Loss: 0.4352 (0.3501) Average CE Loss (Source):  0.4352 ( 0.3501) Learning Rate: 0.0250 (0.0250) Top1_base: 90.6250 (90.7812) Top1_base_per_class: 88.7798 (91.1096) 
Training Epoch: [217/1000] Step: [40 / 285] Batch Time: 0.1463 (0.1776) Data Time: 0.0139 (0.0443) Average Loss: 0.3299 (0.3455) Average CE Loss (Source):  0.3299 ( 0.3455) Learning Rate: 0.0250 (0.0250) Top1_base: 89.8438 (90.7812) Top1_base_per_class: 91.0802 (91.1006) 
Training Epoch: [217/1000] Step: [50 / 285] Batch Time: 0.1630 (0.1746) Data Time: 0.0277 (0.0412) Average Loss: 0.3744 (0.3494) Average CE Loss (Source):  0.3744 ( 0.3494) Learning Rate: 0.0250 (0.0250) Top1_base: 90.6250 (90.6094) Top1_base_per_class: 90.8025 (90.7582) 
Training Epoch: [217/1000] Step: [60 / 285] Batch Time: 0.1435 (0.1724) Data Time: 0.0125 (0.0390) Average Loss: 0.3982 (0.3534) Average CE Loss (Source):  0.3982 ( 0.3534) Learning Rate: 0.0250 (0.0250) Top1_base: 86.7188 (90.3906) Top1_base_per_class: 89.3750 (90.4710) 
Training Epoch: [217/1000] Step: [70 / 285] Batch Time: 0.1816 (0.1703) Data Time: 0.0483 (0.0369) Average Loss: 0.3385 (0.3554) Average CE Loss (Source):  0.3385 ( 0.3554) Learning Rate: 0.0250 (0.0250) Top1_base: 90.6250 (90.4129) Top1_base_per_class: 87.5152 (90.4101) 
Training Epoch: [217/1000] Step: [80 / 285] Batch Time: 0.1492 (0.1677) Data Time: 0.0168 (0.0344) Average Loss: 0.3261 (0.3618) Average CE Loss (Source):  0.3261 ( 0.3618) Learning Rate: 0.0250 (0.0250) Top1_base: 92.9688 (90.4004) Top1_base_per_class: 91.3743 (90.4462) 
Training Epoch: [217/1000] Step: [90 / 285] Batch Time: 0.2536 (0.1667) Data Time: 0.1183 (0.0333) Average Loss: 0.4088 (0.3587) Average CE Loss (Source):  0.4088 ( 0.3587) Learning Rate: 0.0250 (0.0250) Top1_base: 91.4062 (90.5208) Top1_base_per_class: 92.8195 (90.5593) 
Training Epoch: [217/1000] Step: [100 / 285] Batch Time: 0.1411 (0.1649) Data Time: 0.0120 (0.0317) Average Loss: 0.3854 (0.3580) Average CE Loss (Source):  0.3854 ( 0.3580) Learning Rate: 0.0250 (0.0250) Top1_base: 89.0625 (90.5391) Top1_base_per_class: 91.2302 (90.6300) 
Training Epoch: [217/1000] Step: [110 / 285] Batch Time: 0.1779 (0.1636) Data Time: 0.0439 (0.0304) Average Loss: 0.3236 (0.3597) Average CE Loss (Source):  0.3236 ( 0.3597) Learning Rate: 0.0250 (0.0250) Top1_base: 92.1875 (90.5043) Top1_base_per_class: 92.9598 (90.5640) 
Training Epoch: [217/1000] Step: [120 / 285] Batch Time: 0.1438 (0.1629) Data Time: 0.0119 (0.0298) Average Loss: 0.3851 (0.3622) Average CE Loss (Source):  0.3851 ( 0.3622) Learning Rate: 0.0250 (0.0250) Top1_base: 87.5000 (90.4167) Top1_base_per_class: 86.1782 (90.5185) 
Training Epoch: [217/1000] Step: [130 / 285] Batch Time: 0.1552 (0.1623) Data Time: 0.0232 (0.0292) Average Loss: 0.3338 (0.3616) Average CE Loss (Source):  0.3338 ( 0.3616) Learning Rate: 0.0250 (0.0250) Top1_base: 89.8438 (90.3305) Top1_base_per_class: 89.2424 (90.4463) 
Training Epoch: [217/1000] Step: [140 / 285] Batch Time: 0.1466 (0.1614) Data Time: 0.0127 (0.0283) Average Loss: 0.3259 (0.3615) Average CE Loss (Source):  0.3259 ( 0.3615) Learning Rate: 0.0250 (0.0250) Top1_base: 91.4062 (90.3404) Top1_base_per_class: 92.8395 (90.4588) 
Training Epoch: [217/1000] Step: [150 / 285] Batch Time: 0.1847 (0.1613) Data Time: 0.0523 (0.0281) Average Loss: 0.3224 (0.3580) Average CE Loss (Source):  0.3224 ( 0.3580) Learning Rate: 0.0250 (0.0250) Top1_base: 90.6250 (90.4323) Top1_base_per_class: 90.7233 (90.5350) 
Training Epoch: [217/1000] Step: [160 / 285] Batch Time: 0.1437 (0.1608) Data Time: 0.0134 (0.0275) Average Loss: 0.2019 (0.3550) Average CE Loss (Source):  0.2019 ( 0.3550) Learning Rate: 0.0250 (0.0250) Top1_base: 96.0938 (90.4883) Top1_base_per_class: 97.1515 (90.6378) 
Training Epoch: [217/1000] Step: [170 / 285] Batch Time: 0.1555 (0.1603) Data Time: 0.0193 (0.0271) Average Loss: 0.4969 (0.3521) Average CE Loss (Source):  0.4969 ( 0.3521) Learning Rate: 0.0250 (0.0250) Top1_base: 85.9375 (90.5561) Top1_base_per_class: 82.9023 (90.6615) 
Training Epoch: [217/1000] Step: [180 / 285] Batch Time: 0.1442 (0.1601) Data Time: 0.0128 (0.0270) Average Loss: 0.3646 (0.3544) Average CE Loss (Source):  0.3646 ( 0.3544) Learning Rate: 0.0250 (0.0250) Top1_base: 89.0625 (90.4731) Top1_base_per_class: 88.8218 (90.5801) 
Training Epoch: [217/1000] Step: [190 / 285] Batch Time: 0.1486 (0.1595) Data Time: 0.0160 (0.0264) Average Loss: 0.3315 (0.3543) Average CE Loss (Source):  0.3315 ( 0.3543) Learning Rate: 0.0250 (0.0250) Top1_base: 92.1875 (90.5551) Top1_base_per_class: 93.8393 (90.6621) 
Training Epoch: [217/1000] Step: [200 / 285] Batch Time: 0.1465 (0.1591) Data Time: 0.0114 (0.0259) Average Loss: 0.3917 (0.3536) Average CE Loss (Source):  0.3917 ( 0.3536) Learning Rate: 0.0250 (0.0250) Top1_base: 89.8438 (90.5664) Top1_base_per_class: 93.5152 (90.7002) 
Training Epoch: [217/1000] Step: [210 / 285] Batch Time: 0.1640 (0.1589) Data Time: 0.0328 (0.0257) Average Loss: 0.3824 (0.3536) Average CE Loss (Source):  0.3824 ( 0.3536) Learning Rate: 0.0250 (0.0250) Top1_base: 87.5000 (90.5580) Top1_base_per_class: 89.9702 (90.7087) 
Training Epoch: [217/1000] Step: [220 / 285] Batch Time: 0.1456 (0.1591) Data Time: 0.0116 (0.0259) Average Loss: 0.4358 (0.3535) Average CE Loss (Source):  0.4358 ( 0.3535) Learning Rate: 0.0250 (0.0250) Top1_base: 85.1562 (90.5398) Top1_base_per_class: 88.4026 (90.7204) 
Training Epoch: [217/1000] Step: [230 / 285] Batch Time: 0.1871 (0.1591) Data Time: 0.0538 (0.0259) Average Loss: 0.5143 (0.3538) Average CE Loss (Source):  0.5143 ( 0.3538) Learning Rate: 0.0250 (0.0250) Top1_base: 85.1562 (90.5197) Top1_base_per_class: 86.7815 (90.7034) 
Training Epoch: [217/1000] Step: [240 / 285] Batch Time: 0.1442 (0.1589) Data Time: 0.0117 (0.0257) Average Loss: 0.4865 (0.3551) Average CE Loss (Source):  0.4865 ( 0.3551) Learning Rate: 0.0250 (0.0250) Top1_base: 84.3750 (90.4785) Top1_base_per_class: 85.8757 (90.7184) 
Training Epoch: [217/1000] Step: [250 / 285] Batch Time: 0.1652 (0.1588) Data Time: 0.0292 (0.0256) Average Loss: 0.2799 (0.3550) Average CE Loss (Source):  0.2799 ( 0.3550) Learning Rate: 0.0250 (0.0250) Top1_base: 92.9688 (90.4719) Top1_base_per_class: 90.4088 (90.6754) 
Training Epoch: [217/1000] Step: [260 / 285] Batch Time: 0.1449 (0.1589) Data Time: 0.0106 (0.0257) Average Loss: 0.3513 (0.3546) Average CE Loss (Source):  0.3513 ( 0.3546) Learning Rate: 0.0250 (0.0250) Top1_base: 90.6250 (90.4988) Top1_base_per_class: 91.6667 (90.6958) 
Training Epoch: [217/1000] Step: [270 / 285] Batch Time: 0.2111 (0.1589) Data Time: 0.0768 (0.0257) Average Loss: 0.3155 (0.3549) Average CE Loss (Source):  0.3155 ( 0.3549) Learning Rate: 0.0250 (0.0250) Top1_base: 93.7500 (90.4803) Top1_base_per_class: 94.8276 (90.6581) 
Training Epoch: [217/1000] Step: [280 / 285] Batch Time: 0.1422 (0.1591) Data Time: 0.0124 (0.0259) Average Loss: 0.4330 (0.3545) Average CE Loss (Source):  0.4330 ( 0.3545) Learning Rate: 0.0250 (0.0250) Top1_base: 90.6250 (90.4855) Top1_base_per_class: 89.3827 (90.6994) 
Training Epoch: [218/1000] Step: [0] Batch Time: 0.1377 (0.1589) Data Time: 0.0104 (0.0258) Average Loss: 0.4153 (0.3538) Average CE Loss (Source):  0.4153 ( 0.3538) Learning Rate: 0.0250 (0.0250) Top1_base: 89.8438 (90.4852) Top1_base_per_class: 92.5152 (90.7066) 
 22%|██▏       | 218/1000 [2:49:10<10:08:54, 46.72s/it] 22%|██▏       | 219/1000 [2:49:56<10:04:03, 46.41s/it]Training Epoch: [218/1000] Step: [10 / 285] Batch Time: 0.1431 (0.2477) Data Time: 0.0107 (0.1152) Average Loss: 0.3565 (0.3493) Average CE Loss (Source):  0.3565 ( 0.3493) Learning Rate: 0.0250 (0.0250) Top1_base: 89.8438 (90.0000) Top1_base_per_class: 90.5454 (90.3516) 
Training Epoch: [218/1000] Step: [20 / 285] Batch Time: 0.1456 (0.2009) Data Time: 0.0133 (0.0684) Average Loss: 0.3796 (0.3234) Average CE Loss (Source):  0.3796 ( 0.3234) Learning Rate: 0.0250 (0.0250) Top1_base: 90.6250 (91.3281) Top1_base_per_class: 91.2180 (91.8779) 
Training Epoch: [218/1000] Step: [30 / 285] Batch Time: 0.1478 (0.1901) Data Time: 0.0106 (0.0569) Average Loss: 0.3692 (0.3281) Average CE Loss (Source):  0.3692 ( 0.3281) Learning Rate: 0.0250 (0.0250) Top1_base: 91.4062 (91.1979) Top1_base_per_class: 88.6494 (91.4752) 
Training Epoch: [218/1000] Step: [40 / 285] Batch Time: 0.1463 (0.1817) Data Time: 0.0140 (0.0482) Average Loss: 0.3946 (0.3304) Average CE Loss (Source):  0.3946 ( 0.3304) Learning Rate: 0.0250 (0.0250) Top1_base: 89.8438 (91.1133) Top1_base_per_class: 90.1667 (91.2997) 
Training Epoch: [218/1000] Step: [50 / 285] Batch Time: 0.1433 (0.1765) Data Time: 0.0103 (0.0431) Average Loss: 0.4387 (0.3277) Average CE Loss (Source):  0.4387 ( 0.3277) Learning Rate: 0.0250 (0.0250) Top1_base: 86.7188 (91.0625) Top1_base_per_class: 91.0606 (91.4118) 
Training Epoch: [218/1000] Step: [60 / 285] Batch Time: 0.1490 (0.1732) Data Time: 0.0154 (0.0396) Average Loss: 0.2402 (0.3324) Average CE Loss (Source):  0.2402 ( 0.3324) Learning Rate: 0.0250 (0.0250) Top1_base: 93.7500 (91.0156) Top1_base_per_class: 93.6905 (91.2883) 
Training Epoch: [218/1000] Step: [70 / 285] Batch Time: 0.1482 (0.1719) Data Time: 0.0124 (0.0380) Average Loss: 0.3233 (0.3321) Average CE Loss (Source):  0.3233 ( 0.3321) Learning Rate: 0.0250 (0.0250) Top1_base: 92.1875 (91.0268) Top1_base_per_class: 92.2515 (91.3179) 
Training Epoch: [218/1000] Step: [80 / 285] Batch Time: 0.1457 (0.1697) Data Time: 0.0132 (0.0356) Average Loss: 0.2750 (0.3302) Average CE Loss (Source):  0.2750 ( 0.3302) Learning Rate: 0.0250 (0.0250) Top1_base: 92.1875 (91.1816) Top1_base_per_class: 91.5432 (91.4591) 
Training Epoch: [218/1000] Step: [90 / 285] Batch Time: 0.1517 (0.1689) Data Time: 0.0145 (0.0347) Average Loss: 0.2437 (0.3334) Average CE Loss (Source):  0.2437 ( 0.3334) Learning Rate: 0.0250 (0.0250) Top1_base: 91.4062 (91.0417) Top1_base_per_class: 91.4620 (91.3285) 
Training Epoch: [218/1000] Step: [100 / 285] Batch Time: 0.1480 (0.1670) Data Time: 0.0138 (0.0327) Average Loss: 0.2795 (0.3356) Average CE Loss (Source):  0.2795 ( 0.3356) Learning Rate: 0.0250 (0.0250) Top1_base: 90.6250 (91.0234) Top1_base_per_class: 89.9660 (91.2979) 
Training Epoch: [218/1000] Step: [110 / 285] Batch Time: 0.1471 (0.1667) Data Time: 0.0103 (0.0324) Average Loss: 0.4194 (0.3388) Average CE Loss (Source):  0.4194 ( 0.3388) Learning Rate: 0.0250 (0.0250) Top1_base: 89.0625 (90.9375) Top1_base_per_class: 90.0585 (91.1854) 
Training Epoch: [218/1000] Step: [120 / 285] Batch Time: 0.1439 (0.1660) Data Time: 0.0121 (0.0315) Average Loss: 0.3846 (0.3375) Average CE Loss (Source):  0.3846 ( 0.3375) Learning Rate: 0.0250 (0.0250) Top1_base: 89.8438 (90.9635) Top1_base_per_class: 87.9697 (91.1927) 
Training Epoch: [218/1000] Step: [130 / 285] Batch Time: 0.1435 (0.1656) Data Time: 0.0108 (0.0312) Average Loss: 0.3442 (0.3364) Average CE Loss (Source):  0.3442 ( 0.3364) Learning Rate: 0.0250 (0.0250) Top1_base: 92.1875 (91.0276) Top1_base_per_class: 92.8704 (91.2468) 
Training Epoch: [218/1000] Step: [140 / 285] Batch Time: 0.1454 (0.1653) Data Time: 0.0126 (0.0311) Average Loss: 0.3692 (0.3333) Average CE Loss (Source):  0.3692 ( 0.3333) Learning Rate: 0.0250 (0.0250) Top1_base: 92.1875 (91.0938) Top1_base_per_class: 91.6082 (91.3342) 
Training Epoch: [218/1000] Step: [150 / 285] Batch Time: 0.1441 (0.1646) Data Time: 0.0101 (0.0305) Average Loss: 0.2436 (0.3327) Average CE Loss (Source):  0.2436 ( 0.3327) Learning Rate: 0.0250 (0.0250) Top1_base: 95.3125 (91.1302) Top1_base_per_class: 95.9167 (91.3767) 
Training Epoch: [218/1000] Step: [160 / 285] Batch Time: 0.1440 (0.1635) Data Time: 0.0137 (0.0294) Average Loss: 0.2577 (0.3338) Average CE Loss (Source):  0.2577 ( 0.3338) Learning Rate: 0.0250 (0.0250) Top1_base: 95.3125 (91.0889) Top1_base_per_class: 94.6541 (91.3387) 
Training Epoch: [218/1000] Step: [170 / 285] Batch Time: 0.1447 (0.1629) Data Time: 0.0113 (0.0289) Average Loss: 0.4101 (0.3356) Average CE Loss (Source):  0.4101 ( 0.3356) Learning Rate: 0.0250 (0.0250) Top1_base: 86.7188 (91.0340) Top1_base_per_class: 88.7582 (91.2810) 
Training Epoch: [218/1000] Step: [180 / 285] Batch Time: 0.1476 (0.1623) Data Time: 0.0147 (0.0284) Average Loss: 0.4174 (0.3380) Average CE Loss (Source):  0.4174 ( 0.3380) Learning Rate: 0.0250 (0.0250) Top1_base: 87.5000 (90.9158) Top1_base_per_class: 88.2345 (91.1243) 
Training Epoch: [218/1000] Step: [190 / 285] Batch Time: 0.1496 (0.1619) Data Time: 0.0132 (0.0279) Average Loss: 0.3951 (0.3380) Average CE Loss (Source):  0.3951 ( 0.3380) Learning Rate: 0.0250 (0.0250) Top1_base: 85.9375 (90.8717) Top1_base_per_class: 87.0468 (91.1091) 
Training Epoch: [218/1000] Step: [200 / 285] Batch Time: 0.1518 (0.1613) Data Time: 0.0177 (0.0272) Average Loss: 0.3899 (0.3403) Average CE Loss (Source):  0.3899 ( 0.3403) Learning Rate: 0.0250 (0.0250) Top1_base: 86.7188 (90.8047) Top1_base_per_class: 88.0702 (91.0833) 
Training Epoch: [218/1000] Step: [210 / 285] Batch Time: 0.1465 (0.1611) Data Time: 0.0130 (0.0271) Average Loss: 0.2986 (0.3417) Average CE Loss (Source):  0.2986 ( 0.3417) Learning Rate: 0.0250 (0.0250) Top1_base: 92.9688 (90.7738) Top1_base_per_class: 93.4770 (91.0361) 
Training Epoch: [218/1000] Step: [220 / 285] Batch Time: 0.1447 (0.1611) Data Time: 0.0122 (0.0272) Average Loss: 0.2879 (0.3459) Average CE Loss (Source):  0.2879 ( 0.3459) Learning Rate: 0.0250 (0.0250) Top1_base: 93.7500 (90.6392) Top1_base_per_class: 94.8830 (90.8761) 
Training Epoch: [218/1000] Step: [230 / 285] Batch Time: 0.1447 (0.1610) Data Time: 0.0104 (0.0271) Average Loss: 0.4657 (0.3470) Average CE Loss (Source):  0.4657 ( 0.3470) Learning Rate: 0.0250 (0.0250) Top1_base: 84.3750 (90.6080) Top1_base_per_class: 83.9103 (90.8363) 
Training Epoch: [218/1000] Step: [240 / 285] Batch Time: 0.1442 (0.1606) Data Time: 0.0116 (0.0267) Average Loss: 0.4771 (0.3466) Average CE Loss (Source):  0.4771 ( 0.3466) Learning Rate: 0.0250 (0.0250) Top1_base: 85.9375 (90.6217) Top1_base_per_class: 87.7083 (90.8468) 
Training Epoch: [218/1000] Step: [250 / 285] Batch Time: 0.1459 (0.1606) Data Time: 0.0123 (0.0267) Average Loss: 0.3249 (0.3467) Average CE Loss (Source):  0.3249 ( 0.3467) Learning Rate: 0.0250 (0.0250) Top1_base: 91.4062 (90.6094) Top1_base_per_class: 91.8155 (90.8368) 
Training Epoch: [218/1000] Step: [260 / 285] Batch Time: 0.1477 (0.1603) Data Time: 0.0146 (0.0264) Average Loss: 0.3866 (0.3472) Average CE Loss (Source):  0.3866 ( 0.3472) Learning Rate: 0.0250 (0.0250) Top1_base: 91.4062 (90.6220) Top1_base_per_class: 89.7989 (90.8683) 
Training Epoch: [218/1000] Step: [270 / 285] Batch Time: 0.1436 (0.1605) Data Time: 0.0102 (0.0266) Average Loss: 0.2289 (0.3467) Average CE Loss (Source):  0.2289 ( 0.3467) Learning Rate: 0.0250 (0.0250) Top1_base: 92.9688 (90.6424) Top1_base_per_class: 95.0943 (90.9032) 
Training Epoch: [218/1000] Step: [280 / 285] Batch Time: 0.1424 (0.1602) Data Time: 0.0107 (0.0264) Average Loss: 0.4326 (0.3478) Average CE Loss (Source):  0.4326 ( 0.3478) Learning Rate: 0.0250 (0.0250) Top1_base: 85.9375 (90.6166) Top1_base_per_class: 87.0977 (90.9117) 
Training Epoch: [219/1000] Step: [0] Batch Time: 0.1449 (0.1600) Data Time: 0.0142 (0.0263) Average Loss: 0.3593 (0.3481) Average CE Loss (Source):  0.3593 ( 0.3481) Learning Rate: 0.0250 (0.0250) Top1_base: 89.8438 (90.6113) Top1_base_per_class: 90.3030 (90.8849) 
Training Epoch: [219/1000] Step: [10 / 285] Batch Time: 0.1461 (0.2281) Data Time: 0.0132 (0.0944) Average Loss: 0.4300 (0.3686) Average CE Loss (Source):  0.4300 ( 0.3686) Learning Rate: 0.0250 (0.0250) Top1_base: 88.2812 (89.8438) Top1_base_per_class: 88.0357 (89.5964) 
Training Epoch: [219/1000] Step: [20 / 285] Batch Time: 0.1487 (0.1877) Data Time: 0.0136 (0.0542) Average Loss: 0.2683 (0.3462) Average CE Loss (Source):  0.2683 ( 0.3462) Learning Rate: 0.0250 (0.0250) Top1_base: 92.9688 (90.6250) Top1_base_per_class: 93.3333 (90.9998) 
Training Epoch: [219/1000] Step: [30 / 285] Batch Time: 0.1495 (0.1766) Data Time: 0.0127 (0.0431) Average Loss: 0.4066 (0.3486) Average CE Loss (Source):  0.4066 ( 0.3486) Learning Rate: 0.0250 (0.0250) Top1_base: 89.0625 (90.2865) Top1_base_per_class: 88.0357 (90.4004) 
Training Epoch: [219/1000] Step: [40 / 285] Batch Time: 0.1784 (0.1749) Data Time: 0.0471 (0.0414) Average Loss: 0.2889 (0.3598) Average CE Loss (Source):  0.2889 ( 0.3598) Learning Rate: 0.0250 (0.0250) Top1_base: 92.9688 (90.0586) Top1_base_per_class: 92.5595 (90.1610) 
Training Epoch: [219/1000] Step: [50 / 285] Batch Time: 0.1489 (0.1693) Data Time: 0.0140 (0.0358) Average Loss: 0.2709 (0.3540) Average CE Loss (Source):  0.2709 ( 0.3540) Learning Rate: 0.0250 (0.0250) Top1_base: 93.7500 (90.3438) Top1_base_per_class: 94.2424 (90.4336) 
Training Epoch: [219/1000] Step: [60 / 285] Batch Time: 0.1531 (0.1672) Data Time: 0.0224 (0.0338) Average Loss: 0.2659 (0.3501) Average CE Loss (Source):  0.2659 ( 0.3501) Learning Rate: 0.0250 (0.0250) Top1_base: 95.3125 (90.5078) Top1_base_per_class: 96.4333 (90.7273) 
Training Epoch: [219/1000] Step: [70 / 285] Batch Time: 0.1675 (0.1649) Data Time: 0.0337 (0.0315) Average Loss: 0.4060 (0.3542) Average CE Loss (Source):  0.4060 ( 0.3542) Learning Rate: 0.0250 (0.0250) Top1_base: 86.7188 (90.3906) Top1_base_per_class: 88.6667 (90.6746) 
Training Epoch: [219/1000] Step: [80 / 285] Batch Time: 0.1835 (0.1662) Data Time: 0.0515 (0.0329) Average Loss: 0.4482 (0.3550) Average CE Loss (Source):  0.4482 ( 0.3550) Learning Rate: 0.0250 (0.0250) Top1_base: 89.0625 (90.3613) Top1_base_per_class: 89.5556 (90.6740) 
Training Epoch: [219/1000] Step: [90 / 285] Batch Time: 0.1433 (0.1658) Data Time: 0.0125 (0.0326) Average Loss: 0.2498 (0.3545) Average CE Loss (Source):  0.2498 ( 0.3545) Learning Rate: 0.0250 (0.0250) Top1_base: 92.9688 (90.3212) Top1_base_per_class: 92.9487 (90.6523) 
Training Epoch: [219/1000] Step: [100 / 285] Batch Time: 0.1936 (0.1655) Data Time: 0.0604 (0.0325) Average Loss: 0.5152 (0.3544) Average CE Loss (Source):  0.5152 ( 0.3544) Learning Rate: 0.0250 (0.0250) Top1_base: 87.5000 (90.3906) Top1_base_per_class: 89.5089 (90.6591) 
Training Epoch: [219/1000] Step: [110 / 285] Batch Time: 0.1433 (0.1643) Data Time: 0.0104 (0.0313) Average Loss: 0.2933 (0.3572) Average CE Loss (Source):  0.2933 ( 0.3572) Learning Rate: 0.0250 (0.0250) Top1_base: 91.4062 (90.3054) Top1_base_per_class: 90.8788 (90.5578) 
Training Epoch: [219/1000] Step: [120 / 285] Batch Time: 0.1605 (0.1640) Data Time: 0.0269 (0.0309) Average Loss: 0.4733 (0.3562) Average CE Loss (Source):  0.4733 ( 0.3562) Learning Rate: 0.0250 (0.0250) Top1_base: 90.6250 (90.3451) Top1_base_per_class: 89.7799 (90.5743) 
Training Epoch: [219/1000] Step: [130 / 285] Batch Time: 0.1430 (0.1634) Data Time: 0.0123 (0.0304) Average Loss: 0.2764 (0.3557) Average CE Loss (Source):  0.2764 ( 0.3557) Learning Rate: 0.0250 (0.0250) Top1_base: 93.7500 (90.3185) Top1_base_per_class: 95.5247 (90.6104) 
Training Epoch: [219/1000] Step: [140 / 285] Batch Time: 0.1699 (0.1629) Data Time: 0.0383 (0.0300) Average Loss: 0.3167 (0.3554) Average CE Loss (Source):  0.3167 ( 0.3554) Learning Rate: 0.0250 (0.0250) Top1_base: 92.1875 (90.3795) Top1_base_per_class: 95.1935 (90.6627) 
Training Epoch: [219/1000] Step: [150 / 285] Batch Time: 0.1442 (0.1619) Data Time: 0.0122 (0.0290) Average Loss: 0.2660 (0.3527) Average CE Loss (Source):  0.2660 ( 0.3527) Learning Rate: 0.0250 (0.0250) Top1_base: 94.5312 (90.4375) Top1_base_per_class: 96.2644 (90.7701) 
Training Epoch: [219/1000] Step: [160 / 285] Batch Time: 0.1649 (0.1617) Data Time: 0.0301 (0.0288) Average Loss: 0.4094 (0.3562) Average CE Loss (Source):  0.4094 ( 0.3562) Learning Rate: 0.0250 (0.0250) Top1_base: 91.4062 (90.3467) Top1_base_per_class: 90.4802 (90.6647) 
Training Epoch: [219/1000] Step: [170 / 285] Batch Time: 0.1436 (0.1611) Data Time: 0.0105 (0.0282) Average Loss: 0.3380 (0.3569) Average CE Loss (Source):  0.3380 ( 0.3569) Learning Rate: 0.0250 (0.0250) Top1_base: 89.8438 (90.2895) Top1_base_per_class: 92.1345 (90.6374) 
Training Epoch: [219/1000] Step: [180 / 285] Batch Time: 0.2048 (0.1608) Data Time: 0.0729 (0.0280) Average Loss: 0.2477 (0.3564) Average CE Loss (Source):  0.2477 ( 0.3564) Learning Rate: 0.0250 (0.0250) Top1_base: 93.7500 (90.3212) Top1_base_per_class: 93.2759 (90.6646) 
Training Epoch: [219/1000] Step: [190 / 285] Batch Time: 0.1439 (0.1602) Data Time: 0.0119 (0.0274) Average Loss: 0.3500 (0.3567) Average CE Loss (Source):  0.3500 ( 0.3567) Learning Rate: 0.0250 (0.0250) Top1_base: 93.7500 (90.3289) Top1_base_per_class: 93.6218 (90.7276) 
Training Epoch: [219/1000] Step: [200 / 285] Batch Time: 0.2235 (0.1602) Data Time: 0.0921 (0.0273) Average Loss: 0.3113 (0.3587) Average CE Loss (Source):  0.3113 ( 0.3587) Learning Rate: 0.0250 (0.0250) Top1_base: 89.8438 (90.2734) Top1_base_per_class: 91.7787 (90.7009) 
Training Epoch: [219/1000] Step: [210 / 285] Batch Time: 0.1442 (0.1596) Data Time: 0.0105 (0.0267) Average Loss: 0.3257 (0.3587) Average CE Loss (Source):  0.3257 ( 0.3587) Learning Rate: 0.0250 (0.0250) Top1_base: 90.6250 (90.2641) Top1_base_per_class: 89.7747 (90.6871) 
Training Epoch: [219/1000] Step: [220 / 285] Batch Time: 0.1957 (0.1593) Data Time: 0.0635 (0.0264) Average Loss: 0.4766 (0.3588) Average CE Loss (Source):  0.4766 ( 0.3588) Learning Rate: 0.0250 (0.0250) Top1_base: 89.0625 (90.3089) Top1_base_per_class: 88.8095 (90.7181) 
Training Epoch: [219/1000] Step: [230 / 285] Batch Time: 0.1467 (0.1589) Data Time: 0.0112 (0.0260) Average Loss: 0.4604 (0.3611) Average CE Loss (Source):  0.4604 ( 0.3611) Learning Rate: 0.0250 (0.0250) Top1_base: 87.5000 (90.2242) Top1_base_per_class: 87.0130 (90.6232) 
Training Epoch: [219/1000] Step: [240 / 285] Batch Time: 0.1784 (0.1585) Data Time: 0.0475 (0.0256) Average Loss: 0.3057 (0.3594) Average CE Loss (Source):  0.3057 ( 0.3594) Learning Rate: 0.0250 (0.0250) Top1_base: 91.4062 (90.2539) Top1_base_per_class: 91.6049 (90.6774) 
Training Epoch: [219/1000] Step: [250 / 285] Batch Time: 0.1447 (0.1582) Data Time: 0.0108 (0.0253) Average Loss: 0.4105 (0.3595) Average CE Loss (Source):  0.4105 ( 0.3595) Learning Rate: 0.0250 (0.0250) Top1_base: 88.2812 (90.2594) Top1_base_per_class: 87.4425 (90.6888) 
Training Epoch: [219/1000] Step: [260 / 285] Batch Time: 0.1603 (0.1583) Data Time: 0.0282 (0.0255) Average Loss: 0.3684 (0.3594) Average CE Loss (Source):  0.3684 ( 0.3594) Learning Rate: 0.0250 (0.0250) Top1_base: 89.0625 (90.2614) Top1_base_per_class: 91.3393 (90.7068) 
Training Epoch: [219/1000] Step: [270 / 285] Batch Time: 0.1472 (0.1579) Data Time: 0.0112 (0.0250) Average Loss: 0.4175 (0.3597) Average CE Loss (Source):  0.4175 ( 0.3597) Learning Rate: 0.0250 (0.0250) Top1_base: 89.0625 (90.2431) Top1_base_per_class: 87.5962 (90.7062) 
Training Epoch: [219/1000] Step: [280 / 285] Batch Time: 0.1954 (0.1580) Data Time: 0.0623 (0.0250) Average Loss: 0.3744 (0.3587) Average CE Loss (Source):  0.3744 ( 0.3587) Learning Rate: 0.0250 (0.0250) Top1_base: 88.2812 (90.2706) Top1_base_per_class: 87.6144 (90.7301) 
Training Epoch: [220/1000] Step: [0] Batch Time: 0.1394 (0.1578) Data Time: 0.0090 (0.0247) Average Loss: 0.2618 (0.3578) Average CE Loss (Source):  0.2618 ( 0.3578) Learning Rate: 0.0250 (0.0250) Top1_base: 92.9688 (90.2741) Top1_base_per_class: 92.0606 (90.7293) 
 22%|██▏       | 220/1000 [2:50:44<10:08:54, 46.84s/it] 22%|██▏       | 221/1000 [2:51:28<10:00:09, 46.23s/it]Training Epoch: [220/1000] Step: [10 / 285] Batch Time: 0.1448 (0.2335) Data Time: 0.0106 (0.1014) Average Loss: 0.2838 (0.3714) Average CE Loss (Source):  0.2838 ( 0.3714) Learning Rate: 0.0250 (0.0250) Top1_base: 94.5312 (90.1562) Top1_base_per_class: 95.1282 (90.9951) 
Training Epoch: [220/1000] Step: [20 / 285] Batch Time: 0.1479 (0.1963) Data Time: 0.0126 (0.0636) Average Loss: 0.3128 (0.3689) Average CE Loss (Source):  0.3128 ( 0.3689) Learning Rate: 0.0250 (0.0250) Top1_base: 91.4062 (89.9609) Top1_base_per_class: 93.3333 (90.9074) 
Training Epoch: [220/1000] Step: [30 / 285] Batch Time: 0.1483 (0.1871) Data Time: 0.0125 (0.0539) Average Loss: 0.2830 (0.3467) Average CE Loss (Source):  0.2830 ( 0.3467) Learning Rate: 0.0250 (0.0250) Top1_base: 94.5312 (90.7031) Top1_base_per_class: 95.8642 (91.4668) 
Training Epoch: [220/1000] Step: [40 / 285] Batch Time: 0.1464 (0.1803) Data Time: 0.0131 (0.0466) Average Loss: 0.4581 (0.3536) Average CE Loss (Source):  0.4581 ( 0.3536) Learning Rate: 0.0250 (0.0250) Top1_base: 89.0625 (90.5078) Top1_base_per_class: 88.1818 (91.1879) 
Training Epoch: [220/1000] Step: [50 / 285] Batch Time: 0.1945 (0.1771) Data Time: 0.0619 (0.0435) Average Loss: 0.3121 (0.3534) Average CE Loss (Source):  0.3121 ( 0.3534) Learning Rate: 0.0250 (0.0250) Top1_base: 92.9688 (90.4688) Top1_base_per_class: 94.8113 (91.2156) 
Training Epoch: [220/1000] Step: [60 / 285] Batch Time: 0.1470 (0.1732) Data Time: 0.0132 (0.0396) Average Loss: 0.3408 (0.3519) Average CE Loss (Source):  0.3408 ( 0.3519) Learning Rate: 0.0250 (0.0250) Top1_base: 89.8438 (90.4167) Top1_base_per_class: 90.7879 (91.2388) 
Training Epoch: [220/1000] Step: [70 / 285] Batch Time: 0.2694 (0.1729) Data Time: 0.1380 (0.0394) Average Loss: 0.3565 (0.3487) Average CE Loss (Source):  0.3565 ( 0.3487) Learning Rate: 0.0250 (0.0250) Top1_base: 90.6250 (90.5692) Top1_base_per_class: 92.3030 (91.3365) 
Training Epoch: [220/1000] Step: [80 / 285] Batch Time: 0.1430 (0.1697) Data Time: 0.0132 (0.0362) Average Loss: 0.3073 (0.3497) Average CE Loss (Source):  0.3073 ( 0.3497) Learning Rate: 0.0250 (0.0250) Top1_base: 90.6250 (90.5176) Top1_base_per_class: 89.3693 (91.2623) 
Training Epoch: [220/1000] Step: [90 / 285] Batch Time: 0.1769 (0.1688) Data Time: 0.0451 (0.0354) Average Loss: 0.4721 (0.3497) Average CE Loss (Source):  0.4721 ( 0.3497) Learning Rate: 0.0250 (0.0250) Top1_base: 88.2812 (90.5035) Top1_base_per_class: 88.5455 (91.1262) 
Training Epoch: [220/1000] Step: [100 / 285] Batch Time: 0.1510 (0.1675) Data Time: 0.0132 (0.0341) Average Loss: 0.4064 (0.3486) Average CE Loss (Source):  0.4064 ( 0.3486) Learning Rate: 0.0250 (0.0250) Top1_base: 88.2812 (90.4609) Top1_base_per_class: 88.0747 (91.0334) 
Training Epoch: [220/1000] Step: [110 / 285] Batch Time: 0.1510 (0.1658) Data Time: 0.0157 (0.0322) Average Loss: 0.3066 (0.3491) Average CE Loss (Source):  0.3066 ( 0.3491) Learning Rate: 0.0250 (0.0250) Top1_base: 89.8438 (90.4403) Top1_base_per_class: 89.9383 (91.0369) 
Training Epoch: [220/1000] Step: [120 / 285] Batch Time: 0.1480 (0.1651) Data Time: 0.0120 (0.0313) Average Loss: 0.3092 (0.3463) Average CE Loss (Source):  0.3092 ( 0.3463) Learning Rate: 0.0250 (0.0250) Top1_base: 90.6250 (90.5143) Top1_base_per_class: 90.8788 (91.0392) 
Training Epoch: [220/1000] Step: [130 / 285] Batch Time: 0.1493 (0.1642) Data Time: 0.0165 (0.0305) Average Loss: 0.3140 (0.3455) Average CE Loss (Source):  0.3140 ( 0.3455) Learning Rate: 0.0250 (0.0250) Top1_base: 91.4062 (90.5829) Top1_base_per_class: 93.2099 (91.0920) 
Training Epoch: [220/1000] Step: [140 / 285] Batch Time: 0.1463 (0.1634) Data Time: 0.0114 (0.0297) Average Loss: 0.3620 (0.3464) Average CE Loss (Source):  0.3620 ( 0.3464) Learning Rate: 0.0250 (0.0250) Top1_base: 89.0625 (90.5134) Top1_base_per_class: 90.0736 (91.0319) 
Training Epoch: [220/1000] Step: [150 / 285] Batch Time: 0.1755 (0.1629) Data Time: 0.0413 (0.0292) Average Loss: 0.3429 (0.3485) Average CE Loss (Source):  0.3429 ( 0.3485) Learning Rate: 0.0250 (0.0250) Top1_base: 89.8438 (90.4427) Top1_base_per_class: 91.6352 (90.9504) 
Training Epoch: [220/1000] Step: [160 / 285] Batch Time: 0.1506 (0.1621) Data Time: 0.0122 (0.0282) Average Loss: 0.2550 (0.3496) Average CE Loss (Source):  0.2550 ( 0.3496) Learning Rate: 0.0250 (0.0250) Top1_base: 92.1875 (90.3857) Top1_base_per_class: 90.7143 (90.8790) 
Training Epoch: [220/1000] Step: [170 / 285] Batch Time: 0.1498 (0.1612) Data Time: 0.0161 (0.0274) Average Loss: 0.2644 (0.3494) Average CE Loss (Source):  0.2644 ( 0.3494) Learning Rate: 0.0250 (0.0250) Top1_base: 92.9688 (90.4090) Top1_base_per_class: 92.2024 (90.9210) 
Training Epoch: [220/1000] Step: [180 / 285] Batch Time: 0.1498 (0.1604) Data Time: 0.0135 (0.0266) Average Loss: 0.3656 (0.3501) Average CE Loss (Source):  0.3656 ( 0.3501) Learning Rate: 0.0250 (0.0250) Top1_base: 89.8438 (90.3993) Top1_base_per_class: 88.5803 (90.8926) 
Training Epoch: [220/1000] Step: [190 / 285] Batch Time: 0.1841 (0.1600) Data Time: 0.0503 (0.0261) Average Loss: 0.3772 (0.3515) Average CE Loss (Source):  0.3772 ( 0.3515) Learning Rate: 0.0250 (0.0250) Top1_base: 88.2812 (90.3413) Top1_base_per_class: 89.6797 (90.8163) 
Training Epoch: [220/1000] Step: [200 / 285] Batch Time: 0.1490 (0.1597) Data Time: 0.0146 (0.0257) Average Loss: 0.3521 (0.3538) Average CE Loss (Source):  0.3521 ( 0.3538) Learning Rate: 0.0250 (0.0250) Top1_base: 89.8438 (90.2578) Top1_base_per_class: 90.1515 (90.7195) 
Training Epoch: [220/1000] Step: [210 / 285] Batch Time: 0.1903 (0.1592) Data Time: 0.0586 (0.0254) Average Loss: 0.5129 (0.3553) Average CE Loss (Source):  0.5129 ( 0.3553) Learning Rate: 0.0250 (0.0250) Top1_base: 85.1562 (90.2455) Top1_base_per_class: 87.5731 (90.6797) 
Training Epoch: [220/1000] Step: [220 / 285] Batch Time: 0.1488 (0.1591) Data Time: 0.0122 (0.0252) Average Loss: 0.2682 (0.3548) Average CE Loss (Source):  0.2682 ( 0.3548) Learning Rate: 0.0250 (0.0250) Top1_base: 92.1875 (90.2521) Top1_base_per_class: 94.0351 (90.6771) 
Training Epoch: [220/1000] Step: [230 / 285] Batch Time: 0.1511 (0.1586) Data Time: 0.0186 (0.0247) Average Loss: 0.3678 (0.3551) Average CE Loss (Source):  0.3678 ( 0.3551) Learning Rate: 0.0250 (0.0250) Top1_base: 89.0625 (90.2582) Top1_base_per_class: 92.0536 (90.6848) 
Training Epoch: [220/1000] Step: [240 / 285] Batch Time: 0.1488 (0.1582) Data Time: 0.0128 (0.0243) Average Loss: 0.3143 (0.3557) Average CE Loss (Source):  0.3143 ( 0.3557) Learning Rate: 0.0250 (0.0250) Top1_base: 89.8438 (90.2311) Top1_base_per_class: 89.4242 (90.6456) 
Training Epoch: [220/1000] Step: [250 / 285] Batch Time: 0.1499 (0.1578) Data Time: 0.0152 (0.0239) Average Loss: 0.4180 (0.3558) Average CE Loss (Source):  0.4180 ( 0.3558) Learning Rate: 0.0250 (0.0250) Top1_base: 88.2812 (90.2438) Top1_base_per_class: 91.2202 (90.6421) 
Training Epoch: [220/1000] Step: [260 / 285] Batch Time: 0.1493 (0.1574) Data Time: 0.0119 (0.0235) Average Loss: 0.4276 (0.3560) Average CE Loss (Source):  0.4276 ( 0.3560) Learning Rate: 0.0250 (0.0250) Top1_base: 85.1562 (90.2344) Top1_base_per_class: 85.1818 (90.6469) 
Training Epoch: [220/1000] Step: [270 / 285] Batch Time: 0.1812 (0.1572) Data Time: 0.0481 (0.0232) Average Loss: 0.3605 (0.3568) Average CE Loss (Source):  0.3605 ( 0.3568) Learning Rate: 0.0250 (0.0250) Top1_base: 92.1875 (90.2286) Top1_base_per_class: 91.9281 (90.6335) 
Training Epoch: [220/1000] Step: [280 / 285] Batch Time: 0.1471 (0.1570) Data Time: 0.0117 (0.0230) Average Loss: 0.3429 (0.3571) Average CE Loss (Source):  0.3429 ( 0.3571) Learning Rate: 0.0250 (0.0250) Top1_base: 91.4062 (90.2260) Top1_base_per_class: 93.0128 (90.6301) 
Training Epoch: [221/1000] Step: [0] Batch Time: 0.1431 (0.1569) Data Time: 0.0133 (0.0230) Average Loss: 0.3697 (0.3582) Average CE Loss (Source):  0.3697 ( 0.3582) Learning Rate: 0.0250 (0.0250) Top1_base: 89.8438 (90.1919) Top1_base_per_class: 89.6199 (90.5694) 
Training Epoch: [221/1000] Step: [10 / 285] Batch Time: 0.1424 (0.2362) Data Time: 0.0104 (0.1038) Average Loss: 0.2533 (0.3025) Average CE Loss (Source):  0.2533 ( 0.3025) Learning Rate: 0.0250 (0.0250) Top1_base: 94.5312 (92.2656) Top1_base_per_class: 96.7593 (93.2910) 
Training Epoch: [221/1000] Step: [20 / 285] Batch Time: 0.1454 (0.1983) Data Time: 0.0114 (0.0659) Average Loss: 0.3044 (0.3293) Average CE Loss (Source):  0.3044 ( 0.3293) Learning Rate: 0.0250 (0.0250) Top1_base: 92.9688 (91.6406) Top1_base_per_class: 94.5238 (92.1885) 
Training Epoch: [221/1000] Step: [30 / 285] Batch Time: 0.1469 (0.1845) Data Time: 0.0167 (0.0520) Average Loss: 0.3536 (0.3366) Average CE Loss (Source):  0.3536 ( 0.3366) Learning Rate: 0.0250 (0.0250) Top1_base: 91.4062 (91.1198) Top1_base_per_class: 94.2924 (91.7906) 
Training Epoch: [221/1000] Step: [40 / 285] Batch Time: 0.1495 (0.1771) Data Time: 0.0164 (0.0445) Average Loss: 0.2548 (0.3346) Average CE Loss (Source):  0.2548 ( 0.3346) Learning Rate: 0.0250 (0.0250) Top1_base: 93.7500 (91.2500) Top1_base_per_class: 92.8869 (91.5232) 
Training Epoch: [221/1000] Step: [50 / 285] Batch Time: 0.1473 (0.1723) Data Time: 0.0127 (0.0396) Average Loss: 0.3177 (0.3357) Average CE Loss (Source):  0.3177 ( 0.3357) Learning Rate: 0.0250 (0.0250) Top1_base: 90.6250 (91.1719) Top1_base_per_class: 90.6926 (91.4943) 
Training Epoch: [221/1000] Step: [60 / 285] Batch Time: 0.1501 (0.1709) Data Time: 0.0145 (0.0380) Average Loss: 0.3722 (0.3381) Average CE Loss (Source):  0.3722 ( 0.3381) Learning Rate: 0.0250 (0.0250) Top1_base: 92.1875 (91.0677) Top1_base_per_class: 95.3216 (91.4826) 
Training Epoch: [221/1000] Step: [70 / 285] Batch Time: 0.1482 (0.1687) Data Time: 0.0164 (0.0357) Average Loss: 0.2834 (0.3376) Average CE Loss (Source):  0.2834 ( 0.3376) Learning Rate: 0.0250 (0.0250) Top1_base: 92.1875 (91.1719) Top1_base_per_class: 93.0242 (91.4620) 
Training Epoch: [221/1000] Step: [80 / 285] Batch Time: 0.1458 (0.1667) Data Time: 0.0127 (0.0337) Average Loss: 0.4141 (0.3437) Average CE Loss (Source):  0.4141 ( 0.3437) Learning Rate: 0.0250 (0.0250) Top1_base: 89.0625 (90.9570) Top1_base_per_class: 88.6164 (91.2336) 
Training Epoch: [221/1000] Step: [90 / 285] Batch Time: 0.1444 (0.1647) Data Time: 0.0116 (0.0317) Average Loss: 0.2653 (0.3401) Average CE Loss (Source):  0.2653 ( 0.3401) Learning Rate: 0.0250 (0.0250) Top1_base: 92.9688 (90.9809) Top1_base_per_class: 95.0000 (91.2368) 
Training Epoch: [221/1000] Step: [100 / 285] Batch Time: 0.1508 (0.1634) Data Time: 0.0142 (0.0304) Average Loss: 0.3199 (0.3395) Average CE Loss (Source):  0.3199 ( 0.3395) Learning Rate: 0.0250 (0.0250) Top1_base: 89.8438 (90.9297) Top1_base_per_class: 87.3684 (91.2150) 
Training Epoch: [221/1000] Step: [110 / 285] Batch Time: 0.1460 (0.1627) Data Time: 0.0123 (0.0297) Average Loss: 0.2324 (0.3398) Average CE Loss (Source):  0.2324 ( 0.3398) Learning Rate: 0.0250 (0.0250) Top1_base: 95.3125 (90.9162) Top1_base_per_class: 96.1765 (91.1996) 
Training Epoch: [221/1000] Step: [120 / 285] Batch Time: 0.1482 (0.1621) Data Time: 0.0151 (0.0291) Average Loss: 0.1885 (0.3405) Average CE Loss (Source):  0.1885 ( 0.3405) Learning Rate: 0.0250 (0.0250) Top1_base: 92.1875 (90.8659) Top1_base_per_class: 93.2184 (91.2310) 
Training Epoch: [221/1000] Step: [130 / 285] Batch Time: 0.1425 (0.1623) Data Time: 0.0106 (0.0292) Average Loss: 0.3020 (0.3392) Average CE Loss (Source):  0.3020 ( 0.3392) Learning Rate: 0.0250 (0.0250) Top1_base: 91.4062 (90.8594) Top1_base_per_class: 95.1818 (91.2288) 
Training Epoch: [221/1000] Step: [140 / 285] Batch Time: 0.1533 (0.1620) Data Time: 0.0147 (0.0288) Average Loss: 0.2745 (0.3390) Average CE Loss (Source):  0.2745 ( 0.3390) Learning Rate: 0.0250 (0.0250) Top1_base: 92.1875 (90.8705) Top1_base_per_class: 90.0862 (91.2409) 
Training Epoch: [221/1000] Step: [150 / 285] Batch Time: 0.1429 (0.1612) Data Time: 0.0107 (0.0280) Average Loss: 0.2844 (0.3383) Average CE Loss (Source):  0.2844 ( 0.3383) Learning Rate: 0.0250 (0.0250) Top1_base: 92.1875 (90.8906) Top1_base_per_class: 92.4333 (91.2748) 
Training Epoch: [221/1000] Step: [160 / 285] Batch Time: 0.1476 (0.1606) Data Time: 0.0144 (0.0274) Average Loss: 0.5078 (0.3397) Average CE Loss (Source):  0.5078 ( 0.3397) Learning Rate: 0.0250 (0.0250) Top1_base: 85.1562 (90.8594) Top1_base_per_class: 83.4211 (91.2441) 
Training Epoch: [221/1000] Step: [170 / 285] Batch Time: 0.1418 (0.1601) Data Time: 0.0112 (0.0269) Average Loss: 0.4466 (0.3408) Average CE Loss (Source):  0.4466 ( 0.3408) Learning Rate: 0.0250 (0.0250) Top1_base: 85.1562 (90.8134) Top1_base_per_class: 82.7160 (91.1491) 
Training Epoch: [221/1000] Step: [180 / 285] Batch Time: 0.1496 (0.1595) Data Time: 0.0153 (0.0263) Average Loss: 0.3999 (0.3409) Average CE Loss (Source):  0.3999 ( 0.3409) Learning Rate: 0.0250 (0.0250) Top1_base: 89.8438 (90.8116) Top1_base_per_class: 91.2478 (91.1648) 
Training Epoch: [221/1000] Step: [190 / 285] Batch Time: 0.1426 (0.1597) Data Time: 0.0106 (0.0266) Average Loss: 0.3138 (0.3457) Average CE Loss (Source):  0.3138 ( 0.3457) Learning Rate: 0.0250 (0.0250) Top1_base: 92.9688 (90.7196) Top1_base_per_class: 93.3333 (91.0493) 
Training Epoch: [221/1000] Step: [200 / 285] Batch Time: 0.1495 (0.1594) Data Time: 0.0145 (0.0262) Average Loss: 0.3388 (0.3449) Average CE Loss (Source):  0.3388 ( 0.3449) Learning Rate: 0.0250 (0.0250) Top1_base: 92.1875 (90.7305) Top1_base_per_class: 91.2500 (91.0136) 
Training Epoch: [221/1000] Step: [210 / 285] Batch Time: 0.1469 (0.1597) Data Time: 0.0126 (0.0265) Average Loss: 0.2847 (0.3452) Average CE Loss (Source):  0.2847 ( 0.3452) Learning Rate: 0.0250 (0.0250) Top1_base: 93.7500 (90.7068) Top1_base_per_class: 93.1638 (90.9966) 
Training Epoch: [221/1000] Step: [220 / 285] Batch Time: 0.1497 (0.1592) Data Time: 0.0126 (0.0260) Average Loss: 0.4017 (0.3453) Average CE Loss (Source):  0.4017 ( 0.3453) Learning Rate: 0.0250 (0.0250) Top1_base: 88.2812 (90.7067) Top1_base_per_class: 87.6101 (90.9695) 
Training Epoch: [221/1000] Step: [230 / 285] Batch Time: 0.1458 (0.1589) Data Time: 0.0105 (0.0256) Average Loss: 0.2907 (0.3464) Average CE Loss (Source):  0.2907 ( 0.3464) Learning Rate: 0.0250 (0.0250) Top1_base: 92.9688 (90.6624) Top1_base_per_class: 93.1548 (90.9373) 
Training Epoch: [221/1000] Step: [240 / 285] Batch Time: 0.1456 (0.1588) Data Time: 0.0109 (0.0254) Average Loss: 0.3514 (0.3464) Average CE Loss (Source):  0.3514 ( 0.3464) Learning Rate: 0.0250 (0.0250) Top1_base: 91.4062 (90.6673) Top1_base_per_class: 91.2356 (90.9339) 
Training Epoch: [221/1000] Step: [250 / 285] Batch Time: 0.1445 (0.1584) Data Time: 0.0106 (0.0250) Average Loss: 0.2171 (0.3467) Average CE Loss (Source):  0.2171 ( 0.3467) Learning Rate: 0.0250 (0.0250) Top1_base: 93.7500 (90.6500) Top1_base_per_class: 92.7673 (90.9440) 
Training Epoch: [221/1000] Step: [260 / 285] Batch Time: 0.1463 (0.1582) Data Time: 0.0117 (0.0247) Average Loss: 0.3209 (0.3483) Average CE Loss (Source):  0.3209 ( 0.3483) Learning Rate: 0.0250 (0.0250) Top1_base: 89.8438 (90.5859) Top1_base_per_class: 90.1282 (90.8774) 
Training Epoch: [221/1000] Step: [270 / 285] Batch Time: 0.1431 (0.1579) Data Time: 0.0106 (0.0245) Average Loss: 0.5488 (0.3495) Average CE Loss (Source):  0.5488 ( 0.3495) Learning Rate: 0.0250 (0.0250) Top1_base: 85.1562 (90.5758) Top1_base_per_class: 87.5427 (90.8894) 
Training Epoch: [221/1000] Step: [280 / 285] Batch Time: 0.1492 (0.1578) Data Time: 0.0137 (0.0243) Average Loss: 0.2716 (0.3500) Average CE Loss (Source):  0.2716 ( 0.3500) Learning Rate: 0.0250 (0.0250) Top1_base: 90.6250 (90.5469) Top1_base_per_class: 92.5893 (90.8367) 
Training Epoch: [222/1000] Step: [0] Batch Time: 0.2331 (0.1581) Data Time: 0.1023 (0.0246) Average Loss: 0.2805 (0.3494) Average CE Loss (Source):  0.2805 ( 0.3494) Learning Rate: 0.0250 (0.0250) Top1_base: 92.9688 (90.5839) Top1_base_per_class: 92.1053 (90.8696) 
 22%|██▏       | 222/1000 [2:52:16<10:05:51, 46.72s/it] 22%|██▏       | 223/1000 [2:53:01<9:56:56, 46.10s/it] Training Epoch: [222/1000] Step: [10 / 285] Batch Time: 0.1484 (0.2513) Data Time: 0.0149 (0.1185) Average Loss: 0.1820 (0.3349) Average CE Loss (Source):  0.1820 ( 0.3349) Learning Rate: 0.0250 (0.0250) Top1_base: 95.3125 (90.9375) Top1_base_per_class: 95.4403 (91.3146) 
Training Epoch: [222/1000] Step: [20 / 285] Batch Time: 0.1447 (0.2021) Data Time: 0.0107 (0.0694) Average Loss: 0.4496 (0.3214) Average CE Loss (Source):  0.4496 ( 0.3214) Learning Rate: 0.0250 (0.0250) Top1_base: 89.8438 (91.7969) Top1_base_per_class: 88.2121 (92.2694) 
Training Epoch: [222/1000] Step: [30 / 285] Batch Time: 0.1459 (0.1893) Data Time: 0.0120 (0.0566) Average Loss: 0.3951 (0.3247) Average CE Loss (Source):  0.3951 ( 0.3247) Learning Rate: 0.0250 (0.0250) Top1_base: 89.0625 (91.5625) Top1_base_per_class: 89.0881 (92.0649) 
Training Epoch: [222/1000] Step: [40 / 285] Batch Time: 0.1484 (0.1799) Data Time: 0.0108 (0.0464) Average Loss: 0.3890 (0.3361) Average CE Loss (Source):  0.3890 ( 0.3361) Learning Rate: 0.0250 (0.0250) Top1_base: 89.8438 (91.1914) Top1_base_per_class: 88.5876 (91.8497) 
Training Epoch: [222/1000] Step: [50 / 285] Batch Time: 0.1464 (0.1740) Data Time: 0.0118 (0.0406) Average Loss: 0.3555 (0.3408) Average CE Loss (Source):  0.3555 ( 0.3408) Learning Rate: 0.0250 (0.0250) Top1_base: 91.4062 (91.0000) Top1_base_per_class: 92.3611 (91.5573) 
Training Epoch: [222/1000] Step: [60 / 285] Batch Time: 0.1424 (0.1709) Data Time: 0.0118 (0.0376) Average Loss: 0.3419 (0.3387) Average CE Loss (Source):  0.3419 ( 0.3387) Learning Rate: 0.0250 (0.0250) Top1_base: 89.0625 (90.9766) Top1_base_per_class: 87.7381 (91.5149) 
Training Epoch: [222/1000] Step: [70 / 285] Batch Time: 0.1495 (0.1689) Data Time: 0.0138 (0.0357) Average Loss: 0.3033 (0.3434) Average CE Loss (Source):  0.3033 ( 0.3434) Learning Rate: 0.0250 (0.0250) Top1_base: 91.4062 (90.6920) Top1_base_per_class: 93.2759 (91.2349) 
Training Epoch: [222/1000] Step: [80 / 285] Batch Time: 0.1479 (0.1667) Data Time: 0.0116 (0.0335) Average Loss: 0.2664 (0.3424) Average CE Loss (Source):  0.2664 ( 0.3424) Learning Rate: 0.0250 (0.0250) Top1_base: 92.9688 (90.6641) Top1_base_per_class: 92.0679 (91.1312) 
Training Epoch: [222/1000] Step: [90 / 285] Batch Time: 0.1464 (0.1646) Data Time: 0.0140 (0.0313) Average Loss: 0.3431 (0.3410) Average CE Loss (Source):  0.3431 ( 0.3410) Learning Rate: 0.0250 (0.0250) Top1_base: 91.4062 (90.6858) Top1_base_per_class: 91.4080 (91.1299) 
Training Epoch: [222/1000] Step: [100 / 285] Batch Time: 0.1480 (0.1631) Data Time: 0.0110 (0.0298) Average Loss: 0.4926 (0.3406) Average CE Loss (Source):  0.4926 ( 0.3406) Learning Rate: 0.0250 (0.0250) Top1_base: 87.5000 (90.7109) Top1_base_per_class: 87.6364 (91.1147) 
Training Epoch: [222/1000] Step: [110 / 285] Batch Time: 0.1509 (0.1619) Data Time: 0.0203 (0.0283) Average Loss: 0.3728 (0.3392) Average CE Loss (Source):  0.3728 ( 0.3392) Learning Rate: 0.0250 (0.0250) Top1_base: 89.0625 (90.7244) Top1_base_per_class: 89.6605 (91.1297) 
Training Epoch: [222/1000] Step: [120 / 285] Batch Time: 0.1462 (0.1617) Data Time: 0.0112 (0.0282) Average Loss: 0.2395 (0.3414) Average CE Loss (Source):  0.2395 ( 0.3414) Learning Rate: 0.0250 (0.0250) Top1_base: 94.5312 (90.6771) Top1_base_per_class: 96.1299 (91.0740) 
Training Epoch: [222/1000] Step: [130 / 285] Batch Time: 0.1474 (0.1606) Data Time: 0.0159 (0.0272) Average Loss: 0.4058 (0.3437) Average CE Loss (Source):  0.4058 ( 0.3437) Learning Rate: 0.0250 (0.0250) Top1_base: 89.0625 (90.6250) Top1_base_per_class: 91.1012 (91.0360) 
Training Epoch: [222/1000] Step: [140 / 285] Batch Time: 0.1473 (0.1597) Data Time: 0.0146 (0.0262) Average Loss: 0.2883 (0.3454) Average CE Loss (Source):  0.2883 ( 0.3454) Learning Rate: 0.0250 (0.0250) Top1_base: 92.9688 (90.6027) Top1_base_per_class: 94.7701 (91.0071) 
Training Epoch: [222/1000] Step: [150 / 285] Batch Time: 0.1466 (0.1590) Data Time: 0.0147 (0.0256) Average Loss: 0.1728 (0.3441) Average CE Loss (Source):  0.1728 ( 0.3441) Learning Rate: 0.0250 (0.0250) Top1_base: 95.3125 (90.6042) Top1_base_per_class: 96.7836 (90.9746) 
Training Epoch: [222/1000] Step: [160 / 285] Batch Time: 0.1469 (0.1590) Data Time: 0.0119 (0.0256) Average Loss: 0.2734 (0.3462) Average CE Loss (Source):  0.2734 ( 0.3462) Learning Rate: 0.0250 (0.0250) Top1_base: 93.7500 (90.5420) Top1_base_per_class: 93.3929 (90.9079) 
Training Epoch: [222/1000] Step: [170 / 285] Batch Time: 0.1445 (0.1584) Data Time: 0.0121 (0.0250) Average Loss: 0.5261 (0.3499) Average CE Loss (Source):  0.5261 ( 0.3499) Learning Rate: 0.0250 (0.0250) Top1_base: 83.5938 (90.4274) Top1_base_per_class: 82.1345 (90.7785) 
Training Epoch: [222/1000] Step: [180 / 285] Batch Time: 0.1474 (0.1577) Data Time: 0.0133 (0.0243) Average Loss: 0.2503 (0.3497) Average CE Loss (Source):  0.2503 ( 0.3497) Learning Rate: 0.0250 (0.0250) Top1_base: 92.9688 (90.4427) Top1_base_per_class: 90.7848 (90.7889) 
Training Epoch: [222/1000] Step: [190 / 285] Batch Time: 0.1462 (0.1572) Data Time: 0.0133 (0.0238) Average Loss: 0.3410 (0.3501) Average CE Loss (Source):  0.3410 ( 0.3501) Learning Rate: 0.0250 (0.0250) Top1_base: 89.0625 (90.4523) Top1_base_per_class: 89.1509 (90.7683) 
Training Epoch: [222/1000] Step: [200 / 285] Batch Time: 0.1461 (0.1569) Data Time: 0.0105 (0.0235) Average Loss: 0.3095 (0.3491) Average CE Loss (Source):  0.3095 ( 0.3491) Learning Rate: 0.0250 (0.0250) Top1_base: 89.0625 (90.4727) Top1_base_per_class: 88.4848 (90.7991) 
Training Epoch: [222/1000] Step: [210 / 285] Batch Time: 0.1439 (0.1570) Data Time: 0.0120 (0.0236) Average Loss: 0.3003 (0.3473) Average CE Loss (Source):  0.3003 ( 0.3473) Learning Rate: 0.0250 (0.0250) Top1_base: 91.4062 (90.5171) Top1_base_per_class: 93.1212 (90.8386) 
Training Epoch: [222/1000] Step: [220 / 285] Batch Time: 0.1455 (0.1566) Data Time: 0.0106 (0.0232) Average Loss: 0.4349 (0.3490) Average CE Loss (Source):  0.4349 ( 0.3490) Learning Rate: 0.0250 (0.0250) Top1_base: 87.5000 (90.4936) Top1_base_per_class: 87.8182 (90.8261) 
Training Epoch: [222/1000] Step: [230 / 285] Batch Time: 0.1456 (0.1563) Data Time: 0.0140 (0.0229) Average Loss: 0.2637 (0.3496) Average CE Loss (Source):  0.2637 ( 0.3496) Learning Rate: 0.0250 (0.0250) Top1_base: 93.7500 (90.4925) Top1_base_per_class: 90.9877 (90.8227) 
Training Epoch: [222/1000] Step: [240 / 285] Batch Time: 0.1428 (0.1564) Data Time: 0.0120 (0.0231) Average Loss: 0.4681 (0.3498) Average CE Loss (Source):  0.4681 ( 0.3498) Learning Rate: 0.0250 (0.0250) Top1_base: 88.2812 (90.5111) Top1_base_per_class: 88.5247 (90.8303) 
Training Epoch: [222/1000] Step: [250 / 285] Batch Time: 0.1447 (0.1566) Data Time: 0.0140 (0.0233) Average Loss: 0.3225 (0.3499) Average CE Loss (Source):  0.3225 ( 0.3499) Learning Rate: 0.0250 (0.0250) Top1_base: 90.6250 (90.5062) Top1_base_per_class: 90.6122 (90.8026) 
Training Epoch: [222/1000] Step: [260 / 285] Batch Time: 0.1436 (0.1565) Data Time: 0.0101 (0.0232) Average Loss: 0.3773 (0.3510) Average CE Loss (Source):  0.3773 ( 0.3510) Learning Rate: 0.0250 (0.0250) Top1_base: 91.4062 (90.4898) Top1_base_per_class: 91.7560 (90.7717) 
Training Epoch: [222/1000] Step: [270 / 285] Batch Time: 0.1460 (0.1564) Data Time: 0.0128 (0.0231) Average Loss: 0.3736 (0.3515) Average CE Loss (Source):  0.3736 ( 0.3515) Learning Rate: 0.0250 (0.0250) Top1_base: 89.0625 (90.4514) Top1_base_per_class: 88.3800 (90.7316) 
Training Epoch: [222/1000] Step: [280 / 285] Batch Time: 0.1441 (0.1565) Data Time: 0.0097 (0.0233) Average Loss: 0.3798 (0.3521) Average CE Loss (Source):  0.3798 ( 0.3521) Learning Rate: 0.0250 (0.0250) Top1_base: 89.0625 (90.4381) Top1_base_per_class: 90.1190 (90.7040) 
Training Epoch: [223/1000] Step: [0] Batch Time: 0.1444 (0.1563) Data Time: 0.0109 (0.0231) Average Loss: 0.2862 (0.3518) Average CE Loss (Source):  0.2862 ( 0.3518) Learning Rate: 0.0250 (0.0250) Top1_base: 89.8438 (90.4359) Top1_base_per_class: 89.4152 (90.6885) 
Training Epoch: [223/1000] Step: [10 / 285] Batch Time: 0.1424 (0.2434) Data Time: 0.0109 (0.1109) Average Loss: 0.3897 (0.3359) Average CE Loss (Source):  0.3897 ( 0.3359) Learning Rate: 0.0250 (0.0250) Top1_base: 89.8438 (91.0156) Top1_base_per_class: 91.6964 (91.7385) 
Training Epoch: [223/1000] Step: [20 / 285] Batch Time: 0.1448 (0.2015) Data Time: 0.0121 (0.0693) Average Loss: 0.4626 (0.3422) Average CE Loss (Source):  0.4626 ( 0.3422) Learning Rate: 0.0250 (0.0250) Top1_base: 87.5000 (90.5859) Top1_base_per_class: 89.0936 (91.2271) 
Training Epoch: [223/1000] Step: [30 / 285] Batch Time: 0.1461 (0.1888) Data Time: 0.0134 (0.0567) Average Loss: 0.3955 (0.3308) Average CE Loss (Source):  0.3955 ( 0.3308) Learning Rate: 0.0250 (0.0250) Top1_base: 89.0625 (91.1719) Top1_base_per_class: 86.4545 (91.7301) 
Training Epoch: [223/1000] Step: [40 / 285] Batch Time: 0.1449 (0.1814) Data Time: 0.0121 (0.0492) Average Loss: 0.3444 (0.3350) Average CE Loss (Source):  0.3444 ( 0.3350) Learning Rate: 0.0250 (0.0250) Top1_base: 92.9688 (91.1719) Top1_base_per_class: 95.9414 (91.6842) 
Training Epoch: [223/1000] Step: [50 / 285] Batch Time: 0.1449 (0.1751) Data Time: 0.0138 (0.0428) Average Loss: 0.3513 (0.3351) Average CE Loss (Source):  0.3513 ( 0.3351) Learning Rate: 0.0250 (0.0250) Top1_base: 91.4062 (91.2656) Top1_base_per_class: 92.0068 (91.6618) 
Training Epoch: [223/1000] Step: [60 / 285] Batch Time: 0.1482 (0.1708) Data Time: 0.0125 (0.0382) Average Loss: 0.2439 (0.3346) Average CE Loss (Source):  0.2439 ( 0.3346) Learning Rate: 0.0250 (0.0250) Top1_base: 92.1875 (91.1589) Top1_base_per_class: 92.0536 (91.5577) 
Training Epoch: [223/1000] Step: [70 / 285] Batch Time: 0.1491 (0.1700) Data Time: 0.0174 (0.0372) Average Loss: 0.3304 (0.3295) Average CE Loss (Source):  0.3304 ( 0.3295) Learning Rate: 0.0250 (0.0250) Top1_base: 90.6250 (91.1942) Top1_base_per_class: 90.4598 (91.6027) 
Training Epoch: [223/1000] Step: [80 / 285] Batch Time: 0.1480 (0.1680) Data Time: 0.0118 (0.0352) Average Loss: 0.3615 (0.3302) Average CE Loss (Source):  0.3615 ( 0.3302) Learning Rate: 0.0250 (0.0250) Top1_base: 91.4062 (91.1133) Top1_base_per_class: 92.8363 (91.6645) 
Training Epoch: [223/1000] Step: [90 / 285] Batch Time: 0.1509 (0.1663) Data Time: 0.0171 (0.0332) Average Loss: 0.3608 (0.3350) Average CE Loss (Source):  0.3608 ( 0.3350) Learning Rate: 0.0250 (0.0250) Top1_base: 92.1875 (90.9896) Top1_base_per_class: 94.5058 (91.4672) 
Training Epoch: [223/1000] Step: [100 / 285] Batch Time: 0.1484 (0.1646) Data Time: 0.0135 (0.0313) Average Loss: 0.3209 (0.3355) Average CE Loss (Source):  0.3209 ( 0.3355) Learning Rate: 0.0250 (0.0250) Top1_base: 95.3125 (90.9844) Top1_base_per_class: 94.2090 (91.4306) 
Training Epoch: [223/1000] Step: [110 / 285] Batch Time: 0.1463 (0.1638) Data Time: 0.0135 (0.0302) Average Loss: 0.1830 (0.3362) Average CE Loss (Source):  0.1830 ( 0.3362) Learning Rate: 0.0250 (0.0250) Top1_base: 93.7500 (90.9162) Top1_base_per_class: 94.1818 (91.3218) 
Training Epoch: [223/1000] Step: [120 / 285] Batch Time: 0.1486 (0.1630) Data Time: 0.0138 (0.0292) Average Loss: 0.3521 (0.3400) Average CE Loss (Source):  0.3521 ( 0.3400) Learning Rate: 0.0250 (0.0250) Top1_base: 92.9688 (90.8203) Top1_base_per_class: 92.6149 (91.2081) 
Training Epoch: [223/1000] Step: [130 / 285] Batch Time: 0.1480 (0.1621) Data Time: 0.0131 (0.0283) Average Loss: 0.4591 (0.3403) Average CE Loss (Source):  0.4591 ( 0.3403) Learning Rate: 0.0250 (0.0250) Top1_base: 91.4062 (90.8474) Top1_base_per_class: 92.3276 (91.2012) 
Training Epoch: [223/1000] Step: [140 / 285] Batch Time: 0.1497 (0.1622) Data Time: 0.0147 (0.0283) Average Loss: 0.4407 (0.3426) Average CE Loss (Source):  0.4407 ( 0.3426) Learning Rate: 0.0250 (0.0250) Top1_base: 87.5000 (90.7533) Top1_base_per_class: 86.1404 (91.1069) 
Training Epoch: [223/1000] Step: [150 / 285] Batch Time: 0.2283 (0.1625) Data Time: 0.0965 (0.0285) Average Loss: 0.3955 (0.3410) Average CE Loss (Source):  0.3955 ( 0.3410) Learning Rate: 0.0250 (0.0250) Top1_base: 89.0625 (90.8385) Top1_base_per_class: 88.9744 (91.1951) 
Training Epoch: [223/1000] Step: [160 / 285] Batch Time: 0.1460 (0.1620) Data Time: 0.0136 (0.0281) Average Loss: 0.3563 (0.3422) Average CE Loss (Source):  0.3563 ( 0.3422) Learning Rate: 0.0250 (0.0250) Top1_base: 89.8438 (90.7715) Top1_base_per_class: 89.9691 (91.1423) 
Training Epoch: [223/1000] Step: [170 / 285] Batch Time: 0.1505 (0.1617) Data Time: 0.0183 (0.0279) Average Loss: 0.3725 (0.3440) Average CE Loss (Source):  0.3725 ( 0.3440) Learning Rate: 0.0250 (0.0250) Top1_base: 87.5000 (90.7307) Top1_base_per_class: 90.6548 (91.1177) 
Training Epoch: [223/1000] Step: [180 / 285] Batch Time: 0.1468 (0.1612) Data Time: 0.0143 (0.0274) Average Loss: 0.3679 (0.3439) Average CE Loss (Source):  0.3679 ( 0.3439) Learning Rate: 0.0250 (0.0250) Top1_base: 92.9688 (90.7161) Top1_base_per_class: 91.9848 (91.1027) 
Training Epoch: [223/1000] Step: [190 / 285] Batch Time: 0.2009 (0.1611) Data Time: 0.0675 (0.0272) Average Loss: 0.2901 (0.3449) Average CE Loss (Source):  0.2901 ( 0.3449) Learning Rate: 0.0250 (0.0250) Top1_base: 91.4062 (90.6743) Top1_base_per_class: 91.9591 (91.0584) 
Training Epoch: [223/1000] Step: [200 / 285] Batch Time: 0.1464 (0.1607) Data Time: 0.0122 (0.0269) Average Loss: 0.2611 (0.3464) Average CE Loss (Source):  0.2611 ( 0.3464) Learning Rate: 0.0250 (0.0250) Top1_base: 92.1875 (90.6289) Top1_base_per_class: 93.8050 (91.0340) 
Training Epoch: [223/1000] Step: [210 / 285] Batch Time: 0.1944 (0.1610) Data Time: 0.0622 (0.0272) Average Loss: 0.4599 (0.3459) Average CE Loss (Source):  0.4599 ( 0.3459) Learning Rate: 0.0250 (0.0250) Top1_base: 89.8438 (90.6585) Top1_base_per_class: 91.4167 (91.0419) 
Training Epoch: [223/1000] Step: [220 / 285] Batch Time: 0.1482 (0.1607) Data Time: 0.0151 (0.0269) Average Loss: 0.3844 (0.3473) Average CE Loss (Source):  0.3844 ( 0.3473) Learning Rate: 0.0250 (0.0250) Top1_base: 91.4062 (90.6392) Top1_base_per_class: 91.1635 (91.0308) 
Training Epoch: [223/1000] Step: [230 / 285] Batch Time: 0.2061 (0.1606) Data Time: 0.0742 (0.0268) Average Loss: 0.3661 (0.3478) Average CE Loss (Source):  0.3661 ( 0.3478) Learning Rate: 0.0250 (0.0250) Top1_base: 89.0625 (90.5639) Top1_base_per_class: 91.5201 (90.9860) 
Training Epoch: [223/1000] Step: [240 / 285] Batch Time: 0.1431 (0.1609) Data Time: 0.0108 (0.0272) Average Loss: 0.4068 (0.3485) Average CE Loss (Source):  0.4068 ( 0.3485) Learning Rate: 0.0250 (0.0250) Top1_base: 92.1875 (90.5436) Top1_base_per_class: 92.4107 (90.9458) 
Training Epoch: [223/1000] Step: [250 / 285] Batch Time: 0.1718 (0.1606) Data Time: 0.0394 (0.0269) Average Loss: 0.3135 (0.3501) Average CE Loss (Source):  0.3135 ( 0.3501) Learning Rate: 0.0250 (0.0250) Top1_base: 89.8438 (90.4781) Top1_base_per_class: 90.5650 (90.8735) 
Training Epoch: [223/1000] Step: [260 / 285] Batch Time: 0.1459 (0.1603) Data Time: 0.0118 (0.0266) Average Loss: 0.2863 (0.3503) Average CE Loss (Source):  0.2863 ( 0.3503) Learning Rate: 0.0250 (0.0250) Top1_base: 92.9688 (90.4627) Top1_base_per_class: 92.2024 (90.8202) 
Training Epoch: [223/1000] Step: [270 / 285] Batch Time: 0.1640 (0.1604) Data Time: 0.0312 (0.0267) Average Loss: 0.3995 (0.3507) Average CE Loss (Source):  0.3995 ( 0.3507) Learning Rate: 0.0250 (0.0250) Top1_base: 86.7188 (90.4774) Top1_base_per_class: 86.6993 (90.8474) 
Training Epoch: [223/1000] Step: [280 / 285] Batch Time: 0.1445 (0.1601) Data Time: 0.0116 (0.0265) Average Loss: 0.3890 (0.3505) Average CE Loss (Source):  0.3890 ( 0.3505) Learning Rate: 0.0250 (0.0250) Top1_base: 92.9688 (90.4994) Top1_base_per_class: 92.3955 (90.8732) 
Training Epoch: [224/1000] Step: [0] Batch Time: 0.1416 (0.1600) Data Time: 0.0112 (0.0264) Average Loss: 0.3697 (0.3501) Average CE Loss (Source):  0.3697 ( 0.3501) Learning Rate: 0.0250 (0.0250) Top1_base: 90.6250 (90.5126) Top1_base_per_class: 93.0996 (90.8992) 
 22%|██▏       | 224/1000 [2:53:49<10:05:17, 46.80s/it] 22%|██▎       | 225/1000 [2:54:35<9:58:28, 46.33s/it] Training Epoch: [224/1000] Step: [10 / 285] Batch Time: 0.1442 (0.2539) Data Time: 0.0110 (0.1213) Average Loss: 0.4838 (0.3610) Average CE Loss (Source):  0.4838 ( 0.3610) Learning Rate: 0.0250 (0.0250) Top1_base: 85.9375 (90.2344) Top1_base_per_class: 85.8974 (90.6133) 
Training Epoch: [224/1000] Step: [20 / 285] Batch Time: 0.1448 (0.2028) Data Time: 0.0119 (0.0706) Average Loss: 0.3426 (0.3366) Average CE Loss (Source):  0.3426 ( 0.3366) Learning Rate: 0.0250 (0.0250) Top1_base: 90.6250 (90.8594) Top1_base_per_class: 90.6780 (91.0883) 
Training Epoch: [224/1000] Step: [30 / 285] Batch Time: 0.1479 (0.1888) Data Time: 0.0141 (0.0566) Average Loss: 0.2903 (0.3362) Average CE Loss (Source):  0.2903 ( 0.3362) Learning Rate: 0.0250 (0.0250) Top1_base: 92.1875 (91.0417) Top1_base_per_class: 91.6954 (91.3640) 
Training Epoch: [224/1000] Step: [40 / 285] Batch Time: 0.1452 (0.1815) Data Time: 0.0111 (0.0491) Average Loss: 0.2140 (0.3378) Average CE Loss (Source):  0.2140 ( 0.3378) Learning Rate: 0.0250 (0.0250) Top1_base: 96.0938 (91.2109) Top1_base_per_class: 94.0705 (91.4913) 
Training Epoch: [224/1000] Step: [50 / 285] Batch Time: 0.1456 (0.1786) Data Time: 0.0120 (0.0461) Average Loss: 0.3002 (0.3448) Average CE Loss (Source):  0.3002 ( 0.3448) Learning Rate: 0.0250 (0.0250) Top1_base: 91.4062 (90.8438) Top1_base_per_class: 90.9040 (91.0367) 
Training Epoch: [224/1000] Step: [60 / 285] Batch Time: 0.1450 (0.1744) Data Time: 0.0140 (0.0418) Average Loss: 0.3362 (0.3455) Average CE Loss (Source):  0.3362 ( 0.3455) Learning Rate: 0.0250 (0.0250) Top1_base: 91.4062 (90.7292) Top1_base_per_class: 90.6035 (90.9368) 
Training Epoch: [224/1000] Step: [70 / 285] Batch Time: 0.1466 (0.1710) Data Time: 0.0118 (0.0384) Average Loss: 0.3239 (0.3480) Average CE Loss (Source):  0.3239 ( 0.3480) Learning Rate: 0.0250 (0.0250) Top1_base: 90.6250 (90.6696) Top1_base_per_class: 91.3636 (90.8891) 
Training Epoch: [224/1000] Step: [80 / 285] Batch Time: 0.1476 (0.1687) Data Time: 0.0123 (0.0360) Average Loss: 0.3470 (0.3460) Average CE Loss (Source):  0.3470 ( 0.3460) Learning Rate: 0.0250 (0.0250) Top1_base: 91.4062 (90.7031) Top1_base_per_class: 92.5683 (90.9679) 
Training Epoch: [224/1000] Step: [90 / 285] Batch Time: 0.1463 (0.1675) Data Time: 0.0104 (0.0346) Average Loss: 0.3365 (0.3496) Average CE Loss (Source):  0.3365 ( 0.3496) Learning Rate: 0.0250 (0.0250) Top1_base: 91.4062 (90.6858) Top1_base_per_class: 92.2414 (91.0084) 
Training Epoch: [224/1000] Step: [100 / 285] Batch Time: 0.1430 (0.1655) Data Time: 0.0128 (0.0326) Average Loss: 0.3245 (0.3476) Average CE Loss (Source):  0.3245 ( 0.3476) Learning Rate: 0.0250 (0.0250) Top1_base: 91.4062 (90.6641) Top1_base_per_class: 93.3333 (90.9108) 
Training Epoch: [224/1000] Step: [110 / 285] Batch Time: 0.1457 (0.1650) Data Time: 0.0103 (0.0321) Average Loss: 0.3093 (0.3462) Average CE Loss (Source):  0.3093 ( 0.3462) Learning Rate: 0.0250 (0.0250) Top1_base: 91.4062 (90.6960) Top1_base_per_class: 89.7222 (90.8932) 
Training Epoch: [224/1000] Step: [120 / 285] Batch Time: 0.1467 (0.1635) Data Time: 0.0116 (0.0305) Average Loss: 0.3922 (0.3489) Average CE Loss (Source):  0.3922 ( 0.3489) Learning Rate: 0.0250 (0.0250) Top1_base: 87.5000 (90.5469) Top1_base_per_class: 87.5151 (90.6028) 
Training Epoch: [224/1000] Step: [130 / 285] Batch Time: 0.1468 (0.1626) Data Time: 0.0146 (0.0295) Average Loss: 0.4280 (0.3488) Average CE Loss (Source):  0.4280 ( 0.3488) Learning Rate: 0.0250 (0.0250) Top1_base: 89.0625 (90.5769) Top1_base_per_class: 88.5185 (90.6434) 
Training Epoch: [224/1000] Step: [140 / 285] Batch Time: 0.1492 (0.1624) Data Time: 0.0119 (0.0293) Average Loss: 0.4741 (0.3526) Average CE Loss (Source):  0.4741 ( 0.3526) Learning Rate: 0.0250 (0.0250) Top1_base: 89.0625 (90.5190) Top1_base_per_class: 88.8788 (90.5614) 
Training Epoch: [224/1000] Step: [150 / 285] Batch Time: 0.1464 (0.1622) Data Time: 0.0111 (0.0289) Average Loss: 0.3418 (0.3538) Average CE Loss (Source):  0.3418 ( 0.3538) Learning Rate: 0.0250 (0.0250) Top1_base: 87.5000 (90.4427) Top1_base_per_class: 86.0632 (90.5342) 
Training Epoch: [224/1000] Step: [160 / 285] Batch Time: 0.1466 (0.1619) Data Time: 0.0147 (0.0286) Average Loss: 0.3670 (0.3538) Average CE Loss (Source):  0.3670 ( 0.3538) Learning Rate: 0.0250 (0.0250) Top1_base: 90.6250 (90.4883) Top1_base_per_class: 92.3392 (90.5417) 
Training Epoch: [224/1000] Step: [170 / 285] Batch Time: 0.1475 (0.1615) Data Time: 0.0120 (0.0283) Average Loss: 0.3561 (0.3536) Average CE Loss (Source):  0.3561 ( 0.3536) Learning Rate: 0.0250 (0.0250) Top1_base: 88.2812 (90.4779) Top1_base_per_class: 88.8690 (90.5511) 
Training Epoch: [224/1000] Step: [180 / 285] Batch Time: 0.1421 (0.1612) Data Time: 0.0115 (0.0279) Average Loss: 0.2497 (0.3525) Average CE Loss (Source):  0.2497 ( 0.3525) Learning Rate: 0.0250 (0.0250) Top1_base: 95.3125 (90.5382) Top1_base_per_class: 95.2586 (90.6710) 
Training Epoch: [224/1000] Step: [190 / 285] Batch Time: 0.1420 (0.1609) Data Time: 0.0112 (0.0276) Average Loss: 0.3838 (0.3499) Average CE Loss (Source):  0.3838 ( 0.3499) Learning Rate: 0.0250 (0.0250) Top1_base: 90.6250 (90.5839) Top1_base_per_class: 88.0769 (90.7501) 
Training Epoch: [224/1000] Step: [200 / 285] Batch Time: 0.1488 (0.1604) Data Time: 0.0117 (0.0270) Average Loss: 0.2729 (0.3495) Average CE Loss (Source):  0.2729 ( 0.3495) Learning Rate: 0.0250 (0.0250) Top1_base: 93.7500 (90.5820) Top1_base_per_class: 92.3160 (90.7487) 
Training Epoch: [224/1000] Step: [210 / 285] Batch Time: 0.1449 (0.1609) Data Time: 0.0145 (0.0276) Average Loss: 0.4351 (0.3494) Average CE Loss (Source):  0.4351 ( 0.3494) Learning Rate: 0.0250 (0.0250) Top1_base: 89.8438 (90.6176) Top1_base_per_class: 89.7024 (90.8026) 
Training Epoch: [224/1000] Step: [220 / 285] Batch Time: 0.1428 (0.1604) Data Time: 0.0116 (0.0271) Average Loss: 0.3349 (0.3489) Average CE Loss (Source):  0.3349 ( 0.3489) Learning Rate: 0.0250 (0.0250) Top1_base: 89.8438 (90.5930) Top1_base_per_class: 86.2963 (90.7701) 
Training Epoch: [224/1000] Step: [230 / 285] Batch Time: 0.1438 (0.1602) Data Time: 0.0117 (0.0269) Average Loss: 0.3305 (0.3488) Average CE Loss (Source):  0.3305 ( 0.3488) Learning Rate: 0.0250 (0.0250) Top1_base: 92.1875 (90.6114) Top1_base_per_class: 93.4195 (90.7475) 
Training Epoch: [224/1000] Step: [240 / 285] Batch Time: 0.1463 (0.1597) Data Time: 0.0123 (0.0264) Average Loss: 0.3379 (0.3483) Average CE Loss (Source):  0.3379 ( 0.3483) Learning Rate: 0.0250 (0.0250) Top1_base: 91.4062 (90.6250) Top1_base_per_class: 93.2372 (90.7557) 
Training Epoch: [224/1000] Step: [250 / 285] Batch Time: 0.1474 (0.1592) Data Time: 0.0110 (0.0259) Average Loss: 0.3138 (0.3481) Average CE Loss (Source):  0.3138 ( 0.3481) Learning Rate: 0.0250 (0.0250) Top1_base: 92.9688 (90.6375) Top1_base_per_class: 92.3939 (90.7805) 
Training Epoch: [224/1000] Step: [260 / 285] Batch Time: 0.1453 (0.1587) Data Time: 0.0136 (0.0254) Average Loss: 0.3292 (0.3480) Average CE Loss (Source):  0.3292 ( 0.3480) Learning Rate: 0.0250 (0.0250) Top1_base: 92.9688 (90.6310) Top1_base_per_class: 91.4541 (90.7822) 
Training Epoch: [224/1000] Step: [270 / 285] Batch Time: 0.1425 (0.1590) Data Time: 0.0117 (0.0258) Average Loss: 0.3330 (0.3474) Average CE Loss (Source):  0.3330 ( 0.3474) Learning Rate: 0.0250 (0.0250) Top1_base: 91.4062 (90.6395) Top1_base_per_class: 89.1346 (90.7902) 
Training Epoch: [224/1000] Step: [280 / 285] Batch Time: 0.1468 (0.1587) Data Time: 0.0117 (0.0255) Average Loss: 0.3080 (0.3477) Average CE Loss (Source):  0.3080 ( 0.3477) Learning Rate: 0.0250 (0.0250) Top1_base: 92.1875 (90.6278) Top1_base_per_class: 94.5062 (90.7908) 
Training Epoch: [225/1000] Step: [0] Batch Time: 0.1435 (0.1585) Data Time: 0.0143 (0.0253) Average Loss: 0.2906 (0.3472) Average CE Loss (Source):  0.2906 ( 0.3472) Learning Rate: 0.0250 (0.0250) Top1_base: 92.1875 (90.6360) Top1_base_per_class: 90.2941 (90.7893) 
Training Epoch: [225/1000] Step: [10 / 285] Batch Time: 0.1469 (0.2436) Data Time: 0.0119 (0.1102) Average Loss: 0.2475 (0.2988) Average CE Loss (Source):  0.2475 ( 0.2988) Learning Rate: 0.0250 (0.0250) Top1_base: 93.7500 (91.9531) Top1_base_per_class: 94.6258 (91.8580) 
Training Epoch: [225/1000] Step: [20 / 285] Batch Time: 0.1542 (0.2003) Data Time: 0.0161 (0.0655) Average Loss: 0.3594 (0.3216) Average CE Loss (Source):  0.3594 ( 0.3216) Learning Rate: 0.0250 (0.0250) Top1_base: 89.0625 (91.0938) Top1_base_per_class: 90.3279 (91.0092) 
Training Epoch: [225/1000] Step: [30 / 285] Batch Time: 0.1469 (0.1875) Data Time: 0.0117 (0.0530) Average Loss: 0.3558 (0.3239) Average CE Loss (Source):  0.3558 ( 0.3239) Learning Rate: 0.0250 (0.0250) Top1_base: 90.6250 (91.2500) Top1_base_per_class: 91.0714 (91.5620) 
Training Epoch: [225/1000] Step: [40 / 285] Batch Time: 0.1464 (0.1775) Data Time: 0.0150 (0.0433) Average Loss: 0.4400 (0.3400) Average CE Loss (Source):  0.4400 ( 0.3400) Learning Rate: 0.0250 (0.0250) Top1_base: 88.2812 (90.8984) Top1_base_per_class: 88.3636 (91.2392) 
Training Epoch: [225/1000] Step: [50 / 285] Batch Time: 0.1447 (0.1731) Data Time: 0.0109 (0.0390) Average Loss: 0.3856 (0.3437) Average CE Loss (Source):  0.3856 ( 0.3437) Learning Rate: 0.0250 (0.0250) Top1_base: 86.7188 (90.6562) Top1_base_per_class: 86.0151 (91.0357) 
Training Epoch: [225/1000] Step: [60 / 285] Batch Time: 0.1502 (0.1700) Data Time: 0.0158 (0.0359) Average Loss: 0.4110 (0.3547) Average CE Loss (Source):  0.4110 ( 0.3547) Learning Rate: 0.0250 (0.0250) Top1_base: 88.2812 (90.5078) Top1_base_per_class: 91.1111 (91.0790) 
Training Epoch: [225/1000] Step: [70 / 285] Batch Time: 0.1463 (0.1685) Data Time: 0.0106 (0.0345) Average Loss: 0.3162 (0.3540) Average CE Loss (Source):  0.3162 ( 0.3540) Learning Rate: 0.0250 (0.0250) Top1_base: 92.1875 (90.4688) Top1_base_per_class: 93.3030 (90.9561) 
Training Epoch: [225/1000] Step: [80 / 285] Batch Time: 0.2527 (0.1680) Data Time: 0.1201 (0.0341) Average Loss: 0.3340 (0.3555) Average CE Loss (Source):  0.3340 ( 0.3555) Learning Rate: 0.0250 (0.0250) Top1_base: 92.1875 (90.5078) Top1_base_per_class: 90.2047 (90.8711) 
Training Epoch: [225/1000] Step: [90 / 285] Batch Time: 0.1451 (0.1665) Data Time: 0.0117 (0.0327) Average Loss: 0.3821 (0.3580) Average CE Loss (Source):  0.3821 ( 0.3580) Learning Rate: 0.0250 (0.0250) Top1_base: 90.6250 (90.4340) Top1_base_per_class: 89.8851 (90.6897) 
Training Epoch: [225/1000] Step: [100 / 285] Batch Time: 0.1574 (0.1655) Data Time: 0.0241 (0.0317) Average Loss: 0.2632 (0.3511) Average CE Loss (Source):  0.2632 ( 0.3511) Learning Rate: 0.0250 (0.0250) Top1_base: 92.9688 (90.7031) Top1_base_per_class: 93.9506 (91.0393) 
Training Epoch: [225/1000] Step: [110 / 285] Batch Time: 0.1478 (0.1642) Data Time: 0.0118 (0.0302) Average Loss: 0.4506 (0.3558) Average CE Loss (Source):  0.4506 ( 0.3558) Learning Rate: 0.0250 (0.0250) Top1_base: 86.7188 (90.5611) Top1_base_per_class: 85.6322 (90.9174) 
Training Epoch: [225/1000] Step: [120 / 285] Batch Time: 0.1516 (0.1630) Data Time: 0.0172 (0.0289) Average Loss: 0.2612 (0.3527) Average CE Loss (Source):  0.2612 ( 0.3527) Learning Rate: 0.0250 (0.0250) Top1_base: 92.9688 (90.5729) Top1_base_per_class: 93.4463 (90.9424) 
Training Epoch: [225/1000] Step: [130 / 285] Batch Time: 0.1462 (0.1618) Data Time: 0.0120 (0.0277) Average Loss: 0.6001 (0.3590) Average CE Loss (Source):  0.6001 ( 0.3590) Learning Rate: 0.0250 (0.0250) Top1_base: 85.1562 (90.4087) Top1_base_per_class: 86.8827 (90.7777) 
Training Epoch: [225/1000] Step: [140 / 285] Batch Time: 0.1504 (0.1609) Data Time: 0.0183 (0.0267) Average Loss: 0.3070 (0.3608) Average CE Loss (Source):  0.3070 ( 0.3608) Learning Rate: 0.0250 (0.0250) Top1_base: 93.7500 (90.4074) Top1_base_per_class: 94.7879 (90.7453) 
Training Epoch: [225/1000] Step: [150 / 285] Batch Time: 0.1455 (0.1599) Data Time: 0.0106 (0.0258) Average Loss: 0.2993 (0.3594) Average CE Loss (Source):  0.2993 ( 0.3594) Learning Rate: 0.0250 (0.0250) Top1_base: 92.1875 (90.4792) Top1_base_per_class: 89.1228 (90.7848) 
Training Epoch: [225/1000] Step: [160 / 285] Batch Time: 0.1488 (0.1591) Data Time: 0.0166 (0.0251) Average Loss: 0.2947 (0.3579) Average CE Loss (Source):  0.2947 ( 0.3579) Learning Rate: 0.0250 (0.0250) Top1_base: 92.1875 (90.4834) Top1_base_per_class: 92.6724 (90.7617) 
Training Epoch: [225/1000] Step: [170 / 285] Batch Time: 0.1443 (0.1588) Data Time: 0.0104 (0.0248) Average Loss: 0.4541 (0.3596) Average CE Loss (Source):  0.4541 ( 0.3596) Learning Rate: 0.0250 (0.0250) Top1_base: 87.5000 (90.3722) Top1_base_per_class: 88.0563 (90.6794) 
Training Epoch: [225/1000] Step: [180 / 285] Batch Time: 0.1469 (0.1584) Data Time: 0.0125 (0.0244) Average Loss: 0.4857 (0.3607) Average CE Loss (Source):  0.4857 ( 0.3607) Learning Rate: 0.0250 (0.0250) Top1_base: 85.1562 (90.3082) Top1_base_per_class: 84.9839 (90.5982) 
Training Epoch: [225/1000] Step: [190 / 285] Batch Time: 0.1468 (0.1584) Data Time: 0.0133 (0.0245) Average Loss: 0.3680 (0.3601) Average CE Loss (Source):  0.3680 ( 0.3601) Learning Rate: 0.0250 (0.0250) Top1_base: 88.2812 (90.3002) Top1_base_per_class: 86.2500 (90.5518) 
Training Epoch: [225/1000] Step: [200 / 285] Batch Time: 0.1488 (0.1580) Data Time: 0.0167 (0.0242) Average Loss: 0.3467 (0.3575) Average CE Loss (Source):  0.3467 ( 0.3575) Learning Rate: 0.0250 (0.0250) Top1_base: 89.8438 (90.3594) Top1_base_per_class: 88.9308 (90.5899) 
Training Epoch: [225/1000] Step: [210 / 285] Batch Time: 0.1435 (0.1579) Data Time: 0.0116 (0.0241) Average Loss: 0.3512 (0.3574) Average CE Loss (Source):  0.3512 ( 0.3574) Learning Rate: 0.0250 (0.0250) Top1_base: 89.8438 (90.3348) Top1_base_per_class: 91.9643 (90.5911) 
Training Epoch: [225/1000] Step: [220 / 285] Batch Time: 0.1457 (0.1575) Data Time: 0.0150 (0.0238) Average Loss: 0.3074 (0.3566) Average CE Loss (Source):  0.3074 ( 0.3566) Learning Rate: 0.0250 (0.0250) Top1_base: 88.2812 (90.3054) Top1_base_per_class: 89.3082 (90.5801) 
Training Epoch: [225/1000] Step: [230 / 285] Batch Time: 0.1465 (0.1576) Data Time: 0.0104 (0.0238) Average Loss: 0.3753 (0.3582) Average CE Loss (Source):  0.3753 ( 0.3582) Learning Rate: 0.0250 (0.0250) Top1_base: 91.4062 (90.2649) Top1_base_per_class: 90.1190 (90.5463) 
Training Epoch: [225/1000] Step: [240 / 285] Batch Time: 0.1459 (0.1575) Data Time: 0.0135 (0.0238) Average Loss: 0.4265 (0.3573) Average CE Loss (Source):  0.4265 ( 0.3573) Learning Rate: 0.0250 (0.0250) Top1_base: 89.8438 (90.2572) Top1_base_per_class: 89.3707 (90.5524) 
Training Epoch: [225/1000] Step: [250 / 285] Batch Time: 0.1472 (0.1575) Data Time: 0.0103 (0.0239) Average Loss: 0.3389 (0.3569) Average CE Loss (Source):  0.3389 ( 0.3569) Learning Rate: 0.0250 (0.0250) Top1_base: 91.4062 (90.2313) Top1_base_per_class: 93.1753 (90.5415) 
Training Epoch: [225/1000] Step: [260 / 285] Batch Time: 0.1437 (0.1574) Data Time: 0.0116 (0.0238) Average Loss: 0.3936 (0.3573) Average CE Loss (Source):  0.3936 ( 0.3573) Learning Rate: 0.0250 (0.0250) Top1_base: 89.0625 (90.2254) Top1_base_per_class: 89.7665 (90.5538) 
Training Epoch: [225/1000] Step: [270 / 285] Batch Time: 0.1461 (0.1577) Data Time: 0.0102 (0.0241) Average Loss: 0.3465 (0.3564) Average CE Loss (Source):  0.3465 ( 0.3564) Learning Rate: 0.0250 (0.0250) Top1_base: 89.0625 (90.2546) Top1_base_per_class: 88.7500 (90.5894) 
Training Epoch: [225/1000] Step: [280 / 285] Batch Time: 0.1428 (0.1574) Data Time: 0.0110 (0.0238) Average Loss: 0.5058 (0.3562) Average CE Loss (Source):  0.5058 ( 0.3562) Learning Rate: 0.0250 (0.0250) Top1_base: 84.3750 (90.2651) Top1_base_per_class: 85.1818 (90.5887) 
Training Epoch: [226/1000] Step: [0] Batch Time: 0.1548 (0.1573) Data Time: 0.0252 (0.0237) Average Loss: 0.4377 (0.3567) Average CE Loss (Source):  0.4377 ( 0.3567) Learning Rate: 0.0250 (0.0250) Top1_base: 89.8438 (90.2741) Top1_base_per_class: 90.1847 (90.6028) 
 23%|██▎       | 226/1000 [2:55:22<10:02:58, 46.74s/it] 23%|██▎       | 227/1000 [2:56:08<9:58:46, 46.48s/it] Training Epoch: [226/1000] Step: [10 / 285] Batch Time: 0.1452 (0.2349) Data Time: 0.0107 (0.1015) Average Loss: 0.2776 (0.3477) Average CE Loss (Source):  0.2776 ( 0.3477) Learning Rate: 0.0125 (0.0125) Top1_base: 91.4062 (90.7031) Top1_base_per_class: 90.3509 (91.2280) 
Training Epoch: [226/1000] Step: [20 / 285] Batch Time: 0.1446 (0.1984) Data Time: 0.0122 (0.0651) Average Loss: 0.2963 (0.3322) Average CE Loss (Source):  0.2963 ( 0.3322) Learning Rate: 0.0125 (0.0125) Top1_base: 91.4062 (90.7812) Top1_base_per_class: 94.1757 (91.1800) 
Training Epoch: [226/1000] Step: [30 / 285] Batch Time: 0.1444 (0.1882) Data Time: 0.0103 (0.0551) Average Loss: 0.3922 (0.3187) Average CE Loss (Source):  0.3922 ( 0.3187) Learning Rate: 0.0125 (0.0125) Top1_base: 90.6250 (91.3021) Top1_base_per_class: 88.5593 (91.5741) 
Training Epoch: [226/1000] Step: [40 / 285] Batch Time: 0.1438 (0.1805) Data Time: 0.0107 (0.0474) Average Loss: 0.3395 (0.3190) Average CE Loss (Source):  0.3395 ( 0.3190) Learning Rate: 0.0125 (0.0125) Top1_base: 91.4062 (91.4062) Top1_base_per_class: 92.5439 (91.4079) 
Training Epoch: [226/1000] Step: [50 / 285] Batch Time: 0.1442 (0.1773) Data Time: 0.0109 (0.0443) Average Loss: 0.3094 (0.3219) Average CE Loss (Source):  0.3094 ( 0.3219) Learning Rate: 0.0125 (0.0125) Top1_base: 94.5312 (91.2656) Top1_base_per_class: 93.7273 (91.1711) 
Training Epoch: [226/1000] Step: [60 / 285] Batch Time: 0.1459 (0.1727) Data Time: 0.0109 (0.0397) Average Loss: 0.2491 (0.3162) Average CE Loss (Source):  0.2491 ( 0.3162) Learning Rate: 0.0125 (0.0125) Top1_base: 90.6250 (91.3542) Top1_base_per_class: 93.4821 (91.2408) 
Training Epoch: [226/1000] Step: [70 / 285] Batch Time: 0.1453 (0.1711) Data Time: 0.0110 (0.0382) Average Loss: 0.2353 (0.3149) Average CE Loss (Source):  0.2353 ( 0.3149) Learning Rate: 0.0125 (0.0125) Top1_base: 95.3125 (91.4955) Top1_base_per_class: 95.7143 (91.4087) 
Training Epoch: [226/1000] Step: [80 / 285] Batch Time: 0.1423 (0.1683) Data Time: 0.0120 (0.0355) Average Loss: 0.4089 (0.3113) Average CE Loss (Source):  0.4089 ( 0.3113) Learning Rate: 0.0125 (0.0125) Top1_base: 89.0625 (91.6016) Top1_base_per_class: 85.2679 (91.3899) 
Training Epoch: [226/1000] Step: [90 / 285] Batch Time: 0.1450 (0.1671) Data Time: 0.0108 (0.0343) Average Loss: 0.3815 (0.3141) Average CE Loss (Source):  0.3815 ( 0.3141) Learning Rate: 0.0125 (0.0125) Top1_base: 88.2812 (91.5104) Top1_base_per_class: 91.7879 (91.4143) 
Training Epoch: [226/1000] Step: [100 / 285] Batch Time: 0.1445 (0.1657) Data Time: 0.0110 (0.0330) Average Loss: 0.2726 (0.3105) Average CE Loss (Source):  0.2726 ( 0.3105) Learning Rate: 0.0125 (0.0125) Top1_base: 92.1875 (91.6172) Top1_base_per_class: 93.1481 (91.5775) 
Training Epoch: [226/1000] Step: [110 / 285] Batch Time: 0.1446 (0.1645) Data Time: 0.0104 (0.0318) Average Loss: 0.3078 (0.3080) Average CE Loss (Source):  0.3078 ( 0.3080) Learning Rate: 0.0125 (0.0125) Top1_base: 91.4062 (91.6406) Top1_base_per_class: 91.5454 (91.6102) 
Training Epoch: [226/1000] Step: [120 / 285] Batch Time: 0.1445 (0.1637) Data Time: 0.0105 (0.0310) Average Loss: 0.2866 (0.3059) Average CE Loss (Source):  0.2866 ( 0.3059) Learning Rate: 0.0125 (0.0125) Top1_base: 91.4062 (91.6862) Top1_base_per_class: 94.7273 (91.6985) 
Training Epoch: [226/1000] Step: [130 / 285] Batch Time: 0.1414 (0.1634) Data Time: 0.0121 (0.0308) Average Loss: 0.3656 (0.3075) Average CE Loss (Source):  0.3656 ( 0.3075) Learning Rate: 0.0125 (0.0125) Top1_base: 88.2812 (91.5986) Top1_base_per_class: 88.6478 (91.6365) 
Training Epoch: [226/1000] Step: [140 / 285] Batch Time: 0.1420 (0.1629) Data Time: 0.0114 (0.0304) Average Loss: 0.2671 (0.3099) Average CE Loss (Source):  0.2671 ( 0.3099) Learning Rate: 0.0125 (0.0125) Top1_base: 91.4062 (91.5792) Top1_base_per_class: 92.9598 (91.6327) 
Training Epoch: [226/1000] Step: [150 / 285] Batch Time: 0.1420 (0.1628) Data Time: 0.0119 (0.0304) Average Loss: 0.2162 (0.3081) Average CE Loss (Source):  0.2162 ( 0.3081) Learning Rate: 0.0125 (0.0125) Top1_base: 92.9688 (91.6094) Top1_base_per_class: 92.7083 (91.6420) 
Training Epoch: [226/1000] Step: [160 / 285] Batch Time: 0.1423 (0.1619) Data Time: 0.0121 (0.0295) Average Loss: 0.3058 (0.3094) Average CE Loss (Source):  0.3058 ( 0.3094) Learning Rate: 0.0125 (0.0125) Top1_base: 89.0625 (91.5283) Top1_base_per_class: 92.0525 (91.6588) 
Training Epoch: [226/1000] Step: [170 / 285] Batch Time: 0.1452 (0.1621) Data Time: 0.0106 (0.0297) Average Loss: 0.3102 (0.3077) Average CE Loss (Source):  0.3102 ( 0.3077) Learning Rate: 0.0125 (0.0125) Top1_base: 93.7500 (91.6360) Top1_base_per_class: 94.1799 (91.7960) 
Training Epoch: [226/1000] Step: [180 / 285] Batch Time: 0.1446 (0.1613) Data Time: 0.0105 (0.0288) Average Loss: 0.2859 (0.3076) Average CE Loss (Source):  0.2859 ( 0.3076) Learning Rate: 0.0125 (0.0125) Top1_base: 91.4062 (91.6536) Top1_base_per_class: 92.5575 (91.8175) 
Training Epoch: [226/1000] Step: [190 / 285] Batch Time: 0.1462 (0.1611) Data Time: 0.0107 (0.0285) Average Loss: 0.3920 (0.3098) Average CE Loss (Source):  0.3920 ( 0.3098) Learning Rate: 0.0125 (0.0125) Top1_base: 89.8438 (91.5831) Top1_base_per_class: 89.8851 (91.7573) 
Training Epoch: [226/1000] Step: [200 / 285] Batch Time: 0.1455 (0.1606) Data Time: 0.0107 (0.0281) Average Loss: 0.3018 (0.3102) Average CE Loss (Source):  0.3018 ( 0.3102) Learning Rate: 0.0125 (0.0125) Top1_base: 92.9688 (91.5703) Top1_base_per_class: 93.2759 (91.7363) 
Training Epoch: [226/1000] Step: [210 / 285] Batch Time: 0.1436 (0.1605) Data Time: 0.0106 (0.0279) Average Loss: 0.4029 (0.3106) Average CE Loss (Source):  0.4029 ( 0.3106) Learning Rate: 0.0125 (0.0125) Top1_base: 89.0625 (91.5290) Top1_base_per_class: 92.2034 (91.7089) 
Training Epoch: [226/1000] Step: [220 / 285] Batch Time: 0.1450 (0.1605) Data Time: 0.0106 (0.0280) Average Loss: 0.2821 (0.3102) Average CE Loss (Source):  0.2821 ( 0.3102) Learning Rate: 0.0125 (0.0125) Top1_base: 89.8438 (91.5554) Top1_base_per_class: 90.1754 (91.7357) 
Training Epoch: [226/1000] Step: [230 / 285] Batch Time: 0.1439 (0.1611) Data Time: 0.0106 (0.0286) Average Loss: 0.3607 (0.3104) Average CE Loss (Source):  0.3607 ( 0.3104) Learning Rate: 0.0125 (0.0125) Top1_base: 90.6250 (91.5591) Top1_base_per_class: 89.9191 (91.7562) 
Training Epoch: [226/1000] Step: [240 / 285] Batch Time: 0.1452 (0.1607) Data Time: 0.0105 (0.0282) Average Loss: 0.2751 (0.3099) Average CE Loss (Source):  0.2751 ( 0.3099) Learning Rate: 0.0125 (0.0125) Top1_base: 92.1875 (91.5625) Top1_base_per_class: 93.6207 (91.7657) 
Training Epoch: [226/1000] Step: [250 / 285] Batch Time: 0.1455 (0.1606) Data Time: 0.0111 (0.0280) Average Loss: 0.3333 (0.3095) Average CE Loss (Source):  0.3333 ( 0.3095) Learning Rate: 0.0125 (0.0125) Top1_base: 92.1875 (91.5719) Top1_base_per_class: 91.0577 (91.7798) 
Training Epoch: [226/1000] Step: [260 / 285] Batch Time: 0.1430 (0.1609) Data Time: 0.0105 (0.0284) Average Loss: 0.3531 (0.3096) Average CE Loss (Source):  0.3531 ( 0.3096) Learning Rate: 0.0125 (0.0125) Top1_base: 89.0625 (91.5655) Top1_base_per_class: 88.1515 (91.7932) 
Training Epoch: [226/1000] Step: [270 / 285] Batch Time: 0.1443 (0.1608) Data Time: 0.0104 (0.0283) Average Loss: 0.2859 (0.3099) Average CE Loss (Source):  0.2859 ( 0.3099) Learning Rate: 0.0125 (0.0125) Top1_base: 94.5312 (91.5799) Top1_base_per_class: 94.6854 (91.8094) 
Training Epoch: [226/1000] Step: [280 / 285] Batch Time: 0.1442 (0.1608) Data Time: 0.0102 (0.0283) Average Loss: 0.2702 (0.3079) Average CE Loss (Source):  0.2702 ( 0.3079) Learning Rate: 0.0125 (0.0125) Top1_base: 92.9688 (91.6350) Top1_base_per_class: 93.9080 (91.8607) 
Training Epoch: [227/1000] Step: [0] Batch Time: 0.1669 (0.1607) Data Time: 0.0358 (0.0281) Average Loss: 0.3571 (0.3080) Average CE Loss (Source):  0.3571 ( 0.3080) Learning Rate: 0.0125 (0.0125) Top1_base: 90.6250 (91.6475) Top1_base_per_class: 92.4854 (91.8854) 
Training Epoch: [227/1000] Step: [10 / 285] Batch Time: 0.1426 (0.2405) Data Time: 0.0122 (0.1083) Average Loss: 0.3212 (0.3314) Average CE Loss (Source):  0.3212 ( 0.3314) Learning Rate: 0.0125 (0.0125) Top1_base: 92.1875 (91.1719) Top1_base_per_class: 89.2901 (91.5419) 
Training Epoch: [227/1000] Step: [20 / 285] Batch Time: 0.1465 (0.1934) Data Time: 0.0122 (0.0611) Average Loss: 0.3346 (0.3183) Average CE Loss (Source):  0.3346 ( 0.3183) Learning Rate: 0.0125 (0.0125) Top1_base: 92.9688 (91.3672) Top1_base_per_class: 93.4014 (92.2453) 
Training Epoch: [227/1000] Step: [30 / 285] Batch Time: 0.1565 (0.1797) Data Time: 0.0242 (0.0470) Average Loss: 0.2164 (0.3113) Average CE Loss (Source):  0.2164 ( 0.3113) Learning Rate: 0.0125 (0.0125) Top1_base: 93.7500 (91.5625) Top1_base_per_class: 95.6845 (92.3497) 
Training Epoch: [227/1000] Step: [40 / 285] Batch Time: 0.1442 (0.1732) Data Time: 0.0120 (0.0406) Average Loss: 0.1392 (0.2974) Average CE Loss (Source):  0.1392 ( 0.2974) Learning Rate: 0.0125 (0.0125) Top1_base: 96.8750 (91.9141) Top1_base_per_class: 97.8704 (92.4496) 
Training Epoch: [227/1000] Step: [50 / 285] Batch Time: 0.1464 (0.1692) Data Time: 0.0132 (0.0365) Average Loss: 0.2421 (0.2936) Average CE Loss (Source):  0.2421 ( 0.2936) Learning Rate: 0.0125 (0.0125) Top1_base: 93.7500 (92.1094) Top1_base_per_class: 91.9333 (92.6790) 
Training Epoch: [227/1000] Step: [60 / 285] Batch Time: 0.1450 (0.1674) Data Time: 0.0133 (0.0345) Average Loss: 0.3403 (0.2952) Average CE Loss (Source):  0.3403 ( 0.2952) Learning Rate: 0.0125 (0.0125) Top1_base: 89.0625 (91.9792) Top1_base_per_class: 86.6215 (92.4898) 
Training Epoch: [227/1000] Step: [70 / 285] Batch Time: 0.1569 (0.1649) Data Time: 0.0251 (0.0321) Average Loss: 0.2992 (0.2968) Average CE Loss (Source):  0.2992 ( 0.2968) Learning Rate: 0.0125 (0.0125) Top1_base: 90.6250 (91.8527) Top1_base_per_class: 92.8572 (92.4703) 
Training Epoch: [227/1000] Step: [80 / 285] Batch Time: 0.1450 (0.1646) Data Time: 0.0124 (0.0318) Average Loss: 0.2824 (0.2923) Average CE Loss (Source):  0.2824 ( 0.2923) Learning Rate: 0.0125 (0.0125) Top1_base: 90.6250 (92.0312) Top1_base_per_class: 90.9649 (92.6403) 
Training Epoch: [227/1000] Step: [90 / 285] Batch Time: 0.2690 (0.1645) Data Time: 0.1370 (0.0317) Average Loss: 0.2727 (0.2896) Average CE Loss (Source):  0.2727 ( 0.2896) Learning Rate: 0.0125 (0.0125) Top1_base: 91.4062 (92.0660) Top1_base_per_class: 91.3939 (92.6685) 
Training Epoch: [227/1000] Step: [100 / 285] Batch Time: 0.1442 (0.1639) Data Time: 0.0120 (0.0311) Average Loss: 0.2407 (0.2911) Average CE Loss (Source):  0.2407 ( 0.2911) Learning Rate: 0.0125 (0.0125) Top1_base: 93.7500 (92.0859) Top1_base_per_class: 94.0059 (92.6858) 
Training Epoch: [227/1000] Step: [110 / 285] Batch Time: 0.1743 (0.1632) Data Time: 0.0436 (0.0304) Average Loss: 0.2580 (0.2932) Average CE Loss (Source):  0.2580 ( 0.2932) Learning Rate: 0.0125 (0.0125) Top1_base: 91.4062 (92.0384) Top1_base_per_class: 92.1515 (92.6124) 
Training Epoch: [227/1000] Step: [120 / 285] Batch Time: 0.1449 (0.1621) Data Time: 0.0120 (0.0293) Average Loss: 0.2355 (0.2929) Average CE Loss (Source):  0.2355 ( 0.2929) Learning Rate: 0.0125 (0.0125) Top1_base: 92.9688 (92.0508) Top1_base_per_class: 93.6309 (92.6405) 
Training Epoch: [227/1000] Step: [130 / 285] Batch Time: 0.1562 (0.1615) Data Time: 0.0251 (0.0288) Average Loss: 0.2222 (0.2905) Average CE Loss (Source):  0.2222 ( 0.2905) Learning Rate: 0.0125 (0.0125) Top1_base: 93.7500 (92.1514) Top1_base_per_class: 93.2440 (92.7561) 
Training Epoch: [227/1000] Step: [140 / 285] Batch Time: 0.1442 (0.1608) Data Time: 0.0110 (0.0281) Average Loss: 0.3867 (0.2905) Average CE Loss (Source):  0.3867 ( 0.2905) Learning Rate: 0.0125 (0.0125) Top1_base: 88.2812 (92.1205) Top1_base_per_class: 89.9691 (92.6563) 
Training Epoch: [227/1000] Step: [150 / 285] Batch Time: 0.1637 (0.1604) Data Time: 0.0309 (0.0276) Average Loss: 0.1859 (0.2876) Average CE Loss (Source):  0.1859 ( 0.2876) Learning Rate: 0.0125 (0.0125) Top1_base: 94.5312 (92.2240) Top1_base_per_class: 93.2251 (92.7764) 
Training Epoch: [227/1000] Step: [160 / 285] Batch Time: 0.1484 (0.1603) Data Time: 0.0148 (0.0274) Average Loss: 0.2734 (0.2884) Average CE Loss (Source):  0.2734 ( 0.2884) Learning Rate: 0.0125 (0.0125) Top1_base: 92.9688 (92.1680) Top1_base_per_class: 93.6309 (92.7142) 
Training Epoch: [227/1000] Step: [170 / 285] Batch Time: 0.1466 (0.1596) Data Time: 0.0130 (0.0266) Average Loss: 0.3085 (0.2901) Average CE Loss (Source):  0.3085 ( 0.2901) Learning Rate: 0.0125 (0.0125) Top1_base: 94.5312 (92.1553) Top1_base_per_class: 95.1923 (92.6872) 
Training Epoch: [227/1000] Step: [180 / 285] Batch Time: 0.1455 (0.1589) Data Time: 0.0127 (0.0258) Average Loss: 0.3379 (0.2897) Average CE Loss (Source):  0.3379 ( 0.2897) Learning Rate: 0.0125 (0.0125) Top1_base: 89.0625 (92.1441) Top1_base_per_class: 91.3208 (92.6381) 
Training Epoch: [227/1000] Step: [190 / 285] Batch Time: 0.1485 (0.1584) Data Time: 0.0147 (0.0252) Average Loss: 0.2555 (0.2912) Average CE Loss (Source):  0.2555 ( 0.2912) Learning Rate: 0.0125 (0.0125) Top1_base: 95.3125 (92.1176) Top1_base_per_class: 95.4978 (92.6071) 
Training Epoch: [227/1000] Step: [200 / 285] Batch Time: 0.1450 (0.1579) Data Time: 0.0116 (0.0247) Average Loss: 0.2617 (0.2912) Average CE Loss (Source):  0.2617 ( 0.2912) Learning Rate: 0.0125 (0.0125) Top1_base: 92.9688 (92.1445) Top1_base_per_class: 95.3869 (92.6557) 
Training Epoch: [227/1000] Step: [210 / 285] Batch Time: 0.1441 (0.1583) Data Time: 0.0113 (0.0251) Average Loss: 0.3130 (0.2906) Average CE Loss (Source):  0.3130 ( 0.2906) Learning Rate: 0.0125 (0.0125) Top1_base: 91.4062 (92.1577) Top1_base_per_class: 91.2121 (92.6212) 
Training Epoch: [227/1000] Step: [220 / 285] Batch Time: 0.1471 (0.1579) Data Time: 0.0129 (0.0246) Average Loss: 0.3129 (0.2902) Average CE Loss (Source):  0.3129 ( 0.2902) Learning Rate: 0.0125 (0.0125) Top1_base: 91.4062 (92.1626) Top1_base_per_class: 93.0303 (92.6319) 
Training Epoch: [227/1000] Step: [230 / 285] Batch Time: 0.1465 (0.1576) Data Time: 0.0126 (0.0242) Average Loss: 0.4009 (0.2898) Average CE Loss (Source):  0.4009 ( 0.2898) Learning Rate: 0.0125 (0.0125) Top1_base: 89.8438 (92.1875) Top1_base_per_class: 89.2424 (92.6456) 
Training Epoch: [227/1000] Step: [240 / 285] Batch Time: 0.1467 (0.1579) Data Time: 0.0121 (0.0244) Average Loss: 0.3622 (0.2889) Average CE Loss (Source):  0.3622 ( 0.2889) Learning Rate: 0.0125 (0.0125) Top1_base: 87.5000 (92.1908) Top1_base_per_class: 86.3988 (92.6203) 
Training Epoch: [227/1000] Step: [250 / 285] Batch Time: 0.1439 (0.1575) Data Time: 0.0107 (0.0239) Average Loss: 0.4278 (0.2905) Average CE Loss (Source):  0.4278 ( 0.2905) Learning Rate: 0.0125 (0.0125) Top1_base: 89.8438 (92.1625) Top1_base_per_class: 91.0077 (92.5973) 
Training Epoch: [227/1000] Step: [260 / 285] Batch Time: 0.1457 (0.1572) Data Time: 0.0117 (0.0237) Average Loss: 0.1856 (0.2902) Average CE Loss (Source):  0.1856 ( 0.2902) Learning Rate: 0.0125 (0.0125) Top1_base: 92.1875 (92.1635) Top1_base_per_class: 92.4138 (92.5965) 
Training Epoch: [227/1000] Step: [270 / 285] Batch Time: 0.1450 (0.1572) Data Time: 0.0139 (0.0237) Average Loss: 0.2583 (0.2902) Average CE Loss (Source):  0.2583 ( 0.2902) Learning Rate: 0.0125 (0.0125) Top1_base: 92.9688 (92.1412) Top1_base_per_class: 93.3654 (92.5725) 
Training Epoch: [227/1000] Step: [280 / 285] Batch Time: 0.1449 (0.1568) Data Time: 0.0116 (0.0234) Average Loss: 0.3505 (0.2906) Average CE Loss (Source):  0.3505 ( 0.2906) Learning Rate: 0.0125 (0.0125) Top1_base: 91.4062 (92.1373) Top1_base_per_class: 90.0298 (92.5609) 
Training Epoch: [228/1000] Step: [0] Batch Time: 0.2320 (0.1570) Data Time: 0.1009 (0.0236) Average Loss: 0.2277 (0.2901) Average CE Loss (Source):  0.2277 ( 0.2901) Learning Rate: 0.0125 (0.0125) Top1_base: 92.9688 (92.1436) Top1_base_per_class: 90.8485 (92.5647) 
 23%|██▎       | 228/1000 [2:56:56<10:02:36, 46.84s/it] 23%|██▎       | 229/1000 [2:57:42<9:57:56, 46.53s/it] Training Epoch: [228/1000] Step: [10 / 285] Batch Time: 0.1487 (0.2267) Data Time: 0.0149 (0.0941) Average Loss: 0.3985 (0.2990) Average CE Loss (Source):  0.3985 ( 0.2990) Learning Rate: 0.0125 (0.0125) Top1_base: 91.4062 (91.8750) Top1_base_per_class: 89.0880 (92.0402) 
Training Epoch: [228/1000] Step: [20 / 285] Batch Time: 0.1464 (0.1965) Data Time: 0.0145 (0.0632) Average Loss: 0.2646 (0.2988) Average CE Loss (Source):  0.2646 ( 0.2988) Learning Rate: 0.0125 (0.0125) Top1_base: 92.1875 (92.0703) Top1_base_per_class: 92.6488 (92.2513) 
Training Epoch: [228/1000] Step: [30 / 285] Batch Time: 0.1446 (0.1837) Data Time: 0.0117 (0.0507) Average Loss: 0.3067 (0.2855) Average CE Loss (Source):  0.3067 ( 0.2855) Learning Rate: 0.0125 (0.0125) Top1_base: 91.4062 (92.5260) Top1_base_per_class: 87.9012 (92.4411) 
Training Epoch: [228/1000] Step: [40 / 285] Batch Time: 0.1492 (0.1779) Data Time: 0.0160 (0.0447) Average Loss: 0.3635 (0.2870) Average CE Loss (Source):  0.3635 ( 0.2870) Learning Rate: 0.0125 (0.0125) Top1_base: 90.6250 (92.4414) Top1_base_per_class: 92.1751 (92.6657) 
Training Epoch: [228/1000] Step: [50 / 285] Batch Time: 0.1431 (0.1766) Data Time: 0.0119 (0.0435) Average Loss: 0.2775 (0.2819) Average CE Loss (Source):  0.2775 ( 0.2819) Learning Rate: 0.0125 (0.0125) Top1_base: 91.4062 (92.4688) Top1_base_per_class: 93.3951 (92.8239) 
Training Epoch: [228/1000] Step: [60 / 285] Batch Time: 0.1473 (0.1730) Data Time: 0.0136 (0.0400) Average Loss: 0.3825 (0.2815) Average CE Loss (Source):  0.3825 ( 0.2815) Learning Rate: 0.0125 (0.0125) Top1_base: 88.2812 (92.4609) Top1_base_per_class: 85.2976 (92.7559) 
Training Epoch: [228/1000] Step: [70 / 285] Batch Time: 0.1487 (0.1713) Data Time: 0.0134 (0.0381) Average Loss: 0.2281 (0.2771) Average CE Loss (Source):  0.2281 ( 0.2771) Learning Rate: 0.0125 (0.0125) Top1_base: 95.3125 (92.6451) Top1_base_per_class: 93.3962 (92.8150) 
Training Epoch: [228/1000] Step: [80 / 285] Batch Time: 0.1445 (0.1712) Data Time: 0.0116 (0.0379) Average Loss: 0.3861 (0.2828) Average CE Loss (Source):  0.3861 ( 0.2828) Learning Rate: 0.0125 (0.0125) Top1_base: 89.8438 (92.4512) Top1_base_per_class: 87.7966 (92.6692) 
Training Epoch: [228/1000] Step: [90 / 285] Batch Time: 0.1467 (0.1692) Data Time: 0.0118 (0.0359) Average Loss: 0.2716 (0.2895) Average CE Loss (Source):  0.2716 ( 0.2895) Learning Rate: 0.0125 (0.0125) Top1_base: 94.5312 (92.3003) Top1_base_per_class: 95.4630 (92.5481) 
Training Epoch: [228/1000] Step: [100 / 285] Batch Time: 0.1456 (0.1687) Data Time: 0.0121 (0.0355) Average Loss: 0.2060 (0.2868) Average CE Loss (Source):  0.2060 ( 0.2868) Learning Rate: 0.0125 (0.0125) Top1_base: 95.3125 (92.3672) Top1_base_per_class: 93.6364 (92.5769) 
Training Epoch: [228/1000] Step: [110 / 285] Batch Time: 0.1435 (0.1697) Data Time: 0.0106 (0.0365) Average Loss: 0.2625 (0.2863) Average CE Loss (Source):  0.2625 ( 0.2863) Learning Rate: 0.0125 (0.0125) Top1_base: 91.4062 (92.3651) Top1_base_per_class: 92.6901 (92.5262) 
Training Epoch: [228/1000] Step: [120 / 285] Batch Time: 0.1458 (0.1686) Data Time: 0.0133 (0.0355) Average Loss: 0.2651 (0.2863) Average CE Loss (Source):  0.2651 ( 0.2863) Learning Rate: 0.0125 (0.0125) Top1_base: 91.4062 (92.3633) Top1_base_per_class: 91.0802 (92.5597) 
Training Epoch: [228/1000] Step: [130 / 285] Batch Time: 0.1468 (0.1678) Data Time: 0.0107 (0.0347) Average Loss: 0.2311 (0.2836) Average CE Loss (Source):  0.2311 ( 0.2836) Learning Rate: 0.0125 (0.0125) Top1_base: 91.4062 (92.4159) Top1_base_per_class: 91.5319 (92.6332) 
Training Epoch: [228/1000] Step: [140 / 285] Batch Time: 0.1461 (0.1679) Data Time: 0.0126 (0.0347) Average Loss: 0.2301 (0.2830) Average CE Loss (Source):  0.2301 ( 0.2830) Learning Rate: 0.0125 (0.0125) Top1_base: 91.4062 (92.3828) Top1_base_per_class: 93.1034 (92.6478) 
Training Epoch: [228/1000] Step: [150 / 285] Batch Time: 0.1439 (0.1673) Data Time: 0.0102 (0.0341) Average Loss: 0.2264 (0.2834) Average CE Loss (Source):  0.2264 ( 0.2834) Learning Rate: 0.0125 (0.0125) Top1_base: 92.9688 (92.3750) Top1_base_per_class: 93.8788 (92.6256) 
Training Epoch: [228/1000] Step: [160 / 285] Batch Time: 0.1431 (0.1669) Data Time: 0.0112 (0.0338) Average Loss: 0.3354 (0.2853) Average CE Loss (Source):  0.3354 ( 0.2853) Learning Rate: 0.0125 (0.0125) Top1_base: 92.1875 (92.3438) Top1_base_per_class: 92.5472 (92.6316) 
Training Epoch: [228/1000] Step: [170 / 285] Batch Time: 0.1461 (0.1662) Data Time: 0.0107 (0.0331) Average Loss: 0.3386 (0.2856) Average CE Loss (Source):  0.3386 ( 0.2856) Learning Rate: 0.0125 (0.0125) Top1_base: 90.6250 (92.3438) Top1_base_per_class: 91.1859 (92.6187) 
Training Epoch: [228/1000] Step: [180 / 285] Batch Time: 0.1442 (0.1653) Data Time: 0.0118 (0.0322) Average Loss: 0.2210 (0.2850) Average CE Loss (Source):  0.2210 ( 0.2850) Learning Rate: 0.0125 (0.0125) Top1_base: 92.1875 (92.3568) Top1_base_per_class: 92.2414 (92.6492) 
Training Epoch: [228/1000] Step: [190 / 285] Batch Time: 0.1423 (0.1647) Data Time: 0.0112 (0.0316) Average Loss: 0.1748 (0.2845) Average CE Loss (Source):  0.1748 ( 0.2845) Learning Rate: 0.0125 (0.0125) Top1_base: 96.0938 (92.3520) Top1_base_per_class: 96.8182 (92.6410) 
Training Epoch: [228/1000] Step: [200 / 285] Batch Time: 0.1475 (0.1641) Data Time: 0.0153 (0.0309) Average Loss: 0.3071 (0.2841) Average CE Loss (Source):  0.3071 ( 0.2841) Learning Rate: 0.0125 (0.0125) Top1_base: 90.6250 (92.3711) Top1_base_per_class: 91.4151 (92.6278) 
Training Epoch: [228/1000] Step: [210 / 285] Batch Time: 0.1446 (0.1634) Data Time: 0.0109 (0.0303) Average Loss: 0.3570 (0.2865) Average CE Loss (Source):  0.3570 ( 0.2865) Learning Rate: 0.0125 (0.0125) Top1_base: 91.4062 (92.3177) Top1_base_per_class: 93.5211 (92.5914) 
Training Epoch: [228/1000] Step: [220 / 285] Batch Time: 0.1460 (0.1629) Data Time: 0.0150 (0.0297) Average Loss: 0.3413 (0.2858) Average CE Loss (Source):  0.3413 ( 0.2858) Learning Rate: 0.0125 (0.0125) Top1_base: 92.9688 (92.3651) Top1_base_per_class: 93.4211 (92.6445) 
Training Epoch: [228/1000] Step: [230 / 285] Batch Time: 0.1467 (0.1624) Data Time: 0.0112 (0.0292) Average Loss: 0.2421 (0.2860) Average CE Loss (Source):  0.2421 ( 0.2860) Learning Rate: 0.0125 (0.0125) Top1_base: 95.3125 (92.3709) Top1_base_per_class: 95.1170 (92.6229) 
Training Epoch: [228/1000] Step: [240 / 285] Batch Time: 0.1480 (0.1622) Data Time: 0.0162 (0.0290) Average Loss: 0.2534 (0.2867) Average CE Loss (Source):  0.2534 ( 0.2867) Learning Rate: 0.0125 (0.0125) Top1_base: 92.9688 (92.3698) Top1_base_per_class: 93.9286 (92.6408) 
Training Epoch: [228/1000] Step: [250 / 285] Batch Time: 0.1418 (0.1619) Data Time: 0.0120 (0.0288) Average Loss: 0.2170 (0.2876) Average CE Loss (Source):  0.2170 ( 0.2876) Learning Rate: 0.0125 (0.0125) Top1_base: 94.5312 (92.3219) Top1_base_per_class: 95.1786 (92.6028) 
Training Epoch: [228/1000] Step: [260 / 285] Batch Time: 0.1456 (0.1614) Data Time: 0.0134 (0.0283) Average Loss: 0.2947 (0.2884) Average CE Loss (Source):  0.2947 ( 0.2884) Learning Rate: 0.0125 (0.0125) Top1_base: 93.7500 (92.3077) Top1_base_per_class: 94.2284 (92.5981) 
Training Epoch: [228/1000] Step: [270 / 285] Batch Time: 0.1490 (0.1611) Data Time: 0.0107 (0.0279) Average Loss: 0.3273 (0.2886) Average CE Loss (Source):  0.3273 ( 0.2886) Learning Rate: 0.0125 (0.0125) Top1_base: 91.4062 (92.2685) Top1_base_per_class: 90.8772 (92.5631) 
Training Epoch: [228/1000] Step: [280 / 285] Batch Time: 0.1413 (0.1608) Data Time: 0.0097 (0.0277) Average Loss: 0.2974 (0.2890) Average CE Loss (Source):  0.2974 ( 0.2890) Learning Rate: 0.0125 (0.0125) Top1_base: 92.1875 (92.2740) Top1_base_per_class: 93.6404 (92.5892) 
Training Epoch: [229/1000] Step: [0] Batch Time: 0.1426 (0.1605) Data Time: 0.0126 (0.0274) Average Loss: 0.2536 (0.2880) Average CE Loss (Source):  0.2536 ( 0.2880) Learning Rate: 0.0125 (0.0125) Top1_base: 92.9688 (92.2971) Top1_base_per_class: 94.0881 (92.6192) 
slurmstepd: error: *** JOB 25537507 ON blg9509 CANCELLED AT 2021-09-24T13:35:40 ***
